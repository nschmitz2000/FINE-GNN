nohup: ignoring input
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:2859: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  metadata = torch.load(load_path_metadata)
/home/nschmitz/.pyenv/versions/3.12.9/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
‚úÖ Using device: cuda:2
/home/nschmitz/GNNs/kirigami-database/data/cleaned
Model without constraints:  False
üíø Folder that model data gets saved into:  18__constraints_deg_asc__
Metrics---
Amount unfoldings:  3000
Max files per dir:  50
Batch size:  1
Num prop rounds:  2
Learning rate:  6e-05
Num epochs:  50
Accum steps:  4
Training node ordering strategy:  NodeOrder.DEG_ASC
Add edge is deterministic:  True
Add edge is deterministic threshold:  0.5
Calc PR-Curve:  False
---------------
6_7_8_9_10
Found existing dataset files; skipping save.
Loading dataset from disk‚Ä¶
6_7_8_9_10
Max amount of features per node in a graph:  128
Loaded 46571 graphs with actions!
Train size: 32599, Validation size: 6985, Test size: 6987
Graph(num_nodes=10, num_edges=18,
      ndata_schemes={'a': Scheme(shape=(256,), dtype=torch.float32), 'hv': Scheme(shape=(128,), dtype=torch.float32), 'deg_rem': Scheme(shape=(1,), dtype=torch.int16), 'deg_target': Scheme(shape=(1,), dtype=torch.int16)}
      edata_schemes={'he': Scheme(shape=(1,), dtype=torch.float32)})
[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 0. 0. 0. 1.]
 [0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]
 [1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]
--------
Graph(num_nodes=10, num_edges=32,
      ndata_schemes={'deg_target': Scheme(shape=(1,), dtype=torch.int16), 'hv': Scheme(shape=(128,), dtype=torch.float32)}
      edata_schemes={})
[[0. 0. 0. 1. 1. 1. 1. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 0. 0. 1. 1.]
 [0. 1. 0. 1. 0. 0. 0. 1. 0. 0.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]
 [1. 0. 0. 1. 0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 1. 1. 0.]]
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_ASC
Device for model: cuda:2
Dir_name to save to:  6_7_8_9_10
Training started at: 2025-07-14 11:32:57
grad AddEdge W: 249.23342895507812
grad ChooseDest W: 3.441194534301758
grad AddEdge W: 30.87007713317871
grad ChooseDest W: 2.219550848007202
grad AddEdge W: 24.876747131347656
grad ChooseDest W: 2.006930351257324
grad AddEdge W: 11.67915153503418
grad ChooseDest W: 2.3687520027160645
grad AddEdge W: 7.367797374725342
grad ChooseDest W: 3.9474332332611084
grad AddEdge W: 4.631183624267578
grad ChooseDest W: 3.1886839866638184
grad AddEdge W: 2.372772693634033
grad ChooseDest W: 2.5830094814300537
grad AddEdge W: 2.2470498085021973
grad ChooseDest W: 3.3761777877807617
grad AddEdge W: 1.4534498453140259
grad ChooseDest W: 2.512917995452881
grad AddEdge W: 0.9740258455276489
grad ChooseDest W: 3.870842695236206
grad AddEdge W: 1.190232276916504
grad ChooseDest W: 5.787909030914307
grad AddEdge W: 0.7268602848052979
grad ChooseDest W: 4.283210754394531
grad AddEdge W: 0.7125332951545715
grad ChooseDest W: 6.492952346801758
grad AddEdge W: 0.5516542196273804
grad ChooseDest W: 4.798597812652588
grad AddEdge W: 1.4838085174560547
grad ChooseDest W: 1.8420863151550293
grad AddEdge W: 0.3632085919380188
grad ChooseDest W: 5.25689697265625
grad AddEdge W: 0.35278794169425964
grad ChooseDest W: 2.0360915660858154
grad AddEdge W: 0.21629315614700317
grad ChooseDest W: 2.9172282218933105
grad AddEdge W: 0.7930985689163208
grad ChooseDest W: 2.0492687225341797
grad AddEdge W: 0.22323566675186157
grad ChooseDest W: 2.786412477493286
grad AddEdge W: 0.16070418059825897
grad ChooseDest W: 1.9938592910766602
grad AddEdge W: 0.19669149816036224
grad ChooseDest W: 3.067685604095459
grad AddEdge W: 0.15481159090995789
grad ChooseDest W: 5.7938551902771
grad AddEdge W: 0.23062095046043396
grad ChooseDest W: 6.2687087059021
grad AddEdge W: 0.11308974027633667
grad ChooseDest W: 2.740471601486206
grad AddEdge W: 0.228445366024971
grad ChooseDest W: 2.350836753845215
grad AddEdge W: 0.07648980617523193
grad ChooseDest W: 4.756637096405029
grad AddEdge W: 0.07914973795413971
grad ChooseDest W: 2.4311349391937256
grad AddEdge W: 0.12142278254032135
grad ChooseDest W: 3.296654462814331
grad AddEdge W: 0.10524718463420868
grad ChooseDest W: 3.7811574935913086
grad AddEdge W: 0.520281970500946
grad ChooseDest W: 1.0131371021270752
grad AddEdge W: 0.1380831003189087
grad ChooseDest W: 2.1986300945281982
grad AddEdge W: 0.04553113132715225
grad ChooseDest W: 2.115215539932251
grad AddEdge W: 0.04188723862171173
grad ChooseDest W: 3.5519275665283203
grad AddEdge W: 0.04522606357932091
grad ChooseDest W: 4.660989761352539
grad AddEdge W: 0.031199106946587563
grad ChooseDest W: 4.379221439361572
grad AddEdge W: 0.08292423188686371
grad ChooseDest W: 6.398752212524414
grad AddEdge W: 0.06829480826854706
grad ChooseDest W: 3.04412841796875
grad AddEdge W: 0.03074389137327671
grad ChooseDest W: 5.5945963859558105
grad AddEdge W: 0.04275977984070778
grad ChooseDest W: 1.8783798217773438
grad AddEdge W: 0.025547899305820465
grad ChooseDest W: 4.024099349975586
grad AddEdge W: 0.03716791048645973
grad ChooseDest W: 3.609431743621826
grad AddEdge W: 0.02035812847316265
grad ChooseDest W: 3.460841655731201
grad AddEdge W: 0.03920925408601761
grad ChooseDest W: 3.478095769882202
grad AddEdge W: 0.027522314339876175
grad ChooseDest W: 1.978480339050293
grad AddEdge W: 0.019993120804429054
grad ChooseDest W: 3.285754442214966
grad AddEdge W: 0.02277863584458828
grad ChooseDest W: 3.3632185459136963
grad AddEdge W: 0.04103991016745567
grad ChooseDest W: 3.4863061904907227
grad AddEdge W: 0.03350609913468361
grad ChooseDest W: 2.7299716472625732
grad AddEdge W: 0.011672087013721466
grad ChooseDest W: 2.950917959213257
grad AddEdge W: 0.010181503370404243
grad ChooseDest W: 2.7929413318634033
grad AddEdge W: 0.010968205519020557
grad ChooseDest W: 3.333198308944702
grad AddEdge W: 0.06011900305747986
grad ChooseDest W: 2.134695529937744
grad AddEdge W: 0.01931951195001602
grad ChooseDest W: 4.222910404205322
grad AddEdge W: 0.015288653783500195
grad ChooseDest W: 2.4286320209503174
grad AddEdge W: 0.012281350791454315
grad ChooseDest W: 5.000807285308838
grad AddEdge W: 0.016518596559762955
grad ChooseDest W: 2.8004062175750732
grad AddEdge W: 0.007388689089566469
grad ChooseDest W: 4.80677604675293
grad AddEdge W: 0.013222315348684788
grad ChooseDest W: 2.9294092655181885
grad AddEdge W: 0.006397925317287445
grad ChooseDest W: 4.295025825500488
grad AddEdge W: 0.009474892169237137
grad ChooseDest W: 2.571110963821411
grad AddEdge W: 0.00584435136988759
grad ChooseDest W: 2.7927768230438232
grad AddEdge W: 0.005600190721452236
grad ChooseDest W: 2.7776119709014893
grad AddEdge W: 0.004399971105158329
grad ChooseDest W: 4.91472864151001
grad AddEdge W: 0.008198229596018791
grad ChooseDest W: 5.931224346160889
grad AddEdge W: 0.019541816785931587
grad ChooseDest W: 2.6249752044677734
=== Epoch 1: Train Loss: 6.6162, Train Log Prob: 0.0036 ===
Total mismatches: 96199
Predicted valid destination but wrong order: 5677
Epoch 1: Validation Loss: 6.1943, Validation Log Prob: 0.0035
Epoch 1: Edge Precision: 0.3609, Recall: 0.3593, F1: 0.3600, Jaccard: 0.2374
Epoch 1: TP: 2.5152469577666428, FP: 4.476879026485325, FN: 4.506227630637079
Epoch 1: warmup, skipping learning rate scheduler
Epoch 1: Current Learning Rate: 6e-05
[Epoch 1] ‚è±Ô∏è Total: 3430.08s | Current time: 2025-07-14 12:30:07 | üèãÔ∏è Train: 2928.47s | ‚úÖ Val: 501.62s
grad AddEdge W: 0.017305312678217888
grad ChooseDest W: 9.993663787841797
grad AddEdge W: 0.007659205701202154
grad ChooseDest W: 2.5336544513702393
grad AddEdge W: 0.005969365127384663
grad ChooseDest W: 2.243385076522827
grad AddEdge W: 0.008159327320754528
grad ChooseDest W: 4.547419548034668
grad AddEdge W: 0.002608388662338257
grad ChooseDest W: 4.697292327880859
grad AddEdge W: 0.006992453709244728
grad ChooseDest W: 2.7373414039611816
grad AddEdge W: 0.002760485280305147
grad ChooseDest W: 3.1516530513763428
grad AddEdge W: 0.012272926047444344
grad ChooseDest W: 2.0200586318969727
grad AddEdge W: 0.0044364905916154385
grad ChooseDest W: 2.992835760116577
grad AddEdge W: 0.002819998888298869
grad ChooseDest W: 4.680722236633301
grad AddEdge W: 0.0033805202692747116
grad ChooseDest W: 3.6658108234405518
grad AddEdge W: 0.004625113680958748
grad ChooseDest W: 5.2900614738464355
grad AddEdge W: 0.0015592878917232156
grad ChooseDest W: 3.7104012966156006
grad AddEdge W: 0.003550552297383547
grad ChooseDest W: 3.6281075477600098
grad AddEdge W: 0.0006019985885359347
grad ChooseDest W: 2.0990257263183594
grad AddEdge W: 0.002529716119170189
grad ChooseDest W: 3.9457240104675293
grad AddEdge W: 0.0014264053897932172
grad ChooseDest W: 1.5713770389556885
grad AddEdge W: 0.004065262619405985
grad ChooseDest W: 3.28232741355896
grad AddEdge W: 0.0026111635379493237
grad ChooseDest W: 2.820599317550659
grad AddEdge W: 0.00217875256203115
grad ChooseDest W: 2.2749879360198975
grad AddEdge W: 0.0016166603891178966
grad ChooseDest W: 1.929893970489502
grad AddEdge W: 0.0026413898449391127
grad ChooseDest W: 2.9468541145324707
grad AddEdge W: 0.0014901092508807778
grad ChooseDest W: 3.477142810821533
grad AddEdge W: 0.0004337135760579258
grad ChooseDest W: 2.5535550117492676
grad AddEdge W: 0.0005355637986212969
grad ChooseDest W: 3.57401442527771
grad AddEdge W: 0.0006392861832864583
grad ChooseDest W: 3.3679630756378174
grad AddEdge W: 0.0016238460084423423
grad ChooseDest W: 2.0648386478424072
grad AddEdge W: 0.00042886557639576495
grad ChooseDest W: 3.402467727661133
grad AddEdge W: 0.003867299063131213
grad ChooseDest W: 3.4454965591430664
grad AddEdge W: 0.00023821566719561815
grad ChooseDest W: 3.9759013652801514
grad AddEdge W: 0.013191351667046547
grad ChooseDest W: 2.277834415435791
grad AddEdge W: 0.0012543355114758015
grad ChooseDest W: 3.1778392791748047
grad AddEdge W: 0.0006145433289930224
grad ChooseDest W: 2.9578731060028076
grad AddEdge W: 0.00024025986203923821
grad ChooseDest W: 2.1863272190093994
grad AddEdge W: 0.0003772878844756633
grad ChooseDest W: 2.872629165649414
grad AddEdge W: 0.00024995466810651124
grad ChooseDest W: 3.064164876937866
grad AddEdge W: 0.0011406616540625691
grad ChooseDest W: 2.398695468902588
grad AddEdge W: 0.00031779316486790776
grad ChooseDest W: 2.7184948921203613
grad AddEdge W: 0.00021010838099755347
grad ChooseDest W: 4.194186687469482
grad AddEdge W: 0.00020695856073871255
grad ChooseDest W: 1.8047916889190674
grad AddEdge W: 0.00030015630181878805
grad ChooseDest W: 3.7281405925750732
grad AddEdge W: 0.0006003923481330276
grad ChooseDest W: 1.3506453037261963
grad AddEdge W: 0.0001264263119082898
grad ChooseDest W: 2.423201560974121
grad AddEdge W: 0.0014948942698538303
grad ChooseDest W: 1.030494213104248
grad AddEdge W: 0.0001187463931273669
grad ChooseDest W: 3.7233359813690186
grad AddEdge W: 0.00034844232141040266
grad ChooseDest W: 2.7685065269470215
grad AddEdge W: 0.00010442369966767728
grad ChooseDest W: 2.726973533630371
grad AddEdge W: 0.0006990525289438665
grad ChooseDest W: 3.5831727981567383
grad AddEdge W: 0.0003054741828236729
grad ChooseDest W: 4.589478492736816
grad AddEdge W: 8.598561544204131e-05
grad ChooseDest W: 3.515239953994751
grad AddEdge W: 8.723601058591157e-05
grad ChooseDest W: 2.629011631011963
grad AddEdge W: 0.00013217248488217592
grad ChooseDest W: 4.04366397857666
grad AddEdge W: 6.624375964747742e-05
grad ChooseDest W: 3.9903173446655273
grad AddEdge W: 6.378655234584585e-05
grad ChooseDest W: 2.6192069053649902
grad AddEdge W: 7.114256004570052e-05
grad ChooseDest W: 2.719557046890259
grad AddEdge W: 0.00029455305775627494
grad ChooseDest W: 4.047111988067627
grad AddEdge W: 0.00021690056018996984
grad ChooseDest W: 3.4284470081329346
grad AddEdge W: 6.151461275294423e-05
grad ChooseDest W: 3.586055040359497
grad AddEdge W: 5.9057689213659614e-05
grad ChooseDest W: 2.723073959350586
grad AddEdge W: 0.00024165389186237007
grad ChooseDest W: 2.7289140224456787
grad AddEdge W: 0.00015995118883438408
grad ChooseDest W: 2.5133466720581055
grad AddEdge W: 0.00011280334729235619
grad ChooseDest W: 1.4871172904968262
grad AddEdge W: 0.0001218144316226244
grad ChooseDest W: 1.812820315361023
grad AddEdge W: 3.792290954152122e-05
grad ChooseDest W: 3.300570011138916
grad AddEdge W: 0.0001610232429811731
grad ChooseDest W: 3.1496810913085938
grad AddEdge W: 3.66856693290174e-05
grad ChooseDest W: 3.3819055557250977
=== Epoch 2: Train Loss: 6.1911, Train Log Prob: 0.0050 ===
Total mismatches: 90567
Predicted valid destination but wrong order: 5639
Epoch 2: Validation Loss: 5.6439, Validation Log Prob: 0.0058
Epoch 2: Edge Precision: 0.3649, Recall: 0.3643, F1: 0.3646, Jaccard: 0.2405
Epoch 2: TP: 2.5496062992125985, FP: 4.46184681460272, FN: 4.471868289191124
Epoch 2: warmup, skipping learning rate scheduler
Epoch 2: Current Learning Rate: 6e-05
[Epoch 2] ‚è±Ô∏è Total: 3467.70s | Current time: 2025-07-14 13:27:55 | üèãÔ∏è Train: 2961.05s | ‚úÖ Val: 506.64s
grad AddEdge W: 0.0017474693013355136
grad ChooseDest W: 4.572636127471924
grad AddEdge W: 7.425947114825249e-05
grad ChooseDest W: 2.8984389305114746
grad AddEdge W: 0.0015823441790416837
grad ChooseDest W: 2.8042516708374023
grad AddEdge W: 4.111125963390805e-05
grad ChooseDest W: 3.85766863822937
grad AddEdge W: 0.00014731838018633425
grad ChooseDest W: 2.31891131401062
grad AddEdge W: 2.9840552087989636e-05
grad ChooseDest W: 3.0996272563934326
grad AddEdge W: 1.5442930816789158e-05
grad ChooseDest W: 3.86179518699646
grad AddEdge W: 2.6522609914536588e-05
grad ChooseDest W: 3.0984067916870117
grad AddEdge W: 6.570581899723038e-05
grad ChooseDest W: 3.9496448040008545
grad AddEdge W: 2.2790845832787454e-05
grad ChooseDest W: 4.226119041442871
grad AddEdge W: 2.363329622312449e-05
grad ChooseDest W: 2.379599094390869
grad AddEdge W: 9.674102329881862e-06
grad ChooseDest W: 3.7680697441101074
grad AddEdge W: 5.233223782852292e-05
grad ChooseDest W: 3.1268603801727295
grad AddEdge W: 6.134899012977257e-05
grad ChooseDest W: 1.7439970970153809
grad AddEdge W: 3.5209588531870395e-05
grad ChooseDest W: 2.2887725830078125
grad AddEdge W: 6.84682818246074e-05
grad ChooseDest W: 3.434391975402832
grad AddEdge W: 8.27380790724419e-06
grad ChooseDest W: 4.153401851654053
grad AddEdge W: 3.804039442911744e-05
grad ChooseDest W: 3.3248651027679443
grad AddEdge W: 5.4877286856935825e-06
grad ChooseDest W: 1.8878633975982666
grad AddEdge W: 2.6137100576306693e-05
grad ChooseDest W: 2.4650564193725586
grad AddEdge W: 2.079941623378545e-05
grad ChooseDest W: 1.775931477546692
grad AddEdge W: 5.75951980863465e-06
grad ChooseDest W: 3.5411694049835205
grad AddEdge W: 1.1008389265043661e-05
grad ChooseDest W: 2.701892137527466
grad AddEdge W: 3.6677890875580488e-06
grad ChooseDest W: 2.4939675331115723
grad AddEdge W: 3.535083305905573e-05
grad ChooseDest W: 3.295167922973633
grad AddEdge W: 3.541845580912195e-05
grad ChooseDest W: 3.5940101146698
grad AddEdge W: 8.114961929095443e-06
grad ChooseDest W: 2.5086052417755127
grad AddEdge W: 4.258240551280323e-06
grad ChooseDest W: 2.389108896255493
grad AddEdge W: 1.2504387086664792e-05
grad ChooseDest W: 2.617931365966797
grad AddEdge W: 2.3049121864460176e-06
grad ChooseDest W: 4.409437656402588
grad AddEdge W: 2.4951082195912022e-06
grad ChooseDest W: 1.8158475160598755
grad AddEdge W: 1.0460382782184752e-06
grad ChooseDest W: 1.9146950244903564
grad AddEdge W: 9.576752745488193e-06
grad ChooseDest W: 3.2817540168762207
grad AddEdge W: 3.1767085602041334e-05
grad ChooseDest W: 2.883204221725464
grad AddEdge W: 8.857498414727161e-07
grad ChooseDest W: 3.502711296081543
grad AddEdge W: 6.369871243805392e-07
grad ChooseDest W: 3.566600799560547
grad AddEdge W: 1.4298570022219792e-05
grad ChooseDest W: 2.6233716011047363
grad AddEdge W: 1.9457040707493434e-06
grad ChooseDest W: 4.83967924118042
grad AddEdge W: 6.479855869656603e-07
grad ChooseDest W: 1.4100710153579712
grad AddEdge W: 2.3907652575871907e-05
grad ChooseDest W: 2.9807379245758057
grad AddEdge W: 1.6487653056174167e-06
grad ChooseDest W: 2.79750657081604
grad AddEdge W: 1.6605895325483289e-06
grad ChooseDest W: 1.5826687812805176
grad AddEdge W: 5.813804477838858e-07
grad ChooseDest W: 6.417384624481201
grad AddEdge W: 5.445828264782904e-06
grad ChooseDest W: 2.9589269161224365
grad AddEdge W: 7.478058250853792e-06
grad ChooseDest W: 2.410304546356201
grad AddEdge W: 3.4957765819854103e-06
grad ChooseDest W: 2.906846284866333
grad AddEdge W: 5.636283276544418e-06
grad ChooseDest W: 3.5816595554351807
grad AddEdge W: 7.658379104213964e-07
grad ChooseDest W: 2.9631528854370117
grad AddEdge W: 2.521191618143348e-06
grad ChooseDest W: 3.2478232383728027
grad AddEdge W: 1.1810453770522145e-06
grad ChooseDest W: 3.310044050216675
grad AddEdge W: 4.0890105879043404e-07
grad ChooseDest W: 3.7907755374908447
grad AddEdge W: 1.4683706694995635e-06
grad ChooseDest W: 3.6318559646606445
grad AddEdge W: 2.482471018083743e-06
grad ChooseDest W: 2.3692541122436523
grad AddEdge W: 4.496325800573686e-07
grad ChooseDest W: 3.881350517272949
grad AddEdge W: 6.4562505031062756e-06
grad ChooseDest W: 2.467416524887085
grad AddEdge W: 1.9511973903263424e-07
grad ChooseDest W: 2.904398202896118
grad AddEdge W: 8.420904578088084e-07
grad ChooseDest W: 2.7359044551849365
grad AddEdge W: 7.371299943770282e-07
grad ChooseDest W: 2.4772799015045166
grad AddEdge W: 9.876104911654693e-08
grad ChooseDest W: 2.5409817695617676
grad AddEdge W: 6.439393018808914e-08
grad ChooseDest W: 1.3109676837921143
grad AddEdge W: 9.113725809584139e-07
grad ChooseDest W: 2.4639523029327393
grad AddEdge W: 7.362273208855186e-06
grad ChooseDest W: 2.074819326400757
grad AddEdge W: 1.9089993941179273e-07
grad ChooseDest W: 2.9351253509521484
grad AddEdge W: 7.335594887081243e-07
grad ChooseDest W: 2.0173540115356445
grad AddEdge W: 4.494294216783601e-07
grad ChooseDest W: 1.97052800655365
grad AddEdge W: 2.2379914810244372e-07
grad ChooseDest W: 3.1113181114196777
=== Epoch 3: Train Loss: 6.0849, Train Log Prob: 0.0059 ===
Total mismatches: 88874
Predicted valid destination but wrong order: 5512
Epoch 3: Validation Loss: 5.2895, Validation Log Prob: 0.0082
Epoch 3: Edge Precision: 0.3693, Recall: 0.3687, F1: 0.3689, Jaccard: 0.2447
Epoch 3: TP: 2.5802433786685754, FP: 4.429921259842519, FN: 4.441231209735147
Epoch 3: warmup, skipping learning rate scheduler
Epoch 3: Current Learning Rate: 6e-05
[Epoch 3] ‚è±Ô∏è Total: 3473.51s | Current time: 2025-07-14 14:25:49 | üèãÔ∏è Train: 2965.65s | ‚úÖ Val: 507.86s
grad AddEdge W: 1.3032833976467373e-06
grad ChooseDest W: 5.73246431350708
grad AddEdge W: 6.054243385733571e-06
grad ChooseDest W: 3.0348732471466064
grad AddEdge W: 4.796536359208403e-07
grad ChooseDest W: 3.062530755996704
grad AddEdge W: 1.1005803344232845e-06
grad ChooseDest W: 2.626730442047119
grad AddEdge W: 2.0270218215046043e-07
grad ChooseDest W: 2.147193431854248
grad AddEdge W: 4.35852349767174e-08
grad ChooseDest W: 2.397555351257324
grad AddEdge W: 7.082750386189218e-08
grad ChooseDest W: 4.594900608062744
grad AddEdge W: 4.475383263979893e-07
grad ChooseDest W: 3.186579465866089
grad AddEdge W: 9.945416223899883e-08
grad ChooseDest W: 2.812138795852661
grad AddEdge W: 1.8794233724861442e-08
grad ChooseDest W: 3.0781760215759277
grad AddEdge W: 2.421417093501077e-07
grad ChooseDest W: 1.5474618673324585
grad AddEdge W: 3.757796207537467e-08
grad ChooseDest W: 3.7657642364501953
grad AddEdge W: 3.0965459529852524e-08
grad ChooseDest W: 2.910588502883911
grad AddEdge W: 4.74554724405607e-08
grad ChooseDest W: 3.3153269290924072
grad AddEdge W: 1.0960982308461098e-06
grad ChooseDest W: 3.491894006729126
grad AddEdge W: 2.1475383960023464e-07
grad ChooseDest W: 2.6917169094085693
grad AddEdge W: 4.641553275064325e-08
grad ChooseDest W: 3.8888823986053467
grad AddEdge W: 3.5667540032591205e-08
grad ChooseDest W: 2.9937682151794434
grad AddEdge W: 4.255909686889936e-07
grad ChooseDest W: 3.6432156562805176
grad AddEdge W: 1.3913665497966576e-05
grad ChooseDest W: 2.4272897243499756
grad AddEdge W: 1.291583231477489e-07
grad ChooseDest W: 3.4593498706817627
grad AddEdge W: 2.0395215472035488e-07
grad ChooseDest W: 2.3257641792297363
grad AddEdge W: 1.7625075088290032e-07
grad ChooseDest W: 3.132847547531128
grad AddEdge W: 1.665884497015213e-07
grad ChooseDest W: 1.900542140007019
grad AddEdge W: 7.261074408404511e-09
grad ChooseDest W: 3.9512462615966797
grad AddEdge W: 6.741450953029471e-09
grad ChooseDest W: 1.563833236694336
grad AddEdge W: 1.0334217392937717e-07
grad ChooseDest W: 2.7018535137176514
grad AddEdge W: 8.015369701297459e-08
grad ChooseDest W: 3.6796181201934814
grad AddEdge W: 1.3834601020334958e-08
grad ChooseDest W: 2.339054822921753
grad AddEdge W: 6.06601489039349e-08
grad ChooseDest W: 2.7600369453430176
grad AddEdge W: 4.4300865198465544e-09
grad ChooseDest W: 1.9534417390823364
grad AddEdge W: 1.2954585848490296e-08
grad ChooseDest W: 2.5528042316436768
grad AddEdge W: 6.565709309569456e-09
grad ChooseDest W: 2.908435583114624
grad AddEdge W: 1.8609753738019208e-09
grad ChooseDest W: 2.8702504634857178
grad AddEdge W: 3.61475227528274e-09
grad ChooseDest W: 2.442751169204712
grad AddEdge W: 8.887808711222078e-09
grad ChooseDest W: 2.692697048187256
grad AddEdge W: 3.724336616883761e-09
grad ChooseDest W: 2.910257577896118
grad AddEdge W: 2.4533980180763137e-08
grad ChooseDest W: 2.934750556945801
grad AddEdge W: 5.791857304870973e-08
grad ChooseDest W: 2.6596474647521973
grad AddEdge W: 3.759431432825977e-09
grad ChooseDest W: 2.4208993911743164
grad AddEdge W: 6.0628697617914895e-09
grad ChooseDest W: 2.522294759750366
grad AddEdge W: 7.3873502870469565e-09
grad ChooseDest W: 1.8538434505462646
grad AddEdge W: 3.068445275644649e-09
grad ChooseDest W: 2.845810651779175
grad AddEdge W: 4.625415161996216e-09
grad ChooseDest W: 2.7091853618621826
grad AddEdge W: 2.1070007960588555e-09
grad ChooseDest W: 3.65811824798584
grad AddEdge W: 1.1572392821790345e-08
grad ChooseDest W: 4.149909496307373
grad AddEdge W: 4.990253099634856e-09
grad ChooseDest W: 2.530599355697632
grad AddEdge W: 1.3716658919804559e-09
grad ChooseDest W: 3.9871318340301514
grad AddEdge W: 3.825211702945808e-09
grad ChooseDest W: 3.5834908485412598
grad AddEdge W: 6.33488328460885e-09
grad ChooseDest W: 2.284695625305176
grad AddEdge W: 3.783883428809531e-08
grad ChooseDest W: 2.7563202381134033
grad AddEdge W: 1.7207959501774894e-09
grad ChooseDest W: 6.0024237632751465
grad AddEdge W: 2.3788577774297437e-09
grad ChooseDest W: 2.9811861515045166
grad AddEdge W: 1.644273717182898e-09
grad ChooseDest W: 4.200499534606934
grad AddEdge W: 1.5883436788044492e-09
grad ChooseDest W: 2.266705274581909
grad AddEdge W: 6.68040955886795e-10
grad ChooseDest W: 4.604611396789551
grad AddEdge W: 1.1840534108742418e-09
grad ChooseDest W: 2.0605506896972656
grad AddEdge W: 4.563820710234978e-10
grad ChooseDest W: 2.074775218963623
grad AddEdge W: 8.246624494390176e-10
grad ChooseDest W: 2.6005401611328125
grad AddEdge W: 1.0976241027194078e-09
grad ChooseDest W: 1.7338144779205322
grad AddEdge W: 7.684047886868939e-08
grad ChooseDest W: 3.456073760986328
grad AddEdge W: 2.1044157527683183e-09
grad ChooseDest W: 2.546813488006592
grad AddEdge W: 2.9459473749327003e-10
grad ChooseDest W: 3.3072726726531982
grad AddEdge W: 8.606381385334316e-09
grad ChooseDest W: 3.1960337162017822
grad AddEdge W: 1.2598057042012556e-09
grad ChooseDest W: 2.330641031265259
grad AddEdge W: 2.8700000598291808e-08
grad ChooseDest W: 2.5780014991760254
=== Epoch 4: Train Loss: 6.0485, Train Log Prob: 0.0063 ===
Total mismatches: 88235
Predicted valid destination but wrong order: 5472
Epoch 4: Validation Loss: 5.1955, Validation Log Prob: 0.0090
Epoch 4: Edge Precision: 0.3681, Recall: 0.3673, F1: 0.3677, Jaccard: 0.2435
Epoch 4: TP: 2.5710808876163207, FP: 4.435647816750179, FN: 4.4503937007874015
Epoch 4: warmup, skipping learning rate scheduler
Epoch 4: Current Learning Rate: 6e-05
[Epoch 4] ‚è±Ô∏è Total: 3450.33s | Current time: 2025-07-14 15:23:19 | üèãÔ∏è Train: 2942.17s | ‚úÖ Val: 508.15s
grad AddEdge W: 7.940071711232122e-09
grad ChooseDest W: 3.932169198989868
grad AddEdge W: 3.075215360137662e-10
grad ChooseDest W: 3.4393863677978516
grad AddEdge W: 1.9517855776030046e-08
grad ChooseDest W: 3.4957547187805176
grad AddEdge W: 6.084575510101331e-09
grad ChooseDest W: 2.682750940322876
grad AddEdge W: 4.4492109996241425e-10
grad ChooseDest W: 3.0246729850769043
grad AddEdge W: 1.7654600004135546e-10
grad ChooseDest W: 3.164889097213745
grad AddEdge W: 7.565024162659029e-09
grad ChooseDest W: 2.6557273864746094
grad AddEdge W: 2.6730756275128442e-08
grad ChooseDest W: 2.9149348735809326
grad AddEdge W: 2.400922793910354e-10
grad ChooseDest W: 4.080845355987549
grad AddEdge W: 5.285604592897286e-11
grad ChooseDest W: 2.7701711654663086
grad AddEdge W: 7.29346472105874e-10
grad ChooseDest W: 2.5628299713134766
grad AddEdge W: 3.182570873505597e-10
grad ChooseDest W: 2.1659646034240723
grad AddEdge W: 1.327218446256495e-09
grad ChooseDest W: 2.14666485786438
grad AddEdge W: 9.840851050713084e-11
grad ChooseDest W: 3.2558696269989014
grad AddEdge W: 2.0178712034635282e-09
grad ChooseDest W: 3.2298309803009033
grad AddEdge W: 6.80966255606208e-11
grad ChooseDest W: 1.9247952699661255
grad AddEdge W: 4.4013216682348144e-11
grad ChooseDest W: 1.2933547496795654
grad AddEdge W: 3.796053055227233e-11
grad ChooseDest W: 2.6074399948120117
grad AddEdge W: 1.4112379043140777e-09
grad ChooseDest W: 2.0740225315093994
grad AddEdge W: 1.5934054076183202e-09
grad ChooseDest W: 2.5108017921447754
grad AddEdge W: 8.514185190211521e-11
grad ChooseDest W: 3.2952210903167725
grad AddEdge W: 3.454694169624517e-11
grad ChooseDest W: 3.7060704231262207
grad AddEdge W: 3.791923219864657e-09
grad ChooseDest W: 1.8977850675582886
grad AddEdge W: 9.21797707609251e-11
grad ChooseDest W: 2.4613821506500244
grad AddEdge W: 4.197730010813139e-11
grad ChooseDest W: 1.9144939184188843
grad AddEdge W: 2.2870602980895605e-11
grad ChooseDest W: 2.868540048599243
grad AddEdge W: 1.545886162135357e-11
grad ChooseDest W: 2.549725294113159
grad AddEdge W: 9.31664523307063e-10
grad ChooseDest W: 2.610581636428833
grad AddEdge W: 8.568634690675481e-11
grad ChooseDest W: 2.409384250640869
grad AddEdge W: 5.2154867230536084e-11
grad ChooseDest W: 2.4616432189941406
grad AddEdge W: 3.085180028117307e-11
grad ChooseDest W: 2.459577798843384
grad AddEdge W: 1.2233399848682325e-09
grad ChooseDest W: 2.1103334426879883
grad AddEdge W: 5.076739584275458e-10
grad ChooseDest W: 2.1203677654266357
grad AddEdge W: 2.4191193492839602e-09
grad ChooseDest W: 3.651097297668457
grad AddEdge W: 1.1427056523238832e-10
grad ChooseDest W: 3.3936262130737305
grad AddEdge W: 1.3450159389027938e-11
grad ChooseDest W: 3.454193353652954
grad AddEdge W: 5.532267352559295e-11
grad ChooseDest W: 3.131922960281372
grad AddEdge W: 4.4210714950088104e-11
grad ChooseDest W: 3.5256874561309814
grad AddEdge W: 5.4023630187416405e-12
grad ChooseDest W: 3.9963929653167725
grad AddEdge W: 1.1023250888475555e-11
grad ChooseDest W: 2.0157759189605713
grad AddEdge W: 2.4881064222825877e-11
grad ChooseDest W: 1.4499300718307495
grad AddEdge W: 1.421703976767219e-09
grad ChooseDest W: 1.598490595817566
grad AddEdge W: 2.5095192590640636e-10
grad ChooseDest W: 2.8462986946105957
grad AddEdge W: 1.6880992437240394e-10
grad ChooseDest W: 2.4218673706054688
grad AddEdge W: 2.8804296725581935e-09
grad ChooseDest W: 2.3661680221557617
grad AddEdge W: 8.906078999282308e-12
grad ChooseDest W: 3.072504758834839
grad AddEdge W: 1.15618048468491e-09
grad ChooseDest W: 2.186861038208008
grad AddEdge W: 1.5694811006383702e-09
grad ChooseDest W: 2.793628215789795
grad AddEdge W: 2.2314913805665526e-10
grad ChooseDest W: 2.3011560440063477
grad AddEdge W: 4.428750421947569e-11
grad ChooseDest W: 1.634622573852539
grad AddEdge W: 6.847614055643936e-12
grad ChooseDest W: 2.0747597217559814
grad AddEdge W: 7.897298266723585e-13
grad ChooseDest W: 3.1887896060943604
grad AddEdge W: 1.5075609163806014e-11
grad ChooseDest W: 2.6588833332061768
grad AddEdge W: 1.2303882955880252e-12
grad ChooseDest W: 2.3508737087249756
grad AddEdge W: 1.101303857137248e-11
grad ChooseDest W: 3.63297176361084
grad AddEdge W: 3.1785036408438216e-11
grad ChooseDest W: 2.416949987411499
grad AddEdge W: 4.831492736272203e-13
grad ChooseDest W: 5.491616249084473
grad AddEdge W: 2.036641905470149e-12
grad ChooseDest W: 2.0000720024108887
grad AddEdge W: 6.045372535901095e-11
grad ChooseDest W: 1.5212711095809937
grad AddEdge W: 5.64387460377791e-11
grad ChooseDest W: 3.6449575424194336
grad AddEdge W: 2.049762790057308e-11
grad ChooseDest W: 4.403723239898682
grad AddEdge W: 1.4462474186988095e-12
grad ChooseDest W: 4.665822505950928
grad AddEdge W: 9.833370229195282e-12
grad ChooseDest W: 2.7090024948120117
grad AddEdge W: 1.121664176470527e-12
grad ChooseDest W: 3.44392728805542
grad AddEdge W: 2.7820128145616962e-11
grad ChooseDest W: 2.491288900375366
grad AddEdge W: 2.332635473667466e-11
grad ChooseDest W: 3.207639217376709
=== Epoch 5: Train Loss: 6.0359, Train Log Prob: 0.0066 ===
Total mismatches: 87864
Predicted valid destination but wrong order: 5493
Epoch 5: Validation Loss: 5.1495, Validation Log Prob: 0.0095
Epoch 5: Edge Precision: 0.3707, Recall: 0.3698, F1: 0.3702, Jaccard: 0.2458
Epoch 5: TP: 2.587258410880458, FP: 4.414602720114531, FN: 4.434216177523264
Epoch 5: warmup, skipping learning rate scheduler
Epoch 5: Current Learning Rate: 6e-05
[Epoch 5] ‚è±Ô∏è Total: 3459.38s | Current time: 2025-07-14 16:20:58 | üèãÔ∏è Train: 2960.10s | ‚úÖ Val: 499.28s
grad AddEdge W: 6.408511915578785e-11
grad ChooseDest W: 8.0057373046875
grad AddEdge W: 1.0670658801004151e-11
grad ChooseDest W: 2.3855390548706055
grad AddEdge W: 6.728898037725028e-13
grad ChooseDest W: 3.1650989055633545
grad AddEdge W: 6.190591659085976e-13
grad ChooseDest W: 4.635136127471924
grad AddEdge W: 6.297726229398393e-12
grad ChooseDest W: 3.660223960876465
grad AddEdge W: 2.000818130967752e-12
grad ChooseDest W: 2.5580530166625977
grad AddEdge W: 4.756361970947864e-12
grad ChooseDest W: 4.053345680236816
grad AddEdge W: 7.624290196579786e-13
grad ChooseDest W: 4.67933988571167
grad AddEdge W: 2.81770022895686e-13
grad ChooseDest W: 1.4832944869995117
grad AddEdge W: 8.867824009828329e-13
grad ChooseDest W: 3.0848684310913086
grad AddEdge W: 3.004577272744391e-12
grad ChooseDest W: 2.317653179168701
grad AddEdge W: 6.717771412929896e-13
grad ChooseDest W: 3.8625597953796387
grad AddEdge W: 4.957310061580456e-13
grad ChooseDest W: 2.533954620361328
grad AddEdge W: 1.4716794406385847e-12
grad ChooseDest W: 2.665834903717041
grad AddEdge W: 3.0297406944379546e-11
grad ChooseDest W: 3.545632839202881
grad AddEdge W: 6.90371560916822e-14
grad ChooseDest W: 2.054145336151123
grad AddEdge W: 1.2237225989475409e-11
grad ChooseDest W: 1.3492785692214966
grad AddEdge W: 3.8817449146515137e-13
grad ChooseDest W: 4.377981185913086
grad AddEdge W: 4.19058342714107e-13
grad ChooseDest W: 4.80116605758667
grad AddEdge W: 9.600424838787647e-13
grad ChooseDest W: 3.7822370529174805
grad AddEdge W: 2.424973243042583e-11
grad ChooseDest W: 2.7982983589172363
grad AddEdge W: 2.342549440016717e-13
grad ChooseDest W: 5.567841053009033
grad AddEdge W: 5.3623433818317245e-12
grad ChooseDest W: 2.8775477409362793
grad AddEdge W: 3.097791120842963e-12
grad ChooseDest W: 2.3323700428009033
grad AddEdge W: 9.031768388734207e-12
grad ChooseDest W: 3.120342254638672
grad AddEdge W: 4.940823141244555e-13
grad ChooseDest W: 2.7623291015625
grad AddEdge W: 5.4813406417941746e-12
grad ChooseDest W: 4.146515369415283
grad AddEdge W: 2.1368753392193157e-13
grad ChooseDest W: 2.9489400386810303
grad AddEdge W: 7.100383392355525e-09
grad ChooseDest W: 1.4126062393188477
grad AddEdge W: 3.2504268374089484e-12
grad ChooseDest W: 3.0282113552093506
grad AddEdge W: 1.6853108264405087e-13
grad ChooseDest W: 4.053354740142822
grad AddEdge W: 1.2728439179390816e-12
grad ChooseDest W: 4.161823749542236
grad AddEdge W: 2.0887161358146278e-12
grad ChooseDest W: 2.4650001525878906
grad AddEdge W: 2.065176155086057e-12
grad ChooseDest W: 2.354923963546753
grad AddEdge W: 2.4352512329817513e-14
grad ChooseDest W: 3.0309486389160156
grad AddEdge W: 3.3888598307760254e-13
grad ChooseDest W: 2.1474335193634033
grad AddEdge W: 7.445243423512271e-13
grad ChooseDest W: 3.9064579010009766
grad AddEdge W: 2.4222765178209815e-13
grad ChooseDest W: 4.0566911697387695
grad AddEdge W: 8.707246078668018e-13
grad ChooseDest W: 3.8362314701080322
grad AddEdge W: 4.1171599007676363e-13
grad ChooseDest W: 2.5258612632751465
grad AddEdge W: 1.0765693214285707e-13
grad ChooseDest W: 2.5945651531219482
grad AddEdge W: 6.854531455239773e-14
grad ChooseDest W: 5.455286026000977
grad AddEdge W: 4.64740912420325e-09
grad ChooseDest W: 2.5528671741485596
grad AddEdge W: 4.559035915170477e-14
grad ChooseDest W: 2.1992194652557373
grad AddEdge W: 1.0858135571223393e-11
grad ChooseDest W: 3.934936761856079
grad AddEdge W: 3.699967849463137e-12
grad ChooseDest W: 1.6110475063323975
grad AddEdge W: 2.5127076526236525e-13
grad ChooseDest W: 3.366255760192871
grad AddEdge W: 2.3468762198365634e-13
grad ChooseDest W: 3.584066867828369
grad AddEdge W: 2.151335099648266e-12
grad ChooseDest W: 2.2340481281280518
grad AddEdge W: 8.165441413299224e-12
grad ChooseDest W: 2.4187145233154297
grad AddEdge W: 1.1010045956535985e-13
grad ChooseDest W: 2.226233720779419
grad AddEdge W: 7.902227185324975e-14
grad ChooseDest W: 4.4766130447387695
grad AddEdge W: 8.368478842833357e-14
grad ChooseDest W: 3.5679426193237305
grad AddEdge W: 7.793832853403293e-13
grad ChooseDest W: 3.269225597381592
grad AddEdge W: 8.318972816384954e-14
grad ChooseDest W: 4.195169448852539
grad AddEdge W: 1.4001565748836264e-13
grad ChooseDest W: 3.205155849456787
grad AddEdge W: 1.417099770861796e-11
grad ChooseDest W: 3.128150701522827
grad AddEdge W: 3.870162315080215e-14
grad ChooseDest W: 3.637421131134033
grad AddEdge W: 6.555109374143525e-14
grad ChooseDest W: 4.837413787841797
grad AddEdge W: 9.563281156560466e-14
grad ChooseDest W: 3.0694587230682373
grad AddEdge W: 1.4805792225916492e-12
grad ChooseDest W: 3.3201234340667725
grad AddEdge W: 1.0037269409721161e-12
grad ChooseDest W: 2.37626314163208
grad AddEdge W: 2.0581693088109893e-13
grad ChooseDest W: 3.027702808380127
grad AddEdge W: 1.3436734364047354e-13
grad ChooseDest W: 2.9409172534942627
grad AddEdge W: 1.899773605573349e-14
grad ChooseDest W: 3.7607977390289307
grad AddEdge W: 1.528475561179618e-13
grad ChooseDest W: 2.9163336753845215
=== Epoch 6: Train Loss: 6.0270, Train Log Prob: 0.0067 ===
Total mismatches: 87595
Predicted valid destination but wrong order: 5514
Epoch 6: Validation Loss: 5.1526, Validation Log Prob: 0.0095
Epoch 6: Edge Precision: 0.3736, Recall: 0.3727, F1: 0.3731, Jaccard: 0.2479
Epoch 6: TP: 2.6084466714387973, FP: 4.394989262705798, FN: 4.413027916964925
Epoch 6: Current Learning Rate: 6e-05
[Epoch 6] ‚è±Ô∏è Total: 3446.43s | Current time: 2025-07-14 17:18:25 | üèãÔ∏è Train: 2945.29s | ‚úÖ Val: 501.14s
grad AddEdge W: 9.45253653128475e-10
grad ChooseDest W: 3.4095118045806885
grad AddEdge W: 2.4576686375571942e-14
grad ChooseDest W: 4.178866863250732
grad AddEdge W: 1.2300174713399809e-13
grad ChooseDest W: 3.038849115371704
grad AddEdge W: 1.8697907805398373e-12
grad ChooseDest W: 1.519916296005249
grad AddEdge W: 2.7027616256170006e-12
grad ChooseDest W: 3.176098346710205
grad AddEdge W: 1.2913424496385772e-10
grad ChooseDest W: 1.8813176155090332
grad AddEdge W: 1.1373135777332372e-13
grad ChooseDest W: 3.148686170578003
grad AddEdge W: 4.33719663103186e-14
grad ChooseDest W: 3.1413967609405518
grad AddEdge W: 7.072566545005682e-14
grad ChooseDest W: 2.836451530456543
grad AddEdge W: 7.930819334589501e-10
grad ChooseDest W: 1.391374111175537
grad AddEdge W: 1.2472549035247305e-12
grad ChooseDest W: 3.6587486267089844
grad AddEdge W: 1.8967007055659818e-13
grad ChooseDest W: 2.2950785160064697
grad AddEdge W: 5.837395996265149e-13
grad ChooseDest W: 3.192188262939453
grad AddEdge W: 2.549328712575516e-07
grad ChooseDest W: 3.605712890625
grad AddEdge W: 9.13457135452711e-14
grad ChooseDest W: 6.520016193389893
grad AddEdge W: 2.31240183251602e-11
grad ChooseDest W: 1.715694785118103
grad AddEdge W: 9.876650820979382e-14
grad ChooseDest W: 2.5646376609802246
grad AddEdge W: 3.1283621526601024e-12
grad ChooseDest W: 3.95845103263855
grad AddEdge W: 1.0644038954269255e-13
grad ChooseDest W: 3.4055395126342773
grad AddEdge W: 3.0203141691224206e-14
grad ChooseDest W: 2.610795259475708
grad AddEdge W: 1.5869140243952688e-14
grad ChooseDest W: 5.146374702453613
grad AddEdge W: 6.028042783901358e-14
grad ChooseDest W: 4.713153839111328
grad AddEdge W: 4.543133040992367e-14
grad ChooseDest W: 2.6007421016693115
grad AddEdge W: 9.92049220549518e-10
grad ChooseDest W: 1.856247067451477
grad AddEdge W: 2.025655915249315e-14
grad ChooseDest W: 2.0623209476470947
grad AddEdge W: 3.6872889182075486e-14
grad ChooseDest W: 2.259000062942505
grad AddEdge W: 3.5225190819776486e-12
grad ChooseDest W: 3.9359447956085205
grad AddEdge W: 5.064606503277225e-14
grad ChooseDest W: 4.141737461090088
grad AddEdge W: 2.8696097147812294e-12
grad ChooseDest W: 2.154634952545166
grad AddEdge W: 1.5759042562655395e-13
grad ChooseDest W: 3.56887149810791
grad AddEdge W: 4.638785189303718e-11
grad ChooseDest W: 2.3889477252960205
grad AddEdge W: 5.602512404738816e-14
grad ChooseDest W: 2.923886775970459
grad AddEdge W: 5.73522295193446e-13
grad ChooseDest W: 4.6298980712890625
grad AddEdge W: 7.104075493017184e-14
grad ChooseDest W: 3.6146321296691895
grad AddEdge W: 8.441339939329814e-14
grad ChooseDest W: 3.7286078929901123
grad AddEdge W: 6.043483422035756e-12
grad ChooseDest W: 3.8284153938293457
grad AddEdge W: 5.925036801251657e-14
grad ChooseDest W: 2.7120139598846436
grad AddEdge W: 1.1005652904858346e-13
grad ChooseDest W: 2.5789363384246826
grad AddEdge W: 2.3456632469720518e-11
grad ChooseDest W: 1.6924384832382202
grad AddEdge W: 1.918505285192218e-12
grad ChooseDest W: 2.528890609741211
grad AddEdge W: 5.555646546105686e-13
grad ChooseDest W: 2.9178640842437744
grad AddEdge W: 1.8307268678449673e-14
grad ChooseDest W: 4.1309990882873535
grad AddEdge W: 8.403436909006079e-14
grad ChooseDest W: 2.446410894393921
grad AddEdge W: 1.5807327506407037e-13
grad ChooseDest W: 2.4677932262420654
grad AddEdge W: 9.513459898330412e-13
grad ChooseDest W: 1.3077090978622437
grad AddEdge W: 1.6963482485019e-12
grad ChooseDest W: 4.999911308288574
grad AddEdge W: 4.3947992760164784e-14
grad ChooseDest W: 3.23771333694458
grad AddEdge W: 1.7095740378891833e-09
grad ChooseDest W: 1.7341731786727905
grad AddEdge W: 1.347959938113874e-12
grad ChooseDest W: 2.685258388519287
grad AddEdge W: 9.355976280170375e-13
grad ChooseDest W: 3.6897261142730713
grad AddEdge W: 6.770370939226944e-14
grad ChooseDest W: 2.527693271636963
grad AddEdge W: 1.5676857598526106e-12
grad ChooseDest W: 3.1295711994171143
grad AddEdge W: 6.490464497235435e-14
grad ChooseDest W: 3.7813737392425537
grad AddEdge W: 2.4921823502457863e-13
grad ChooseDest W: 2.753295421600342
grad AddEdge W: 8.288353727306519e-13
grad ChooseDest W: 1.6404492855072021
grad AddEdge W: 1.898481155268583e-12
grad ChooseDest W: 3.2555301189422607
grad AddEdge W: 4.2570152047546883e-13
grad ChooseDest W: 2.3177812099456787
grad AddEdge W: 1.4031499215565874e-13
grad ChooseDest W: 3.8116562366485596
grad AddEdge W: 1.5641440508258608e-13
grad ChooseDest W: 3.4780802726745605
grad AddEdge W: 1.1953735527467368e-13
grad ChooseDest W: 3.2124598026275635
grad AddEdge W: 3.13069421732301e-13
grad ChooseDest W: 3.1649787425994873
grad AddEdge W: 2.1824224014348886e-14
grad ChooseDest W: 3.206465244293213
grad AddEdge W: 1.7812404329298204e-11
grad ChooseDest W: 2.4435956478118896
grad AddEdge W: 5.822218521103067e-14
grad ChooseDest W: 2.715749979019165
grad AddEdge W: 4.317024033173231e-14
grad ChooseDest W: 5.681248188018799
grad AddEdge W: 2.512402720762641e-13
grad ChooseDest W: 2.334458112716675
=== Epoch 7: Train Loss: 6.0189, Train Log Prob: 0.0068 ===
Total mismatches: 87439
Predicted valid destination but wrong order: 5500
Epoch 7: Validation Loss: 5.0240, Validation Log Prob: 0.0106
Epoch 7: Edge Precision: 0.3737, Recall: 0.3729, F1: 0.3733, Jaccard: 0.2481
Epoch 7: TP: 2.6097351467430205, FP: 4.3932712956335, FN: 4.411739441660702
Epoch 7: Current Learning Rate: 6e-05
[Epoch 7] ‚è±Ô∏è Total: 3450.65s | Current time: 2025-07-14 18:15:55 | üèãÔ∏è Train: 2943.64s | ‚úÖ Val: 507.01s
grad AddEdge W: 2.6276975387262702e-12
grad ChooseDest W: 6.142045974731445
grad AddEdge W: 1.2818219792889995e-12
grad ChooseDest W: 4.408026218414307
grad AddEdge W: 4.1639756828129246e-14
grad ChooseDest W: 2.882175922393799
grad AddEdge W: 3.235022791097872e-14
grad ChooseDest W: 2.198086977005005
grad AddEdge W: 6.178307868700281e-15
grad ChooseDest W: 2.5229878425598145
grad AddEdge W: 3.564206221828847e-14
grad ChooseDest W: 3.841899871826172
grad AddEdge W: 2.1386380825451877e-14
grad ChooseDest W: 2.167452096939087
grad AddEdge W: 5.565311124271222e-13
grad ChooseDest W: 2.837432622909546
grad AddEdge W: 5.992684240551174e-14
grad ChooseDest W: 3.0414891242980957
grad AddEdge W: 1.0502270711074124e-12
grad ChooseDest W: 4.849799156188965
grad AddEdge W: 5.870556319710618e-14
grad ChooseDest W: 3.3301455974578857
grad AddEdge W: 2.383483221988364e-13
grad ChooseDest W: 3.9351072311401367
grad AddEdge W: 1.1021888696866045e-12
grad ChooseDest W: 2.5833451747894287
grad AddEdge W: 7.42054258751762e-14
grad ChooseDest W: 3.9448468685150146
grad AddEdge W: 2.2517853467268756e-12
grad ChooseDest W: 2.9744513034820557
grad AddEdge W: 6.463012633753373e-13
grad ChooseDest W: 2.7815003395080566
grad AddEdge W: 7.77994764558686e-15
grad ChooseDest W: 4.016881942749023
grad AddEdge W: 7.939008608501275e-13
grad ChooseDest W: 2.260051965713501
grad AddEdge W: 3.228062131835352e-12
grad ChooseDest W: 3.3731093406677246
grad AddEdge W: 3.693757370012551e-15
grad ChooseDest W: 2.8094539642333984
grad AddEdge W: 1.6720796720549576e-15
grad ChooseDest W: 4.007225513458252
grad AddEdge W: 1.518991231625258e-13
grad ChooseDest W: 2.5433974266052246
grad AddEdge W: 3.437957993919667e-14
grad ChooseDest W: 4.445197582244873
grad AddEdge W: 3.831838139975105e-15
grad ChooseDest W: 2.4904682636260986
grad AddEdge W: 1.2093367214756345e-14
grad ChooseDest W: 2.9969289302825928
grad AddEdge W: 5.2861259477749584e-14
grad ChooseDest W: 2.758150100708008
grad AddEdge W: 6.974533797721172e-13
grad ChooseDest W: 1.713700294494629
grad AddEdge W: 1.409279187488191e-13
grad ChooseDest W: 2.2307262420654297
grad AddEdge W: 4.636114083779452e-13
grad ChooseDest W: 2.3516488075256348
grad AddEdge W: 1.8500227866031886e-14
grad ChooseDest W: 3.394002676010132
grad AddEdge W: 2.4356577410337976e-13
grad ChooseDest W: 4.036686420440674
grad AddEdge W: 6.596123387075936e-13
grad ChooseDest W: 3.3747591972351074
grad AddEdge W: 1.4370195571683508e-12
grad ChooseDest W: 3.4776337146759033
grad AddEdge W: 6.961960955648161e-12
grad ChooseDest W: 3.8711960315704346
grad AddEdge W: 1.2782466057847941e-11
grad ChooseDest W: 2.64286732673645
grad AddEdge W: 5.831817776087711e-13
grad ChooseDest W: 2.419034957885742
grad AddEdge W: 4.298952669946855e-15
grad ChooseDest W: 3.0056889057159424
grad AddEdge W: 4.916168214435645e-15
grad ChooseDest W: 2.0378987789154053
grad AddEdge W: 2.1134209660100822e-10
grad ChooseDest W: 1.2139809131622314
grad AddEdge W: 3.5621058511701997e-13
grad ChooseDest W: 2.9488742351531982
grad AddEdge W: 7.33566954738956e-15
grad ChooseDest W: 3.135010242462158
grad AddEdge W: 2.0361381851408122e-13
grad ChooseDest W: 3.672191619873047
grad AddEdge W: 5.34094795300033e-13
grad ChooseDest W: 3.5046868324279785
grad AddEdge W: 6.072577336813101e-13
grad ChooseDest W: 2.5100858211517334
grad AddEdge W: 1.1266951896471162e-14
grad ChooseDest W: 4.221593379974365
grad AddEdge W: 1.8826947379563252e-12
grad ChooseDest W: 2.216127395629883
grad AddEdge W: 2.7539419583753194e-14
grad ChooseDest W: 2.5634591579437256
grad AddEdge W: 1.144406563870909e-13
grad ChooseDest W: 6.943317413330078
grad AddEdge W: 2.5247934575282557e-14
grad ChooseDest W: 3.4915733337402344
grad AddEdge W: 2.9277426837059917e-13
grad ChooseDest W: 2.742826223373413
grad AddEdge W: 1.4857564370430662e-14
grad ChooseDest W: 3.9354536533355713
grad AddEdge W: 6.622434940923086e-14
grad ChooseDest W: 2.9232795238494873
grad AddEdge W: 4.799793510779429e-14
grad ChooseDest W: 2.2716212272644043
grad AddEdge W: 2.9858729963354314e-13
grad ChooseDest W: 2.955833911895752
grad AddEdge W: 2.0342522832244095e-14
grad ChooseDest W: 3.0414321422576904
grad AddEdge W: 4.458303284247912e-15
grad ChooseDest W: 4.20421838760376
grad AddEdge W: 6.641314559928391e-13
grad ChooseDest W: 2.763843059539795
grad AddEdge W: 7.750353161442743e-15
grad ChooseDest W: 2.8074145317077637
grad AddEdge W: 2.4869415879945345e-13
grad ChooseDest W: 3.3161840438842773
grad AddEdge W: 1.4934319107979058e-14
grad ChooseDest W: 4.32765531539917
grad AddEdge W: 4.0135608595295857e-13
grad ChooseDest W: 3.0662999153137207
grad AddEdge W: 1.3248524490200395e-14
grad ChooseDest W: 4.375738143920898
grad AddEdge W: 1.7976753034299256e-14
grad ChooseDest W: 4.3101654052734375
grad AddEdge W: 3.7042631874199816e-13
grad ChooseDest W: 2.0455362796783447
grad AddEdge W: 1.2232219631733848e-13
grad ChooseDest W: 3.234467029571533
grad AddEdge W: 1.3000451409839187e-13
grad ChooseDest W: 4.5454277992248535
=== Epoch 8: Train Loss: 6.0107, Train Log Prob: 0.0068 ===
Total mismatches: 86983
Predicted valid destination but wrong order: 5484
Epoch 8: Validation Loss: 5.0795, Validation Log Prob: 0.0099
Epoch 8: Edge Precision: 0.3680, Recall: 0.3669, F1: 0.3674, Jaccard: 0.2433
Epoch 8: TP: 2.567644953471725, FP: 4.432211882605583, FN: 4.4538296349319975
Epoch 8: Current Learning Rate: 6e-05
[Epoch 8] ‚è±Ô∏è Total: 3437.31s | Current time: 2025-07-14 19:13:13 | üèãÔ∏è Train: 2940.15s | ‚úÖ Val: 497.17s
grad AddEdge W: 1.404395480117393e-12
grad ChooseDest W: 5.688265800476074
grad AddEdge W: 1.6925508913791416e-14
grad ChooseDest W: 2.8375611305236816
grad AddEdge W: 5.32197238210276e-15
grad ChooseDest W: 2.1303393840789795
grad AddEdge W: 4.3757608213929045e-13
grad ChooseDest W: 3.130019426345825
grad AddEdge W: 3.6858908395061285e-13
grad ChooseDest W: 3.3878512382507324
grad AddEdge W: 5.417583343606458e-15
grad ChooseDest W: 4.148985862731934
grad AddEdge W: 6.43366057043876e-13
grad ChooseDest W: 4.767014026641846
grad AddEdge W: 2.1432451625079396e-13
grad ChooseDest W: 2.692486047744751
grad AddEdge W: 3.7593257669430325e-15
grad ChooseDest W: 3.261003017425537
grad AddEdge W: 6.641698042236799e-12
grad ChooseDest W: 3.3101046085357666
grad AddEdge W: 8.18853346945276e-15
grad ChooseDest W: 2.361438751220703
grad AddEdge W: 1.292068292906446e-14
grad ChooseDest W: 1.99221932888031
grad AddEdge W: 1.1102822491688286e-13
grad ChooseDest W: 2.1469287872314453
grad AddEdge W: 5.386703910481355e-15
grad ChooseDest W: 2.5374066829681396
grad AddEdge W: 1.5660262766192725e-15
grad ChooseDest W: 4.8323469161987305
grad AddEdge W: 4.758610430070746e-14
grad ChooseDest W: 2.961045742034912
grad AddEdge W: 3.162387682991742e-14
grad ChooseDest W: 3.5157885551452637
grad AddEdge W: 4.021287697362347e-13
grad ChooseDest W: 1.7013344764709473
grad AddEdge W: 3.6269899979452305e-14
grad ChooseDest W: 3.6599886417388916
grad AddEdge W: 2.5451855639751662e-15
grad ChooseDest W: 4.370851993560791
grad AddEdge W: 2.542823265318239e-13
grad ChooseDest W: 4.124324798583984
grad AddEdge W: 6.494885740337963e-10
grad ChooseDest W: 2.163459300994873
grad AddEdge W: 8.58567638642102e-14
grad ChooseDest W: 2.6640119552612305
grad AddEdge W: 4.6978039676664335e-15
grad ChooseDest W: 3.381037712097168
grad AddEdge W: 2.3772638656324903e-14
grad ChooseDest W: 4.82222318649292
grad AddEdge W: 9.957818854292857e-16
grad ChooseDest W: 3.731281280517578
grad AddEdge W: 8.400053690008156e-15
grad ChooseDest W: 3.5100014209747314
grad AddEdge W: 2.7252812094709367e-13
grad ChooseDest W: 3.7621867656707764
grad AddEdge W: 9.47073467555664e-15
grad ChooseDest W: 4.094451427459717
grad AddEdge W: 7.582052390445182e-13
grad ChooseDest W: 2.1488988399505615
grad AddEdge W: 7.60452680457314e-16
grad ChooseDest W: 3.0050439834594727
grad AddEdge W: 2.5781817324354575e-15
grad ChooseDest W: 3.8267359733581543
grad AddEdge W: 1.8085290480907706e-13
grad ChooseDest W: 3.640397787094116
grad AddEdge W: 9.817242301751218e-15
grad ChooseDest W: 2.1713528633117676
grad AddEdge W: 5.458601168187131e-14
grad ChooseDest W: 3.1672873497009277
grad AddEdge W: 5.098808745010452e-13
grad ChooseDest W: 6.527126312255859
grad AddEdge W: 1.0318530799496416e-14
grad ChooseDest W: 3.330326795578003
grad AddEdge W: 2.0975000978706165e-13
grad ChooseDest W: 2.715873956680298
grad AddEdge W: 1.1078344188189537e-12
grad ChooseDest W: 3.0526511669158936
grad AddEdge W: 1.2058357784505702e-12
grad ChooseDest W: 3.7222819328308105
grad AddEdge W: 1.6102609629270286e-14
grad ChooseDest W: 3.180903673171997
grad AddEdge W: 2.921217794095714e-15
grad ChooseDest W: 3.0837624073028564
grad AddEdge W: 3.631085825761679e-15
grad ChooseDest W: 4.691464424133301
grad AddEdge W: 1.2806803584470856e-14
grad ChooseDest W: 2.9000985622406006
grad AddEdge W: 3.4075091923449485e-14
grad ChooseDest W: 3.1649107933044434
grad AddEdge W: 4.299862061459686e-13
grad ChooseDest W: 3.678100109100342
grad AddEdge W: 1.621050705778379e-13
grad ChooseDest W: 3.911304235458374
grad AddEdge W: 3.5474585508704637e-13
grad ChooseDest W: 2.6651880741119385
grad AddEdge W: 3.4834179133856266e-14
grad ChooseDest W: 3.484790086746216
grad AddEdge W: 3.853318895517474e-15
grad ChooseDest W: 2.1592094898223877
grad AddEdge W: 1.4914933911948196e-14
grad ChooseDest W: 4.285656929016113
grad AddEdge W: 9.51849886345231e-14
grad ChooseDest W: 4.998540878295898
grad AddEdge W: 6.171868978345138e-14
grad ChooseDest W: 2.7887139320373535
grad AddEdge W: 1.6451950479029476e-12
grad ChooseDest W: 4.142010688781738
grad AddEdge W: 3.650346084432821e-12
grad ChooseDest W: 3.1219754219055176
grad AddEdge W: 2.866167852304236e-15
grad ChooseDest W: 3.433842420578003
grad AddEdge W: 1.751980417024398e-14
grad ChooseDest W: 3.4496066570281982
grad AddEdge W: 2.29421109930808e-13
grad ChooseDest W: 4.099714756011963
grad AddEdge W: 1.824712256293104e-14
grad ChooseDest W: 3.3403637409210205
grad AddEdge W: 5.08152276767343e-13
grad ChooseDest W: 3.402928590774536
grad AddEdge W: 2.2399615528297806e-13
grad ChooseDest W: 2.6597096920013428
grad AddEdge W: 1.3552197829658913e-13
grad ChooseDest W: 1.62112295627594
grad AddEdge W: 2.3996924086911895e-15
grad ChooseDest W: 1.699463963508606
grad AddEdge W: 9.001610568049045e-11
grad ChooseDest W: 1.9667184352874756
grad AddEdge W: 4.920179762473841e-15
grad ChooseDest W: 3.5302863121032715
grad AddEdge W: 1.9873641306841078e-13
grad ChooseDest W: 2.561168909072876
=== Epoch 9: Train Loss: 5.9995, Train Log Prob: 0.0069 ===
Total mismatches: 86729
Predicted valid destination but wrong order: 5445
Epoch 9: Validation Loss: 5.0957, Validation Log Prob: 0.0098
Epoch 9: Edge Precision: 0.3704, Recall: 0.3694, F1: 0.3699, Jaccard: 0.2453
Epoch 9: TP: 2.585110952040086, FP: 4.416893342877595, FN: 4.4363636363636365
Epoch 9: Current Learning Rate: 6e-05
[Epoch 9] ‚è±Ô∏è Total: 3451.19s | Current time: 2025-07-14 20:10:44 | üèãÔ∏è Train: 2950.51s | ‚úÖ Val: 500.67s
grad AddEdge W: 3.463761499844509e-10
grad ChooseDest W: 7.231066703796387
grad AddEdge W: 1.2815388941017636e-13
grad ChooseDest W: 3.898862838745117
grad AddEdge W: 5.169634777088495e-15
grad ChooseDest W: 3.0692546367645264
grad AddEdge W: 1.6842683702868286e-15
grad ChooseDest W: 3.6485581398010254
grad AddEdge W: 5.717163396347369e-13
grad ChooseDest W: 2.5220730304718018
grad AddEdge W: 3.082503057059288e-13
grad ChooseDest W: 2.9229609966278076
grad AddEdge W: 1.0431644426305703e-14
grad ChooseDest W: 4.4615254402160645
grad AddEdge W: 1.9907290198890523e-15
grad ChooseDest W: 3.9483742713928223
grad AddEdge W: 1.2490609403986025e-13
grad ChooseDest W: 2.1000921726226807
grad AddEdge W: 1.374552149551833e-15
grad ChooseDest W: 2.4449901580810547
grad AddEdge W: 3.7816785429046e-15
grad ChooseDest W: 3.0034713745117188
grad AddEdge W: 5.045630254753297e-13
grad ChooseDest W: 2.970690965652466
grad AddEdge W: 6.417483189823103e-13
grad ChooseDest W: 3.8304710388183594
grad AddEdge W: 8.199705834027043e-15
grad ChooseDest W: 3.5678083896636963
grad AddEdge W: 1.1866546191041747e-14
grad ChooseDest W: 3.44707989692688
grad AddEdge W: 2.688769295237795e-15
grad ChooseDest W: 3.8734376430511475
grad AddEdge W: 1.1380204070765565e-11
grad ChooseDest W: 1.7186936140060425
grad AddEdge W: 1.610570892282429e-15
grad ChooseDest W: 4.313365459442139
grad AddEdge W: 2.137190842051509e-14
grad ChooseDest W: 3.121692180633545
grad AddEdge W: 2.686251286514174e-13
grad ChooseDest W: 2.9517104625701904
grad AddEdge W: 3.963840177991689e-15
grad ChooseDest W: 3.206078290939331
grad AddEdge W: 8.97150734778529e-13
grad ChooseDest W: 7.79222297668457
grad AddEdge W: 5.054961762623314e-15
grad ChooseDest W: 5.162752628326416
grad AddEdge W: 8.025574494796399e-15
grad ChooseDest W: 3.5798661708831787
grad AddEdge W: 6.740406979311234e-15
grad ChooseDest W: 4.3087544441223145
grad AddEdge W: 1.5201330320381568e-13
grad ChooseDest W: 5.970283031463623
grad AddEdge W: 7.664766580759916e-14
grad ChooseDest W: 2.48510479927063
grad AddEdge W: 1.1490263662685286e-14
grad ChooseDest W: 3.645940065383911
grad AddEdge W: 4.298865679663172e-14
grad ChooseDest W: 3.477010726928711
grad AddEdge W: 6.592103707521446e-14
grad ChooseDest W: 7.880438327789307
grad AddEdge W: 2.0039671284151003e-14
grad ChooseDest W: 4.553411483764648
grad AddEdge W: 2.1167479390387517e-13
grad ChooseDest W: 4.036652088165283
grad AddEdge W: 4.0532440820579066e-15
grad ChooseDest W: 3.747817039489746
grad AddEdge W: 1.0900419564370545e-14
grad ChooseDest W: 3.4506962299346924
grad AddEdge W: 6.285806293873653e-13
grad ChooseDest W: 5.161959171295166
grad AddEdge W: 1.3797068744314674e-15
grad ChooseDest W: 4.995403289794922
grad AddEdge W: 7.31419556811077e-15
grad ChooseDest W: 3.0305709838867188
grad AddEdge W: 5.9552231073160215e-15
grad ChooseDest W: 4.225419044494629
grad AddEdge W: 5.040478126029646e-13
grad ChooseDest W: 2.4540226459503174
grad AddEdge W: 1.6443798904995643e-13
grad ChooseDest W: 4.855278015136719
grad AddEdge W: 6.490343371523977e-15
grad ChooseDest W: 2.78429913520813
grad AddEdge W: 9.322742137803553e-16
grad ChooseDest W: 5.338325500488281
grad AddEdge W: 1.4293992693040908e-14
grad ChooseDest W: 5.005547523498535
grad AddEdge W: 2.117638780530038e-14
grad ChooseDest W: 3.619028091430664
grad AddEdge W: 7.594571096948468e-15
grad ChooseDest W: 5.046604633331299
grad AddEdge W: 8.54726581395529e-14
grad ChooseDest W: 3.3853769302368164
grad AddEdge W: 1.2511639707407044e-14
grad ChooseDest W: 2.205209970474243
grad AddEdge W: 1.1658553015678717e-14
grad ChooseDest W: 3.813633918762207
grad AddEdge W: 1.505281202927812e-15
grad ChooseDest W: 3.6963553428649902
grad AddEdge W: 5.127819725097866e-15
grad ChooseDest W: 4.057075023651123
grad AddEdge W: 2.334534822740126e-15
grad ChooseDest W: 3.2180256843566895
grad AddEdge W: 2.4858333707439284e-12
grad ChooseDest W: 5.067464351654053
grad AddEdge W: 5.948431851254821e-13
grad ChooseDest W: 4.940450668334961
grad AddEdge W: 3.713768946907907e-15
grad ChooseDest W: 3.4483234882354736
grad AddEdge W: 1.4842040585848096e-15
grad ChooseDest W: 3.346569776535034
grad AddEdge W: 4.989731501245376e-14
grad ChooseDest W: 5.076623916625977
grad AddEdge W: 1.2918798788976588e-13
grad ChooseDest W: 3.845313310623169
grad AddEdge W: 2.262915603599286e-13
grad ChooseDest W: 3.250434160232544
grad AddEdge W: 3.682419834013552e-14
grad ChooseDest W: 4.251158714294434
grad AddEdge W: 1.7243502869882573e-15
grad ChooseDest W: 5.9025678634643555
grad AddEdge W: 5.5035582888956006e-14
grad ChooseDest W: 4.7112627029418945
grad AddEdge W: 4.000109705276644e-15
grad ChooseDest W: 3.2459030151367188
grad AddEdge W: 7.022747624586562e-15
grad ChooseDest W: 2.025513172149658
grad AddEdge W: 1.1978134311513029e-15
grad ChooseDest W: 3.0952329635620117
grad AddEdge W: 1.2070264391119984e-14
grad ChooseDest W: 4.195806503295898
grad AddEdge W: 3.410154645645813e-13
grad ChooseDest W: 4.588620662689209
=== Epoch 10: Train Loss: 5.9875, Train Log Prob: 0.0069 ===
Total mismatches: 86373
Predicted valid destination but wrong order: 5445
Epoch 10: Validation Loss: 5.0410, Validation Log Prob: 0.0102
Epoch 10: Edge Precision: 0.3688, Recall: 0.3677, F1: 0.3682, Jaccard: 0.2437
Epoch 10: TP: 2.574373657838225, FP: 4.425769506084467, FN: 4.447100930565497
Epoch 10: Current Learning Rate: 6e-05
[Epoch 10] ‚è±Ô∏è Total: 3446.96s | Current time: 2025-07-14 21:08:11 | üèãÔ∏è Train: 2946.81s | ‚úÖ Val: 500.15s
grad AddEdge W: 6.743458330800423e-13
grad ChooseDest W: 8.62294864654541
grad AddEdge W: 1.5668274639082567e-15
grad ChooseDest W: 5.376285552978516
grad AddEdge W: 2.0578270736189806e-14
grad ChooseDest W: 3.6347556114196777
grad AddEdge W: 3.867405053430313e-15
grad ChooseDest W: 2.1375410556793213
grad AddEdge W: 2.4197853007494824e-15
grad ChooseDest W: 2.6911516189575195
grad AddEdge W: 8.787456873271537e-11
grad ChooseDest W: 1.3758867979049683
grad AddEdge W: 2.7707245609724478e-14
grad ChooseDest W: 2.5772621631622314
grad AddEdge W: 2.338077410987075e-14
grad ChooseDest W: 3.4578027725219727
grad AddEdge W: 1.9454832981147946e-13
grad ChooseDest W: 7.024681091308594
grad AddEdge W: 8.30942302812443e-14
grad ChooseDest W: 2.1241724491119385
grad AddEdge W: 7.048111009752556e-14
grad ChooseDest W: 2.2771923542022705
grad AddEdge W: 2.065511652978003e-15
grad ChooseDest W: 5.694253444671631
grad AddEdge W: 8.979186209671919e-14
grad ChooseDest W: 3.704073905944824
grad AddEdge W: 2.33234899492743e-13
grad ChooseDest W: 2.3951056003570557
grad AddEdge W: 3.2197801791021465e-15
grad ChooseDest W: 5.74308967590332
grad AddEdge W: 4.023957917906589e-15
grad ChooseDest W: 3.2510132789611816
grad AddEdge W: 2.376733368897625e-15
grad ChooseDest W: 3.406892776489258
grad AddEdge W: 2.9702328378962417e-13
grad ChooseDest W: 3.7514169216156006
grad AddEdge W: 5.068958558560217e-15
grad ChooseDest W: 3.837675094604492
grad AddEdge W: 1.1325913648171297e-15
grad ChooseDest W: 2.979137420654297
grad AddEdge W: 2.7231755617970277e-15
grad ChooseDest W: 2.478691577911377
grad AddEdge W: 5.132131698781794e-13
grad ChooseDest W: 3.7268166542053223
grad AddEdge W: 3.621511050029211e-14
grad ChooseDest W: 3.811091184616089
grad AddEdge W: 2.7248696276915363e-15
grad ChooseDest W: 4.915137767791748
grad AddEdge W: 4.353141856857333e-14
grad ChooseDest W: 4.001519680023193
grad AddEdge W: 3.652205321752044e-15
grad ChooseDest W: 4.727056980133057
grad AddEdge W: 4.47188376349124e-15
grad ChooseDest W: 2.3184328079223633
grad AddEdge W: 2.7822330282202025e-15
grad ChooseDest W: 4.26677131652832
grad AddEdge W: 1.658017019306405e-15
grad ChooseDest W: 3.8014564514160156
grad AddEdge W: 3.4870557504874944e-14
grad ChooseDest W: 2.323300361633301
grad AddEdge W: 1.1715792452935553e-13
grad ChooseDest W: 2.6197292804718018
grad AddEdge W: 1.4546919441596473e-13
grad ChooseDest W: 3.714212656021118
grad AddEdge W: 5.172203065687865e-14
grad ChooseDest W: 5.647136211395264
grad AddEdge W: 5.675839030543084e-13
grad ChooseDest W: 3.836763381958008
grad AddEdge W: 7.770605719211593e-14
grad ChooseDest W: 3.454324245452881
grad AddEdge W: 8.171497095784633e-15
grad ChooseDest W: 4.01118803024292
grad AddEdge W: 3.4373501630767175e-14
grad ChooseDest W: 5.370445251464844
grad AddEdge W: 6.644432217156691e-15
grad ChooseDest W: 4.784310340881348
grad AddEdge W: 1.2011602700841414e-15
grad ChooseDest W: 4.756673336029053
grad AddEdge W: 1.2772856773993202e-12
grad ChooseDest W: 3.040250062942505
grad AddEdge W: 1.1785741365456055e-15
grad ChooseDest W: 4.188507080078125
grad AddEdge W: 1.25514277248516e-13
grad ChooseDest W: 4.218235015869141
grad AddEdge W: 2.241178163192581e-13
grad ChooseDest W: 3.2588374614715576
grad AddEdge W: 2.945962140898928e-09
grad ChooseDest W: 2.249971389770508
grad AddEdge W: 4.8762504315435704e-14
grad ChooseDest W: 3.1397738456726074
grad AddEdge W: 1.4231652762188886e-15
grad ChooseDest W: 3.8730146884918213
grad AddEdge W: 3.079833395556791e-15
grad ChooseDest W: 3.7510972023010254
grad AddEdge W: 2.6621747476829674e-14
grad ChooseDest W: 3.5788562297821045
grad AddEdge W: 4.157302926661045e-15
grad ChooseDest W: 3.284423828125
grad AddEdge W: 3.501719246057182e-14
grad ChooseDest W: 2.506801128387451
grad AddEdge W: 2.1211257187123524e-15
grad ChooseDest W: 3.1710455417633057
grad AddEdge W: 1.8805779416347645e-13
grad ChooseDest W: 2.7204015254974365
grad AddEdge W: 3.2128467909123964e-15
grad ChooseDest W: 4.266456127166748
grad AddEdge W: 1.1877087854883506e-13
grad ChooseDest W: 2.469251871109009
grad AddEdge W: 2.879235207458447e-13
grad ChooseDest W: 4.023096561431885
grad AddEdge W: 2.4057571645935303e-15
grad ChooseDest W: 3.621795892715454
grad AddEdge W: 3.1660505922688487e-13
grad ChooseDest W: 2.9052295684814453
grad AddEdge W: 2.5505932340686745e-15
grad ChooseDest W: 3.8729395866394043
grad AddEdge W: 3.383727759792565e-13
grad ChooseDest W: 3.557805299758911
grad AddEdge W: 7.322193253198744e-16
grad ChooseDest W: 2.711242914199829
grad AddEdge W: 1.7815135759831346e-14
grad ChooseDest W: 3.0530903339385986
grad AddEdge W: 4.451559631438347e-15
grad ChooseDest W: 3.4269163608551025
grad AddEdge W: 1.900599361052968e-13
grad ChooseDest W: 2.8174479007720947
grad AddEdge W: 4.674956168709832e-12
grad ChooseDest W: 2.1479413509368896
grad AddEdge W: 3.487912947830116e-14
grad ChooseDest W: 2.3401618003845215
grad AddEdge W: 2.353166794722642e-15
grad ChooseDest W: 4.2568888664245605
=== Epoch 11: Train Loss: 5.9762, Train Log Prob: 0.0070 ===
Total mismatches: 86023
Predicted valid destination but wrong order: 5481
Epoch 11: Validation Loss: 4.9650, Validation Log Prob: 0.0109
Epoch 11: Edge Precision: 0.3719, Recall: 0.3705, F1: 0.3711, Jaccard: 0.2466
Epoch 11: TP: 2.591982820329277, FP: 4.401145311381532, FN: 4.4294917680744454
Epoch 11: Current Learning Rate: 6e-05
[Epoch 11] ‚è±Ô∏è Total: 3466.87s | Current time: 2025-07-14 22:05:58 | üèãÔ∏è Train: 2963.78s | ‚úÖ Val: 503.09s
grad AddEdge W: 1.4660593634810253e-14
grad ChooseDest W: 7.597566604614258
grad AddEdge W: 4.961549275134215e-15
grad ChooseDest W: 3.217163324356079
grad AddEdge W: 9.042450761689164e-14
grad ChooseDest W: 1.6671770811080933
grad AddEdge W: 7.185811461921793e-14
grad ChooseDest W: 5.289989948272705
grad AddEdge W: 1.7772676776453555e-12
grad ChooseDest W: 5.065242767333984
grad AddEdge W: 5.265201798758054e-16
grad ChooseDest W: 3.83778715133667
grad AddEdge W: 2.4233245008646424e-14
grad ChooseDest W: 7.506124973297119
grad AddEdge W: 6.777597824332918e-14
grad ChooseDest W: 3.815629720687866
grad AddEdge W: 9.691404037788509e-14
grad ChooseDest W: 3.066039800643921
grad AddEdge W: 5.187060362395884e-16
grad ChooseDest W: 6.0173020362854
grad AddEdge W: 2.3723270015096887e-09
grad ChooseDest W: 1.0434743165969849
grad AddEdge W: 1.0234812604088643e-14
grad ChooseDest W: 6.028463363647461
grad AddEdge W: 4.342472799260307e-15
grad ChooseDest W: 5.1235809326171875
grad AddEdge W: 1.8007374291782036e-13
grad ChooseDest W: 5.556291580200195
grad AddEdge W: 3.3714659922634994e-15
grad ChooseDest W: 4.611209392547607
grad AddEdge W: 1.7755257941998756e-15
grad ChooseDest W: 3.19976806640625
grad AddEdge W: 4.4288820183415074e-15
grad ChooseDest W: 3.1304821968078613
grad AddEdge W: 1.826605205523628e-14
grad ChooseDest W: 2.994741201400757
grad AddEdge W: 2.3275033904867314e-14
grad ChooseDest W: 3.3807852268218994
grad AddEdge W: 2.6593431588919436e-15
grad ChooseDest W: 3.9988272190093994
grad AddEdge W: 3.62793779393189e-13
grad ChooseDest W: 2.2239811420440674
grad AddEdge W: 1.335262738051679e-13
grad ChooseDest W: 2.6157751083374023
grad AddEdge W: 9.402927048096643e-11
grad ChooseDest W: 2.1965925693511963
grad AddEdge W: 1.553428745229915e-13
grad ChooseDest W: 3.273895502090454
grad AddEdge W: 2.1462175874671034e-15
grad ChooseDest W: 3.268955707550049
grad AddEdge W: 6.023546733017332e-14
grad ChooseDest W: 4.353045463562012
grad AddEdge W: 1.5109235011477097e-15
grad ChooseDest W: 4.23963737487793
grad AddEdge W: 8.147507598059087e-14
grad ChooseDest W: 5.263383388519287
grad AddEdge W: 5.518684772674257e-15
grad ChooseDest W: 5.382590293884277
grad AddEdge W: 3.096761772524142e-15
grad ChooseDest W: 3.3106725215911865
grad AddEdge W: 2.054421027083129e-15
grad ChooseDest W: 6.17168664932251
grad AddEdge W: 1.9414510147100494e-14
grad ChooseDest W: 5.553012371063232
grad AddEdge W: 8.794852866811365e-14
grad ChooseDest W: 3.95350980758667
grad AddEdge W: 1.40561892095388e-13
grad ChooseDest W: 3.8913958072662354
grad AddEdge W: 4.337879763103821e-15
grad ChooseDest W: 5.025172710418701
grad AddEdge W: 3.2680979030288472e-15
grad ChooseDest W: 4.668268203735352
grad AddEdge W: 1.3525292505715738e-14
grad ChooseDest W: 2.938382387161255
grad AddEdge W: 1.3673435815333436e-15
grad ChooseDest W: 3.0759735107421875
grad AddEdge W: 3.2583824351238404e-15
grad ChooseDest W: 2.770505666732788
grad AddEdge W: 6.89880146282143e-14
grad ChooseDest W: 3.751415252685547
grad AddEdge W: 4.513105384199023e-13
grad ChooseDest W: 2.5751845836639404
grad AddEdge W: 1.2483002370493324e-13
grad ChooseDest W: 4.423122406005859
grad AddEdge W: 2.267637642873639e-15
grad ChooseDest W: 4.684915065765381
grad AddEdge W: 2.5435713309359363e-15
grad ChooseDest W: 3.5681662559509277
grad AddEdge W: 1.277909036050259e-14
grad ChooseDest W: 5.513165473937988
grad AddEdge W: 2.2893077102797196e-15
grad ChooseDest W: 4.881152153015137
grad AddEdge W: 1.2600663717196418e-14
grad ChooseDest W: 2.80609130859375
grad AddEdge W: 4.5038075882403075e-15
grad ChooseDest W: 4.999571800231934
grad AddEdge W: 7.104474022018867e-15
grad ChooseDest W: 4.172439098358154
grad AddEdge W: 8.174938908286683e-16
grad ChooseDest W: 4.771806240081787
grad AddEdge W: 1.696503231814325e-15
grad ChooseDest W: 5.113410949707031
grad AddEdge W: 3.090059624328992e-15
grad ChooseDest W: 4.521945953369141
grad AddEdge W: 2.0550964088036222e-14
grad ChooseDest W: 3.8391242027282715
grad AddEdge W: 2.9418733616705384e-13
grad ChooseDest W: 3.161069869995117
grad AddEdge W: 2.8834123673784906e-13
grad ChooseDest W: 3.888977527618408
grad AddEdge W: 3.1341781947524794e-10
grad ChooseDest W: 1.8747689723968506
grad AddEdge W: 9.409742429689061e-11
grad ChooseDest W: 1.6404832601547241
grad AddEdge W: 3.59143917811602e-15
grad ChooseDest W: 2.9098148345947266
grad AddEdge W: 1.7044165015987767e-13
grad ChooseDest W: 3.735025644302368
grad AddEdge W: 4.1086545422475596e-16
grad ChooseDest W: 4.22318172454834
grad AddEdge W: 5.950489124877112e-14
grad ChooseDest W: 2.563061475753784
grad AddEdge W: 1.3587100499876884e-14
grad ChooseDest W: 4.414767742156982
grad AddEdge W: 1.912930805512275e-13
grad ChooseDest W: 1.8573404550552368
grad AddEdge W: 2.631790998238598e-14
grad ChooseDest W: 4.751589775085449
grad AddEdge W: 2.6223225251410104e-15
grad ChooseDest W: 3.1567373275756836
grad AddEdge W: 3.4380155921600805e-14
grad ChooseDest W: 3.9782564640045166
=== Epoch 12: Train Loss: 5.9608, Train Log Prob: 0.0071 ===
Total mismatches: 85669
Predicted valid destination but wrong order: 5497
Epoch 12: Validation Loss: 4.9585, Validation Log Prob: 0.0111
Epoch 12: Edge Precision: 0.3727, Recall: 0.3716, F1: 0.3721, Jaccard: 0.2469
Epoch 12: TP: 2.6010021474588405, FP: 4.398568360773085, FN: 4.420472440944882
Epoch 12: Current Learning Rate: 6e-05
[Epoch 12] ‚è±Ô∏è Total: 3481.15s | Current time: 2025-07-14 23:03:59 | üèãÔ∏è Train: 2979.31s | ‚úÖ Val: 501.85s
grad AddEdge W: 6.319539076066194e-13
grad ChooseDest W: 7.252511024475098
grad AddEdge W: 9.332936814598469e-15
grad ChooseDest W: 6.70091438293457
grad AddEdge W: 1.409434766264778e-15
grad ChooseDest W: 2.857665538787842
grad AddEdge W: 8.146955057291769e-16
grad ChooseDest W: 3.3603103160858154
grad AddEdge W: 1.0167402334014357e-15
grad ChooseDest W: 5.848495006561279
grad AddEdge W: 1.6690211631373644e-14
grad ChooseDest W: 3.755784273147583
grad AddEdge W: 1.707873039768614e-14
grad ChooseDest W: 4.012905120849609
grad AddEdge W: 2.469814666504347e-16
grad ChooseDest W: 4.5269646644592285
grad AddEdge W: 1.8220006666597177e-13
grad ChooseDest W: 3.1012470722198486
grad AddEdge W: 5.257455682455413e-16
grad ChooseDest W: 3.1064016819000244
grad AddEdge W: 3.973483648096179e-15
grad ChooseDest W: 5.455761909484863
grad AddEdge W: 1.82495641354015e-15
grad ChooseDest W: 3.0539050102233887
grad AddEdge W: 1.626142153061689e-14
grad ChooseDest W: 5.478026390075684
grad AddEdge W: 6.8152736804202e-16
grad ChooseDest W: 6.519317150115967
grad AddEdge W: 4.571551165779338e-16
grad ChooseDest W: 2.824512481689453
grad AddEdge W: 2.2931104646964177e-15
grad ChooseDest W: 3.514171600341797
grad AddEdge W: 2.257169874186199e-13
grad ChooseDest W: 3.219282627105713
grad AddEdge W: 5.140345614440545e-13
grad ChooseDest W: 2.480257987976074
grad AddEdge W: 4.3580899692253084e-15
grad ChooseDest W: 2.625056505203247
grad AddEdge W: 1.3185587189362322e-15
grad ChooseDest W: 5.32848596572876
grad AddEdge W: 1.4228101576557522e-15
grad ChooseDest W: 4.80978536605835
grad AddEdge W: 5.191382771525723e-15
grad ChooseDest W: 2.338514804840088
grad AddEdge W: 6.355637858449642e-14
grad ChooseDest W: 3.8366646766662598
grad AddEdge W: 8.613869793367085e-16
grad ChooseDest W: 3.7975330352783203
grad AddEdge W: 2.0932689226595266e-15
grad ChooseDest W: 4.427585124969482
grad AddEdge W: 1.9996395947359307e-15
grad ChooseDest W: 4.140263557434082
grad AddEdge W: 1.1620595436433179e-13
grad ChooseDest W: 5.175389289855957
grad AddEdge W: 1.4052694182191839e-14
grad ChooseDest W: 3.3816797733306885
grad AddEdge W: 3.421696528343337e-15
grad ChooseDest W: 4.271248817443848
grad AddEdge W: 2.4509149050555568e-14
grad ChooseDest W: 5.033267974853516
grad AddEdge W: 1.1109835543326725e-15
grad ChooseDest W: 3.986288547515869
grad AddEdge W: 9.884099459310947e-16
grad ChooseDest W: 4.68283224105835
grad AddEdge W: 1.3035400666869257e-13
grad ChooseDest W: 5.091660499572754
grad AddEdge W: 1.4722202364470557e-15
grad ChooseDest W: 2.556769609451294
grad AddEdge W: 5.58121073313732e-16
grad ChooseDest W: 2.8440334796905518
grad AddEdge W: 1.265599766913511e-13
grad ChooseDest W: 7.063772678375244
grad AddEdge W: 1.7685278197478974e-15
grad ChooseDest W: 2.5920968055725098
grad AddEdge W: 3.92797570186211e-14
grad ChooseDest W: 5.532035827636719
grad AddEdge W: 5.502312049320305e-15
grad ChooseDest W: 4.900084495544434
grad AddEdge W: 1.2827811060353946e-15
grad ChooseDest W: 3.8623032569885254
grad AddEdge W: 3.775115054002916e-14
grad ChooseDest W: 3.2051022052764893
grad AddEdge W: 3.8844630637080435e-12
grad ChooseDest W: 3.3392763137817383
grad AddEdge W: 1.6000880125272097e-15
grad ChooseDest W: 3.9113264083862305
grad AddEdge W: 7.760328986099912e-16
grad ChooseDest W: 3.1593313217163086
grad AddEdge W: 3.7815383420111703e-13
grad ChooseDest W: 3.402985095977783
grad AddEdge W: 1.2134535768849983e-15
grad ChooseDest W: 4.399507999420166
grad AddEdge W: 8.595393040172154e-15
grad ChooseDest W: 3.783742904663086
grad AddEdge W: 5.91989897467932e-16
grad ChooseDest W: 3.6096150875091553
grad AddEdge W: 1.9737054840640334e-16
grad ChooseDest W: 4.176036834716797
grad AddEdge W: 3.3549333016552607e-12
grad ChooseDest W: 6.078022480010986
grad AddEdge W: 2.925575337542341e-10
grad ChooseDest W: 2.6504735946655273
grad AddEdge W: 3.789888403105124e-09
grad ChooseDest W: 1.7932225465774536
grad AddEdge W: 5.728619876947986e-16
grad ChooseDest W: 3.977349042892456
grad AddEdge W: 1.1793501246044088e-15
grad ChooseDest W: 3.229907274246216
grad AddEdge W: 1.0690376357516923e-15
grad ChooseDest W: 2.9463653564453125
grad AddEdge W: 9.022879557223085e-14
grad ChooseDest W: 3.627350330352783
grad AddEdge W: 3.589546737105265e-14
grad ChooseDest W: 4.14192533493042
grad AddEdge W: 8.276476834608026e-13
grad ChooseDest W: 2.3734357357025146
grad AddEdge W: 4.142434279711532e-14
grad ChooseDest W: 2.6507866382598877
grad AddEdge W: 2.9580128629727934e-14
grad ChooseDest W: 4.7979512214660645
grad AddEdge W: 1.0004083499104421e-11
grad ChooseDest W: 2.568265914916992
grad AddEdge W: 1.220953524237343e-15
grad ChooseDest W: 2.80161714553833
grad AddEdge W: 3.7744694454905185e-15
grad ChooseDest W: 3.2597928047180176
grad AddEdge W: 3.398207457683028e-15
grad ChooseDest W: 3.884601593017578
grad AddEdge W: 3.0766828565094786e-15
grad ChooseDest W: 2.9900598526000977
grad AddEdge W: 3.357850890548452e-16
grad ChooseDest W: 3.851985216140747
=== Epoch 13: Train Loss: 5.9422, Train Log Prob: 0.0072 ===
Total mismatches: 85312
Predicted valid destination but wrong order: 5468
Epoch 13: Validation Loss: 4.9878, Validation Log Prob: 0.0108
Epoch 13: Edge Precision: 0.3706, Recall: 0.3695, F1: 0.3700, Jaccard: 0.2449
Epoch 13: TP: 2.5871152469577665, FP: 4.413027916964925, FN: 4.434359341445956
Epoch 13: Current Learning Rate: 6e-05
[Epoch 13] ‚è±Ô∏è Total: 3448.01s | Current time: 2025-07-15 00:01:27 | üèãÔ∏è Train: 2946.89s | ‚úÖ Val: 501.12s
grad AddEdge W: 3.3871335098668853e-13
grad ChooseDest W: 8.353900909423828
grad AddEdge W: 1.7588414156608932e-16
grad ChooseDest W: 2.7723937034606934
grad AddEdge W: 6.305174345957662e-14
grad ChooseDest W: 3.357898712158203
grad AddEdge W: 3.3227920062791835e-14
grad ChooseDest W: 3.8591015338897705
grad AddEdge W: 4.721430257664198e-15
grad ChooseDest W: 6.564271926879883
grad AddEdge W: 2.2429688586057123e-13
grad ChooseDest W: 5.681281089782715
grad AddEdge W: 1.2551958084028314e-10
grad ChooseDest W: 1.323961853981018
grad AddEdge W: 7.769795108681071e-16
grad ChooseDest W: 3.8294482231140137
grad AddEdge W: 9.54656885769796e-14
grad ChooseDest W: 2.7879538536071777
grad AddEdge W: 7.32995366318237e-16
grad ChooseDest W: 2.9590682983398438
grad AddEdge W: 4.645500953722901e-15
grad ChooseDest W: 3.7950639724731445
grad AddEdge W: 7.566574434580227e-16
grad ChooseDest W: 2.898061752319336
grad AddEdge W: 4.350832908570589e-16
grad ChooseDest W: 4.409841537475586
grad AddEdge W: 3.028982704304621e-14
grad ChooseDest W: 4.310818195343018
grad AddEdge W: 3.531650679907718e-14
grad ChooseDest W: 5.225553512573242
grad AddEdge W: 1.0753776773618907e-15
grad ChooseDest W: 4.528324604034424
grad AddEdge W: 1.6502505742130302e-15
grad ChooseDest W: 5.67899227142334
grad AddEdge W: 7.389263354841413e-14
grad ChooseDest W: 3.235748052597046
grad AddEdge W: 1.479293173314866e-15
grad ChooseDest W: 5.258699893951416
grad AddEdge W: 1.942482234971684e-15
grad ChooseDest W: 5.507451057434082
grad AddEdge W: 8.356676285746316e-15
grad ChooseDest W: 3.2466444969177246
grad AddEdge W: 1.5151542520630557e-10
grad ChooseDest W: 2.8647854328155518
grad AddEdge W: 1.3721570537791883e-13
grad ChooseDest W: 2.465555191040039
grad AddEdge W: 3.3176651530186785e-12
grad ChooseDest W: 2.0781455039978027
grad AddEdge W: 7.6020298996754e-14
grad ChooseDest W: 4.333572864532471
grad AddEdge W: 1.0338991219150523e-13
grad ChooseDest W: 6.227042198181152
grad AddEdge W: 3.8451237988132295e-16
grad ChooseDest W: 4.8461833000183105
grad AddEdge W: 1.7915814095941993e-15
grad ChooseDest W: 4.248292446136475
grad AddEdge W: 6.4022549096248455e-15
grad ChooseDest W: 3.2902371883392334
grad AddEdge W: 2.8373072798572666e-14
grad ChooseDest W: 1.8693211078643799
grad AddEdge W: 1.3433038600479805e-16
grad ChooseDest W: 2.8395447731018066
grad AddEdge W: 1.2653252393001412e-15
grad ChooseDest W: 2.878251314163208
grad AddEdge W: 4.135068470614297e-16
grad ChooseDest W: 3.252997636795044
grad AddEdge W: 2.648531736232308e-16
grad ChooseDest W: 3.6814961433410645
grad AddEdge W: 1.9603454059699543e-13
grad ChooseDest W: 2.849968194961548
grad AddEdge W: 9.34761631909086e-16
grad ChooseDest W: 4.74592924118042
grad AddEdge W: 6.3759443722172324e-15
grad ChooseDest W: 4.072972774505615
grad AddEdge W: 2.555797912716373e-13
grad ChooseDest W: 5.698902130126953
grad AddEdge W: 3.504671028823421e-15
grad ChooseDest W: 3.9315967559814453
grad AddEdge W: 2.0348921319127654e-14
grad ChooseDest W: 3.029116630554199
grad AddEdge W: 2.280478027079304e-15
grad ChooseDest W: 4.271371841430664
grad AddEdge W: 6.001798992689988e-13
grad ChooseDest W: 1.4055954217910767
grad AddEdge W: 5.867570020351778e-14
grad ChooseDest W: 4.649353981018066
grad AddEdge W: 1.405706199228765e-13
grad ChooseDest W: 3.2562973499298096
grad AddEdge W: 2.5965987698076077e-15
grad ChooseDest W: 5.558687210083008
grad AddEdge W: 2.7395443676235987e-16
grad ChooseDest W: 5.325232982635498
grad AddEdge W: 1.735187544152784e-15
grad ChooseDest W: 4.9007182121276855
grad AddEdge W: 1.1243243232519277e-15
grad ChooseDest W: 5.254828453063965
grad AddEdge W: 1.5382612718328748e-12
grad ChooseDest W: 4.236730575561523
grad AddEdge W: 1.3281400379982176e-15
grad ChooseDest W: 4.8181962966918945
grad AddEdge W: 7.900978997573901e-14
grad ChooseDest W: 4.581887245178223
grad AddEdge W: 3.3200148817066682e-15
grad ChooseDest W: 3.912158727645874
grad AddEdge W: 1.2256115701725313e-15
grad ChooseDest W: 5.25050687789917
grad AddEdge W: 4.5663051519238135e-14
grad ChooseDest W: 4.502542018890381
grad AddEdge W: 3.852165818978465e-16
grad ChooseDest W: 4.023368835449219
grad AddEdge W: 2.5514101126430065e-14
grad ChooseDest W: 2.875932216644287
grad AddEdge W: 1.406023023432356e-15
grad ChooseDest W: 6.359663009643555
grad AddEdge W: 1.2878334458075297e-15
grad ChooseDest W: 3.783201217651367
grad AddEdge W: 4.2187075637327084e-14
grad ChooseDest W: 3.624497175216675
grad AddEdge W: 3.0234129544566557e-13
grad ChooseDest W: 3.5534892082214355
grad AddEdge W: 2.2983259641900177e-16
grad ChooseDest W: 3.0622870922088623
grad AddEdge W: 9.25930042884539e-16
grad ChooseDest W: 4.8796305656433105
grad AddEdge W: 2.8767827963543935e-12
grad ChooseDest W: 3.3918752670288086
grad AddEdge W: 3.3738309611917926e-16
grad ChooseDest W: 3.596345901489258
grad AddEdge W: 1.7143960616712432e-15
grad ChooseDest W: 2.84405517578125
grad AddEdge W: 7.32078802553925e-15
grad ChooseDest W: 4.095586776733398
=== Epoch 14: Train Loss: 5.9195, Train Log Prob: 0.0074 ===
Total mismatches: 84587
Predicted valid destination but wrong order: 5573
Epoch 14: Validation Loss: 4.9144, Validation Log Prob: 0.0115
Epoch 14: Edge Precision: 0.3705, Recall: 0.3692, F1: 0.3698, Jaccard: 0.2451
Epoch 14: TP: 2.5838224767358624, FP: 4.412168933428776, FN: 4.43765211166786
Epoch 14: Current Learning Rate: 6e-05
[Epoch 14] ‚è±Ô∏è Total: 3432.47s | Current time: 2025-07-15 00:58:39 | üèãÔ∏è Train: 2926.91s | ‚úÖ Val: 505.56s
grad AddEdge W: 1.387961333322238e-13
grad ChooseDest W: 9.397635459899902
grad AddEdge W: 8.724083602881447e-14
grad ChooseDest W: 5.600398540496826
grad AddEdge W: 2.519881852280307e-14
grad ChooseDest W: 4.420560359954834
grad AddEdge W: 6.1106646645655e-15
grad ChooseDest W: 4.957547664642334
grad AddEdge W: 2.74574067833056e-16
grad ChooseDest W: 3.9050493240356445
grad AddEdge W: 4.3682254807688586e-14
grad ChooseDest W: 4.284811973571777
grad AddEdge W: 2.292810191516616e-15
grad ChooseDest W: 4.476356506347656
grad AddEdge W: 9.891375472327862e-16
grad ChooseDest W: 2.827396869659424
grad AddEdge W: 1.98109232604814e-14
grad ChooseDest W: 3.2765097618103027
grad AddEdge W: 1.0346026759513712e-15
grad ChooseDest W: 4.917292594909668
grad AddEdge W: 4.343196538091759e-13
grad ChooseDest W: 1.7634236812591553
grad AddEdge W: 1.1534153521880215e-16
grad ChooseDest W: 4.843832492828369
grad AddEdge W: 5.902946139635617e-16
grad ChooseDest W: 4.2307538986206055
grad AddEdge W: 5.340649797402897e-13
grad ChooseDest W: 3.3040785789489746
grad AddEdge W: 2.2705845763762553e-16
grad ChooseDest W: 3.886310338973999
grad AddEdge W: 1.26368983043723e-15
grad ChooseDest W: 5.625860691070557
grad AddEdge W: 1.8281226226969866e-15
grad ChooseDest W: 5.0769195556640625
grad AddEdge W: 5.76116370863862e-14
grad ChooseDest W: 5.230349063873291
grad AddEdge W: 6.278926065471672e-15
grad ChooseDest W: 3.9744186401367188
grad AddEdge W: 9.06343888286941e-16
grad ChooseDest W: 4.355061054229736
grad AddEdge W: 1.4724561847589968e-10
grad ChooseDest W: 2.5202343463897705
grad AddEdge W: 6.011621525559528e-16
grad ChooseDest W: 3.7356345653533936
grad AddEdge W: 4.944314611053137e-14
grad ChooseDest W: 3.0512161254882812
grad AddEdge W: 2.9507449814721726e-14
grad ChooseDest W: 4.791504859924316
grad AddEdge W: 3.592901580499455e-15
grad ChooseDest W: 5.175398826599121
grad AddEdge W: 5.161662502988938e-15
grad ChooseDest W: 4.089308738708496
grad AddEdge W: 1.5155652205228395e-14
grad ChooseDest W: 3.4234018325805664
grad AddEdge W: 9.908475542873621e-14
grad ChooseDest W: 3.961634397506714
grad AddEdge W: 4.1136642974382714e-14
grad ChooseDest W: 3.9664463996887207
grad AddEdge W: 2.184634851493117e-14
grad ChooseDest W: 3.0188279151916504
grad AddEdge W: 4.881728701833232e-15
grad ChooseDest W: 3.125852346420288
grad AddEdge W: 1.490979648771651e-13
grad ChooseDest W: 2.758509874343872
grad AddEdge W: 5.913073850005723e-13
grad ChooseDest W: 3.575456142425537
grad AddEdge W: 1.9721241529608484e-15
grad ChooseDest W: 4.416644096374512
grad AddEdge W: 7.1311827970488295e-12
grad ChooseDest W: 3.943004608154297
grad AddEdge W: 1.3032249026679113e-14
grad ChooseDest W: 5.295445442199707
grad AddEdge W: 3.3687876740842813e-16
grad ChooseDest W: 4.8501715660095215
grad AddEdge W: 1.1568560000197684e-14
grad ChooseDest W: 4.513688087463379
grad AddEdge W: 6.683373180478168e-16
grad ChooseDest W: 4.5694804191589355
grad AddEdge W: 1.738941869460723e-14
grad ChooseDest W: 2.4152183532714844
grad AddEdge W: 7.7571277309548825e-16
grad ChooseDest W: 6.302179336547852
grad AddEdge W: 2.566740646658657e-16
grad ChooseDest W: 3.190242290496826
grad AddEdge W: 1.6387527372287635e-15
grad ChooseDest W: 2.540147066116333
grad AddEdge W: 7.554830852162138e-16
grad ChooseDest W: 3.1336817741394043
grad AddEdge W: 8.932623114495455e-16
grad ChooseDest W: 6.749887943267822
grad AddEdge W: 6.032797349240886e-16
grad ChooseDest W: 6.535985469818115
grad AddEdge W: 1.012448656270877e-13
grad ChooseDest W: 2.6322786808013916
grad AddEdge W: 8.038732833994639e-16
grad ChooseDest W: 6.516785144805908
grad AddEdge W: 1.382786156832092e-15
grad ChooseDest W: 6.411652565002441
grad AddEdge W: 1.1226915613669767e-15
grad ChooseDest W: 3.3938934803009033
grad AddEdge W: 1.592896618101726e-14
grad ChooseDest W: 6.083347797393799
grad AddEdge W: 9.550356111411723e-14
grad ChooseDest W: 2.8823418617248535
grad AddEdge W: 2.06384448037957e-15
grad ChooseDest W: 3.715446949005127
grad AddEdge W: 7.609686399892221e-15
grad ChooseDest W: 3.99930477142334
grad AddEdge W: 3.212441909163609e-14
grad ChooseDest W: 4.559288024902344
grad AddEdge W: 2.3735245539835415e-13
grad ChooseDest W: 2.6989810466766357
grad AddEdge W: 3.0856637774426265e-14
grad ChooseDest W: 3.8881094455718994
grad AddEdge W: 1.6223042467776796e-14
grad ChooseDest W: 2.2670822143554688
grad AddEdge W: 5.202485171178564e-14
grad ChooseDest W: 5.2451958656311035
grad AddEdge W: 1.8378905981743937e-13
grad ChooseDest W: 3.5420491695404053
grad AddEdge W: 9.641823472440747e-15
grad ChooseDest W: 5.086851119995117
grad AddEdge W: 8.382711706852661e-14
grad ChooseDest W: 4.672513484954834
grad AddEdge W: 1.546211211367679e-13
grad ChooseDest W: 4.028101921081543
grad AddEdge W: 1.6827852791236574e-14
grad ChooseDest W: 4.336300373077393
grad AddEdge W: 1.017733464235386e-14
grad ChooseDest W: 4.118837356567383
grad AddEdge W: 3.2484753789540765e-16
grad ChooseDest W: 4.6672563552856445
=== Epoch 15: Train Loss: 5.8961, Train Log Prob: 0.0075 ===
Total mismatches: 84013
Predicted valid destination but wrong order: 5655
Epoch 15: Validation Loss: 4.7985, Validation Log Prob: 0.0126
Epoch 15: Edge Precision: 0.3686, Recall: 0.3671, F1: 0.3678, Jaccard: 0.2435
Epoch 15: TP: 2.5693629205440227, FP: 4.420329277022191, FN: 4.4521116678596995
Epoch 15: Current Learning Rate: 6e-05
[Epoch 15] ‚è±Ô∏è Total: 3424.63s | Current time: 2025-07-15 01:55:44 | üèãÔ∏è Train: 2923.24s | ‚úÖ Val: 501.39s
grad AddEdge W: 4.7098366873221664e-12
grad ChooseDest W: 8.337841033935547
grad AddEdge W: 5.595157660009454e-16
grad ChooseDest W: 4.9210004806518555
grad AddEdge W: 2.280821202477884e-14
grad ChooseDest W: 4.942612171173096
grad AddEdge W: 2.1401341121366282e-14
grad ChooseDest W: 2.6289467811584473
grad AddEdge W: 4.530668697063636e-15
grad ChooseDest W: 3.9324488639831543
grad AddEdge W: 2.680447281234316e-14
grad ChooseDest W: 4.443894386291504
grad AddEdge W: 5.699767047229187e-12
grad ChooseDest W: 4.148077011108398
grad AddEdge W: 5.318802107187777e-14
grad ChooseDest W: 3.5643393993377686
grad AddEdge W: 3.993575693121525e-15
grad ChooseDest W: 5.264223575592041
grad AddEdge W: 1.0244590328915273e-15
grad ChooseDest W: 5.2548675537109375
grad AddEdge W: 1.968766133193106e-14
grad ChooseDest W: 3.2050576210021973
grad AddEdge W: 3.6036820229290445e-14
grad ChooseDest W: 5.345527172088623
grad AddEdge W: 2.3046142309113152e-15
grad ChooseDest W: 5.202260494232178
grad AddEdge W: 1.6345040284356654e-13
grad ChooseDest W: 3.2311360836029053
grad AddEdge W: 1.2791243589229794e-15
grad ChooseDest W: 4.011279106140137
grad AddEdge W: 1.0841914786945453e-15
grad ChooseDest W: 3.675260066986084
grad AddEdge W: 5.9333341191625255e-12
grad ChooseDest W: 1.667810082435608
grad AddEdge W: 1.4736674337420541e-12
grad ChooseDest W: 3.09364652633667
grad AddEdge W: 6.325138065491499e-15
grad ChooseDest W: 3.5902459621429443
grad AddEdge W: 7.956672811460235e-16
grad ChooseDest W: 3.4026060104370117
grad AddEdge W: 1.385452722429167e-15
grad ChooseDest W: 5.078954219818115
grad AddEdge W: 1.485917942509185e-12
grad ChooseDest W: 1.764387607574463
grad AddEdge W: 4.185217168488353e-13
grad ChooseDest W: 4.356090068817139
grad AddEdge W: 2.8604475559024234e-12
grad ChooseDest W: 4.468122959136963
grad AddEdge W: 3.370115737042281e-14
grad ChooseDest W: 3.5888781547546387
grad AddEdge W: 6.155886998066018e-12
grad ChooseDest W: 4.512126922607422
grad AddEdge W: 2.8919285065104035e-16
grad ChooseDest W: 3.5093002319335938
grad AddEdge W: 1.6549676477567302e-16
grad ChooseDest W: 5.579476833343506
grad AddEdge W: 2.357313359812631e-14
grad ChooseDest W: 3.5135481357574463
grad AddEdge W: 1.4192080399332702e-13
grad ChooseDest W: 3.592031955718994
grad AddEdge W: 1.2529790458796401e-16
grad ChooseDest W: 4.958067893981934
grad AddEdge W: 4.399926874665977e-14
grad ChooseDest W: 4.7545928955078125
grad AddEdge W: 2.7459984939838804e-16
grad ChooseDest W: 3.702141523361206
grad AddEdge W: 3.1892636318323064e-13
grad ChooseDest W: 2.9608588218688965
grad AddEdge W: 1.8369485620117754e-13
grad ChooseDest W: 3.8505609035491943
grad AddEdge W: 4.859107734064741e-16
grad ChooseDest W: 3.764338493347168
grad AddEdge W: 9.34763749491454e-16
grad ChooseDest W: 3.0134055614471436
grad AddEdge W: 4.5240775101845765e-15
grad ChooseDest W: 4.913525104522705
grad AddEdge W: 5.386911619900681e-13
grad ChooseDest W: 3.616939067840576
grad AddEdge W: 8.001944816666846e-15
grad ChooseDest W: 6.932337760925293
grad AddEdge W: 1.076783925696087e-13
grad ChooseDest W: 3.0698752403259277
grad AddEdge W: 2.0848813906575777e-15
grad ChooseDest W: 4.749211311340332
grad AddEdge W: 6.929165730508013e-16
grad ChooseDest W: 5.685798168182373
grad AddEdge W: 9.860604628826597e-14
grad ChooseDest W: 3.4181175231933594
grad AddEdge W: 1.5375853454701965e-15
grad ChooseDest W: 3.828603506088257
grad AddEdge W: 4.635689347578381e-14
grad ChooseDest W: 3.5490283966064453
grad AddEdge W: 2.339683724268248e-15
grad ChooseDest W: 7.248685359954834
grad AddEdge W: 5.922109201276062e-16
grad ChooseDest W: 4.07716178894043
grad AddEdge W: 1.5620725809313736e-14
grad ChooseDest W: 4.562410831451416
grad AddEdge W: 8.496844991923852e-15
grad ChooseDest W: 2.255143165588379
grad AddEdge W: 2.0535784444469796e-12
grad ChooseDest W: 2.9872844219207764
grad AddEdge W: 6.639249646068915e-16
grad ChooseDest W: 4.113811016082764
grad AddEdge W: 3.579211834005931e-15
grad ChooseDest W: 4.5811591148376465
grad AddEdge W: 1.8639722333983408e-15
grad ChooseDest W: 4.88733434677124
grad AddEdge W: 3.5592848545261814e-16
grad ChooseDest W: 2.8763697147369385
grad AddEdge W: 7.398448982462089e-16
grad ChooseDest W: 5.301563739776611
grad AddEdge W: 4.730722039688988e-14
grad ChooseDest W: 3.093923807144165
grad AddEdge W: 5.013979682833014e-14
grad ChooseDest W: 4.040931224822998
grad AddEdge W: 2.1770055675036823e-16
grad ChooseDest W: 5.241836071014404
grad AddEdge W: 2.9046989575583606e-15
grad ChooseDest W: 4.513384819030762
grad AddEdge W: 3.954155626789257e-15
grad ChooseDest W: 5.860414505004883
grad AddEdge W: 1.0559811353247003e-13
grad ChooseDest W: 2.1237480640411377
grad AddEdge W: 5.4018292719413565e-16
grad ChooseDest W: 3.883375644683838
grad AddEdge W: 1.2529852609838906e-14
grad ChooseDest W: 3.2300851345062256
grad AddEdge W: 4.963515238604792e-15
grad ChooseDest W: 5.032867908477783
grad AddEdge W: 2.860771405397279e-15
grad ChooseDest W: 3.9946274757385254
=== Epoch 16: Train Loss: 5.8637, Train Log Prob: 0.0077 ===
Total mismatches: 83390
Predicted valid destination but wrong order: 5650
Epoch 16: Validation Loss: 4.7987, Validation Log Prob: 0.0128
Epoch 16: Edge Precision: 0.3686, Recall: 0.3666, F1: 0.3675, Jaccard: 0.2433
Epoch 16: TP: 2.5647816750178953, FP: 4.417609162491052, FN: 4.456692913385827
Epoch 16: Current Learning Rate: 6e-05
[Epoch 16] ‚è±Ô∏è Total: 3433.62s | Current time: 2025-07-15 02:52:58 | üèãÔ∏è Train: 2932.86s | ‚úÖ Val: 500.75s
grad AddEdge W: 7.593139441861019e-14
grad ChooseDest W: 10.781487464904785
grad AddEdge W: 3.897474045431483e-14
grad ChooseDest W: 6.897789478302002
grad AddEdge W: 6.220900602815608e-16
grad ChooseDest W: 3.5369675159454346
grad AddEdge W: 2.378190689083376e-14
grad ChooseDest W: 2.372734308242798
grad AddEdge W: 6.585166168870255e-14
grad ChooseDest W: 2.9687483310699463
grad AddEdge W: 4.0782901686818585e-14
grad ChooseDest W: 4.373599529266357
grad AddEdge W: 1.9444109819321414e-16
grad ChooseDest W: 4.502274036407471
grad AddEdge W: 4.0591588792472655e-13
grad ChooseDest W: 5.7433319091796875
grad AddEdge W: 8.495650463709987e-16
grad ChooseDest W: 3.351449728012085
grad AddEdge W: 1.607023306541091e-15
grad ChooseDest W: 2.429025173187256
grad AddEdge W: 7.990106790075138e-17
grad ChooseDest W: 5.898176193237305
grad AddEdge W: 4.556397322836485e-15
grad ChooseDest W: 6.474327564239502
grad AddEdge W: 8.343700757433917e-14
grad ChooseDest W: 5.19085168838501
grad AddEdge W: 4.773934336053584e-16
grad ChooseDest W: 5.63533353805542
grad AddEdge W: 5.504098045394645e-12
grad ChooseDest W: 2.1295337677001953
grad AddEdge W: 2.6016642385904253e-14
grad ChooseDest W: 4.524106979370117
grad AddEdge W: 2.56664937885859e-15
grad ChooseDest W: 4.639366149902344
grad AddEdge W: 3.016819279418314e-16
grad ChooseDest W: 3.3711178302764893
grad AddEdge W: 1.618514458741338e-12
grad ChooseDest W: 2.5624403953552246
grad AddEdge W: 2.201457603451945e-14
grad ChooseDest W: 3.571744918823242
grad AddEdge W: 3.0507455959338087e-16
grad ChooseDest W: 3.655731439590454
grad AddEdge W: 4.017612794098707e-15
grad ChooseDest W: 3.219822883605957
grad AddEdge W: 3.580782995419793e-14
grad ChooseDest W: 5.44130802154541
grad AddEdge W: 9.822013638343102e-15
grad ChooseDest W: 4.054024696350098
grad AddEdge W: 2.8993855728197935e-16
grad ChooseDest W: 4.165075778961182
grad AddEdge W: 2.0258996913315348e-14
grad ChooseDest W: 3.960175037384033
grad AddEdge W: 8.818331900131249e-16
grad ChooseDest W: 4.853760242462158
grad AddEdge W: 3.5301836611947206e-15
grad ChooseDest W: 2.7284939289093018
grad AddEdge W: 3.5861422575803655e-15
grad ChooseDest W: 3.6346218585968018
grad AddEdge W: 1.526442441760609e-16
grad ChooseDest W: 2.0077807903289795
grad AddEdge W: 1.528398786113279e-14
grad ChooseDest W: 5.123549938201904
grad AddEdge W: 1.0906944682679718e-15
grad ChooseDest W: 6.7927446365356445
grad AddEdge W: 4.068539855958984e-16
grad ChooseDest W: 7.166441917419434
grad AddEdge W: 2.52944112730984e-15
grad ChooseDest W: 5.095441818237305
grad AddEdge W: 5.511835558383641e-16
grad ChooseDest W: 4.031249046325684
grad AddEdge W: 2.2275875534352035e-14
grad ChooseDest W: 4.120457649230957
grad AddEdge W: 8.040551053743392e-14
grad ChooseDest W: 6.020727157592773
grad AddEdge W: 3.838879948382104e-15
grad ChooseDest W: 5.609988212585449
grad AddEdge W: 5.026067520616691e-14
grad ChooseDest W: 3.065845489501953
grad AddEdge W: 4.4233807511073276e-16
grad ChooseDest W: 3.5072600841522217
grad AddEdge W: 3.2478682829122085e-13
grad ChooseDest W: 4.423065662384033
grad AddEdge W: 3.864219531922279e-14
grad ChooseDest W: 3.4798707962036133
grad AddEdge W: 1.5459587955493972e-14
grad ChooseDest W: 4.169605731964111
grad AddEdge W: 2.4156200585830068e-14
grad ChooseDest W: 5.080641269683838
grad AddEdge W: 1.042758544442246e-12
grad ChooseDest W: 3.151068687438965
grad AddEdge W: 8.294299492020429e-13
grad ChooseDest W: 3.791417121887207
grad AddEdge W: 9.18296038168731e-13
grad ChooseDest W: 2.8482234477996826
grad AddEdge W: 4.43602324724069e-16
grad ChooseDest W: 4.999269962310791
grad AddEdge W: 1.7980071709386598e-14
grad ChooseDest W: 4.187023162841797
grad AddEdge W: 5.174183873410843e-16
grad ChooseDest W: 6.598361492156982
grad AddEdge W: 1.942782042283365e-14
grad ChooseDest W: 5.732690334320068
grad AddEdge W: 1.0075230326276512e-15
grad ChooseDest W: 4.512599468231201
grad AddEdge W: 1.6937004792011993e-16
grad ChooseDest W: 4.556278228759766
grad AddEdge W: 5.619786201742057e-16
grad ChooseDest W: 5.427542209625244
grad AddEdge W: 1.1497666518886051e-15
grad ChooseDest W: 3.0357069969177246
grad AddEdge W: 2.90268229916589e-14
grad ChooseDest W: 3.2693419456481934
grad AddEdge W: 3.0607450845739417e-16
grad ChooseDest W: 4.753654479980469
grad AddEdge W: 5.079382146009129e-14
grad ChooseDest W: 3.104837656021118
grad AddEdge W: 3.772186352884489e-14
grad ChooseDest W: 5.222176551818848
grad AddEdge W: 2.6384159817322526e-14
grad ChooseDest W: 4.899641513824463
grad AddEdge W: 2.629074648280048e-15
grad ChooseDest W: 5.499079704284668
grad AddEdge W: 2.0604869264799486e-14
grad ChooseDest W: 4.167825222015381
grad AddEdge W: 1.7947016672136473e-15
grad ChooseDest W: 6.80824089050293
grad AddEdge W: 4.0928194167122456e-10
grad ChooseDest W: 4.324456691741943
grad AddEdge W: 4.871279597516785e-16
grad ChooseDest W: 4.4355950355529785
grad AddEdge W: 1.921549086229715e-15
grad ChooseDest W: 3.8703465461730957
=== Epoch 17: Train Loss: 5.8283, Train Log Prob: 0.0080 ===
Total mismatches: 82608
Predicted valid destination but wrong order: 5685
Epoch 17: Validation Loss: 4.7274, Validation Log Prob: 0.0133
Epoch 17: Edge Precision: 0.3702, Recall: 0.3686, F1: 0.3693, Jaccard: 0.2445
Epoch 17: TP: 2.578954903364352, FP: 4.410737294201861, FN: 4.44251968503937
Epoch 17: Current Learning Rate: 6e-05
[Epoch 17] ‚è±Ô∏è Total: 3430.73s | Current time: 2025-07-15 03:50:08 | üèãÔ∏è Train: 2927.99s | ‚úÖ Val: 502.74s
grad AddEdge W: 6.138691714240724e-14
grad ChooseDest W: 6.842925071716309
grad AddEdge W: 2.9788306458273465e-15
grad ChooseDest W: 6.525082111358643
grad AddEdge W: 3.3260588853018013e-15
grad ChooseDest W: 4.460419654846191
grad AddEdge W: 2.6514492776916546e-14
grad ChooseDest W: 6.154424667358398
grad AddEdge W: 2.451775511705791e-16
grad ChooseDest W: 2.678070545196533
grad AddEdge W: 1.2329403109904123e-15
grad ChooseDest W: 3.8183956146240234
grad AddEdge W: 4.788814587354474e-16
grad ChooseDest W: 3.9707095623016357
grad AddEdge W: 5.636859794037885e-13
grad ChooseDest W: 2.503031015396118
grad AddEdge W: 3.773521615622541e-15
grad ChooseDest W: 3.842327117919922
grad AddEdge W: 3.156531011320806e-16
grad ChooseDest W: 3.6996865272521973
grad AddEdge W: 2.5209223052010668e-15
grad ChooseDest W: 3.480044364929199
grad AddEdge W: 2.1890548388184793e-14
grad ChooseDest W: 5.752671241760254
grad AddEdge W: 3.256866076741666e-14
grad ChooseDest W: 4.738946437835693
grad AddEdge W: 1.5224624192299182e-15
grad ChooseDest W: 8.117268562316895
grad AddEdge W: 1.1824776455313796e-13
grad ChooseDest W: 4.173519611358643
grad AddEdge W: 3.171358323062493e-16
grad ChooseDest W: 6.5611796379089355
grad AddEdge W: 6.733669340435594e-14
grad ChooseDest W: 3.224482297897339
grad AddEdge W: 5.747221779260874e-16
grad ChooseDest W: 4.2989182472229
grad AddEdge W: 1.2301139208641023e-16
grad ChooseDest W: 3.3840787410736084
grad AddEdge W: 2.428741784782102e-14
grad ChooseDest W: 1.779540777206421
grad AddEdge W: 2.6343741099145446e-16
grad ChooseDest W: 4.7610979080200195
grad AddEdge W: 1.1630814804238507e-15
grad ChooseDest W: 5.299813747406006
grad AddEdge W: 1.4214739631814586e-15
grad ChooseDest W: 3.9557549953460693
grad AddEdge W: 1.6604521331506426e-15
grad ChooseDest W: 3.7827484607696533
grad AddEdge W: 2.7770472553478864e-13
grad ChooseDest W: 3.401446580886841
grad AddEdge W: 8.239210180137563e-16
grad ChooseDest W: 4.354445934295654
grad AddEdge W: 5.339241411898695e-17
grad ChooseDest W: 4.574176788330078
grad AddEdge W: 7.215653449093098e-14
grad ChooseDest W: 3.6787545680999756
grad AddEdge W: 2.1261511228367648e-14
grad ChooseDest W: 4.8208112716674805
grad AddEdge W: 3.212010610574779e-16
grad ChooseDest W: 5.6036152839660645
grad AddEdge W: 1.311488243757925e-16
grad ChooseDest W: 4.134626865386963
grad AddEdge W: 6.994987813806197e-14
grad ChooseDest W: 4.2651543617248535
grad AddEdge W: 1.0709613534540252e-12
grad ChooseDest W: 7.953822612762451
grad AddEdge W: 9.822561668659975e-15
grad ChooseDest W: 4.184614181518555
grad AddEdge W: 4.964069409910533e-16
grad ChooseDest W: 5.810282230377197
grad AddEdge W: 1.4950195046509445e-15
grad ChooseDest W: 4.854666709899902
grad AddEdge W: 1.2517578625977158e-16
grad ChooseDest W: 5.218302249908447
grad AddEdge W: 1.1428050998533589e-15
grad ChooseDest W: 3.18349289894104
grad AddEdge W: 1.990560910318802e-16
grad ChooseDest W: 6.787498474121094
grad AddEdge W: 4.62546077828474e-11
grad ChooseDest W: 3.4075701236724854
grad AddEdge W: 4.508117927150648e-16
grad ChooseDest W: 4.3697638511657715
grad AddEdge W: 4.1749041018983996e-14
grad ChooseDest W: 3.93965220451355
grad AddEdge W: 9.95432103173717e-15
grad ChooseDest W: 3.865131378173828
grad AddEdge W: 1.7076694553997416e-15
grad ChooseDest W: 5.064882278442383
grad AddEdge W: 4.965656961411925e-15
grad ChooseDest W: 8.67876148223877
grad AddEdge W: 3.1819181769367937e-16
grad ChooseDest W: 5.6132493019104
grad AddEdge W: 3.1663033892519567e-16
grad ChooseDest W: 3.9337997436523438
grad AddEdge W: 1.4437030723327268e-16
grad ChooseDest W: 6.467240810394287
grad AddEdge W: 4.026580162504699e-14
grad ChooseDest W: 8.677011489868164
grad AddEdge W: 5.494250887583263e-13
grad ChooseDest W: 2.657093048095703
grad AddEdge W: 1.8755532913696752e-15
grad ChooseDest W: 4.508501052856445
grad AddEdge W: 2.090485120079255e-12
grad ChooseDest W: 3.199465751647949
grad AddEdge W: 9.202472564897625e-15
grad ChooseDest W: 10.058862686157227
grad AddEdge W: 5.797503454954903e-14
grad ChooseDest W: 6.343859672546387
grad AddEdge W: 1.860390554580876e-15
grad ChooseDest W: 3.192997932434082
grad AddEdge W: 3.0983947504024945e-13
grad ChooseDest W: 3.7157838344573975
grad AddEdge W: 5.888187119925303e-16
grad ChooseDest W: 5.235091686248779
grad AddEdge W: 1.079996315089208e-14
grad ChooseDest W: 3.046316623687744
grad AddEdge W: 3.0153197664038777e-16
grad ChooseDest W: 4.7881269454956055
grad AddEdge W: 1.2764733575563103e-15
grad ChooseDest W: 3.9463984966278076
grad AddEdge W: 5.0461635466968885e-14
grad ChooseDest W: 4.026574611663818
grad AddEdge W: 6.269685020720422e-14
grad ChooseDest W: 3.9881842136383057
grad AddEdge W: 1.6559091778171626e-15
grad ChooseDest W: 4.4434990882873535
grad AddEdge W: 3.994893252870979e-17
grad ChooseDest W: 3.3075714111328125
grad AddEdge W: 2.2460661489267955e-16
grad ChooseDest W: 3.9685122966766357
grad AddEdge W: 1.698797569629762e-12
grad ChooseDest W: 5.445073127746582
=== Epoch 18: Train Loss: 5.7904, Train Log Prob: 0.0083 ===
Total mismatches: 81696
Predicted valid destination but wrong order: 5696
Epoch 18: Validation Loss: 4.6238, Validation Log Prob: 0.0146
Epoch 18: Edge Precision: 0.3683, Recall: 0.3659, F1: 0.3670, Jaccard: 0.2427
Epoch 18: TP: 2.5617752326413745, FP: 4.414030064423765, FN: 4.459699355762348
Epoch 18: Current Learning Rate: 6e-05
[Epoch 18] ‚è±Ô∏è Total: 3422.19s | Current time: 2025-07-15 04:47:11 | üèãÔ∏è Train: 2919.91s | ‚úÖ Val: 502.28s
grad AddEdge W: 3.5661632067501836e-12
grad ChooseDest W: 7.804991245269775
grad AddEdge W: 8.979484153511116e-16
grad ChooseDest W: 5.087738990783691
grad AddEdge W: 1.7828698451382782e-14
grad ChooseDest W: 4.566273212432861
grad AddEdge W: 3.778194272876069e-15
grad ChooseDest W: 5.273906707763672
grad AddEdge W: 1.0299768172681786e-13
grad ChooseDest W: 3.713557720184326
grad AddEdge W: 1.2728093894880197e-14
grad ChooseDest W: 2.4514834880828857
grad AddEdge W: 1.1128795232356534e-13
grad ChooseDest W: 5.409980297088623
grad AddEdge W: 8.070986525137103e-17
grad ChooseDest W: 4.588350296020508
grad AddEdge W: 2.1905371835338657e-16
grad ChooseDest W: 5.471659183502197
grad AddEdge W: 1.8412810677743453e-15
grad ChooseDest W: 3.6803431510925293
grad AddEdge W: 1.7560333426220676e-15
grad ChooseDest W: 5.1055731773376465
grad AddEdge W: 2.5700171818568733e-15
grad ChooseDest W: 4.646568298339844
grad AddEdge W: 2.5379699020557436e-14
grad ChooseDest W: 3.6621601581573486
grad AddEdge W: 1.859421294779333e-14
grad ChooseDest W: 4.002238750457764
grad AddEdge W: 3.565016355903337e-16
grad ChooseDest W: 5.445346355438232
grad AddEdge W: 1.4079300122339807e-15
grad ChooseDest W: 5.200935363769531
grad AddEdge W: 5.4339301477522237e-14
grad ChooseDest W: 4.114417552947998
grad AddEdge W: 3.0543093282407036e-14
grad ChooseDest W: 2.896289825439453
grad AddEdge W: 9.33519754553469e-15
grad ChooseDest W: 6.962832927703857
grad AddEdge W: 4.8311506704867835e-14
grad ChooseDest W: 4.580584526062012
grad AddEdge W: 2.712382762837251e-09
grad ChooseDest W: 3.142864942550659
grad AddEdge W: 1.7746660557584125e-15
grad ChooseDest W: 7.796703338623047
grad AddEdge W: 3.7967354535145515e-16
grad ChooseDest W: 4.900171279907227
grad AddEdge W: 1.4576761513471074e-15
grad ChooseDest W: 5.749896049499512
grad AddEdge W: 1.8619776825657937e-15
grad ChooseDest W: 3.317171335220337
grad AddEdge W: 1.119903234783734e-15
grad ChooseDest W: 5.60090970993042
grad AddEdge W: 1.159383292224491e-14
grad ChooseDest W: 5.257252216339111
grad AddEdge W: 6.776106876939161e-16
grad ChooseDest W: 4.537775993347168
grad AddEdge W: 6.394094488331879e-16
grad ChooseDest W: 3.188854932785034
grad AddEdge W: 2.038718518548692e-15
grad ChooseDest W: 3.8240957260131836
grad AddEdge W: 7.627021352674254e-16
grad ChooseDest W: 3.5463767051696777
grad AddEdge W: 6.399429737108397e-16
grad ChooseDest W: 5.140161514282227
grad AddEdge W: 3.8709859699181254e-14
grad ChooseDest W: 5.6078996658325195
grad AddEdge W: 1.615612326505368e-15
grad ChooseDest W: 4.707590579986572
grad AddEdge W: 1.2220903483316768e-15
grad ChooseDest W: 5.13691520690918
grad AddEdge W: 6.74484119679011e-15
grad ChooseDest W: 3.1693944931030273
grad AddEdge W: 3.0472874251079654e-14
grad ChooseDest W: 5.005810260772705
grad AddEdge W: 2.231672412174985e-16
grad ChooseDest W: 4.8145341873168945
grad AddEdge W: 2.379717733633213e-12
grad ChooseDest W: 2.8034896850585938
grad AddEdge W: 4.0744928432169566e-17
grad ChooseDest W: 4.118395805358887
grad AddEdge W: 2.851581140271217e-14
grad ChooseDest W: 1.9350918531417847
grad AddEdge W: 3.732366995220886e-14
grad ChooseDest W: 5.764289855957031
grad AddEdge W: 2.8065096701148685e-14
grad ChooseDest W: 4.772105693817139
grad AddEdge W: 3.311504106410894e-14
grad ChooseDest W: 4.715546607971191
grad AddEdge W: 6.457563975735547e-13
grad ChooseDest W: 2.9659414291381836
grad AddEdge W: 6.406209282939102e-15
grad ChooseDest W: 4.0530571937561035
grad AddEdge W: 3.375773578316761e-14
grad ChooseDest W: 4.240447521209717
grad AddEdge W: 1.661559205212704e-15
grad ChooseDest W: 3.2643167972564697
grad AddEdge W: 7.523615570473449e-16
grad ChooseDest W: 6.600367069244385
grad AddEdge W: 5.15470105683281e-16
grad ChooseDest W: 4.1475605964660645
grad AddEdge W: 2.7529910156612607e-16
grad ChooseDest W: 5.6569437980651855
grad AddEdge W: 4.1938823833014005e-14
grad ChooseDest W: 2.5943679809570312
grad AddEdge W: 3.3393090746352595e-16
grad ChooseDest W: 4.838903903961182
grad AddEdge W: 1.2524893549570087e-16
grad ChooseDest W: 4.680820465087891
grad AddEdge W: 2.635403700823602e-11
grad ChooseDest W: 3.407292366027832
grad AddEdge W: 2.29277736898991e-16
grad ChooseDest W: 3.1760501861572266
grad AddEdge W: 2.163264820097613e-13
grad ChooseDest W: 3.4535911083221436
grad AddEdge W: 2.7653897780640507e-15
grad ChooseDest W: 3.464859962463379
grad AddEdge W: 3.769863449729939e-14
grad ChooseDest W: 5.215415954589844
grad AddEdge W: 9.460672982934443e-16
grad ChooseDest W: 3.9255619049072266
grad AddEdge W: 3.428539326359378e-14
grad ChooseDest W: 3.641807794570923
grad AddEdge W: 4.207201806990385e-14
grad ChooseDest W: 3.914773464202881
grad AddEdge W: 2.1787534612831977e-13
grad ChooseDest W: 4.575411319732666
grad AddEdge W: 2.0601658162896445e-15
grad ChooseDest W: 3.6771719455718994
grad AddEdge W: 1.064810240848646e-12
grad ChooseDest W: 3.062612771987915
grad AddEdge W: 5.6039859032538594e-14
grad ChooseDest W: 4.13743782043457
=== Epoch 19: Train Loss: 5.7454, Train Log Prob: 0.0087 ===
Total mismatches: 80865
Predicted valid destination but wrong order: 5755
Epoch 19: Validation Loss: 4.5423, Validation Log Prob: 0.0157
Epoch 19: Edge Precision: 0.3716, Recall: 0.3696, F1: 0.3705, Jaccard: 0.2456
Epoch 19: TP: 2.5859699355762347, FP: 4.395991410164639, FN: 4.435504652827487
Epoch 19: Current Learning Rate: 6e-05
[Epoch 19] ‚è±Ô∏è Total: 3428.28s | Current time: 2025-07-15 05:44:19 | üèãÔ∏è Train: 2925.78s | ‚úÖ Val: 502.49s
grad AddEdge W: 5.826729479766965e-15
grad ChooseDest W: 8.83258056640625
grad AddEdge W: 9.309058515358237e-13
grad ChooseDest W: 4.614077568054199
grad AddEdge W: 1.9148516496553345e-16
grad ChooseDest W: 5.506894588470459
grad AddEdge W: 7.745036335632827e-16
grad ChooseDest W: 4.793397903442383
grad AddEdge W: 4.3036719669520415e-16
grad ChooseDest W: 4.930346965789795
grad AddEdge W: 8.525715368777186e-16
grad ChooseDest W: 4.7925214767456055
grad AddEdge W: 9.311265767810543e-17
grad ChooseDest W: 3.0482358932495117
grad AddEdge W: 8.320120037808715e-14
grad ChooseDest W: 5.470865726470947
grad AddEdge W: 9.093203620635926e-16
grad ChooseDest W: 6.455314636230469
grad AddEdge W: 5.43252923996076e-15
grad ChooseDest W: 5.6962127685546875
grad AddEdge W: 2.413657991463987e-14
grad ChooseDest W: 5.518052101135254
grad AddEdge W: 7.989506984869364e-15
grad ChooseDest W: 6.465227127075195
grad AddEdge W: 1.6226516996926434e-14
grad ChooseDest W: 5.196619987487793
grad AddEdge W: 1.245272369548606e-15
grad ChooseDest W: 3.9587345123291016
grad AddEdge W: 4.92231174440208e-14
grad ChooseDest W: 4.13077974319458
grad AddEdge W: 3.4353196556955595e-14
grad ChooseDest W: 4.5565876960754395
grad AddEdge W: 3.240881040367672e-15
grad ChooseDest W: 4.877762794494629
grad AddEdge W: 6.234293252502883e-16
grad ChooseDest W: 2.8299949169158936
grad AddEdge W: 4.617980217991899e-16
grad ChooseDest W: 7.673034191131592
grad AddEdge W: 1.7710463663374396e-16
grad ChooseDest W: 5.467522621154785
grad AddEdge W: 1.2758606350980902e-15
grad ChooseDest W: 4.342022895812988
grad AddEdge W: 7.8619083535082e-16
grad ChooseDest W: 4.2057881355285645
grad AddEdge W: 1.630456430675234e-14
grad ChooseDest W: 2.916597604751587
grad AddEdge W: 5.782534011084667e-14
grad ChooseDest W: 4.429900646209717
grad AddEdge W: 7.75222341019028e-16
grad ChooseDest W: 5.158940315246582
grad AddEdge W: 6.620949990522595e-13
grad ChooseDest W: 2.7024357318878174
grad AddEdge W: 3.5712731871143794e-14
grad ChooseDest W: 5.233813285827637
grad AddEdge W: 3.7358975767758074e-16
grad ChooseDest W: 4.973053455352783
grad AddEdge W: 2.173540752763159e-14
grad ChooseDest W: 3.557396411895752
grad AddEdge W: 8.77545052683365e-13
grad ChooseDest W: 2.06361985206604
grad AddEdge W: 2.0231981220979146e-15
grad ChooseDest W: 4.119086265563965
grad AddEdge W: 2.3807319467438165e-16
grad ChooseDest W: 3.8215906620025635
grad AddEdge W: 1.0216812306926542e-14
grad ChooseDest W: 4.861727237701416
grad AddEdge W: 7.587949501586602e-14
grad ChooseDest W: 4.8266682624816895
grad AddEdge W: 3.403062438778453e-15
grad ChooseDest W: 2.689088821411133
grad AddEdge W: 2.557427519403596e-16
grad ChooseDest W: 3.5079402923583984
grad AddEdge W: 9.57696785373538e-15
grad ChooseDest W: 3.660139322280884
grad AddEdge W: 1.2959436380467239e-14
grad ChooseDest W: 3.5202064514160156
grad AddEdge W: 1.1902756002503921e-14
grad ChooseDest W: 4.64072322845459
grad AddEdge W: 2.6299964318848975e-15
grad ChooseDest W: 2.5558154582977295
grad AddEdge W: 2.271703453960019e-16
grad ChooseDest W: 4.5067138671875
grad AddEdge W: 2.012601369350849e-16
grad ChooseDest W: 4.080755710601807
grad AddEdge W: 1.6895179893263351e-16
grad ChooseDest W: 7.056814193725586
grad AddEdge W: 2.4940284267905915e-16
grad ChooseDest W: 4.270408630371094
grad AddEdge W: 2.4952897753160834e-14
grad ChooseDest W: 3.080225706100464
grad AddEdge W: 4.539321934830809e-13
grad ChooseDest W: 2.668471336364746
grad AddEdge W: 1.1901811349009496e-15
grad ChooseDest W: 5.494768142700195
grad AddEdge W: 6.778591902199815e-14
grad ChooseDest W: 4.166801929473877
grad AddEdge W: 5.1806205958910366e-17
grad ChooseDest W: 3.8094003200531006
grad AddEdge W: 4.869978872547157e-16
grad ChooseDest W: 5.901054859161377
grad AddEdge W: 3.0508662981287924e-16
grad ChooseDest W: 3.944302558898926
grad AddEdge W: 9.976387801730142e-17
grad ChooseDest W: 5.4244465827941895
grad AddEdge W: 1.6005517630658314e-14
grad ChooseDest W: 3.731767177581787
grad AddEdge W: 6.192168631145856e-14
grad ChooseDest W: 3.557813882827759
grad AddEdge W: 1.60085513638622e-13
grad ChooseDest W: 2.8715200424194336
grad AddEdge W: 1.7243681593834444e-14
grad ChooseDest W: 4.570079803466797
grad AddEdge W: 7.90328273660802e-16
grad ChooseDest W: 3.9046924114227295
grad AddEdge W: 8.19242643287834e-15
grad ChooseDest W: 4.348300933837891
grad AddEdge W: 7.676320787786822e-15
grad ChooseDest W: 4.773326396942139
grad AddEdge W: 4.470203165420593e-14
grad ChooseDest W: 3.3538477420806885
grad AddEdge W: 5.288803791615726e-13
grad ChooseDest W: 3.4952023029327393
grad AddEdge W: 2.2984357608358055e-14
grad ChooseDest W: 3.5612313747406006
grad AddEdge W: 1.551611385219604e-14
grad ChooseDest W: 3.143611192703247
grad AddEdge W: 5.614863500362499e-14
grad ChooseDest W: 4.424705505371094
grad AddEdge W: 7.291814585952058e-14
grad ChooseDest W: 4.021823406219482
grad AddEdge W: 2.0182868133114974e-16
grad ChooseDest W: 3.078158140182495
=== Epoch 20: Train Loss: 5.6977, Train Log Prob: 0.0091 ===
Total mismatches: 79974
Predicted valid destination but wrong order: 5832
Epoch 20: Validation Loss: 4.4803, Validation Log Prob: 0.0167
Epoch 20: Edge Precision: 0.3696, Recall: 0.3666, F1: 0.3680, Jaccard: 0.2437
Epoch 20: TP: 2.565926986399427, FP: 4.397852541159628, FN: 4.455547602004295
Epoch 20: Current Learning Rate: 6e-05
[Epoch 20] ‚è±Ô∏è Total: 3433.14s | Current time: 2025-07-15 06:41:32 | üèãÔ∏è Train: 2934.40s | ‚úÖ Val: 498.74s
grad AddEdge W: 3.846540328009823e-13
grad ChooseDest W: 8.681724548339844
grad AddEdge W: 2.9332518029355926e-15
grad ChooseDest W: 5.902212142944336
grad AddEdge W: 4.435719098885155e-14
grad ChooseDest W: 4.700343132019043
grad AddEdge W: 1.5715023446232716e-15
grad ChooseDest W: 4.059940814971924
grad AddEdge W: 2.253893599535317e-11
grad ChooseDest W: 3.157464027404785
grad AddEdge W: 6.139055250193774e-17
grad ChooseDest W: 3.379595994949341
grad AddEdge W: 9.584291088839104e-16
grad ChooseDest W: 5.235706329345703
grad AddEdge W: 3.0619220368541516e-15
grad ChooseDest W: 5.060013771057129
grad AddEdge W: 5.564341712003748e-14
grad ChooseDest W: 7.829411506652832
grad AddEdge W: 1.1397258174527343e-15
grad ChooseDest W: 3.91566801071167
grad AddEdge W: 1.3037584063697394e-15
grad ChooseDest W: 3.8985443115234375
grad AddEdge W: 3.331676248989314e-16
grad ChooseDest W: 5.316924095153809
grad AddEdge W: 5.267877469959312e-14
grad ChooseDest W: 3.503892421722412
grad AddEdge W: 8.083160029715483e-15
grad ChooseDest W: 4.663650989532471
grad AddEdge W: 1.859640983362115e-16
grad ChooseDest W: 4.447920322418213
grad AddEdge W: 6.0097775348333556e-15
grad ChooseDest W: 4.028735637664795
grad AddEdge W: 5.884295871741441e-14
grad ChooseDest W: 3.6707046031951904
grad AddEdge W: 1.9989232166207904e-14
grad ChooseDest W: 4.12580680847168
grad AddEdge W: 3.967412592386293e-16
grad ChooseDest W: 4.06453275680542
grad AddEdge W: 3.353274053897082e-15
grad ChooseDest W: 4.6154046058654785
grad AddEdge W: 2.9259842602481507e-16
grad ChooseDest W: 4.556180477142334
grad AddEdge W: 4.537188097900415e-16
grad ChooseDest W: 4.605488300323486
grad AddEdge W: 7.192883085888535e-16
grad ChooseDest W: 5.830320358276367
grad AddEdge W: 1.614795389697521e-16
grad ChooseDest W: 6.9999823570251465
grad AddEdge W: 3.949473652173309e-15
grad ChooseDest W: 3.5536763668060303
grad AddEdge W: 1.0935565925967441e-15
grad ChooseDest W: 4.0080389976501465
grad AddEdge W: 3.6356427571387884e-16
grad ChooseDest W: 5.411686420440674
grad AddEdge W: 1.317424088657232e-13
grad ChooseDest W: 3.809375762939453
grad AddEdge W: 3.3428056329942724e-12
grad ChooseDest W: 2.4550576210021973
grad AddEdge W: 8.058600309409844e-15
grad ChooseDest W: 4.722753047943115
grad AddEdge W: 9.032010572394486e-14
grad ChooseDest W: 3.5760505199432373
grad AddEdge W: 7.379094385496447e-15
grad ChooseDest W: 6.033874034881592
grad AddEdge W: 5.767536795375783e-11
grad ChooseDest W: 4.526337623596191
grad AddEdge W: 3.8199023340175487e-16
grad ChooseDest W: 4.6793718338012695
grad AddEdge W: 1.0964885839087751e-16
grad ChooseDest W: 3.447763442993164
grad AddEdge W: 1.216886072024628e-15
grad ChooseDest W: 4.329423904418945
grad AddEdge W: 1.1300560469752318e-14
grad ChooseDest W: 5.233036994934082
grad AddEdge W: 4.506211467744615e-15
grad ChooseDest W: 2.9646754264831543
grad AddEdge W: 2.711669604138489e-11
grad ChooseDest W: 2.409306287765503
grad AddEdge W: 2.6973206654345994e-11
grad ChooseDest W: 3.739168882369995
grad AddEdge W: 3.0678819724292697e-15
grad ChooseDest W: 3.732685089111328
grad AddEdge W: 5.2617521247314626e-17
grad ChooseDest W: 3.5325918197631836
grad AddEdge W: 9.717424551114982e-16
grad ChooseDest W: 3.727363109588623
grad AddEdge W: 1.1245342815437284e-15
grad ChooseDest W: 7.599422454833984
grad AddEdge W: 3.445657523410209e-14
grad ChooseDest W: 4.778893947601318
grad AddEdge W: 1.6618100328442097e-14
grad ChooseDest W: 5.733921527862549
grad AddEdge W: 7.094742884004336e-15
grad ChooseDest W: 4.249529838562012
grad AddEdge W: 1.9588845250694513e-16
grad ChooseDest W: 4.811396598815918
grad AddEdge W: 3.650160160700898e-15
grad ChooseDest W: 4.432509422302246
grad AddEdge W: 6.150378600508488e-13
grad ChooseDest W: 2.1667861938476562
grad AddEdge W: 7.867076842673227e-16
grad ChooseDest W: 4.0945048332214355
grad AddEdge W: 3.2367236332559585e-14
grad ChooseDest W: 5.831142902374268
grad AddEdge W: 6.322142787583418e-13
grad ChooseDest W: 2.487403154373169
grad AddEdge W: 9.742991393594906e-15
grad ChooseDest W: 4.315813064575195
grad AddEdge W: 2.898282841801587e-16
grad ChooseDest W: 4.275964736938477
grad AddEdge W: 2.1644995230841665e-15
grad ChooseDest W: 6.251040458679199
grad AddEdge W: 1.346763412596319e-14
grad ChooseDest W: 2.0308215618133545
grad AddEdge W: 3.610323354158581e-15
grad ChooseDest W: 3.67448353767395
grad AddEdge W: 1.837097201470942e-16
grad ChooseDest W: 2.1221184730529785
grad AddEdge W: 1.8146542694400512e-16
grad ChooseDest W: 6.216495990753174
grad AddEdge W: 3.462078294708094e-16
grad ChooseDest W: 4.384568691253662
grad AddEdge W: 9.353619665104524e-15
grad ChooseDest W: 3.496647834777832
grad AddEdge W: 2.714920590451324e-16
grad ChooseDest W: 4.864415168762207
grad AddEdge W: 5.5032355931654983e-17
grad ChooseDest W: 4.3952789306640625
grad AddEdge W: 2.5983084634599932e-14
grad ChooseDest W: 3.5394601821899414
grad AddEdge W: 2.2164220074761447e-15
grad ChooseDest W: 5.105273246765137
=== Epoch 21: Train Loss: 5.6488, Train Log Prob: 0.0096 ===
Total mismatches: 79199
Predicted valid destination but wrong order: 5773
Epoch 21: Validation Loss: 4.4635, Validation Log Prob: 0.0168
Epoch 21: Edge Precision: 0.3691, Recall: 0.3657, F1: 0.3673, Jaccard: 0.2428
Epoch 21: TP: 2.5589119541875447, FP: 4.397566213314245, FN: 4.4625626342161775
Epoch 21: Current Learning Rate: 6e-05
[Epoch 21] ‚è±Ô∏è Total: 3434.04s | Current time: 2025-07-15 07:38:46 | üèãÔ∏è Train: 2930.48s | ‚úÖ Val: 503.55s
grad AddEdge W: 1.2058553313591246e-14
grad ChooseDest W: 7.669403076171875
grad AddEdge W: 2.0632729872500574e-14
grad ChooseDest W: 4.940892696380615
grad AddEdge W: 1.418251468685277e-14
grad ChooseDest W: 4.438207149505615
grad AddEdge W: 1.6573294138416916e-16
grad ChooseDest W: 4.770553112030029
grad AddEdge W: 1.9444217286626597e-15
grad ChooseDest W: 3.037752151489258
grad AddEdge W: 4.036309855269264e-17
grad ChooseDest W: 4.55259895324707
grad AddEdge W: 1.4446629724202027e-14
grad ChooseDest W: 6.308208465576172
grad AddEdge W: 1.6423342042879915e-15
grad ChooseDest W: 2.970604181289673
grad AddEdge W: 8.470400623310573e-15
grad ChooseDest W: 4.754011631011963
grad AddEdge W: 1.2701378687482033e-15
grad ChooseDest W: 4.52923583984375
grad AddEdge W: 2.593180250711608e-16
grad ChooseDest W: 4.689740180969238
grad AddEdge W: 1.0576733652752958e-16
grad ChooseDest W: 3.853583574295044
grad AddEdge W: 6.788066982154391e-16
grad ChooseDest W: 3.5111541748046875
grad AddEdge W: 9.341036990673061e-15
grad ChooseDest W: 3.9734838008880615
grad AddEdge W: 7.703094440458347e-16
grad ChooseDest W: 5.480982303619385
grad AddEdge W: 6.825917919951871e-15
grad ChooseDest W: 4.476840972900391
grad AddEdge W: 4.902830516010823e-16
grad ChooseDest W: 5.111479759216309
grad AddEdge W: 3.570850824723143e-16
grad ChooseDest W: 4.899351596832275
grad AddEdge W: 8.51773631841405e-16
grad ChooseDest W: 4.543961524963379
grad AddEdge W: 1.9997210422477652e-16
grad ChooseDest W: 6.177437782287598
grad AddEdge W: 3.725454189931754e-14
grad ChooseDest W: 3.370283842086792
grad AddEdge W: 9.286277369424255e-16
grad ChooseDest W: 5.582481861114502
grad AddEdge W: 2.585919081947094e-14
grad ChooseDest W: 4.378429412841797
grad AddEdge W: 6.17517240683943e-14
grad ChooseDest W: 3.431206226348877
grad AddEdge W: 1.1220078787236003e-14
grad ChooseDest W: 3.905848503112793
grad AddEdge W: 6.171223179250328e-16
grad ChooseDest W: 5.832200050354004
grad AddEdge W: 2.235733670459273e-16
grad ChooseDest W: 5.467118740081787
grad AddEdge W: 1.1660345549153344e-15
grad ChooseDest W: 5.2628984451293945
grad AddEdge W: 1.844819097925247e-16
grad ChooseDest W: 4.890918731689453
grad AddEdge W: 4.211990973625808e-16
grad ChooseDest W: 4.224945068359375
grad AddEdge W: 4.324662766873983e-16
grad ChooseDest W: 5.402838706970215
grad AddEdge W: 2.8191858993353554e-15
grad ChooseDest W: 4.9993391036987305
grad AddEdge W: 5.119930883743613e-16
grad ChooseDest W: 3.3524794578552246
grad AddEdge W: 3.619363048590357e-16
grad ChooseDest W: 5.315957546234131
grad AddEdge W: 2.8682240501946843e-13
grad ChooseDest W: 4.461704254150391
grad AddEdge W: 5.253086580634357e-15
grad ChooseDest W: 3.1594038009643555
grad AddEdge W: 1.401661566083649e-14
grad ChooseDest W: 3.369147300720215
grad AddEdge W: 1.0889462187346186e-16
grad ChooseDest W: 5.205817699432373
grad AddEdge W: 2.1931118989957228e-16
grad ChooseDest W: 5.674665451049805
grad AddEdge W: 1.179676417577559e-16
grad ChooseDest W: 3.9015376567840576
grad AddEdge W: 2.3697059600507296e-15
grad ChooseDest W: 5.490379810333252
grad AddEdge W: 1.1772953285534883e-14
grad ChooseDest W: 4.732602596282959
grad AddEdge W: 6.183359573197706e-15
grad ChooseDest W: 3.319657802581787
grad AddEdge W: 6.296277138349482e-17
grad ChooseDest W: 5.81646203994751
grad AddEdge W: 1.709155257068344e-16
grad ChooseDest W: 4.873421669006348
grad AddEdge W: 1.2261095726059576e-16
grad ChooseDest W: 4.385430812835693
grad AddEdge W: 6.23841840883513e-15
grad ChooseDest W: 5.917330741882324
grad AddEdge W: 1.1744311713456426e-14
grad ChooseDest W: 6.409167289733887
grad AddEdge W: 4.117742388384804e-13
grad ChooseDest W: 3.3317689895629883
grad AddEdge W: 1.2097114488514998e-14
grad ChooseDest W: 3.6853649616241455
grad AddEdge W: 6.50541288174902e-17
grad ChooseDest W: 7.689567565917969
grad AddEdge W: 1.6453776466070354e-16
grad ChooseDest W: 4.727071285247803
grad AddEdge W: 8.861194414240276e-16
grad ChooseDest W: 6.883961200714111
grad AddEdge W: 9.385205523707637e-15
grad ChooseDest W: 5.013200283050537
grad AddEdge W: 1.862727359663673e-16
grad ChooseDest W: 5.533825874328613
grad AddEdge W: 2.771050711008788e-15
grad ChooseDest W: 3.778346538543701
grad AddEdge W: 1.3488724399316875e-16
grad ChooseDest W: 4.823480606079102
grad AddEdge W: 1.0306489776164943e-16
grad ChooseDest W: 4.0936760902404785
grad AddEdge W: 2.533952265968239e-16
grad ChooseDest W: 5.319764137268066
grad AddEdge W: 4.8468148375454675e-17
grad ChooseDest W: 3.6382687091827393
grad AddEdge W: 1.8687614106216758e-16
grad ChooseDest W: 5.886864185333252
grad AddEdge W: 1.690499091707272e-16
grad ChooseDest W: 3.9931507110595703
grad AddEdge W: 6.904592457675218e-15
grad ChooseDest W: 4.841777801513672
grad AddEdge W: 3.3333163165334353e-16
grad ChooseDest W: 6.303417205810547
grad AddEdge W: 4.60180930023763e-15
grad ChooseDest W: 4.567991256713867
grad AddEdge W: 5.86463854520045e-16
grad ChooseDest W: 4.92597770690918
=== Epoch 22: Train Loss: 5.5959, Train Log Prob: 0.0101 ===
Total mismatches: 78159
Predicted valid destination but wrong order: 5839
Epoch 22: Validation Loss: 4.3166, Validation Log Prob: 0.0193
Epoch 22: Edge Precision: 0.3670, Recall: 0.3632, F1: 0.3649, Jaccard: 0.2410
Epoch 22: TP: 2.540586972083035, FP: 4.407301360057265, FN: 4.480887616320687
Epoch 22: Current Learning Rate: 6e-05
[Epoch 22] ‚è±Ô∏è Total: 3423.85s | Current time: 2025-07-15 08:35:50 | üèãÔ∏è Train: 2923.26s | ‚úÖ Val: 500.59s
grad AddEdge W: 5.705109101068404e-14
grad ChooseDest W: 7.258340835571289
grad AddEdge W: 4.708418561044951e-15
grad ChooseDest W: 4.542409896850586
grad AddEdge W: 4.785602214902012e-16
grad ChooseDest W: 5.0697526931762695
grad AddEdge W: 7.415992834744738e-15
grad ChooseDest W: 2.796937942504883
grad AddEdge W: 2.8310975525719373e-12
grad ChooseDest W: 3.9865124225616455
grad AddEdge W: 8.972937647620024e-16
grad ChooseDest W: 6.4593281745910645
grad AddEdge W: 5.109502231037677e-13
grad ChooseDest W: 2.174208164215088
grad AddEdge W: 3.9932542441180417e-16
grad ChooseDest W: 4.2331976890563965
grad AddEdge W: 4.847689200540161e-16
grad ChooseDest W: 3.8932249546051025
grad AddEdge W: 2.67529691857436e-16
grad ChooseDest W: 5.322725772857666
grad AddEdge W: 5.11129241823104e-15
grad ChooseDest W: 4.951874256134033
grad AddEdge W: 5.6433241462034225e-14
grad ChooseDest W: 4.3546552658081055
grad AddEdge W: 5.750339440724339e-12
grad ChooseDest W: 4.167056083679199
grad AddEdge W: 1.3598094987532245e-14
grad ChooseDest W: 4.710540294647217
grad AddEdge W: 6.533055537284867e-16
grad ChooseDest W: 4.489696979522705
grad AddEdge W: 3.6527991447876283e-16
grad ChooseDest W: 5.1276960372924805
grad AddEdge W: 4.128322304234461e-13
grad ChooseDest W: 3.7989718914031982
grad AddEdge W: 4.468277732476542e-16
grad ChooseDest W: 4.67899751663208
grad AddEdge W: 6.029903672934828e-16
grad ChooseDest W: 4.465158939361572
grad AddEdge W: 4.628343136705963e-16
grad ChooseDest W: 4.370821475982666
grad AddEdge W: 1.5204176816952463e-15
grad ChooseDest W: 7.377047538757324
grad AddEdge W: 8.420742469744842e-15
grad ChooseDest W: 7.2310872077941895
grad AddEdge W: 3.291695235087727e-16
grad ChooseDest W: 4.860343933105469
grad AddEdge W: 5.739959424650234e-14
grad ChooseDest W: 4.123069763183594
grad AddEdge W: 2.08674600134206e-16
grad ChooseDest W: 8.59118366241455
grad AddEdge W: 7.657361146402617e-17
grad ChooseDest W: 3.676464796066284
grad AddEdge W: 2.5043376118520644e-16
grad ChooseDest W: 5.084933280944824
grad AddEdge W: 6.847358229671008e-16
grad ChooseDest W: 4.504322052001953
grad AddEdge W: 9.658642836267786e-14
grad ChooseDest W: 7.8061957359313965
grad AddEdge W: 3.979556027295045e-15
grad ChooseDest W: 4.5675482749938965
grad AddEdge W: 1.4382100636697826e-16
grad ChooseDest W: 3.77651047706604
grad AddEdge W: 2.6786579850137345e-17
grad ChooseDest W: 4.070044994354248
grad AddEdge W: 7.369244239352826e-15
grad ChooseDest W: 4.957289218902588
grad AddEdge W: 2.5620832889377383e-16
grad ChooseDest W: 3.5669875144958496
grad AddEdge W: 1.927025975855673e-13
grad ChooseDest W: 3.1861913204193115
grad AddEdge W: 5.872136374970426e-16
grad ChooseDest W: 4.0841498374938965
grad AddEdge W: 1.6090816230726986e-16
grad ChooseDest W: 5.4614458084106445
grad AddEdge W: 7.674432920753982e-13
grad ChooseDest W: 3.797814130783081
grad AddEdge W: 9.379801453504154e-16
grad ChooseDest W: 3.369608163833618
grad AddEdge W: 1.6865856671420591e-16
grad ChooseDest W: 6.318904399871826
grad AddEdge W: 5.653526038660258e-17
grad ChooseDest W: 5.186418533325195
grad AddEdge W: 1.4927724850605565e-16
grad ChooseDest W: 8.190242767333984
grad AddEdge W: 1.1719809909028556e-16
grad ChooseDest W: 7.020756721496582
grad AddEdge W: 6.909612398437121e-15
grad ChooseDest W: 5.83888578414917
grad AddEdge W: 7.235699013185464e-16
grad ChooseDest W: 3.519475221633911
grad AddEdge W: 3.742734475207371e-13
grad ChooseDest W: 3.640077829360962
grad AddEdge W: 7.0472179829162655e-15
grad ChooseDest W: 3.1484127044677734
grad AddEdge W: 5.355587096372784e-16
grad ChooseDest W: 3.959096908569336
grad AddEdge W: 1.3482394945618517e-15
grad ChooseDest W: 4.146885871887207
grad AddEdge W: 3.6217426817765493e-16
grad ChooseDest W: 6.608999729156494
grad AddEdge W: 4.947442802660795e-11
grad ChooseDest W: 2.053590774536133
grad AddEdge W: 7.94203343515372e-16
grad ChooseDest W: 5.40413236618042
grad AddEdge W: 1.2279003590751308e-15
grad ChooseDest W: 5.188108444213867
grad AddEdge W: 1.6552371101130755e-16
grad ChooseDest W: 4.426377773284912
grad AddEdge W: 8.145894169701157e-14
grad ChooseDest W: 2.7975974082946777
grad AddEdge W: 3.260068877721824e-14
grad ChooseDest W: 3.8123414516448975
grad AddEdge W: 8.981339155665602e-17
grad ChooseDest W: 4.524471282958984
grad AddEdge W: 5.4096301277482134e-14
grad ChooseDest W: 6.124996185302734
grad AddEdge W: 7.993475863622842e-16
grad ChooseDest W: 4.447314262390137
grad AddEdge W: 4.005256700980635e-16
grad ChooseDest W: 5.04748010635376
grad AddEdge W: 1.1038013290388428e-14
grad ChooseDest W: 7.460440158843994
grad AddEdge W: 4.2854145423508894e-15
grad ChooseDest W: 4.660275936126709
grad AddEdge W: 5.611541924187312e-16
grad ChooseDest W: 4.572000980377197
grad AddEdge W: 2.1107490145370715e-14
grad ChooseDest W: 5.458484649658203
grad AddEdge W: 5.053468972932896e-16
grad ChooseDest W: 3.287832260131836
grad AddEdge W: 4.612790658882308e-15
grad ChooseDest W: 5.599478244781494
=== Epoch 23: Train Loss: 5.5427, Train Log Prob: 0.0106 ===
Total mismatches: 77482
Predicted valid destination but wrong order: 5854
Epoch 23: Validation Loss: 4.2509, Validation Log Prob: 0.0206
Epoch 23: Edge Precision: 0.3696, Recall: 0.3657, F1: 0.3675, Jaccard: 0.2433
Epoch 23: TP: 2.5597709377236937, FP: 4.38840372226199, FN: 4.461703650680029
Epoch 23: Current Learning Rate: 6e-05
[Epoch 23] ‚è±Ô∏è Total: 3423.51s | Current time: 2025-07-15 09:32:53 | üèãÔ∏è Train: 2923.74s | ‚úÖ Val: 499.77s
grad AddEdge W: 2.5488600352520027e-14
grad ChooseDest W: 8.835455894470215
grad AddEdge W: 1.2842802220031367e-16
grad ChooseDest W: 7.788074493408203
grad AddEdge W: 2.4975833711306586e-15
grad ChooseDest W: 3.5083088874816895
grad AddEdge W: 8.891113539855056e-12
grad ChooseDest W: 2.1905813217163086
grad AddEdge W: 6.589307524707618e-16
grad ChooseDest W: 4.90927267074585
grad AddEdge W: 8.072537918919558e-16
grad ChooseDest W: 5.850812911987305
grad AddEdge W: 2.947389841616451e-16
grad ChooseDest W: 3.9438130855560303
grad AddEdge W: 5.117808981507446e-14
grad ChooseDest W: 6.874054431915283
grad AddEdge W: 6.00054974614773e-16
grad ChooseDest W: 4.562370300292969
grad AddEdge W: 1.4645877284384656e-16
grad ChooseDest W: 6.746214866638184
grad AddEdge W: 2.4049234724151953e-16
grad ChooseDest W: 5.613481521606445
grad AddEdge W: 1.1566903203752855e-14
grad ChooseDest W: 2.604886054992676
grad AddEdge W: 4.995869475205073e-17
grad ChooseDest W: 7.148061752319336
grad AddEdge W: 5.1275749325761094e-14
grad ChooseDest W: 2.7417666912078857
grad AddEdge W: 1.7186365997727738e-16
grad ChooseDest W: 4.159627437591553
grad AddEdge W: 5.873081346102207e-16
grad ChooseDest W: 4.943749904632568
grad AddEdge W: 1.9111144873524893e-15
grad ChooseDest W: 3.5501253604888916
grad AddEdge W: 3.904623681132667e-14
grad ChooseDest W: 3.6042444705963135
grad AddEdge W: 1.1907101069765099e-15
grad ChooseDest W: 4.198561668395996
grad AddEdge W: 1.0433608245724132e-16
grad ChooseDest W: 4.942989826202393
grad AddEdge W: 1.817959683167813e-16
grad ChooseDest W: 5.4347710609436035
grad AddEdge W: 6.201322685613422e-14
grad ChooseDest W: 3.5979154109954834
grad AddEdge W: 2.3545432232619304e-15
grad ChooseDest W: 4.217789173126221
grad AddEdge W: 1.749003096214799e-14
grad ChooseDest W: 3.94809889793396
grad AddEdge W: 1.743646571029437e-16
grad ChooseDest W: 7.687265396118164
grad AddEdge W: 1.2144746539270897e-14
grad ChooseDest W: 5.562920570373535
grad AddEdge W: 1.6060350837894413e-16
grad ChooseDest W: 5.030040740966797
grad AddEdge W: 1.1778309445437286e-16
grad ChooseDest W: 4.107350826263428
grad AddEdge W: 1.7877019457562154e-16
grad ChooseDest W: 6.82665491104126
grad AddEdge W: 1.6293967924582188e-14
grad ChooseDest W: 5.603442192077637
grad AddEdge W: 8.68732766692653e-16
grad ChooseDest W: 4.56490421295166
grad AddEdge W: 2.647061869371026e-16
grad ChooseDest W: 7.610579013824463
grad AddEdge W: 9.708959303840123e-15
grad ChooseDest W: 7.326119899749756
grad AddEdge W: 4.946559650704011e-16
grad ChooseDest W: 4.3357038497924805
grad AddEdge W: 5.932434532903092e-15
grad ChooseDest W: 4.905910015106201
grad AddEdge W: 1.864812490082017e-14
grad ChooseDest W: 3.9106242656707764
grad AddEdge W: 7.942736472499941e-16
grad ChooseDest W: 3.757145643234253
grad AddEdge W: 1.4116261463784432e-15
grad ChooseDest W: 6.180609226226807
grad AddEdge W: 1.259263500952675e-16
grad ChooseDest W: 5.9335103034973145
grad AddEdge W: 6.362828490545473e-15
grad ChooseDest W: 5.085587501525879
grad AddEdge W: 5.679132294642009e-13
grad ChooseDest W: 3.0189859867095947
grad AddEdge W: 3.319673908593751e-14
grad ChooseDest W: 4.94096565246582
grad AddEdge W: 5.239518701006119e-16
grad ChooseDest W: 5.316998481750488
grad AddEdge W: 4.0109731145834175e-16
grad ChooseDest W: 3.242342233657837
grad AddEdge W: 2.2630257043299018e-11
grad ChooseDest W: 3.0342516899108887
grad AddEdge W: 7.140812661898363e-17
grad ChooseDest W: 3.1622800827026367
grad AddEdge W: 7.819594425581417e-17
grad ChooseDest W: 2.8127145767211914
grad AddEdge W: 3.709713607266338e-14
grad ChooseDest W: 5.754525661468506
grad AddEdge W: 1.8418347626240536e-16
grad ChooseDest W: 4.104176044464111
grad AddEdge W: 4.02772128529124e-14
grad ChooseDest W: 2.3315272331237793
grad AddEdge W: 6.810426788489421e-13
grad ChooseDest W: 6.455133438110352
grad AddEdge W: 5.2213198804970055e-15
grad ChooseDest W: 3.5144729614257812
grad AddEdge W: 6.909529643318174e-14
grad ChooseDest W: 4.122294902801514
grad AddEdge W: 2.033351823674007e-16
grad ChooseDest W: 4.721599578857422
grad AddEdge W: 2.917337324406105e-15
grad ChooseDest W: 4.59024715423584
grad AddEdge W: 9.542854501757219e-17
grad ChooseDest W: 4.019760608673096
grad AddEdge W: 3.7382660926545672e-16
grad ChooseDest W: 4.297463417053223
grad AddEdge W: 1.4689887263439418e-16
grad ChooseDest W: 4.975197792053223
grad AddEdge W: 2.0531686888706135e-15
grad ChooseDest W: 4.197296142578125
grad AddEdge W: 5.366238535684507e-16
grad ChooseDest W: 4.549931049346924
grad AddEdge W: 7.084708931711162e-15
grad ChooseDest W: 5.101042747497559
grad AddEdge W: 1.5045066971766663e-14
grad ChooseDest W: 3.941927909851074
grad AddEdge W: 2.2093434325452793e-16
grad ChooseDest W: 4.219573974609375
grad AddEdge W: 3.982857761723442e-15
grad ChooseDest W: 9.688493728637695
grad AddEdge W: 6.166819560836671e-15
grad ChooseDest W: 4.409825801849365
grad AddEdge W: 4.686453726173226e-15
grad ChooseDest W: 4.500446319580078
=== Epoch 24: Train Loss: 5.4903, Train Log Prob: 0.0112 ===
Total mismatches: 76376
Predicted valid destination but wrong order: 5849
Epoch 24: Validation Loss: 4.2046, Validation Log Prob: 0.0214
Epoch 24: Edge Precision: 0.3687, Recall: 0.3646, F1: 0.3665, Jaccard: 0.2421
Epoch 24: TP: 2.5507516105941304, FP: 4.389119541875448, FN: 4.470722977809592
Epoch 24: Current Learning Rate: 6e-05
[Epoch 24] ‚è±Ô∏è Total: 3423.42s | Current time: 2025-07-15 10:29:57 | üèãÔ∏è Train: 2923.97s | ‚úÖ Val: 499.46s
grad AddEdge W: 3.655136902782491e-14
grad ChooseDest W: 8.57144832611084
grad AddEdge W: 8.22070293375653e-15
grad ChooseDest W: 2.0612850189208984
grad AddEdge W: 1.522701732507297e-16
grad ChooseDest W: 3.6314260959625244
grad AddEdge W: 1.0400523668199971e-16
grad ChooseDest W: 3.5866212844848633
grad AddEdge W: 1.9166167869080736e-16
grad ChooseDest W: 5.424124717712402
grad AddEdge W: 1.4111124208959335e-16
grad ChooseDest W: 6.1024298667907715
grad AddEdge W: 4.552499277213221e-15
grad ChooseDest W: 4.370314121246338
grad AddEdge W: 3.6287314976847854e-17
grad ChooseDest W: 5.671241760253906
grad AddEdge W: 4.884825115475215e-14
grad ChooseDest W: 3.7589874267578125
grad AddEdge W: 2.2740405766801712e-15
grad ChooseDest W: 3.851423978805542
grad AddEdge W: 1.5649645737594484e-16
grad ChooseDest W: 4.409378528594971
grad AddEdge W: 7.033309622513011e-17
grad ChooseDest W: 6.794949054718018
grad AddEdge W: 3.205293374605256e-16
grad ChooseDest W: 2.4249074459075928
grad AddEdge W: 4.317656216213414e-16
grad ChooseDest W: 2.902606725692749
grad AddEdge W: 3.0260746707901076e-14
grad ChooseDest W: 4.333574295043945
grad AddEdge W: 2.1438228135669786e-15
grad ChooseDest W: 5.738009452819824
grad AddEdge W: 1.5266958704185374e-12
grad ChooseDest W: 2.2458126544952393
grad AddEdge W: 1.9002574307928205e-13
grad ChooseDest W: 3.298971176147461
grad AddEdge W: 2.5619688865502997e-14
grad ChooseDest W: 4.1203203201293945
grad AddEdge W: 2.202759154278696e-15
grad ChooseDest W: 4.185605049133301
grad AddEdge W: 1.0501126036043161e-16
grad ChooseDest W: 8.689064025878906
grad AddEdge W: 9.243250425044341e-15
grad ChooseDest W: 3.066051959991455
grad AddEdge W: 2.7858998338488664e-14
grad ChooseDest W: 3.24678373336792
grad AddEdge W: 9.377912942726274e-13
grad ChooseDest W: 3.6565001010894775
grad AddEdge W: 7.01052311274289e-17
grad ChooseDest W: 4.0017409324646
grad AddEdge W: 1.718872048462331e-16
grad ChooseDest W: 6.191250801086426
grad AddEdge W: 1.6102414811692417e-13
grad ChooseDest W: 3.918823719024658
grad AddEdge W: 2.913197768513755e-16
grad ChooseDest W: 7.094139099121094
grad AddEdge W: 1.2873463489232993e-16
grad ChooseDest W: 4.518795967102051
grad AddEdge W: 6.808744540398592e-11
grad ChooseDest W: 1.818552017211914
grad AddEdge W: 1.3876517258393575e-16
grad ChooseDest W: 4.540673732757568
grad AddEdge W: 7.947524855629888e-16
grad ChooseDest W: 3.6844944953918457
grad AddEdge W: 1.064743996095907e-12
grad ChooseDest W: 4.275031089782715
grad AddEdge W: 3.582076499433545e-15
grad ChooseDest W: 6.164644241333008
grad AddEdge W: 3.0831226362492163e-15
grad ChooseDest W: 4.019415378570557
grad AddEdge W: 3.4660209154402074e-15
grad ChooseDest W: 7.174079895019531
grad AddEdge W: 5.209601497309097e-16
grad ChooseDest W: 4.81430196762085
grad AddEdge W: 8.021577346318306e-15
grad ChooseDest W: 4.7378997802734375
grad AddEdge W: 4.165130728703536e-16
grad ChooseDest W: 4.520053386688232
grad AddEdge W: 2.8880068475567455e-11
grad ChooseDest W: 3.2523462772369385
grad AddEdge W: 5.162830984939675e-16
grad ChooseDest W: 3.757084846496582
grad AddEdge W: 1.708253188155342e-14
grad ChooseDest W: 4.69094705581665
grad AddEdge W: 8.582050471307885e-16
grad ChooseDest W: 2.6795120239257812
grad AddEdge W: 1.1025037751488117e-16
grad ChooseDest W: 4.13754940032959
grad AddEdge W: 8.865516929249233e-15
grad ChooseDest W: 3.5474696159362793
grad AddEdge W: 6.76605736041558e-16
grad ChooseDest W: 4.9007134437561035
grad AddEdge W: 1.8383513396284703e-16
grad ChooseDest W: 4.577603340148926
grad AddEdge W: 7.646048359647546e-16
grad ChooseDest W: 5.620278835296631
grad AddEdge W: 7.288950259337623e-14
grad ChooseDest W: 6.294414520263672
grad AddEdge W: 2.3897679354064477e-14
grad ChooseDest W: 4.001211643218994
grad AddEdge W: 1.1117321832272795e-14
grad ChooseDest W: 6.053677082061768
grad AddEdge W: 4.8941584868177155e-15
grad ChooseDest W: 4.391229152679443
grad AddEdge W: 8.122117040340843e-18
grad ChooseDest W: 4.2375640869140625
grad AddEdge W: 3.8204608463671445e-16
grad ChooseDest W: 3.1816182136535645
grad AddEdge W: 1.7850140243409578e-14
grad ChooseDest W: 4.261329650878906
grad AddEdge W: 1.6953396203030343e-15
grad ChooseDest W: 4.328220367431641
grad AddEdge W: 1.3089438997211829e-14
grad ChooseDest W: 4.06552267074585
grad AddEdge W: 1.3669238978838028e-14
grad ChooseDest W: 3.945512533187866
grad AddEdge W: 9.467719370613313e-17
grad ChooseDest W: 4.138982772827148
grad AddEdge W: 7.144858435361584e-16
grad ChooseDest W: 4.929226875305176
grad AddEdge W: 1.44306580709486e-14
grad ChooseDest W: 5.963866233825684
grad AddEdge W: 7.911812887782463e-15
grad ChooseDest W: 4.466357231140137
grad AddEdge W: 1.7142284973784526e-14
grad ChooseDest W: 4.458998680114746
grad AddEdge W: 5.476200141138823e-15
grad ChooseDest W: 3.205479383468628
grad AddEdge W: 3.19686822587012e-13
grad ChooseDest W: 3.1426801681518555
grad AddEdge W: 6.608243343290182e-17
grad ChooseDest W: 4.7229413986206055
=== Epoch 25: Train Loss: 5.4359, Train Log Prob: 0.0117 ===
Total mismatches: 75367
Predicted valid destination but wrong order: 5912
Epoch 25: Validation Loss: 4.1119, Validation Log Prob: 0.0233
Epoch 25: Edge Precision: 0.3684, Recall: 0.3634, F1: 0.3657, Jaccard: 0.2417
Epoch 25: TP: 2.5427344309234075, FP: 4.38453829634932, FN: 4.478740157480315
Epoch 25: Current Learning Rate: 6e-05
üíæ Checkpoint saved: /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/checkpoint_epoch_25.pth
[Epoch 25] ‚è±Ô∏è Total: 3411.77s | Current time: 2025-07-15 11:26:49 | üèãÔ∏è Train: 2913.81s | ‚úÖ Val: 497.96s
grad AddEdge W: 3.873604656977857e-14
grad ChooseDest W: 8.551020622253418
grad AddEdge W: 8.89552849241658e-14
grad ChooseDest W: 3.9666647911071777
grad AddEdge W: 1.551758260732658e-14
grad ChooseDest W: 5.028679370880127
grad AddEdge W: 3.342438861375364e-16
grad ChooseDest W: 6.410574436187744
grad AddEdge W: 1.3390517281829844e-15
grad ChooseDest W: 3.7834219932556152
grad AddEdge W: 3.3517591354709176e-16
grad ChooseDest W: 4.17546272277832
grad AddEdge W: 2.426442344440191e-16
grad ChooseDest W: 2.3835256099700928
grad AddEdge W: 3.775573976453738e-15
grad ChooseDest W: 4.860084533691406
grad AddEdge W: 2.440166565174668e-14
grad ChooseDest W: 3.5848822593688965
grad AddEdge W: 1.2566678214253734e-15
grad ChooseDest W: 5.841683387756348
grad AddEdge W: 2.2777676487030322e-14
grad ChooseDest W: 4.513983726501465
grad AddEdge W: 1.5270061604066854e-10
grad ChooseDest W: 3.2539288997650146
grad AddEdge W: 8.330861556160585e-10
grad ChooseDest W: 2.3253605365753174
grad AddEdge W: 1.624032681034023e-16
grad ChooseDest W: 5.009969711303711
grad AddEdge W: 1.4613800146672136e-14
grad ChooseDest W: 8.905287742614746
grad AddEdge W: 2.295103268523511e-16
grad ChooseDest W: 6.8252854347229
grad AddEdge W: 2.0394287556749647e-16
grad ChooseDest W: 5.785770893096924
grad AddEdge W: 5.862296054408994e-14
grad ChooseDest W: 6.457851886749268
grad AddEdge W: 7.68096358712896e-17
grad ChooseDest W: 4.814291477203369
grad AddEdge W: 8.324804130007031e-15
grad ChooseDest W: 6.850733280181885
grad AddEdge W: 1.4150456183865089e-14
grad ChooseDest W: 6.0847883224487305
grad AddEdge W: 5.201728855459961e-16
grad ChooseDest W: 6.525622844696045
grad AddEdge W: 7.068718220216421e-15
grad ChooseDest W: 3.926543951034546
grad AddEdge W: 1.6519361697780663e-15
grad ChooseDest W: 6.355297088623047
grad AddEdge W: 2.305788324455328e-16
grad ChooseDest W: 3.536045551300049
grad AddEdge W: 1.2501195791167399e-14
grad ChooseDest W: 3.5912375450134277
grad AddEdge W: 8.251875969676975e-16
grad ChooseDest W: 5.55051851272583
grad AddEdge W: 9.949703855141687e-15
grad ChooseDest W: 3.07326340675354
grad AddEdge W: 5.645417418725972e-15
grad ChooseDest W: 5.8782196044921875
grad AddEdge W: 6.257290197020837e-16
grad ChooseDest W: 4.723064422607422
grad AddEdge W: 5.919619720622105e-13
grad ChooseDest W: 3.803156614303589
grad AddEdge W: 7.567355758946598e-14
grad ChooseDest W: 3.132065773010254
grad AddEdge W: 8.423559357220275e-17
grad ChooseDest W: 4.3358540534973145
grad AddEdge W: 1.6314605035309092e-14
grad ChooseDest W: 4.120475769042969
grad AddEdge W: 2.2774540135784877e-16
grad ChooseDest W: 2.799234390258789
grad AddEdge W: 9.503206742380818e-17
grad ChooseDest W: 4.835694313049316
grad AddEdge W: 4.120144544177064e-16
grad ChooseDest W: 5.802944183349609
grad AddEdge W: 4.581581899347313e-14
grad ChooseDest W: 4.639320373535156
grad AddEdge W: 2.1935048097866855e-17
grad ChooseDest W: 3.684143304824829
grad AddEdge W: 1.5449526898146486e-14
grad ChooseDest W: 2.7266111373901367
grad AddEdge W: 4.080813363364699e-16
grad ChooseDest W: 3.685943841934204
grad AddEdge W: 2.259241217025744e-16
grad ChooseDest W: 4.866431713104248
grad AddEdge W: 3.9853148984243087e-16
grad ChooseDest W: 3.4921340942382812
grad AddEdge W: 2.6319605742346382e-14
grad ChooseDest W: 4.240578651428223
grad AddEdge W: 2.0269023626123802e-17
grad ChooseDest W: 4.442859649658203
grad AddEdge W: 1.0436736973673053e-16
grad ChooseDest W: 6.417812347412109
grad AddEdge W: 1.958847335029111e-15
grad ChooseDest W: 3.1504721641540527
grad AddEdge W: 8.292545859592696e-17
grad ChooseDest W: 4.854822158813477
grad AddEdge W: 2.518822669343501e-16
grad ChooseDest W: 4.787667274475098
grad AddEdge W: 1.3294616211541712e-15
grad ChooseDest W: 3.554182767868042
grad AddEdge W: 3.109605671916538e-14
grad ChooseDest W: 3.311241626739502
grad AddEdge W: 2.2269743015813914e-14
grad ChooseDest W: 4.903670787811279
grad AddEdge W: 1.468015988413359e-15
grad ChooseDest W: 4.261985778808594
grad AddEdge W: 3.2631690183087744e-14
grad ChooseDest W: 3.791640520095825
grad AddEdge W: 7.883417167016946e-16
grad ChooseDest W: 7.501164436340332
grad AddEdge W: 1.8676866383081734e-17
grad ChooseDest W: 2.960210084915161
grad AddEdge W: 1.3124010541074895e-16
grad ChooseDest W: 3.4782297611236572
grad AddEdge W: 1.862742849778696e-14
grad ChooseDest W: 5.781459808349609
grad AddEdge W: 1.7937692162876183e-16
grad ChooseDest W: 4.140167713165283
grad AddEdge W: 3.34773170556496e-14
grad ChooseDest W: 3.745685577392578
grad AddEdge W: 1.5069838450309115e-16
grad ChooseDest W: 5.556487560272217
grad AddEdge W: 3.1033047632285024e-14
grad ChooseDest W: 5.001900672912598
grad AddEdge W: 1.0281987892327735e-15
grad ChooseDest W: 4.300252914428711
grad AddEdge W: 7.094704056014034e-13
grad ChooseDest W: 5.634978771209717
grad AddEdge W: 5.689763405162997e-15
grad ChooseDest W: 5.37771463394165
grad AddEdge W: 5.314488528376413e-16
grad ChooseDest W: 3.83988094329834
=== Epoch 26: Train Loss: 5.3868, Train Log Prob: 0.0123 ===
Total mismatches: 74516
Predicted valid destination but wrong order: 5944
Epoch 26: Validation Loss: 4.0786, Validation Log Prob: 0.0241
Epoch 26: Edge Precision: 0.3680, Recall: 0.3632, F1: 0.3654, Jaccard: 0.2413
Epoch 26: TP: 2.5418754473872585, FP: 4.386685755189692, FN: 4.479599141016464
Epoch 26: Current Learning Rate: 6e-05
[Epoch 26] ‚è±Ô∏è Total: 3429.44s | Current time: 2025-07-15 12:23:58 | üèãÔ∏è Train: 2931.64s | ‚úÖ Val: 497.80s
grad AddEdge W: 1.8718337579400448e-15
grad ChooseDest W: 7.6745100021362305
grad AddEdge W: 7.571866405267096e-17
grad ChooseDest W: 3.594264268875122
grad AddEdge W: 1.14222220883675e-16
grad ChooseDest W: 3.803116798400879
grad AddEdge W: 2.136178050050433e-16
grad ChooseDest W: 4.346188068389893
grad AddEdge W: 4.56575004888183e-16
grad ChooseDest W: 4.913190841674805
grad AddEdge W: 7.685926141408686e-15
grad ChooseDest W: 8.605055809020996
grad AddEdge W: 2.435039993552618e-16
grad ChooseDest W: 4.472758769989014
grad AddEdge W: 2.913006953166562e-14
grad ChooseDest W: 7.594727993011475
grad AddEdge W: 2.369048154263892e-14
grad ChooseDest W: 4.93591833114624
grad AddEdge W: 1.813529436155877e-16
grad ChooseDest W: 3.9234466552734375
grad AddEdge W: 1.889058967015849e-16
grad ChooseDest W: 4.410127639770508
grad AddEdge W: 1.5399894102629614e-16
grad ChooseDest W: 6.336215496063232
grad AddEdge W: 1.6223194933707302e-14
grad ChooseDest W: 3.7118375301361084
grad AddEdge W: 8.1584273774085e-15
grad ChooseDest W: 5.838989734649658
grad AddEdge W: 3.481674401942822e-16
grad ChooseDest W: 4.663503646850586
grad AddEdge W: 9.71520701885907e-15
grad ChooseDest W: 2.4806175231933594
grad AddEdge W: 3.200724394184472e-14
grad ChooseDest W: 3.3308775424957275
grad AddEdge W: 6.750817353046168e-14
grad ChooseDest W: 2.886721134185791
grad AddEdge W: 1.362900152571166e-15
grad ChooseDest W: 5.696305751800537
grad AddEdge W: 5.527774283231243e-14
grad ChooseDest W: 5.42475700378418
grad AddEdge W: 3.842277651643425e-14
grad ChooseDest W: 8.106176376342773
grad AddEdge W: 1.835206570993111e-15
grad ChooseDest W: 6.707216262817383
grad AddEdge W: 2.5730849234335915e-15
grad ChooseDest W: 4.5204267501831055
grad AddEdge W: 8.450270885319074e-15
grad ChooseDest W: 4.267348289489746
grad AddEdge W: 1.5745434576017105e-16
grad ChooseDest W: 5.131845474243164
grad AddEdge W: 4.349149959983513e-15
grad ChooseDest W: 4.449427127838135
grad AddEdge W: 3.5829025153757954e-16
grad ChooseDest W: 6.170491695404053
grad AddEdge W: 1.2785881605975878e-16
grad ChooseDest W: 6.320223331451416
grad AddEdge W: 6.786285698336095e-17
grad ChooseDest W: 4.525854110717773
grad AddEdge W: 3.025386223586403e-16
grad ChooseDest W: 5.153356552124023
grad AddEdge W: 7.2060449190976825e-16
grad ChooseDest W: 4.995993137359619
grad AddEdge W: 7.790518034433443e-17
grad ChooseDest W: 3.7909786701202393
grad AddEdge W: 6.380011506792592e-16
grad ChooseDest W: 4.769697666168213
grad AddEdge W: 1.6080431342095853e-15
grad ChooseDest W: 4.449048042297363
grad AddEdge W: 2.303684315790172e-14
grad ChooseDest W: 3.5398316383361816
grad AddEdge W: 1.3350888421876077e-14
grad ChooseDest W: 4.3410468101501465
grad AddEdge W: 3.1175804659391133e-16
grad ChooseDest W: 5.334245204925537
grad AddEdge W: 1.1390752167399042e-16
grad ChooseDest W: 4.800505638122559
grad AddEdge W: 2.0852733128022723e-14
grad ChooseDest W: 3.2259461879730225
grad AddEdge W: 8.352779828309828e-16
grad ChooseDest W: 6.135110378265381
grad AddEdge W: 1.9296014439063036e-11
grad ChooseDest W: 3.1442651748657227
grad AddEdge W: 5.304022737510905e-14
grad ChooseDest W: 2.9268290996551514
grad AddEdge W: 1.7010428321032404e-17
grad ChooseDest W: 5.837685585021973
grad AddEdge W: 3.0958884815555227e-14
grad ChooseDest W: 4.9990057945251465
grad AddEdge W: 3.5847274584485667e-13
grad ChooseDest W: 4.352790832519531
grad AddEdge W: 3.745799921324802e-14
grad ChooseDest W: 4.759909629821777
grad AddEdge W: 8.054842871255824e-15
grad ChooseDest W: 4.160679340362549
grad AddEdge W: 1.4236754136698337e-11
grad ChooseDest W: 2.0809478759765625
grad AddEdge W: 1.1897739026357334e-14
grad ChooseDest W: 5.986703872680664
grad AddEdge W: 6.044727384786489e-15
grad ChooseDest W: 2.1245148181915283
grad AddEdge W: 5.815777184940289e-17
grad ChooseDest W: 4.544820308685303
grad AddEdge W: 1.8056135268050034e-14
grad ChooseDest W: 3.2760965824127197
grad AddEdge W: 4.666997802891268e-15
grad ChooseDest W: 6.134378433227539
grad AddEdge W: 3.3475311175751386e-17
grad ChooseDest W: 3.0767128467559814
grad AddEdge W: 4.139080029240405e-14
grad ChooseDest W: 3.903308629989624
grad AddEdge W: 5.481935824741156e-16
grad ChooseDest W: 4.719345569610596
grad AddEdge W: 2.518448651357729e-16
grad ChooseDest W: 3.465411424636841
grad AddEdge W: 1.5881240956637163e-14
grad ChooseDest W: 4.445186138153076
grad AddEdge W: 1.4676099155244894e-16
grad ChooseDest W: 4.998650074005127
grad AddEdge W: 8.443700874263696e-18
grad ChooseDest W: 8.881285667419434
grad AddEdge W: 3.2088049614463357e-15
grad ChooseDest W: 4.413330078125
grad AddEdge W: 8.36728579692715e-16
grad ChooseDest W: 4.324604511260986
grad AddEdge W: 2.0762864626384936e-14
grad ChooseDest W: 2.294562578201294
grad AddEdge W: 1.3679217873989631e-15
grad ChooseDest W: 3.465414047241211
grad AddEdge W: 1.3090318482108875e-16
grad ChooseDest W: 3.51053524017334
grad AddEdge W: 1.536128925256952e-16
grad ChooseDest W: 4.4719719886779785
=== Epoch 27: Train Loss: 5.3316, Train Log Prob: 0.0130 ===
Total mismatches: 73726
Predicted valid destination but wrong order: 5964
Epoch 27: Validation Loss: 3.9967, Validation Log Prob: 0.0260
Epoch 27: Edge Precision: 0.3672, Recall: 0.3624, F1: 0.3646, Jaccard: 0.2414
Epoch 27: TP: 2.537580529706514, FP: 4.393414459556192, FN: 4.483894058697208
Epoch 27: Current Learning Rate: 6e-05
[Epoch 27] ‚è±Ô∏è Total: 3436.76s | Current time: 2025-07-15 13:21:15 | üèãÔ∏è Train: 2939.12s | ‚úÖ Val: 497.64s
grad AddEdge W: 4.586056605001068e-15
grad ChooseDest W: 9.068422317504883
grad AddEdge W: 2.5733686463836972e-17
grad ChooseDest W: 5.344234466552734
grad AddEdge W: 3.922882797682131e-13
grad ChooseDest W: 4.685096740722656
grad AddEdge W: 4.513018012750514e-16
grad ChooseDest W: 6.439517021179199
grad AddEdge W: 3.1982329111446273e-12
grad ChooseDest W: 5.854834079742432
grad AddEdge W: 3.787588291777593e-16
grad ChooseDest W: 4.588205814361572
grad AddEdge W: 7.667099378318081e-17
grad ChooseDest W: 5.659167289733887
grad AddEdge W: 1.9410382555548524e-15
grad ChooseDest W: 5.77458381652832
grad AddEdge W: 9.963061564719888e-15
grad ChooseDest W: 3.1316797733306885
grad AddEdge W: 3.0482298000837627e-13
grad ChooseDest W: 2.977857828140259
grad AddEdge W: 2.695310189535611e-16
grad ChooseDest W: 5.380614757537842
grad AddEdge W: 3.003758401948567e-15
grad ChooseDest W: 4.15277099609375
grad AddEdge W: 6.456934803897492e-17
grad ChooseDest W: 4.953639984130859
grad AddEdge W: 1.1673965574247397e-16
grad ChooseDest W: 2.992567777633667
grad AddEdge W: 1.1282517238607703e-16
grad ChooseDest W: 6.580562114715576
grad AddEdge W: 6.84918835023267e-16
grad ChooseDest W: 7.215372085571289
grad AddEdge W: 2.182989855276034e-16
grad ChooseDest W: 4.50548791885376
grad AddEdge W: 4.908719372816173e-13
grad ChooseDest W: 2.7154669761657715
grad AddEdge W: 9.023880326650266e-16
grad ChooseDest W: 5.149344444274902
grad AddEdge W: 2.3096047372783007e-16
grad ChooseDest W: 5.63394832611084
grad AddEdge W: 2.953091940362425e-14
grad ChooseDest W: 4.410148620605469
grad AddEdge W: 3.1277665665254382e-15
grad ChooseDest W: 4.794270038604736
grad AddEdge W: 7.825317191931304e-17
grad ChooseDest W: 3.2019803524017334
grad AddEdge W: 1.1483806942286603e-15
grad ChooseDest W: 3.682311534881592
grad AddEdge W: 4.730288316468346e-16
grad ChooseDest W: 2.162140130996704
grad AddEdge W: 1.9589989962783168e-14
grad ChooseDest W: 5.4087910652160645
grad AddEdge W: 1.7924514183101478e-16
grad ChooseDest W: 4.0694684982299805
grad AddEdge W: 1.776900687491947e-16
grad ChooseDest W: 4.667812824249268
grad AddEdge W: 1.3749733631546348e-16
grad ChooseDest W: 3.9474942684173584
grad AddEdge W: 2.796867216449915e-15
grad ChooseDest W: 3.439847469329834
grad AddEdge W: 3.2808614189945486e-16
grad ChooseDest W: 5.097894191741943
grad AddEdge W: 2.464211411209362e-17
grad ChooseDest W: 5.4506330490112305
grad AddEdge W: 2.1467961374398576e-16
grad ChooseDest W: 5.736154079437256
grad AddEdge W: 2.877320364543819e-16
grad ChooseDest W: 3.725921154022217
grad AddEdge W: 4.778670626657275e-15
grad ChooseDest W: 5.484710216522217
grad AddEdge W: 1.020414323513446e-14
grad ChooseDest W: 7.2383904457092285
grad AddEdge W: 1.1511567388341679e-14
grad ChooseDest W: 4.654665470123291
grad AddEdge W: 5.557351932595535e-16
grad ChooseDest W: 4.957890510559082
grad AddEdge W: 3.0899258990024444e-17
grad ChooseDest W: 4.861261367797852
grad AddEdge W: 3.342081982571884e-17
grad ChooseDest W: 4.49179220199585
grad AddEdge W: 2.488606092439184e-15
grad ChooseDest W: 2.7615058422088623
grad AddEdge W: 1.001338113852086e-17
grad ChooseDest W: 4.451930999755859
grad AddEdge W: 3.3544890300156896e-17
grad ChooseDest W: 5.526709079742432
grad AddEdge W: 7.11749397720935e-16
grad ChooseDest W: 3.7797951698303223
grad AddEdge W: 1.55506844960866e-16
grad ChooseDest W: 5.208463668823242
grad AddEdge W: 2.4844541910416275e-14
grad ChooseDest W: 3.3089029788970947
grad AddEdge W: 1.35580434581378e-16
grad ChooseDest W: 3.4394428730010986
grad AddEdge W: 1.0091250057797652e-09
grad ChooseDest W: 1.492368459701538
grad AddEdge W: 1.5652491238901667e-16
grad ChooseDest W: 5.648342609405518
grad AddEdge W: 8.151534726209557e-17
grad ChooseDest W: 2.2440426349639893
grad AddEdge W: 4.531254102709307e-16
grad ChooseDest W: 7.09487771987915
grad AddEdge W: 5.739304668182007e-16
grad ChooseDest W: 3.437361240386963
grad AddEdge W: 6.496489257300797e-17
grad ChooseDest W: 3.9807376861572266
grad AddEdge W: 1.955600869500522e-14
grad ChooseDest W: 5.7912774085998535
grad AddEdge W: 1.4094327545615282e-14
grad ChooseDest W: 2.9525272846221924
grad AddEdge W: 1.6335571694792037e-16
grad ChooseDest W: 4.345812797546387
grad AddEdge W: 1.8475307944965428e-16
grad ChooseDest W: 5.2581892013549805
grad AddEdge W: 6.4875079287330436e-15
grad ChooseDest W: 5.0644049644470215
grad AddEdge W: 2.7739823449787944e-16
grad ChooseDest W: 4.838325500488281
grad AddEdge W: 5.219642344979858e-17
grad ChooseDest W: 6.404412746429443
grad AddEdge W: 8.596064737299326e-15
grad ChooseDest W: 7.9741902351379395
grad AddEdge W: 2.156386641515365e-15
grad ChooseDest W: 2.2515835762023926
grad AddEdge W: 6.708403004069532e-16
grad ChooseDest W: 3.9593167304992676
grad AddEdge W: 3.478475462903508e-17
grad ChooseDest W: 4.321893215179443
grad AddEdge W: 2.0452482955390754e-15
grad ChooseDest W: 6.9627366065979
grad AddEdge W: 1.6366365524649908e-14
grad ChooseDest W: 3.9163196086883545
=== Epoch 28: Train Loss: 5.2777, Train Log Prob: 0.0137 ===
Total mismatches: 72817
Predicted valid destination but wrong order: 5944
Epoch 28: Validation Loss: 3.9192, Validation Log Prob: 0.0278
Epoch 28: Edge Precision: 0.3639, Recall: 0.3591, F1: 0.3613, Jaccard: 0.2381
Epoch 28: TP: 2.513242662848962, FP: 4.413027916964925, FN: 4.50823192555476
Epoch 28: Current Learning Rate: 6e-05
[Epoch 28] ‚è±Ô∏è Total: 3418.24s | Current time: 2025-07-15 14:18:13 | üèãÔ∏è Train: 2915.58s | ‚úÖ Val: 502.66s
grad AddEdge W: 4.3930435461234096e-13
grad ChooseDest W: 12.34329891204834
grad AddEdge W: 4.0436201466507624e-16
grad ChooseDest W: 4.960137367248535
grad AddEdge W: 1.3979698576863358e-15
grad ChooseDest W: 3.0545456409454346
grad AddEdge W: 3.003983867211346e-11
grad ChooseDest W: 2.329564332962036
grad AddEdge W: 1.618082126348796e-14
grad ChooseDest W: 5.1207380294799805
grad AddEdge W: 5.456038639411803e-15
grad ChooseDest W: 5.916420936584473
grad AddEdge W: 9.74895858485425e-11
grad ChooseDest W: 2.8330986499786377
grad AddEdge W: 4.679820441756688e-13
grad ChooseDest W: 5.64484977722168
grad AddEdge W: 3.718353870076946e-17
grad ChooseDest W: 5.587203025817871
grad AddEdge W: 3.8915300870153325e-17
grad ChooseDest W: 6.053988933563232
grad AddEdge W: 3.65102811536195e-14
grad ChooseDest W: 5.019926071166992
grad AddEdge W: 6.758034502567204e-17
grad ChooseDest W: 3.663032293319702
grad AddEdge W: 2.498173414281716e-14
grad ChooseDest W: 5.0997538566589355
grad AddEdge W: 1.141205880473119e-14
grad ChooseDest W: 3.228217363357544
grad AddEdge W: 5.297113320353562e-14
grad ChooseDest W: 5.814575672149658
grad AddEdge W: 3.001677506694959e-16
grad ChooseDest W: 5.797140598297119
grad AddEdge W: 3.5499092585912603e-16
grad ChooseDest W: 6.051777362823486
grad AddEdge W: 9.65706837142543e-15
grad ChooseDest W: 5.290128231048584
grad AddEdge W: 5.4446510225897977e-17
grad ChooseDest W: 4.214423179626465
grad AddEdge W: 2.5490414900380953e-12
grad ChooseDest W: 3.7462456226348877
grad AddEdge W: 2.2792798989754127e-16
grad ChooseDest W: 4.91215181350708
grad AddEdge W: 4.4046298239352815e-16
grad ChooseDest W: 6.325557708740234
grad AddEdge W: 6.86449273012084e-18
grad ChooseDest W: 5.0597405433654785
grad AddEdge W: 2.1578026688449372e-16
grad ChooseDest W: 6.6306681632995605
grad AddEdge W: 9.399371090959281e-17
grad ChooseDest W: 4.217535018920898
grad AddEdge W: 2.5120229247416193e-12
grad ChooseDest W: 3.9336628913879395
grad AddEdge W: 2.4139888425331844e-16
grad ChooseDest W: 4.0253167152404785
grad AddEdge W: 8.675296887399763e-17
grad ChooseDest W: 6.220778942108154
grad AddEdge W: 8.351397444070129e-17
grad ChooseDest W: 4.913383483886719
grad AddEdge W: 2.439676969543243e-16
grad ChooseDest W: 4.23236083984375
grad AddEdge W: 1.1941606809756075e-16
grad ChooseDest W: 3.3775675296783447
grad AddEdge W: 7.492492933013366e-16
grad ChooseDest W: 4.537394046783447
grad AddEdge W: 1.7885199942948058e-16
grad ChooseDest W: 4.566040992736816
grad AddEdge W: 1.3494941112929953e-13
grad ChooseDest W: 3.967860698699951
grad AddEdge W: 1.278146544088669e-14
grad ChooseDest W: 4.4639081954956055
grad AddEdge W: 5.329375721112306e-13
grad ChooseDest W: 4.782628536224365
grad AddEdge W: 2.008513831869372e-14
grad ChooseDest W: 5.621232986450195
grad AddEdge W: 1.4596768008168746e-14
grad ChooseDest W: 5.078558921813965
grad AddEdge W: 8.12631696718302e-17
grad ChooseDest W: 4.545937538146973
grad AddEdge W: 2.4264852890106166e-14
grad ChooseDest W: 4.660492420196533
grad AddEdge W: 8.169445502577045e-17
grad ChooseDest W: 4.5128045082092285
grad AddEdge W: 3.0862776222195017e-15
grad ChooseDest W: 2.794945478439331
grad AddEdge W: 7.54141080095902e-14
grad ChooseDest W: 4.306437015533447
grad AddEdge W: 1.151636413592198e-14
grad ChooseDest W: 4.967239856719971
grad AddEdge W: 1.2057082017361866e-14
grad ChooseDest W: 4.1112284660339355
grad AddEdge W: 1.8476864368006008e-16
grad ChooseDest W: 4.5894951820373535
grad AddEdge W: 3.297401590174261e-16
grad ChooseDest W: 4.835094451904297
grad AddEdge W: 1.162329712213383e-16
grad ChooseDest W: 4.011881351470947
grad AddEdge W: 1.3930694279793348e-16
grad ChooseDest W: 8.115850448608398
grad AddEdge W: 6.500442968870564e-15
grad ChooseDest W: 4.231566429138184
grad AddEdge W: 2.9691914108875925e-15
grad ChooseDest W: 3.477710008621216
grad AddEdge W: 1.2206024290807062e-14
grad ChooseDest W: 4.577399253845215
grad AddEdge W: 2.9195043734983606e-14
grad ChooseDest W: 7.072995662689209
grad AddEdge W: 8.853743700677991e-16
grad ChooseDest W: 3.858192205429077
grad AddEdge W: 1.5429143422965308e-12
grad ChooseDest W: 3.064326524734497
grad AddEdge W: 4.614417451831959e-17
grad ChooseDest W: 4.762187957763672
grad AddEdge W: 4.1299947432602436e-16
grad ChooseDest W: 4.285137176513672
grad AddEdge W: 3.187054637668503e-16
grad ChooseDest W: 5.699534893035889
grad AddEdge W: 2.4048898452071893e-14
grad ChooseDest W: 2.981914758682251
grad AddEdge W: 2.6132043742824955e-16
grad ChooseDest W: 4.638517379760742
grad AddEdge W: 1.0826347380166104e-14
grad ChooseDest W: 4.630733013153076
grad AddEdge W: 3.053615978833817e-17
grad ChooseDest W: 6.283304691314697
grad AddEdge W: 2.25113679916897e-17
grad ChooseDest W: 4.226914882659912
grad AddEdge W: 7.259315456425216e-15
grad ChooseDest W: 3.217914342880249
grad AddEdge W: 4.665736067906994e-17
grad ChooseDest W: 3.8574166297912598
grad AddEdge W: 1.9372225838857086e-15
grad ChooseDest W: 7.511798858642578
=== Epoch 29: Train Loss: 5.2227, Train Log Prob: 0.0145 ===
Total mismatches: 71925
Predicted valid destination but wrong order: 5957
Epoch 29: Validation Loss: 3.8846, Validation Log Prob: 0.0287
Epoch 29: Edge Precision: 0.3670, Recall: 0.3615, F1: 0.3640, Jaccard: 0.2408
Epoch 29: TP: 2.53042233357194, FP: 4.384251968503937, FN: 4.491052254831782
Epoch 29: Current Learning Rate: 6e-05
[Epoch 29] ‚è±Ô∏è Total: 3360.23s | Current time: 2025-07-15 15:14:13 | üèãÔ∏è Train: 2863.75s | ‚úÖ Val: 496.48s
grad AddEdge W: 1.2946042892217346e-12
grad ChooseDest W: 9.831404685974121
grad AddEdge W: 1.6578965712213053e-14
grad ChooseDest W: 3.5098557472229004
grad AddEdge W: 2.2195764852266618e-14
grad ChooseDest W: 5.83134126663208
grad AddEdge W: 2.3462058779621063e-14
grad ChooseDest W: 3.0554308891296387
grad AddEdge W: 8.912589091226997e-15
grad ChooseDest W: 3.030876874923706
grad AddEdge W: 1.1539190720938417e-16
grad ChooseDest W: 4.8377299308776855
grad AddEdge W: 1.987474931063938e-16
grad ChooseDest W: 4.9577860832214355
grad AddEdge W: 1.3781162524356422e-15
grad ChooseDest W: 4.832861423492432
grad AddEdge W: 8.3521902139692e-17
grad ChooseDest W: 5.813320159912109
grad AddEdge W: 7.719978559954203e-15
grad ChooseDest W: 3.590362548828125
grad AddEdge W: 3.003776613156933e-15
grad ChooseDest W: 4.034587860107422
grad AddEdge W: 3.2352221487723376e-13
grad ChooseDest W: 3.1329102516174316
grad AddEdge W: 7.324124488318484e-17
grad ChooseDest W: 4.199064254760742
grad AddEdge W: 6.792240737001987e-16
grad ChooseDest W: 6.797004222869873
grad AddEdge W: 2.096587465397971e-16
grad ChooseDest W: 5.796929836273193
grad AddEdge W: 4.39596335339589e-15
grad ChooseDest W: 4.637338638305664
grad AddEdge W: 1.3026208675913565e-16
grad ChooseDest W: 5.654902458190918
grad AddEdge W: 1.3376047841508372e-16
grad ChooseDest W: 7.474635601043701
grad AddEdge W: 1.7408201014937883e-15
grad ChooseDest W: 2.8905465602874756
grad AddEdge W: 9.90103164792656e-15
grad ChooseDest W: 3.9475197792053223
grad AddEdge W: 1.988534526929306e-14
grad ChooseDest W: 4.755123615264893
grad AddEdge W: 1.1969352273915896e-14
grad ChooseDest W: 4.4872026443481445
grad AddEdge W: 2.4398397586877936e-16
grad ChooseDest W: 4.619316577911377
grad AddEdge W: 1.302502680025435e-16
grad ChooseDest W: 3.2107391357421875
grad AddEdge W: 1.7054103457375204e-17
grad ChooseDest W: 5.829499244689941
grad AddEdge W: 2.8284693380856152e-14
grad ChooseDest W: 8.448752403259277
grad AddEdge W: 5.549975440295252e-15
grad ChooseDest W: 3.357301712036133
grad AddEdge W: 2.4291151569052517e-14
grad ChooseDest W: 3.4039947986602783
grad AddEdge W: 9.305874535450167e-17
grad ChooseDest W: 4.499871253967285
grad AddEdge W: 1.2748670389811813e-16
grad ChooseDest W: 4.904205799102783
grad AddEdge W: 5.771857864880664e-17
grad ChooseDest W: 4.743084907531738
grad AddEdge W: 1.8614617971492685e-14
grad ChooseDest W: 5.628060340881348
grad AddEdge W: 3.494245826717954e-17
grad ChooseDest W: 3.4155044555664062
grad AddEdge W: 3.9258944783832355e-16
grad ChooseDest W: 3.091500759124756
grad AddEdge W: 6.205587305920435e-16
grad ChooseDest W: 3.92502760887146
grad AddEdge W: 1.5497572300980644e-14
grad ChooseDest W: 4.694466590881348
grad AddEdge W: 2.6271618559792457e-17
grad ChooseDest W: 5.104143142700195
grad AddEdge W: 1.1871311598403e-14
grad ChooseDest W: 2.759756088256836
grad AddEdge W: 1.3741272566496665e-16
grad ChooseDest W: 3.0944459438323975
grad AddEdge W: 3.6808531618743104e-14
grad ChooseDest W: 5.056755065917969
grad AddEdge W: 9.026520422467739e-17
grad ChooseDest W: 5.604623794555664
grad AddEdge W: 2.3025222183502747e-16
grad ChooseDest W: 5.664254188537598
grad AddEdge W: 6.87753196407237e-12
grad ChooseDest W: 3.336906671524048
grad AddEdge W: 6.738797193194977e-15
grad ChooseDest W: 3.317258596420288
grad AddEdge W: 1.8883073576240588e-16
grad ChooseDest W: 5.495233535766602
grad AddEdge W: 2.640739460869207e-13
grad ChooseDest W: 2.0416259765625
grad AddEdge W: 4.603092356629373e-17
grad ChooseDest W: 3.670156717300415
grad AddEdge W: 2.885716188574805e-12
grad ChooseDest W: 4.0759477615356445
grad AddEdge W: 2.84245529729475e-17
grad ChooseDest W: 4.1485276222229
grad AddEdge W: 2.3347206194171063e-14
grad ChooseDest W: 4.960575103759766
grad AddEdge W: 1.8388529419519225e-16
grad ChooseDest W: 4.9183268547058105
grad AddEdge W: 5.36251942577135e-15
grad ChooseDest W: 5.115607261657715
grad AddEdge W: 9.759701659578339e-15
grad ChooseDest W: 4.960252285003662
grad AddEdge W: 5.179797563092947e-13
grad ChooseDest W: 3.055173635482788
grad AddEdge W: 5.570921718047904e-15
grad ChooseDest W: 4.767384052276611
grad AddEdge W: 1.738452623230389e-14
grad ChooseDest W: 5.513803958892822
grad AddEdge W: 3.1394865908396816e-17
grad ChooseDest W: 2.8504679203033447
grad AddEdge W: 5.973739840466064e-14
grad ChooseDest W: 4.68812370300293
grad AddEdge W: 1.0872653877299108e-16
grad ChooseDest W: 2.9741733074188232
grad AddEdge W: 1.837140135453456e-15
grad ChooseDest W: 3.3010082244873047
grad AddEdge W: 1.8450959718198807e-16
grad ChooseDest W: 4.490315914154053
grad AddEdge W: 2.6949059303560396e-13
grad ChooseDest W: 4.0128889083862305
grad AddEdge W: 2.389399740772188e-16
grad ChooseDest W: 5.240589618682861
grad AddEdge W: 7.580013141684008e-16
grad ChooseDest W: 4.7011542320251465
grad AddEdge W: 9.165508047079447e-15
grad ChooseDest W: 2.8492591381073
grad AddEdge W: 4.197218189630101e-16
grad ChooseDest W: 2.386502742767334
=== Epoch 30: Train Loss: 5.1702, Train Log Prob: 0.0152 ===
Total mismatches: 71075
Predicted valid destination but wrong order: 6026
Epoch 30: Validation Loss: 3.7633, Validation Log Prob: 0.0322
Epoch 30: Edge Precision: 0.3616, Recall: 0.3552, F1: 0.3581, Jaccard: 0.2361
Epoch 30: TP: 2.4866141732283467, FP: 4.412884753042233, FN: 4.534860415175376
Epoch 30: Current Learning Rate: 6e-05
[Epoch 30] ‚è±Ô∏è Total: 3344.05s | Current time: 2025-07-15 16:09:57 | üèãÔ∏è Train: 2848.00s | ‚úÖ Val: 496.05s
grad AddEdge W: 1.0509385110204703e-13
grad ChooseDest W: 10.141740798950195
grad AddEdge W: 4.931213531282131e-16
grad ChooseDest W: 2.5351171493530273
grad AddEdge W: 7.987610478100461e-15
grad ChooseDest W: 4.869422435760498
grad AddEdge W: 2.0588081071784906e-14
grad ChooseDest W: 3.9245553016662598
grad AddEdge W: 4.020372003924388e-16
grad ChooseDest W: 3.103994131088257
grad AddEdge W: 2.633478107875027e-16
grad ChooseDest W: 3.8104870319366455
grad AddEdge W: 2.661801566142231e-16
grad ChooseDest W: 4.722830772399902
grad AddEdge W: 3.2930110478317275e-16
grad ChooseDest W: 6.17775297164917
grad AddEdge W: 3.137758114231691e-17
grad ChooseDest W: 4.447225093841553
grad AddEdge W: 2.722883858208372e-17
grad ChooseDest W: 4.719757080078125
grad AddEdge W: 1.964263184284516e-16
grad ChooseDest W: 3.6466641426086426
grad AddEdge W: 3.763500792340049e-16
grad ChooseDest W: 2.571603775024414
grad AddEdge W: 1.8739158708035142e-16
grad ChooseDest W: 3.2439584732055664
grad AddEdge W: 1.9347730704813676e-16
grad ChooseDest W: 6.635883331298828
grad AddEdge W: 1.455903390797843e-16
grad ChooseDest W: 6.716974258422852
grad AddEdge W: 5.142145169818304e-15
grad ChooseDest W: 5.189571857452393
grad AddEdge W: 3.61585659688652e-16
grad ChooseDest W: 4.023787975311279
grad AddEdge W: 4.7021438256749856e-14
grad ChooseDest W: 4.070359706878662
grad AddEdge W: 3.215833707017101e-17
grad ChooseDest W: 6.711620807647705
grad AddEdge W: 2.0258886693153087e-16
grad ChooseDest W: 2.36641526222229
grad AddEdge W: 1.1058872747263986e-15
grad ChooseDest W: 5.3851637840271
grad AddEdge W: 7.596225881690048e-17
grad ChooseDest W: 4.978758335113525
grad AddEdge W: 5.832369872162731e-15
grad ChooseDest W: 4.2321577072143555
grad AddEdge W: 7.67503499177289e-15
grad ChooseDest W: 2.5803890228271484
grad AddEdge W: 1.6825785395570563e-16
grad ChooseDest W: 4.371835708618164
grad AddEdge W: 2.8942356125004874e-16
grad ChooseDest W: 3.479318857192993
grad AddEdge W: 3.935827951393042e-15
grad ChooseDest W: 2.5595195293426514
grad AddEdge W: 2.561155565514346e-14
grad ChooseDest W: 3.51947283744812
grad AddEdge W: 1.7215218322191384e-15
grad ChooseDest W: 4.624325752258301
grad AddEdge W: 5.1523349761737735e-15
grad ChooseDest W: 3.535705089569092
grad AddEdge W: 3.088998133227405e-16
grad ChooseDest W: 6.881820201873779
grad AddEdge W: 1.4929802728304298e-15
grad ChooseDest W: 3.9577066898345947
grad AddEdge W: 2.1183579326780806e-16
grad ChooseDest W: 4.403719902038574
grad AddEdge W: 4.388584902331917e-16
grad ChooseDest W: 5.778251647949219
grad AddEdge W: 1.3215909314512801e-17
grad ChooseDest W: 5.309674263000488
grad AddEdge W: 3.7962127812465364e-15
grad ChooseDest W: 7.455453395843506
grad AddEdge W: 1.2768205087157865e-16
grad ChooseDest W: 3.2726473808288574
grad AddEdge W: 2.92884723160987e-16
grad ChooseDest W: 4.694844722747803
grad AddEdge W: 9.942084793781135e-15
grad ChooseDest W: 4.948644161224365
grad AddEdge W: 1.3273143926328815e-16
grad ChooseDest W: 4.540482997894287
grad AddEdge W: 2.221596690569599e-16
grad ChooseDest W: 3.3181498050689697
grad AddEdge W: 3.16576552333045e-16
grad ChooseDest W: 4.132782459259033
grad AddEdge W: 1.0059103242477264e-14
grad ChooseDest W: 4.066699504852295
grad AddEdge W: 4.057044718892237e-15
grad ChooseDest W: 5.371772289276123
grad AddEdge W: 8.083755493877402e-15
grad ChooseDest W: 2.821063280105591
grad AddEdge W: 2.067575067589162e-14
grad ChooseDest W: 7.112236499786377
grad AddEdge W: 4.275433106100445e-15
grad ChooseDest W: 3.1836023330688477
grad AddEdge W: 2.493150688898999e-16
grad ChooseDest W: 4.7117791175842285
grad AddEdge W: 1.0788790998076032e-16
grad ChooseDest W: 4.400384426116943
grad AddEdge W: 3.923032301114904e-16
grad ChooseDest W: 7.532463073730469
grad AddEdge W: 3.690078123587474e-16
grad ChooseDest W: 3.5177268981933594
grad AddEdge W: 4.853450149547123e-17
grad ChooseDest W: 4.743682861328125
grad AddEdge W: 3.3367820709511345e-17
grad ChooseDest W: 4.166758060455322
grad AddEdge W: 1.9988251725571457e-16
grad ChooseDest W: 3.5496816635131836
grad AddEdge W: 3.32310697548062e-15
grad ChooseDest W: 3.853274345397949
grad AddEdge W: 1.18215848881081e-16
grad ChooseDest W: 5.769689083099365
grad AddEdge W: 3.241337802884479e-15
grad ChooseDest W: 5.214695930480957
grad AddEdge W: 5.205398096308348e-16
grad ChooseDest W: 3.6754143238067627
grad AddEdge W: 5.124615505337521e-16
grad ChooseDest W: 5.132214546203613
grad AddEdge W: 2.25818204467685e-14
grad ChooseDest W: 3.0856122970581055
grad AddEdge W: 1.3022055567494059e-16
grad ChooseDest W: 5.959068775177002
grad AddEdge W: 7.950871271046253e-15
grad ChooseDest W: 3.55728816986084
grad AddEdge W: 1.4119884647216313e-15
grad ChooseDest W: 4.258205890655518
grad AddEdge W: 2.306844468661436e-16
grad ChooseDest W: 3.055250406265259
grad AddEdge W: 2.9874891754328576e-16
grad ChooseDest W: 6.046313285827637
grad AddEdge W: 1.9496206474863172e-14
grad ChooseDest W: 3.624063014984131
=== Epoch 31: Train Loss: 5.1163, Train Log Prob: 0.0159 ===
Total mismatches: 70313
Predicted valid destination but wrong order: 5961
Epoch 31: Validation Loss: 3.7789, Validation Log Prob: 0.0322
Epoch 31: Edge Precision: 0.3643, Recall: 0.3578, F1: 0.3608, Jaccard: 0.2379
Epoch 31: TP: 2.5047959914101647, FP: 4.39226914817466, FN: 4.5166785969935574
Epoch 31: Current Learning Rate: 6e-05
[Epoch 31] ‚è±Ô∏è Total: 3364.86s | Current time: 2025-07-15 17:06:02 | üèãÔ∏è Train: 2867.86s | ‚úÖ Val: 497.00s
grad AddEdge W: 3.0642731462058453e-14
grad ChooseDest W: 11.243953704833984
grad AddEdge W: 2.9291307229494044e-16
grad ChooseDest W: 3.5837268829345703
grad AddEdge W: 1.0988606705608032e-14
grad ChooseDest W: 4.528319358825684
grad AddEdge W: 4.052023507580913e-16
grad ChooseDest W: 4.293731212615967
grad AddEdge W: 3.5386593693264787e-14
grad ChooseDest W: 2.578904867172241
grad AddEdge W: 1.1615942176234142e-14
grad ChooseDest W: 4.210962772369385
grad AddEdge W: 1.314639206321711e-16
grad ChooseDest W: 5.6410040855407715
grad AddEdge W: 4.015098959129934e-16
grad ChooseDest W: 3.872743606567383
grad AddEdge W: 1.4946175610476927e-16
grad ChooseDest W: 6.023396968841553
grad AddEdge W: 4.198558936906486e-15
grad ChooseDest W: 4.673589706420898
grad AddEdge W: 8.692015200196195e-17
grad ChooseDest W: 4.581382751464844
grad AddEdge W: 1.574973591520238e-16
grad ChooseDest W: 5.896162509918213
grad AddEdge W: 2.4619310767543673e-14
grad ChooseDest W: 3.9440956115722656
grad AddEdge W: 2.0720368983421188e-14
grad ChooseDest W: 3.1785950660705566
grad AddEdge W: 2.3863465575742508e-15
grad ChooseDest W: 5.197991847991943
grad AddEdge W: 8.09162612402329e-15
grad ChooseDest W: 4.071663856506348
grad AddEdge W: 8.030271371898263e-17
grad ChooseDest W: 4.83455228805542
grad AddEdge W: 3.706244499127563e-14
grad ChooseDest W: 4.234596252441406
grad AddEdge W: 4.863196298573666e-14
grad ChooseDest W: 3.1904947757720947
grad AddEdge W: 2.3561259890271698e-14
grad ChooseDest W: 4.620946407318115
grad AddEdge W: 1.2052714503727586e-15
grad ChooseDest W: 3.962306022644043
grad AddEdge W: 1.058263482541736e-14
grad ChooseDest W: 4.8585896492004395
grad AddEdge W: 8.040730243563383e-16
grad ChooseDest W: 4.348613739013672
grad AddEdge W: 1.1782540639706618e-16
grad ChooseDest W: 4.014296054840088
grad AddEdge W: 1.183562186517044e-14
grad ChooseDest W: 3.1941769123077393
grad AddEdge W: 4.8901653882159015e-17
grad ChooseDest W: 6.279067039489746
grad AddEdge W: 9.228068206497755e-16
grad ChooseDest W: 3.124447822570801
grad AddEdge W: 1.266905855719277e-16
grad ChooseDest W: 5.117441654205322
grad AddEdge W: 7.641452147117507e-17
grad ChooseDest W: 6.040985584259033
grad AddEdge W: 4.80916847143964e-14
grad ChooseDest W: 5.768141746520996
grad AddEdge W: 7.22468546728879e-17
grad ChooseDest W: 4.0049543380737305
grad AddEdge W: 4.442888449278186e-16
grad ChooseDest W: 6.549831390380859
grad AddEdge W: 3.887141132859575e-16
grad ChooseDest W: 2.5935604572296143
grad AddEdge W: 1.352888831939551e-16
grad ChooseDest W: 3.531238555908203
grad AddEdge W: 4.50387323329372e-16
grad ChooseDest W: 3.6168549060821533
grad AddEdge W: 2.8113891728141164e-16
grad ChooseDest W: 7.374682903289795
grad AddEdge W: 2.598462659190596e-17
grad ChooseDest W: 5.294132709503174
grad AddEdge W: 9.156161038506496e-15
grad ChooseDest W: 2.3426976203918457
grad AddEdge W: 3.509955116809925e-14
grad ChooseDest W: 4.731855392456055
grad AddEdge W: 1.9783247253023255e-16
grad ChooseDest W: 4.812010765075684
grad AddEdge W: 3.1935784854282556e-13
grad ChooseDest W: 2.481137275695801
grad AddEdge W: 8.670872993134932e-15
grad ChooseDest W: 2.8080413341522217
grad AddEdge W: 3.4973768707725897e-17
grad ChooseDest W: 4.44888162612915
grad AddEdge W: 5.089714571537092e-16
grad ChooseDest W: 5.440739631652832
grad AddEdge W: 3.327619416452175e-14
grad ChooseDest W: 6.517388820648193
grad AddEdge W: 2.2587423146198113e-15
grad ChooseDest W: 2.9339098930358887
grad AddEdge W: 7.91616134317543e-16
grad ChooseDest W: 5.646160125732422
grad AddEdge W: 1.2953073468967465e-15
grad ChooseDest W: 5.41542387008667
grad AddEdge W: 1.2836796174100183e-14
grad ChooseDest W: 3.571700096130371
grad AddEdge W: 3.5852698305853525e-13
grad ChooseDest W: 1.7603578567504883
grad AddEdge W: 2.7890071212763096e-16
grad ChooseDest W: 4.226729869842529
grad AddEdge W: 1.1928943720134182e-14
grad ChooseDest W: 7.14625358581543
grad AddEdge W: 7.370307371580749e-16
grad ChooseDest W: 3.93576979637146
grad AddEdge W: 1.5791044984121034e-17
grad ChooseDest W: 3.834899425506592
grad AddEdge W: 4.235538277801241e-15
grad ChooseDest W: 5.414783477783203
grad AddEdge W: 9.174661190986596e-17
grad ChooseDest W: 5.754498481750488
grad AddEdge W: 2.395858631692798e-16
grad ChooseDest W: 4.991504669189453
grad AddEdge W: 3.6947455398246413e-16
grad ChooseDest W: 4.344029426574707
grad AddEdge W: 2.1544983933176982e-15
grad ChooseDest W: 4.14330530166626
grad AddEdge W: 1.0053958364355641e-14
grad ChooseDest W: 3.3970861434936523
grad AddEdge W: 1.8030022724593842e-16
grad ChooseDest W: 4.1847615242004395
grad AddEdge W: 7.172141366592645e-16
grad ChooseDest W: 4.978586673736572
grad AddEdge W: 3.9908757756021516e-15
grad ChooseDest W: 5.423455715179443
grad AddEdge W: 7.521299200060504e-17
grad ChooseDest W: 6.333709239959717
grad AddEdge W: 3.24266777166661e-14
grad ChooseDest W: 2.9546802043914795
grad AddEdge W: 2.2178349378415037e-16
grad ChooseDest W: 8.785841941833496
=== Epoch 32: Train Loss: 5.0696, Train Log Prob: 0.0168 ===
Total mismatches: 69445
Predicted valid destination but wrong order: 6006
Epoch 32: Validation Loss: 3.6537, Validation Log Prob: 0.0356
Epoch 32: Edge Precision: 0.3642, Recall: 0.3574, F1: 0.3605, Jaccard: 0.2378
Epoch 32: TP: 2.5020758768790263, FP: 4.3859699355762345, FN: 4.519398711524696
Epoch 32: Current Learning Rate: 6e-05
[Epoch 32] ‚è±Ô∏è Total: 3377.93s | Current time: 2025-07-15 18:02:20 | üèãÔ∏è Train: 2880.44s | ‚úÖ Val: 497.49s
grad AddEdge W: 4.088516566860649e-14
grad ChooseDest W: 10.008925437927246
grad AddEdge W: 1.2727657355275006e-16
grad ChooseDest W: 4.6073994636535645
grad AddEdge W: 1.365405887787381e-15
grad ChooseDest W: 1.6232712268829346
grad AddEdge W: 6.472918209733062e-15
grad ChooseDest W: 5.355068206787109
grad AddEdge W: 6.848649743157334e-15
grad ChooseDest W: 2.1608352661132812
grad AddEdge W: 3.747156232831593e-16
grad ChooseDest W: 5.341172218322754
grad AddEdge W: 1.6074602167231967e-16
grad ChooseDest W: 5.376195907592773
grad AddEdge W: 4.221520226631317e-17
grad ChooseDest W: 5.632631778717041
grad AddEdge W: 1.2103506569711894e-16
grad ChooseDest W: 4.486660480499268
grad AddEdge W: 6.173458684486589e-17
grad ChooseDest W: 4.180474758148193
grad AddEdge W: 4.876773664970913e-16
grad ChooseDest W: 4.551329612731934
grad AddEdge W: 3.549003198035494e-17
grad ChooseDest W: 6.234777927398682
grad AddEdge W: 1.1058698046718615e-16
grad ChooseDest W: 5.8817853927612305
grad AddEdge W: 4.56695760022726e-16
grad ChooseDest W: 5.341152667999268
grad AddEdge W: 3.898311644549287e-17
grad ChooseDest W: 7.73397970199585
grad AddEdge W: 1.9498274929320367e-16
grad ChooseDest W: 6.317654609680176
grad AddEdge W: 5.647891009041839e-14
grad ChooseDest W: 2.5342187881469727
grad AddEdge W: 2.500031931622934e-15
grad ChooseDest W: 4.228581428527832
grad AddEdge W: 1.2245137095937713e-16
grad ChooseDest W: 3.4079222679138184
grad AddEdge W: 1.086863576475557e-16
grad ChooseDest W: 3.216329574584961
grad AddEdge W: 6.026114656333743e-17
grad ChooseDest W: 6.215095520019531
grad AddEdge W: 2.2382583050981238e-14
grad ChooseDest W: 4.371988773345947
grad AddEdge W: 3.7458791189053705e-15
grad ChooseDest W: 2.2699365615844727
grad AddEdge W: 1.8626691579122848e-14
grad ChooseDest W: 4.213920593261719
grad AddEdge W: 3.6276472955123e-15
grad ChooseDest W: 3.3997576236724854
grad AddEdge W: 1.7178028281851e-15
grad ChooseDest W: 2.981107234954834
grad AddEdge W: 7.096292107264864e-15
grad ChooseDest W: 3.6500864028930664
grad AddEdge W: 4.199227709123013e-17
grad ChooseDest W: 4.534671783447266
grad AddEdge W: 8.498805026163798e-15
grad ChooseDest W: 5.971205711364746
grad AddEdge W: 3.664381420368824e-15
grad ChooseDest W: 4.389225959777832
grad AddEdge W: 1.933836993195533e-15
grad ChooseDest W: 3.620953321456909
grad AddEdge W: 2.3200769444183846e-14
grad ChooseDest W: 4.539709091186523
grad AddEdge W: 2.2080527660919006e-17
grad ChooseDest W: 5.6455769538879395
grad AddEdge W: 5.5635770953622616e-15
grad ChooseDest W: 4.438903331756592
grad AddEdge W: 8.026909709888847e-17
grad ChooseDest W: 4.442535877227783
grad AddEdge W: 4.762947916387046e-14
grad ChooseDest W: 5.494228363037109
grad AddEdge W: 1.0716867312942301e-16
grad ChooseDest W: 4.062246322631836
grad AddEdge W: 5.799917075338104e-15
grad ChooseDest W: 3.8353164196014404
grad AddEdge W: 6.913768789109298e-17
grad ChooseDest W: 3.1035192012786865
grad AddEdge W: 3.833853099007725e-17
grad ChooseDest W: 3.508551836013794
grad AddEdge W: 6.822560281348955e-16
grad ChooseDest W: 3.6354715824127197
grad AddEdge W: 8.795999744127991e-17
grad ChooseDest W: 5.604557037353516
grad AddEdge W: 1.1368943980683e-14
grad ChooseDest W: 4.611546039581299
grad AddEdge W: 2.1928063477418686e-14
grad ChooseDest W: 4.952237129211426
grad AddEdge W: 2.07139789668671e-14
grad ChooseDest W: 6.622477054595947
grad AddEdge W: 2.776331537918445e-16
grad ChooseDest W: 5.730492115020752
grad AddEdge W: 4.995205282260417e-16
grad ChooseDest W: 4.108074188232422
grad AddEdge W: 9.07037025935591e-17
grad ChooseDest W: 3.851834297180176
grad AddEdge W: 4.680458956368152e-16
grad ChooseDest W: 3.446340560913086
grad AddEdge W: 1.0722821689863703e-16
grad ChooseDest W: 2.8187930583953857
grad AddEdge W: 8.527718461937006e-13
grad ChooseDest W: 2.9083845615386963
grad AddEdge W: 7.543189443093312e-16
grad ChooseDest W: 4.6379075050354
grad AddEdge W: 1.2673143479460022e-14
grad ChooseDest W: 5.09066104888916
grad AddEdge W: 5.453361591782006e-15
grad ChooseDest W: 5.436318874359131
grad AddEdge W: 4.042142471204498e-17
grad ChooseDest W: 5.951364517211914
grad AddEdge W: 7.929534669923595e-17
grad ChooseDest W: 4.758573532104492
grad AddEdge W: 1.3675782308355568e-14
grad ChooseDest W: 2.1873130798339844
grad AddEdge W: 3.681639822548249e-16
grad ChooseDest W: 5.63801908493042
grad AddEdge W: 6.260156780978077e-13
grad ChooseDest W: 5.111904144287109
grad AddEdge W: 3.0542386803989466e-17
grad ChooseDest W: 4.436878681182861
grad AddEdge W: 2.4662497165875907e-15
grad ChooseDest W: 3.9781863689422607
grad AddEdge W: 7.702112385377102e-12
grad ChooseDest W: 5.001103401184082
grad AddEdge W: 8.133705026776988e-15
grad ChooseDest W: 4.2268195152282715
grad AddEdge W: 4.2478794461987823e-13
grad ChooseDest W: 7.138069152832031
grad AddEdge W: 7.541386959353247e-11
grad ChooseDest W: 3.3486545085906982
grad AddEdge W: 9.009085440388591e-17
grad ChooseDest W: 3.4949355125427246
=== Epoch 33: Train Loss: 5.0245, Train Log Prob: 0.0174 ===
Total mismatches: 68747
Predicted valid destination but wrong order: 5975
Epoch 33: Validation Loss: 3.6589, Validation Log Prob: 0.0359
Epoch 33: Edge Precision: 0.3642, Recall: 0.3572, F1: 0.3604, Jaccard: 0.2373
Epoch 33: TP: 2.5006442376521116, FP: 4.386828919112384, FN: 4.520830350751611
Epoch 33: Current Learning Rate: 6e-05
[Epoch 33] ‚è±Ô∏è Total: 3385.26s | Current time: 2025-07-15 18:58:45 | üèãÔ∏è Train: 2889.12s | ‚úÖ Val: 496.13s
grad AddEdge W: 2.1843243630959713e-13
grad ChooseDest W: 9.022092819213867
grad AddEdge W: 3.910444915062672e-15
grad ChooseDest W: 2.025763511657715
grad AddEdge W: 1.8830466212771196e-16
grad ChooseDest W: 3.946364641189575
grad AddEdge W: 2.715277276025413e-13
grad ChooseDest W: 3.751274347305298
grad AddEdge W: 2.801770584302452e-17
grad ChooseDest W: 3.8392653465270996
grad AddEdge W: 2.4375136606308455e-17
grad ChooseDest W: 4.059105396270752
grad AddEdge W: 5.045191661093209e-15
grad ChooseDest W: 3.350842237472534
grad AddEdge W: 9.792361291260774e-17
grad ChooseDest W: 3.606275796890259
grad AddEdge W: 3.5332193849260327e-14
grad ChooseDest W: 3.833754539489746
grad AddEdge W: 2.667775001304946e-16
grad ChooseDest W: 5.408633708953857
grad AddEdge W: 1.8827418058831383e-14
grad ChooseDest W: 2.9676051139831543
grad AddEdge W: 7.467738924525451e-15
grad ChooseDest W: 4.2312846183776855
grad AddEdge W: 9.366114459867709e-17
grad ChooseDest W: 4.3731465339660645
grad AddEdge W: 6.333074764207271e-17
grad ChooseDest W: 4.559224605560303
grad AddEdge W: 1.1502266966580826e-14
grad ChooseDest W: 4.252261638641357
grad AddEdge W: 7.914369868491987e-16
grad ChooseDest W: 4.308225631713867
grad AddEdge W: 9.495579845965503e-15
grad ChooseDest W: 5.134805202484131
grad AddEdge W: 5.353700529006122e-17
grad ChooseDest W: 4.389288902282715
grad AddEdge W: 1.8505041977787606e-15
grad ChooseDest W: 2.45906925201416
grad AddEdge W: 2.899248856408151e-17
grad ChooseDest W: 3.3236262798309326
grad AddEdge W: 2.4472473794488877e-15
grad ChooseDest W: 4.105080604553223
grad AddEdge W: 2.9421567661891954e-16
grad ChooseDest W: 5.198225975036621
grad AddEdge W: 2.195024896437317e-13
grad ChooseDest W: 3.1244447231292725
grad AddEdge W: 1.470745161656637e-17
grad ChooseDest W: 4.685441970825195
grad AddEdge W: 2.7040095818633822e-17
grad ChooseDest W: 6.31726598739624
grad AddEdge W: 1.499286433122738e-16
grad ChooseDest W: 5.099363327026367
grad AddEdge W: 1.842955990724246e-13
grad ChooseDest W: 2.9444596767425537
grad AddEdge W: 3.961496331947518e-17
grad ChooseDest W: 3.077650547027588
grad AddEdge W: 6.891774387493758e-17
grad ChooseDest W: 4.623349189758301
grad AddEdge W: 1.1694014050015519e-14
grad ChooseDest W: 3.819768190383911
grad AddEdge W: 1.7300915954187552e-17
grad ChooseDest W: 3.7453596591949463
grad AddEdge W: 4.71217938733076e-15
grad ChooseDest W: 3.8553128242492676
grad AddEdge W: 7.091347552435267e-15
grad ChooseDest W: 3.663745164871216
grad AddEdge W: 7.681724593292509e-17
grad ChooseDest W: 5.5041656494140625
grad AddEdge W: 1.082534872832129e-14
grad ChooseDest W: 4.998945713043213
grad AddEdge W: 6.39086729280284e-16
grad ChooseDest W: 3.143007278442383
grad AddEdge W: 5.2123012824795725e-17
grad ChooseDest W: 5.29364538192749
grad AddEdge W: 4.345581767518755e-17
grad ChooseDest W: 3.2259743213653564
grad AddEdge W: 8.325507484990607e-16
grad ChooseDest W: 4.4084391593933105
grad AddEdge W: 4.133475381635013e-14
grad ChooseDest W: 5.014732360839844
grad AddEdge W: 1.746737476882032e-10
grad ChooseDest W: 1.0684374570846558
grad AddEdge W: 1.725177119216159e-11
grad ChooseDest W: 3.9083499908447266
grad AddEdge W: 1.9011920522407768e-16
grad ChooseDest W: 4.4607744216918945
grad AddEdge W: 5.4107998802483716e-15
grad ChooseDest W: 4.386277675628662
grad AddEdge W: 1.4911219619534926e-16
grad ChooseDest W: 4.044837474822998
grad AddEdge W: 4.56006804599253e-17
grad ChooseDest W: 6.22509765625
grad AddEdge W: 3.187082695634881e-16
grad ChooseDest W: 4.240864276885986
grad AddEdge W: 6.400548561752602e-15
grad ChooseDest W: 4.118354320526123
grad AddEdge W: 8.581875241366922e-15
grad ChooseDest W: 4.186841011047363
grad AddEdge W: 6.487649806751709e-15
grad ChooseDest W: 4.172745227813721
grad AddEdge W: 4.9244856544612085e-15
grad ChooseDest W: 3.689185380935669
grad AddEdge W: 1.3933625913763355e-14
grad ChooseDest W: 2.7851099967956543
grad AddEdge W: 2.8748441127657287e-11
grad ChooseDest W: 10.403853416442871
grad AddEdge W: 1.3589832339950457e-16
grad ChooseDest W: 4.7699294090271
grad AddEdge W: 9.094472475990913e-15
grad ChooseDest W: 3.8189244270324707
grad AddEdge W: 2.2459198875126284e-14
grad ChooseDest W: 5.031905174255371
grad AddEdge W: 3.1090549734458803e-15
grad ChooseDest W: 7.122182369232178
grad AddEdge W: 1.0243108021257578e-15
grad ChooseDest W: 6.000056743621826
grad AddEdge W: 3.039587683859187e-15
grad ChooseDest W: 5.552818298339844
grad AddEdge W: 5.5244196092436425e-15
grad ChooseDest W: 6.967555046081543
grad AddEdge W: 4.291156261062971e-16
grad ChooseDest W: 4.889673709869385
grad AddEdge W: 1.3399648297001245e-16
grad ChooseDest W: 5.435451030731201
grad AddEdge W: 3.5702906288955644e-14
grad ChooseDest W: 2.42624831199646
grad AddEdge W: 2.476172972262471e-16
grad ChooseDest W: 3.8159241676330566
grad AddEdge W: 6.332487796844604e-17
grad ChooseDest W: 5.072137832641602
grad AddEdge W: 9.163824145580306e-15
grad ChooseDest W: 2.559087038040161
=== Epoch 34: Train Loss: 4.9696, Train Log Prob: 0.0183 ===
Total mismatches: 67921
Predicted valid destination but wrong order: 6012
Epoch 34: Validation Loss: 3.6148, Validation Log Prob: 0.0371
Epoch 34: Edge Precision: 0.3644, Recall: 0.3576, F1: 0.3607, Jaccard: 0.2375
Epoch 34: TP: 2.5029348604151753, FP: 4.386256263421617, FN: 4.518539727988547
Epoch 34: Current Learning Rate: 6e-05
[Epoch 34] ‚è±Ô∏è Total: 3391.12s | Current time: 2025-07-15 19:55:16 | üèãÔ∏è Train: 2894.59s | ‚úÖ Val: 496.53s
grad AddEdge W: 3.472719940201364e-16
grad ChooseDest W: 9.728540420532227
grad AddEdge W: 2.1184959064042544e-17
grad ChooseDest W: 6.6075663566589355
grad AddEdge W: 4.813142630914149e-17
grad ChooseDest W: 3.509833574295044
grad AddEdge W: 5.687404841921368e-16
grad ChooseDest W: 6.884912967681885
grad AddEdge W: 8.318219295875076e-15
grad ChooseDest W: 3.6884074211120605
grad AddEdge W: 7.246304659778475e-17
grad ChooseDest W: 3.3474183082580566
grad AddEdge W: 1.3153791478346527e-14
grad ChooseDest W: 4.245724678039551
grad AddEdge W: 3.0778310943727766e-14
grad ChooseDest W: 3.88018536567688
grad AddEdge W: 8.290149153398661e-16
grad ChooseDest W: 3.9093096256256104
grad AddEdge W: 3.940420987549528e-15
grad ChooseDest W: 4.545833110809326
grad AddEdge W: 4.010422410818804e-17
grad ChooseDest W: 7.033839702606201
grad AddEdge W: 5.409371359182827e-15
grad ChooseDest W: 1.5455430746078491
grad AddEdge W: 3.446386479964616e-16
grad ChooseDest W: 3.848451614379883
grad AddEdge W: 7.94474354353824e-17
grad ChooseDest W: 3.1276066303253174
grad AddEdge W: 1.5072929273533646e-14
grad ChooseDest W: 4.843583583831787
grad AddEdge W: 4.648744454636175e-16
grad ChooseDest W: 3.1569814682006836
grad AddEdge W: 9.80565150290099e-15
grad ChooseDest W: 1.8203773498535156
grad AddEdge W: 5.0009655695228895e-17
grad ChooseDest W: 5.269509315490723
grad AddEdge W: 2.399517792849113e-14
grad ChooseDest W: 4.5928802490234375
grad AddEdge W: 1.1601984767329286e-14
grad ChooseDest W: 5.530342102050781
grad AddEdge W: 7.72902487183088e-15
grad ChooseDest W: 9.214974403381348
grad AddEdge W: 5.236438148056074e-16
grad ChooseDest W: 4.515549182891846
grad AddEdge W: 2.6972412592192283e-17
grad ChooseDest W: 2.6951193809509277
grad AddEdge W: 3.515164496490481e-16
grad ChooseDest W: 2.4252848625183105
grad AddEdge W: 4.079432307907936e-14
grad ChooseDest W: 2.7238762378692627
grad AddEdge W: 4.482524826649359e-17
grad ChooseDest W: 4.706518650054932
grad AddEdge W: 4.7269348600906074e-17
grad ChooseDest W: 4.907230377197266
grad AddEdge W: 7.18272689615316e-17
grad ChooseDest W: 4.622968673706055
grad AddEdge W: 4.213567937215359e-15
grad ChooseDest W: 4.970302581787109
grad AddEdge W: 1.1766400691594483e-16
grad ChooseDest W: 4.519120216369629
grad AddEdge W: 4.3492969201998615e-15
grad ChooseDest W: 5.970803737640381
grad AddEdge W: 5.492439562682701e-17
grad ChooseDest W: 3.5387582778930664
grad AddEdge W: 7.121481173050313e-15
grad ChooseDest W: 4.250678062438965
grad AddEdge W: 8.173261617614997e-18
grad ChooseDest W: 4.154359340667725
grad AddEdge W: 3.7184644740510114e-15
grad ChooseDest W: 4.303261756896973
grad AddEdge W: 2.057372553092506e-17
grad ChooseDest W: 4.116423606872559
grad AddEdge W: 2.3629853491843078e-17
grad ChooseDest W: 7.176292419433594
grad AddEdge W: 2.0255119196482818e-14
grad ChooseDest W: 3.009399175643921
grad AddEdge W: 1.816612080218511e-14
grad ChooseDest W: 5.079630374908447
grad AddEdge W: 1.6507691277833393e-14
grad ChooseDest W: 4.333407402038574
grad AddEdge W: 1.0529247529892003e-16
grad ChooseDest W: 3.1452908515930176
grad AddEdge W: 6.632932897864766e-15
grad ChooseDest W: 3.3907792568206787
grad AddEdge W: 1.1173017848444791e-15
grad ChooseDest W: 2.776566505432129
grad AddEdge W: 7.262729046636496e-12
grad ChooseDest W: 2.665485143661499
grad AddEdge W: 1.6353870094612012e-14
grad ChooseDest W: 3.3167951107025146
grad AddEdge W: 1.0593155821655206e-14
grad ChooseDest W: 7.18247127532959
grad AddEdge W: 5.233475226806578e-15
grad ChooseDest W: 2.8760082721710205
grad AddEdge W: 1.7352753348826022e-12
grad ChooseDest W: 2.9815518856048584
grad AddEdge W: 2.8055123523469476e-16
grad ChooseDest W: 3.9138317108154297
grad AddEdge W: 3.125421809920849e-14
grad ChooseDest W: 3.7251603603363037
grad AddEdge W: 3.012016602607382e-16
grad ChooseDest W: 4.144586086273193
grad AddEdge W: 4.276660033324543e-15
grad ChooseDest W: 4.043755531311035
grad AddEdge W: 3.117244696784866e-17
grad ChooseDest W: 4.295848846435547
grad AddEdge W: 5.5444377903490096e-17
grad ChooseDest W: 6.867947578430176
grad AddEdge W: 4.422900324607557e-16
grad ChooseDest W: 3.4991953372955322
grad AddEdge W: 1.500673317224969e-16
grad ChooseDest W: 4.901574611663818
grad AddEdge W: 9.676703442175732e-15
grad ChooseDest W: 5.870684623718262
grad AddEdge W: 2.616757095161076e-15
grad ChooseDest W: 5.047447681427002
grad AddEdge W: 1.0530452513668812e-14
grad ChooseDest W: 5.1061224937438965
grad AddEdge W: 2.562003879598933e-16
grad ChooseDest W: 5.985737323760986
grad AddEdge W: 1.2870877391765907e-14
grad ChooseDest W: 7.932391166687012
grad AddEdge W: 5.856951588855219e-17
grad ChooseDest W: 3.899418592453003
grad AddEdge W: 1.169193458413001e-14
grad ChooseDest W: 4.235369682312012
grad AddEdge W: 2.8314037672643475e-16
grad ChooseDest W: 6.278899669647217
grad AddEdge W: 5.319055200632417e-13
grad ChooseDest W: 4.9303388595581055
grad AddEdge W: 7.346329986426348e-16
grad ChooseDest W: 3.3584389686584473
=== Epoch 35: Train Loss: 4.9237, Train Log Prob: 0.0191 ===
Total mismatches: 67217
Predicted valid destination but wrong order: 6016
Epoch 35: Validation Loss: 3.6055, Validation Log Prob: 0.0375
Epoch 35: Edge Precision: 0.3647, Recall: 0.3576, F1: 0.3609, Jaccard: 0.2377
Epoch 35: TP: 2.5035075161059415, FP: 4.382104509663565, FN: 4.517967072297781
Epoch 35: Current Learning Rate: 6e-05
[Epoch 35] ‚è±Ô∏è Total: 3391.37s | Current time: 2025-07-15 20:51:48 | üèãÔ∏è Train: 2895.01s | ‚úÖ Val: 496.36s
grad AddEdge W: 2.055472491432203e-14
grad ChooseDest W: 10.310592651367188
grad AddEdge W: 8.388116454682501e-15
grad ChooseDest W: 4.282830238342285
grad AddEdge W: 1.4575200855265757e-14
grad ChooseDest W: 2.8356006145477295
grad AddEdge W: 5.115983379337163e-17
grad ChooseDest W: 3.8782968521118164
grad AddEdge W: 8.033922877994317e-17
grad ChooseDest W: 2.3775174617767334
grad AddEdge W: 3.7131738003833427e-16
grad ChooseDest W: 3.6759042739868164
grad AddEdge W: 3.1019831885428784e-13
grad ChooseDest W: 6.123010158538818
grad AddEdge W: 3.0663693833437103e-15
grad ChooseDest W: 4.174452304840088
grad AddEdge W: 1.7975161289984776e-12
grad ChooseDest W: 2.8970136642456055
grad AddEdge W: 1.114693108655393e-16
grad ChooseDest W: 3.5955095291137695
grad AddEdge W: 9.782983048347893e-17
grad ChooseDest W: 3.0038015842437744
grad AddEdge W: 4.476844411946835e-16
grad ChooseDest W: 4.833735466003418
grad AddEdge W: 5.732163783389959e-17
grad ChooseDest W: 3.646507978439331
grad AddEdge W: 1.309306869220949e-16
grad ChooseDest W: 5.373008728027344
grad AddEdge W: 6.295514782227174e-15
grad ChooseDest W: 3.2015225887298584
grad AddEdge W: 8.125531158835984e-15
grad ChooseDest W: 5.474377632141113
grad AddEdge W: 7.484177292932815e-15
grad ChooseDest W: 9.934456825256348
grad AddEdge W: 7.84781361938677e-15
grad ChooseDest W: 3.5179948806762695
grad AddEdge W: 4.1162008117142073e-16
grad ChooseDest W: 4.4859185218811035
grad AddEdge W: 6.824292993121682e-17
grad ChooseDest W: 5.270042896270752
grad AddEdge W: 3.9091582984855726e-17
grad ChooseDest W: 5.269474506378174
grad AddEdge W: 4.113449489882848e-13
grad ChooseDest W: 5.144250392913818
grad AddEdge W: 1.1673398115112296e-14
grad ChooseDest W: 1.6026636362075806
grad AddEdge W: 4.549413297958357e-17
grad ChooseDest W: 5.694591522216797
grad AddEdge W: 3.570919182928964e-17
grad ChooseDest W: 3.1265780925750732
grad AddEdge W: 4.466052351930978e-17
grad ChooseDest W: 4.4816999435424805
grad AddEdge W: 5.9732767675538e-15
grad ChooseDest W: 3.2560272216796875
grad AddEdge W: 4.76141360090639e-15
grad ChooseDest W: 4.184841156005859
grad AddEdge W: 4.740885333913208e-15
grad ChooseDest W: 3.4289560317993164
grad AddEdge W: 9.366573339966884e-15
grad ChooseDest W: 3.7689049243927
grad AddEdge W: 1.1552878243970455e-15
grad ChooseDest W: 4.954366207122803
grad AddEdge W: 1.6955958477695788e-15
grad ChooseDest W: 5.557460308074951
grad AddEdge W: 1.4213151974434076e-16
grad ChooseDest W: 4.637759208679199
grad AddEdge W: 3.16806892355139e-16
grad ChooseDest W: 4.949474334716797
grad AddEdge W: 6.334082204018912e-16
grad ChooseDest W: 4.648934841156006
grad AddEdge W: 1.8881816261709508e-16
grad ChooseDest W: 3.2023913860321045
grad AddEdge W: 3.568421904807332e-15
grad ChooseDest W: 3.5147202014923096
grad AddEdge W: 7.024458128214204e-17
grad ChooseDest W: 5.629659652709961
grad AddEdge W: 5.6185292048483316e-15
grad ChooseDest W: 1.9249558448791504
grad AddEdge W: 3.8693186332070586e-17
grad ChooseDest W: 2.5538828372955322
grad AddEdge W: 7.509510387406521e-18
grad ChooseDest W: 6.26287317276001
grad AddEdge W: 2.392238095238878e-16
grad ChooseDest W: 2.8975563049316406
grad AddEdge W: 1.3935508868005101e-15
grad ChooseDest W: 6.1841583251953125
grad AddEdge W: 1.0248515903109323e-14
grad ChooseDest W: 4.815600872039795
grad AddEdge W: 2.238629729045495e-16
grad ChooseDest W: 5.476373672485352
grad AddEdge W: 4.4296157076925073e-16
grad ChooseDest W: 4.745190143585205
grad AddEdge W: 2.893369256614124e-16
grad ChooseDest W: 3.474072217941284
grad AddEdge W: 7.578666359297874e-15
grad ChooseDest W: 7.136021137237549
grad AddEdge W: 1.2885655469717535e-16
grad ChooseDest W: 4.965068817138672
grad AddEdge W: 2.795293022658102e-13
grad ChooseDest W: 6.818002223968506
grad AddEdge W: 5.356171760864626e-15
grad ChooseDest W: 3.0353927612304688
grad AddEdge W: 1.4805402705110203e-16
grad ChooseDest W: 3.161532163619995
grad AddEdge W: 1.6251627864630191e-12
grad ChooseDest W: 2.8253941535949707
grad AddEdge W: 2.7532335847215306e-15
grad ChooseDest W: 4.43104362487793
grad AddEdge W: 3.1818779958113583e-15
grad ChooseDest W: 3.4219982624053955
grad AddEdge W: 2.496263058524126e-15
grad ChooseDest W: 4.06575870513916
grad AddEdge W: 5.526098203551974e-17
grad ChooseDest W: 6.180064678192139
grad AddEdge W: 1.3790028841731807e-15
grad ChooseDest W: 2.878617525100708
grad AddEdge W: 4.758878007778784e-15
grad ChooseDest W: 5.981027126312256
grad AddEdge W: 2.1394875996812576e-17
grad ChooseDest W: 2.0046677589416504
grad AddEdge W: 8.38182577921126e-17
grad ChooseDest W: 5.437387943267822
grad AddEdge W: 3.215500036916376e-14
grad ChooseDest W: 3.9675703048706055
grad AddEdge W: 1.9981160823134836e-11
grad ChooseDest W: 1.8984848260879517
grad AddEdge W: 3.4291633355316205e-15
grad ChooseDest W: 3.661597967147827
grad AddEdge W: 2.519093603419592e-14
grad ChooseDest W: 5.946040153503418
grad AddEdge W: 4.23983739352503e-15
grad ChooseDest W: 3.370936393737793
=== Epoch 36: Train Loss: 4.8802, Train Log Prob: 0.0199 ===
Total mismatches: 66672
Predicted valid destination but wrong order: 5994
Epoch 36: Validation Loss: 3.5316, Validation Log Prob: 0.0403
Epoch 36: Edge Precision: 0.3661, Recall: 0.3587, F1: 0.3621, Jaccard: 0.2390
Epoch 36: TP: 2.5100930565497497, FP: 4.370937723693629, FN: 4.5113815318539725
Epoch 36: Current Learning Rate: 6e-05
[Epoch 36] ‚è±Ô∏è Total: 3389.76s | Current time: 2025-07-15 21:48:18 | üèãÔ∏è Train: 2894.07s | ‚úÖ Val: 495.70s
grad AddEdge W: 4.876861650518309e-14
grad ChooseDest W: 10.369139671325684
grad AddEdge W: 3.4934004084272554e-15
grad ChooseDest W: 4.006428241729736
grad AddEdge W: 1.2266749670982499e-16
grad ChooseDest W: 7.968087673187256
grad AddEdge W: 1.63331219166899e-16
grad ChooseDest W: 4.263551235198975
grad AddEdge W: 3.6087180282001874e-17
grad ChooseDest W: 6.4609832763671875
grad AddEdge W: 1.865457590374646e-14
grad ChooseDest W: 4.496323585510254
grad AddEdge W: 6.350253651168773e-17
grad ChooseDest W: 3.6463639736175537
grad AddEdge W: 1.0651475707669779e-16
grad ChooseDest W: 4.316401958465576
grad AddEdge W: 1.598574576408703e-16
grad ChooseDest W: 4.788217067718506
grad AddEdge W: 2.2680073727551157e-15
grad ChooseDest W: 3.930931568145752
grad AddEdge W: 1.3961622046736004e-14
grad ChooseDest W: 6.506325721740723
grad AddEdge W: 4.984468716137495e-15
grad ChooseDest W: 5.49223518371582
grad AddEdge W: 3.244697347311526e-17
grad ChooseDest W: 4.400314807891846
grad AddEdge W: 1.579080663699061e-14
grad ChooseDest W: 4.727114200592041
grad AddEdge W: 2.7461538715901424e-16
grad ChooseDest W: 4.909677028656006
grad AddEdge W: 2.086540860550147e-16
grad ChooseDest W: 3.6861369609832764
grad AddEdge W: 9.038575077735707e-15
grad ChooseDest W: 2.9618101119995117
grad AddEdge W: 9.705623793972954e-17
grad ChooseDest W: 3.0865440368652344
grad AddEdge W: 8.707936772626616e-17
grad ChooseDest W: 4.387054443359375
grad AddEdge W: 1.0188044526938944e-15
grad ChooseDest W: 5.324707508087158
grad AddEdge W: 2.4093121618731566e-16
grad ChooseDest W: 4.503730297088623
grad AddEdge W: 4.1565332447625336e-13
grad ChooseDest W: 6.799691677093506
grad AddEdge W: 1.5324365040814136e-11
grad ChooseDest W: 1.477949857711792
grad AddEdge W: 2.7163421234950537e-15
grad ChooseDest W: 6.463904857635498
grad AddEdge W: 4.585071730676538e-17
grad ChooseDest W: 4.540571689605713
grad AddEdge W: 1.730620660138544e-16
grad ChooseDest W: 4.211543560028076
grad AddEdge W: 2.761251175083766e-16
grad ChooseDest W: 5.71908712387085
grad AddEdge W: 6.11535832823612e-13
grad ChooseDest W: 3.0942366123199463
grad AddEdge W: 1.4538463977552154e-15
grad ChooseDest W: 6.65562629699707
grad AddEdge W: 9.865980365777994e-16
grad ChooseDest W: 5.193981170654297
grad AddEdge W: 2.293087859504638e-16
grad ChooseDest W: 4.863178730010986
grad AddEdge W: 4.6890777813042605e-17
grad ChooseDest W: 5.289285182952881
grad AddEdge W: 2.3208182337725036e-13
grad ChooseDest W: 2.2516701221466064
grad AddEdge W: 6.648226077727443e-15
grad ChooseDest W: 4.242376327514648
grad AddEdge W: 1.4997406121890558e-14
grad ChooseDest W: 5.16645622253418
grad AddEdge W: 1.693640889109871e-17
grad ChooseDest W: 4.248971939086914
grad AddEdge W: 1.651674542476483e-16
grad ChooseDest W: 4.44483757019043
grad AddEdge W: 3.977298790369731e-17
grad ChooseDest W: 3.7109529972076416
grad AddEdge W: 6.076967999857829e-16
grad ChooseDest W: 7.2813310623168945
grad AddEdge W: 2.648577065729876e-17
grad ChooseDest W: 4.329860687255859
grad AddEdge W: 2.0443224207650906e-13
grad ChooseDest W: 4.938323020935059
grad AddEdge W: 1.7151318686046111e-16
grad ChooseDest W: 5.392644882202148
grad AddEdge W: 7.097842601074813e-15
grad ChooseDest W: 8.533132553100586
grad AddEdge W: 3.5591004263368066e-17
grad ChooseDest W: 3.904254198074341
grad AddEdge W: 1.2556800221901973e-16
grad ChooseDest W: 3.320242404937744
grad AddEdge W: 1.707079496951979e-16
grad ChooseDest W: 4.566377639770508
grad AddEdge W: 2.568942667623722e-16
grad ChooseDest W: 5.309796333312988
grad AddEdge W: 2.0249679180318637e-17
grad ChooseDest W: 4.104959487915039
grad AddEdge W: 6.688006810688651e-14
grad ChooseDest W: 3.1321680545806885
grad AddEdge W: 3.5898781625686796e-17
grad ChooseDest W: 3.8007802963256836
grad AddEdge W: 8.446638358054995e-17
grad ChooseDest W: 4.841155052185059
grad AddEdge W: 8.609097186225781e-15
grad ChooseDest W: 4.720158576965332
grad AddEdge W: 7.514082638168575e-15
grad ChooseDest W: 4.49083137512207
grad AddEdge W: 2.587974968552934e-16
grad ChooseDest W: 4.812165260314941
grad AddEdge W: 2.4439272882283367e-17
grad ChooseDest W: 5.842115879058838
grad AddEdge W: 6.080881953818634e-17
grad ChooseDest W: 3.8645496368408203
grad AddEdge W: 1.3749851422065575e-16
grad ChooseDest W: 5.490384578704834
grad AddEdge W: 9.344211378991795e-17
grad ChooseDest W: 5.507636070251465
grad AddEdge W: 2.270022093559719e-16
grad ChooseDest W: 6.496824741363525
grad AddEdge W: 2.2939117578645203e-15
grad ChooseDest W: 4.01024866104126
grad AddEdge W: 3.459115532277276e-16
grad ChooseDest W: 4.151407241821289
grad AddEdge W: 6.723387580183371e-13
grad ChooseDest W: 2.2893102169036865
grad AddEdge W: 3.126812529494144e-17
grad ChooseDest W: 5.001811504364014
grad AddEdge W: 6.28546829384638e-14
grad ChooseDest W: 4.55694580078125
grad AddEdge W: 9.659262864385176e-14
grad ChooseDest W: 4.1101155281066895
grad AddEdge W: 1.717942593737476e-10
grad ChooseDest W: 1.2288799285888672
=== Epoch 37: Train Loss: 4.8369, Train Log Prob: 0.0206 ===
Total mismatches: 65951
Predicted valid destination but wrong order: 6060
Epoch 37: Validation Loss: 3.4858, Validation Log Prob: 0.0420
Epoch 37: Edge Precision: 0.3646, Recall: 0.3571, F1: 0.3605, Jaccard: 0.2378
Epoch 37: TP: 2.501073729420186, FP: 4.375089477451682, FN: 4.520400858983536
Epoch 37: Current Learning Rate: 6e-05
[Epoch 37] ‚è±Ô∏è Total: 3390.67s | Current time: 2025-07-15 22:44:48 | üèãÔ∏è Train: 2894.59s | ‚úÖ Val: 496.08s
grad AddEdge W: 2.351380063423704e-14
grad ChooseDest W: 7.91612434387207
grad AddEdge W: 6.304875184508604e-17
grad ChooseDest W: 6.196999549865723
grad AddEdge W: 5.38244439354785e-17
grad ChooseDest W: 4.745344161987305
grad AddEdge W: 4.0485074738168605e-15
grad ChooseDest W: 3.527726650238037
grad AddEdge W: 1.2849931114013256e-14
grad ChooseDest W: 3.719355344772339
grad AddEdge W: 6.8311750299390045e-15
grad ChooseDest W: 9.22183609008789
grad AddEdge W: 6.921409449810005e-15
grad ChooseDest W: 1.5572670698165894
grad AddEdge W: 5.4748494015206386e-17
grad ChooseDest W: 3.334744453430176
grad AddEdge W: 4.4583265776539614e-15
grad ChooseDest W: 4.511397361755371
grad AddEdge W: 3.3727007545423593e-15
grad ChooseDest W: 3.131758451461792
grad AddEdge W: 2.3147541020275658e-17
grad ChooseDest W: 5.229635238647461
grad AddEdge W: 1.3229385145482474e-15
grad ChooseDest W: 3.153867721557617
grad AddEdge W: 6.028470599067192e-16
grad ChooseDest W: 7.063117504119873
grad AddEdge W: 1.1487756233403176e-15
grad ChooseDest W: 2.2820680141448975
grad AddEdge W: 1.3962634039349736e-16
grad ChooseDest W: 3.686583995819092
grad AddEdge W: 9.885555429537939e-17
grad ChooseDest W: 4.683173656463623
grad AddEdge W: 3.645632716658265e-16
grad ChooseDest W: 5.5884528160095215
grad AddEdge W: 1.849798407575461e-15
grad ChooseDest W: 3.6006574630737305
grad AddEdge W: 1.3431948966708546e-13
grad ChooseDest W: 7.387173652648926
grad AddEdge W: 4.1512703580106995e-16
grad ChooseDest W: 4.969939231872559
grad AddEdge W: 1.5248919214808803e-15
grad ChooseDest W: 9.405745506286621
grad AddEdge W: 4.18307432759773e-15
grad ChooseDest W: 3.6798222064971924
grad AddEdge W: 1.5668925372144295e-14
grad ChooseDest W: 7.075414657592773
grad AddEdge W: 5.464991460026926e-16
grad ChooseDest W: 4.610812664031982
grad AddEdge W: 1.6708847203246186e-15
grad ChooseDest W: 7.560318946838379
grad AddEdge W: 9.669685435394551e-14
grad ChooseDest W: 5.817875385284424
grad AddEdge W: 8.178857812096273e-15
grad ChooseDest W: 5.617928981781006
grad AddEdge W: 2.1573402417952956e-16
grad ChooseDest W: 3.7196390628814697
grad AddEdge W: 9.266146572641572e-15
grad ChooseDest W: 6.770850658416748
grad AddEdge W: 1.0018977842545394e-17
grad ChooseDest W: 4.737155437469482
grad AddEdge W: 1.8888788401656595e-17
grad ChooseDest W: 3.7147748470306396
grad AddEdge W: 2.4368717023010554e-16
grad ChooseDest W: 3.0983166694641113
grad AddEdge W: 1.805230498506255e-14
grad ChooseDest W: 3.0076606273651123
grad AddEdge W: 1.109216908302496e-16
grad ChooseDest W: 2.247802734375
grad AddEdge W: 2.413375273042017e-16
grad ChooseDest W: 4.7206645011901855
grad AddEdge W: 1.6258602604968427e-15
grad ChooseDest W: 5.107229709625244
grad AddEdge W: 6.986429492168813e-18
grad ChooseDest W: 5.683969497680664
grad AddEdge W: 1.3675808831074729e-16
grad ChooseDest W: 8.443737983703613
grad AddEdge W: 1.4002842958053694e-16
grad ChooseDest W: 7.138773441314697
grad AddEdge W: 3.2626408800312716e-17
grad ChooseDest W: 4.947702884674072
grad AddEdge W: 3.121399790437842e-16
grad ChooseDest W: 4.287125587463379
grad AddEdge W: 6.131297619537006e-17
grad ChooseDest W: 6.889863967895508
grad AddEdge W: 2.5546651332043627e-16
grad ChooseDest W: 4.630007743835449
grad AddEdge W: 1.236924330457823e-15
grad ChooseDest W: 5.139511585235596
grad AddEdge W: 1.7497698304386536e-14
grad ChooseDest W: 4.946105003356934
grad AddEdge W: 8.590123092341913e-17
grad ChooseDest W: 5.818976402282715
grad AddEdge W: 2.822190282847619e-14
grad ChooseDest W: 4.64703893661499
grad AddEdge W: 7.285121929819874e-17
grad ChooseDest W: 4.774953365325928
grad AddEdge W: 6.33928986845775e-15
grad ChooseDest W: 5.84608268737793
grad AddEdge W: 1.6248740092143776e-13
grad ChooseDest W: 3.2070600986480713
grad AddEdge W: 4.461506762854428e-15
grad ChooseDest W: 2.4108119010925293
grad AddEdge W: 9.625639213917559e-15
grad ChooseDest W: 2.6456286907196045
grad AddEdge W: 1.1856561790175987e-15
grad ChooseDest W: 3.4467227458953857
grad AddEdge W: 8.13911179689799e-17
grad ChooseDest W: 3.919686794281006
grad AddEdge W: 2.6885346671114054e-15
grad ChooseDest W: 6.852952480316162
grad AddEdge W: 8.550256348478866e-15
grad ChooseDest W: 2.7519278526306152
grad AddEdge W: 1.3887462512258877e-16
grad ChooseDest W: 4.644881725311279
grad AddEdge W: 3.0343682753085355e-13
grad ChooseDest W: 7.526142597198486
grad AddEdge W: 2.0959136771582097e-16
grad ChooseDest W: 3.250087261199951
grad AddEdge W: 5.619341509444748e-16
grad ChooseDest W: 3.907158136367798
grad AddEdge W: 2.038093487642957e-16
grad ChooseDest W: 8.377030372619629
grad AddEdge W: 9.352742588957422e-17
grad ChooseDest W: 3.2116336822509766
grad AddEdge W: 4.445814881936501e-17
grad ChooseDest W: 2.9950482845306396
grad AddEdge W: 1.3457230655546776e-16
grad ChooseDest W: 5.328249454498291
grad AddEdge W: 9.94966510338435e-16
grad ChooseDest W: 6.082016944885254
grad AddEdge W: 4.401069043008812e-17
grad ChooseDest W: 4.479771137237549
=== Epoch 38: Train Loss: 4.7914, Train Log Prob: 0.0215 ===
Total mismatches: 65258
Predicted valid destination but wrong order: 6107
Epoch 38: Validation Loss: 3.4762, Validation Log Prob: 0.0424
Epoch 38: Edge Precision: 0.3636, Recall: 0.3561, F1: 0.3596, Jaccard: 0.2367
Epoch 38: TP: 2.494774516821761, FP: 4.378382247673586, FN: 4.526700071581962
Epoch 38: Current Learning Rate: 6e-05
[Epoch 38] ‚è±Ô∏è Total: 3386.32s | Current time: 2025-07-15 23:41:15 | üèãÔ∏è Train: 2886.32s | ‚úÖ Val: 499.99s
grad AddEdge W: 2.4897282152602784e-11
grad ChooseDest W: 8.816502571105957
grad AddEdge W: 2.996509414576626e-17
grad ChooseDest W: 5.000243186950684
grad AddEdge W: 6.834911715785817e-15
grad ChooseDest W: 3.2561838626861572
grad AddEdge W: 2.533155790300024e-16
grad ChooseDest W: 3.61694073677063
grad AddEdge W: 2.657219647293177e-16
grad ChooseDest W: 8.111268997192383
grad AddEdge W: 1.2627706144010018e-16
grad ChooseDest W: 3.748044967651367
grad AddEdge W: 2.88868368210815e-15
grad ChooseDest W: 4.42858362197876
grad AddEdge W: 1.0299104945884086e-14
grad ChooseDest W: 4.218260288238525
grad AddEdge W: 1.252302230158837e-17
grad ChooseDest W: 4.627587795257568
grad AddEdge W: 4.775767632988798e-17
grad ChooseDest W: 6.287614822387695
grad AddEdge W: 9.918164378209882e-18
grad ChooseDest W: 3.7560348510742188
grad AddEdge W: 1.3561688346788953e-16
grad ChooseDest W: 3.0112197399139404
grad AddEdge W: 1.0133556088582157e-16
grad ChooseDest W: 3.4659011363983154
grad AddEdge W: 3.9681405113253397e-16
grad ChooseDest W: 5.756471157073975
grad AddEdge W: 4.21291609454047e-13
grad ChooseDest W: 2.058654308319092
grad AddEdge W: 8.813344993654289e-16
grad ChooseDest W: 3.5290873050689697
grad AddEdge W: 1.1560215666876045e-16
grad ChooseDest W: 5.072998046875
grad AddEdge W: 4.207060606598078e-15
grad ChooseDest W: 4.870833396911621
grad AddEdge W: 8.45065660294743e-16
grad ChooseDest W: 4.84378719329834
grad AddEdge W: 5.487625239168745e-16
grad ChooseDest W: 3.690006971359253
grad AddEdge W: 4.5265850982853636e-17
grad ChooseDest W: 3.7673721313476562
grad AddEdge W: 3.5801750692856366e-16
grad ChooseDest W: 3.3701672554016113
grad AddEdge W: 1.8644163963000573e-16
grad ChooseDest W: 5.42759895324707
grad AddEdge W: 4.598294401497727e-13
grad ChooseDest W: 3.3453009128570557
grad AddEdge W: 1.6602589566991094e-16
grad ChooseDest W: 3.0408847332000732
grad AddEdge W: 9.712040068548405e-17
grad ChooseDest W: 6.937363147735596
grad AddEdge W: 8.785606782214079e-16
grad ChooseDest W: 5.028138637542725
grad AddEdge W: 5.41155162198906e-15
grad ChooseDest W: 3.938786506652832
grad AddEdge W: 5.605191824060865e-16
grad ChooseDest W: 4.3221540451049805
grad AddEdge W: 9.235448378097403e-17
grad ChooseDest W: 3.8595571517944336
grad AddEdge W: 2.2178116444354542e-16
grad ChooseDest W: 5.583749294281006
grad AddEdge W: 2.5838971666563947e-17
grad ChooseDest W: 6.159573078155518
grad AddEdge W: 1.1093204051407387e-15
grad ChooseDest W: 2.912574529647827
grad AddEdge W: 1.4561627946379395e-16
grad ChooseDest W: 1.9126871824264526
grad AddEdge W: 2.741450721150513e-16
grad ChooseDest W: 4.599579811096191
grad AddEdge W: 1.862070644431755e-15
grad ChooseDest W: 6.48994779586792
grad AddEdge W: 1.0067969136336175e-15
grad ChooseDest W: 4.60086727142334
grad AddEdge W: 4.85747031349858e-16
grad ChooseDest W: 3.3197507858276367
grad AddEdge W: 1.2961271689105702e-17
grad ChooseDest W: 7.276976585388184
grad AddEdge W: 1.7594489775708821e-13
grad ChooseDest W: 2.3114173412323
grad AddEdge W: 9.467774295405986e-17
grad ChooseDest W: 8.566876411437988
grad AddEdge W: 1.209394573825932e-14
grad ChooseDest W: 6.292641639709473
grad AddEdge W: 6.596259812320003e-17
grad ChooseDest W: 2.9552245140075684
grad AddEdge W: 5.0496041204132526e-17
grad ChooseDest W: 3.7691760063171387
grad AddEdge W: 1.3128560696188426e-16
grad ChooseDest W: 4.087286949157715
grad AddEdge W: 3.2701901273481245e-16
grad ChooseDest W: 7.558941841125488
grad AddEdge W: 2.051849435055265e-15
grad ChooseDest W: 2.648242712020874
grad AddEdge W: 1.3689346799852016e-16
grad ChooseDest W: 4.355601787567139
grad AddEdge W: 6.706355831315137e-16
grad ChooseDest W: 2.725374221801758
grad AddEdge W: 1.3102290763422722e-16
grad ChooseDest W: 5.92728853225708
grad AddEdge W: 8.955545678932729e-17
grad ChooseDest W: 4.834892272949219
grad AddEdge W: 1.9672337553003165e-16
grad ChooseDest W: 4.913936138153076
grad AddEdge W: 4.385600328802707e-15
grad ChooseDest W: 4.994970798492432
grad AddEdge W: 2.90928182931948e-15
grad ChooseDest W: 4.177838325500488
grad AddEdge W: 6.681133837123864e-17
grad ChooseDest W: 4.479354381561279
grad AddEdge W: 6.892038582363962e-15
grad ChooseDest W: 5.528871536254883
grad AddEdge W: 1.7941014120216196e-16
grad ChooseDest W: 3.5299155712127686
grad AddEdge W: 2.4516781029168566e-16
grad ChooseDest W: 4.887405872344971
grad AddEdge W: 2.4609180743185434e-17
grad ChooseDest W: 4.645997047424316
grad AddEdge W: 3.421182220525676e-16
grad ChooseDest W: 3.9170546531677246
grad AddEdge W: 1.9881483222570053e-16
grad ChooseDest W: 4.264481544494629
grad AddEdge W: 5.4063055763697995e-17
grad ChooseDest W: 4.582966327667236
grad AddEdge W: 1.1429458555533688e-14
grad ChooseDest W: 4.691537380218506
grad AddEdge W: 1.425182739292659e-14
grad ChooseDest W: 5.670701503753662
grad AddEdge W: 7.481254521045019e-14
grad ChooseDest W: 4.819149017333984
grad AddEdge W: 1.0515043184413243e-16
grad ChooseDest W: 5.068338871002197
=== Epoch 39: Train Loss: 4.7519, Train Log Prob: 0.0223 ===
Total mismatches: 64414
Predicted valid destination but wrong order: 6035
Epoch 39: Validation Loss: 3.3785, Validation Log Prob: 0.0463
Epoch 39: Edge Precision: 0.3608, Recall: 0.3526, F1: 0.3564, Jaccard: 0.2342
Epoch 39: TP: 2.468861846814603, FP: 4.389119541875448, FN: 4.55261274158912
Epoch 39: Current Learning Rate: 6e-05
[Epoch 39] ‚è±Ô∏è Total: 3385.97s | Current time: 2025-07-16 00:37:41 | üèãÔ∏è Train: 2889.48s | ‚úÖ Val: 496.49s
grad AddEdge W: 3.910147013575123e-14
grad ChooseDest W: 8.972944259643555
grad AddEdge W: 7.891701615109215e-13
grad ChooseDest W: 2.212791919708252
grad AddEdge W: 9.591485151418371e-15
grad ChooseDest W: 6.237572193145752
grad AddEdge W: 1.0901288620174428e-15
grad ChooseDest W: 2.3296148777008057
grad AddEdge W: 1.4174098792481977e-17
grad ChooseDest W: 4.3234405517578125
grad AddEdge W: 2.3326389512459342e-14
grad ChooseDest W: 5.931054592132568
grad AddEdge W: 2.3491000307241966e-16
grad ChooseDest W: 3.5240602493286133
grad AddEdge W: 1.1933844712324e-17
grad ChooseDest W: 5.942996501922607
grad AddEdge W: 8.712659500115238e-13
grad ChooseDest W: 2.8793551921844482
grad AddEdge W: 1.8230607114525475e-14
grad ChooseDest W: 3.3108720779418945
grad AddEdge W: 2.036344629304673e-17
grad ChooseDest W: 3.6331207752227783
grad AddEdge W: 3.099651690121496e-16
grad ChooseDest W: 4.327025890350342
grad AddEdge W: 2.321425313667806e-17
grad ChooseDest W: 4.762217998504639
grad AddEdge W: 6.566645422901625e-17
grad ChooseDest W: 6.430489540100098
grad AddEdge W: 4.1287773980963616e-15
grad ChooseDest W: 3.3821473121643066
grad AddEdge W: 5.334434777855713e-15
grad ChooseDest W: 3.988544464111328
grad AddEdge W: 2.0600965713462064e-15
grad ChooseDest W: 4.4179229736328125
grad AddEdge W: 1.460284462253235e-14
grad ChooseDest W: 4.660653114318848
grad AddEdge W: 7.642821693514099e-16
grad ChooseDest W: 6.472416400909424
grad AddEdge W: 7.942261181137413e-15
grad ChooseDest W: 3.8463025093078613
grad AddEdge W: 1.0243491038968415e-16
grad ChooseDest W: 4.690036296844482
grad AddEdge W: 1.3334451747534608e-14
grad ChooseDest W: 2.8692266941070557
grad AddEdge W: 1.4571415147387123e-16
grad ChooseDest W: 4.050786972045898
grad AddEdge W: 3.1035618059642586e-16
grad ChooseDest W: 5.924454212188721
grad AddEdge W: 2.4421068466062845e-13
grad ChooseDest W: 3.963083267211914
grad AddEdge W: 1.4313118273473436e-15
grad ChooseDest W: 3.898620843887329
grad AddEdge W: 1.2817992095610697e-16
grad ChooseDest W: 8.284738540649414
grad AddEdge W: 1.9832311967365206e-17
grad ChooseDest W: 4.848546981811523
grad AddEdge W: 1.5211078017890217e-15
grad ChooseDest W: 2.5277836322784424
grad AddEdge W: 2.4416392166567644e-14
grad ChooseDest W: 6.800651550292969
grad AddEdge W: 2.7873764240341674e-15
grad ChooseDest W: 2.0599799156188965
grad AddEdge W: 1.3763646147705e-16
grad ChooseDest W: 2.5387628078460693
grad AddEdge W: 1.0154175550583511e-17
grad ChooseDest W: 9.073330879211426
grad AddEdge W: 1.161424445751005e-16
grad ChooseDest W: 4.278824806213379
grad AddEdge W: 1.5651177999020244e-13
grad ChooseDest W: 2.3442788124084473
grad AddEdge W: 1.1600132094515404e-16
grad ChooseDest W: 2.929210901260376
grad AddEdge W: 2.123840816650327e-17
grad ChooseDest W: 4.5635085105896
grad AddEdge W: 1.9575447571749114e-16
grad ChooseDest W: 3.278334140777588
grad AddEdge W: 2.889162943937618e-16
grad ChooseDest W: 4.775925636291504
grad AddEdge W: 7.008850355020961e-15
grad ChooseDest W: 7.158780097961426
grad AddEdge W: 7.329445972809609e-16
grad ChooseDest W: 3.133524179458618
grad AddEdge W: 1.2549613676740112e-15
grad ChooseDest W: 7.655819892883301
grad AddEdge W: 4.198372007322939e-16
grad ChooseDest W: 4.220670700073242
grad AddEdge W: 1.159343424765944e-17
grad ChooseDest W: 6.141223430633545
grad AddEdge W: 8.432946520448882e-15
grad ChooseDest W: 5.2617082595825195
grad AddEdge W: 2.332973766429325e-13
grad ChooseDest W: 4.389854431152344
grad AddEdge W: 3.4540259892299106e-17
grad ChooseDest W: 3.494372606277466
grad AddEdge W: 2.410893201808766e-16
grad ChooseDest W: 5.698611259460449
grad AddEdge W: 3.504108797469791e-17
grad ChooseDest W: 3.973982810974121
grad AddEdge W: 6.746613454413562e-17
grad ChooseDest W: 5.974084377288818
grad AddEdge W: 2.91148219592332e-17
grad ChooseDest W: 4.734251976013184
grad AddEdge W: 1.5652922166913582e-15
grad ChooseDest W: 4.802521705627441
grad AddEdge W: 6.743079738836735e-17
grad ChooseDest W: 4.335282325744629
grad AddEdge W: 1.3401464123881921e-15
grad ChooseDest W: 2.785329818725586
grad AddEdge W: 4.9121915535669635e-17
grad ChooseDest W: 6.280459403991699
grad AddEdge W: 3.032940764859176e-17
grad ChooseDest W: 4.560783863067627
grad AddEdge W: 8.985531472446144e-18
grad ChooseDest W: 3.2098724842071533
grad AddEdge W: 1.4600563668684511e-16
grad ChooseDest W: 3.0416083335876465
grad AddEdge W: 6.457940464939943e-14
grad ChooseDest W: 5.731163501739502
grad AddEdge W: 3.7134989816257495e-17
grad ChooseDest W: 4.802522659301758
grad AddEdge W: 2.449832100487434e-16
grad ChooseDest W: 8.097634315490723
grad AddEdge W: 2.0192683127391283e-16
grad ChooseDest W: 4.25900936126709
grad AddEdge W: 1.0833558674571892e-16
grad ChooseDest W: 4.2721052169799805
grad AddEdge W: 7.19141217929431e-13
grad ChooseDest W: 2.8704442977905273
grad AddEdge W: 3.6213525701647795e-15
grad ChooseDest W: 3.870112180709839
grad AddEdge W: 8.07326414379271e-15
grad ChooseDest W: 6.93853235244751
=== Epoch 40: Train Loss: 4.7116, Train Log Prob: 0.0231 ===
Total mismatches: 63818
Predicted valid destination but wrong order: 6093
Epoch 40: Validation Loss: 3.3465, Validation Log Prob: 0.0481
Epoch 40: Edge Precision: 0.3606, Recall: 0.3523, F1: 0.3561, Jaccard: 0.2342
Epoch 40: TP: 2.466571224051539, FP: 4.394416607015033, FN: 4.5549033643521835
Epoch 40: Current Learning Rate: 6e-05
[Epoch 40] ‚è±Ô∏è Total: 3386.85s | Current time: 2025-07-16 01:34:07 | üèãÔ∏è Train: 2891.48s | ‚úÖ Val: 495.36s
grad AddEdge W: 1.4060735065960124e-14
grad ChooseDest W: 9.225276947021484
grad AddEdge W: 1.126343252751488e-16
grad ChooseDest W: 4.692345142364502
grad AddEdge W: 4.9613287289305735e-17
grad ChooseDest W: 4.094188690185547
grad AddEdge W: 1.2793125061163883e-15
grad ChooseDest W: 4.896417140960693
grad AddEdge W: 7.168213515997549e-17
grad ChooseDest W: 4.452630519866943
grad AddEdge W: 2.41496604062163e-17
grad ChooseDest W: 2.740020513534546
grad AddEdge W: 3.2239675394164574e-17
grad ChooseDest W: 3.11087965965271
grad AddEdge W: 6.837418033337183e-17
grad ChooseDest W: 4.091568946838379
grad AddEdge W: 1.4073822995544624e-15
grad ChooseDest W: 3.0378305912017822
grad AddEdge W: 2.059840132121425e-15
grad ChooseDest W: 6.904623031616211
grad AddEdge W: 1.7038497603240983e-15
grad ChooseDest W: 5.108540058135986
grad AddEdge W: 5.551925733656305e-15
grad ChooseDest W: 4.64763879776001
grad AddEdge W: 5.497742121281411e-17
grad ChooseDest W: 4.8784613609313965
grad AddEdge W: 3.007756556278285e-16
grad ChooseDest W: 6.251481533050537
grad AddEdge W: 2.45924179458068e-12
grad ChooseDest W: 1.9895836114883423
grad AddEdge W: 2.1471942429250672e-16
grad ChooseDest W: 4.284213066101074
grad AddEdge W: 1.5604631561276084e-17
grad ChooseDest W: 2.5476808547973633
grad AddEdge W: 2.597424878394087e-17
grad ChooseDest W: 3.8075757026672363
grad AddEdge W: 3.945099378819063e-18
grad ChooseDest W: 3.856557846069336
grad AddEdge W: 3.2018528326526277e-16
grad ChooseDest W: 3.9975147247314453
grad AddEdge W: 1.0119840772281538e-16
grad ChooseDest W: 3.177624225616455
grad AddEdge W: 1.6559380828164876e-15
grad ChooseDest W: 4.45781946182251
grad AddEdge W: 4.4828392029277325e-14
grad ChooseDest W: 3.906632900238037
grad AddEdge W: 4.446331042638734e-17
grad ChooseDest W: 4.680752754211426
grad AddEdge W: 5.415952487545638e-17
grad ChooseDest W: 6.06073522567749
grad AddEdge W: 1.4650390381806746e-16
grad ChooseDest W: 2.535715341567993
grad AddEdge W: 1.822499912113994e-17
grad ChooseDest W: 4.497820854187012
grad AddEdge W: 4.7382758371609544e-17
grad ChooseDest W: 2.4598400592803955
grad AddEdge W: 1.3899469204286207e-16
grad ChooseDest W: 2.4390594959259033
grad AddEdge W: 1.341931633586204e-17
grad ChooseDest W: 4.641645431518555
grad AddEdge W: 3.160944271086985e-13
grad ChooseDest W: 4.9549713134765625
grad AddEdge W: 3.0010091447600163e-16
grad ChooseDest W: 4.4778733253479
grad AddEdge W: 4.206437349167576e-16
grad ChooseDest W: 3.880775213241577
grad AddEdge W: 1.0385197665810589e-16
grad ChooseDest W: 2.6273815631866455
grad AddEdge W: 1.3611834020755387e-16
grad ChooseDest W: 3.8257346153259277
grad AddEdge W: 8.921480396074325e-16
grad ChooseDest W: 3.3229289054870605
grad AddEdge W: 8.286406855958573e-17
grad ChooseDest W: 3.6071221828460693
grad AddEdge W: 3.306072825273981e-16
grad ChooseDest W: 3.1677825450897217
grad AddEdge W: 6.820342494983159e-14
grad ChooseDest W: 2.852489471435547
grad AddEdge W: 5.594033885516464e-17
grad ChooseDest W: 3.5089111328125
grad AddEdge W: 5.574019741052486e-15
grad ChooseDest W: 6.7839531898498535
grad AddEdge W: 4.457436438670626e-17
grad ChooseDest W: 6.060935020446777
grad AddEdge W: 1.984113963886237e-17
grad ChooseDest W: 5.155725002288818
grad AddEdge W: 7.969277296990089e-15
grad ChooseDest W: 3.6779377460479736
grad AddEdge W: 5.593836288611737e-16
grad ChooseDest W: 3.1969141960144043
grad AddEdge W: 9.481479023794765e-17
grad ChooseDest W: 6.578219890594482
grad AddEdge W: 1.8064367263627044e-16
grad ChooseDest W: 3.224980592727661
grad AddEdge W: 9.424546498338455e-17
grad ChooseDest W: 4.230434894561768
grad AddEdge W: 2.2386448168198677e-16
grad ChooseDest W: 4.914708137512207
grad AddEdge W: 1.507861001857902e-12
grad ChooseDest W: 5.61479377746582
grad AddEdge W: 2.1010379512033904e-14
grad ChooseDest W: 2.764270067214966
grad AddEdge W: 3.461024691600828e-15
grad ChooseDest W: 3.85781192779541
grad AddEdge W: 1.3906272467039435e-15
grad ChooseDest W: 2.927377700805664
grad AddEdge W: 3.908264228739966e-15
grad ChooseDest W: 4.028639793395996
grad AddEdge W: 3.8452175018330195e-16
grad ChooseDest W: 5.254862308502197
grad AddEdge W: 1.4112756441448694e-14
grad ChooseDest W: 4.641927242279053
grad AddEdge W: 3.916923023043273e-15
grad ChooseDest W: 4.517672061920166
grad AddEdge W: 2.0278399050005155e-14
grad ChooseDest W: 4.096816539764404
grad AddEdge W: 1.1258086955524317e-16
grad ChooseDest W: 3.19289231300354
grad AddEdge W: 2.900363631176076e-16
grad ChooseDest W: 3.7616841793060303
grad AddEdge W: 2.235506464459084e-14
grad ChooseDest W: 4.669998645782471
grad AddEdge W: 7.161967309756039e-17
grad ChooseDest W: 3.230179786682129
grad AddEdge W: 1.0779344595480676e-16
grad ChooseDest W: 2.2450571060180664
grad AddEdge W: 1.3451576710623854e-16
grad ChooseDest W: 5.140500545501709
grad AddEdge W: 6.299697695618512e-17
grad ChooseDest W: 3.6626570224761963
grad AddEdge W: 7.115980435211725e-16
grad ChooseDest W: 4.040778160095215
=== Epoch 41: Train Loss: 4.6811, Train Log Prob: 0.0239 ===
Total mismatches: 63506
Predicted valid destination but wrong order: 6116
Epoch 41: Validation Loss: 3.3356, Validation Log Prob: 0.0481
Epoch 41: Edge Precision: 0.3620, Recall: 0.3535, F1: 0.3574, Jaccard: 0.2353
Epoch 41: TP: 2.4755905511811025, FP: 4.37967072297781, FN: 4.54588403722262
Epoch 41: Current Learning Rate: 6e-05
[Epoch 41] ‚è±Ô∏è Total: 3382.03s | Current time: 2025-07-16 02:30:29 | üèãÔ∏è Train: 2885.94s | ‚úÖ Val: 496.10s
grad AddEdge W: 4.026928801265789e-14
grad ChooseDest W: 8.70398998260498
grad AddEdge W: 1.9069843547016773e-15
grad ChooseDest W: 3.328407049179077
grad AddEdge W: 3.044420377400187e-16
grad ChooseDest W: 7.635845184326172
grad AddEdge W: 2.768970292211213e-16
grad ChooseDest W: 5.660590171813965
grad AddEdge W: 1.1395192684685463e-14
grad ChooseDest W: 2.5795786380767822
grad AddEdge W: 1.3915617093332222e-16
grad ChooseDest W: 5.813978672027588
grad AddEdge W: 3.128335534437977e-17
grad ChooseDest W: 2.594320058822632
grad AddEdge W: 2.395663355192479e-11
grad ChooseDest W: 3.0829432010650635
grad AddEdge W: 1.385762672960391e-14
grad ChooseDest W: 6.40220308303833
grad AddEdge W: 2.7887557245445424e-17
grad ChooseDest W: 5.417635440826416
grad AddEdge W: 6.481828969868398e-17
grad ChooseDest W: 3.3660640716552734
grad AddEdge W: 2.3782476096974314e-14
grad ChooseDest W: 5.762105464935303
grad AddEdge W: 3.5246091256106032e-15
grad ChooseDest W: 3.156703472137451
grad AddEdge W: 9.247873292642439e-17
grad ChooseDest W: 2.2070415019989014
grad AddEdge W: 1.0870608425080387e-16
grad ChooseDest W: 3.0794777870178223
grad AddEdge W: 1.6704885630151878e-14
grad ChooseDest W: 4.346138954162598
grad AddEdge W: 1.869769750405823e-15
grad ChooseDest W: 4.45185661315918
grad AddEdge W: 5.716746954292917e-12
grad ChooseDest W: 1.586266279220581
grad AddEdge W: 5.967427184489841e-17
grad ChooseDest W: 5.770027160644531
grad AddEdge W: 1.0069390034105194e-15
grad ChooseDest W: 2.304022789001465
grad AddEdge W: 7.453352916949284e-15
grad ChooseDest W: 5.372569561004639
grad AddEdge W: 3.89890027950807e-15
grad ChooseDest W: 2.7756965160369873
grad AddEdge W: 7.926561425460055e-15
grad ChooseDest W: 4.132691860198975
grad AddEdge W: 2.2415640629330205e-15
grad ChooseDest W: 6.842845916748047
grad AddEdge W: 5.007109906817603e-14
grad ChooseDest W: 3.4044747352600098
grad AddEdge W: 1.4029385529549295e-15
grad ChooseDest W: 4.583795547485352
grad AddEdge W: 8.180793758836782e-17
grad ChooseDest W: 3.4555370807647705
grad AddEdge W: 4.2979044666746277e-16
grad ChooseDest W: 5.382692337036133
grad AddEdge W: 4.94819918885254e-15
grad ChooseDest W: 2.2882163524627686
grad AddEdge W: 1.4526822568483328e-15
grad ChooseDest W: 5.216991901397705
grad AddEdge W: 1.0396462277566785e-15
grad ChooseDest W: 2.3020832538604736
grad AddEdge W: 7.659835574487008e-18
grad ChooseDest W: 4.389548301696777
grad AddEdge W: 3.391198312984058e-17
grad ChooseDest W: 3.0534322261810303
grad AddEdge W: 4.5178762099241603e-17
grad ChooseDest W: 7.017574787139893
grad AddEdge W: 1.4722280715018178e-15
grad ChooseDest W: 6.579758167266846
grad AddEdge W: 7.911454592845774e-15
grad ChooseDest W: 5.471563339233398
grad AddEdge W: 1.8741124089170568e-16
grad ChooseDest W: 7.00509786605835
grad AddEdge W: 6.202390153591244e-17
grad ChooseDest W: 2.7939395904541016
grad AddEdge W: 7.110213940785936e-15
grad ChooseDest W: 3.65338397026062
grad AddEdge W: 7.028684902030341e-15
grad ChooseDest W: 4.506102561950684
grad AddEdge W: 2.1115050761457907e-14
grad ChooseDest W: 3.7295424938201904
grad AddEdge W: 1.036418079315574e-14
grad ChooseDest W: 7.606376647949219
grad AddEdge W: 4.6357262782148814e-14
grad ChooseDest W: 2.8702616691589355
grad AddEdge W: 1.313907713962418e-16
grad ChooseDest W: 2.454759120941162
grad AddEdge W: 8.134934203932352e-17
grad ChooseDest W: 4.79376220703125
grad AddEdge W: 5.2428440994174805e-17
grad ChooseDest W: 6.111658096313477
grad AddEdge W: 1.315139352807285e-16
grad ChooseDest W: 9.991350173950195
grad AddEdge W: 1.018347393715556e-13
grad ChooseDest W: 4.985495567321777
grad AddEdge W: 2.0903267669521286e-17
grad ChooseDest W: 4.880774021148682
grad AddEdge W: 1.9047020244253006e-15
grad ChooseDest W: 3.2007710933685303
grad AddEdge W: 4.984096445157177e-15
grad ChooseDest W: 4.601419925689697
grad AddEdge W: 2.1833719465445844e-16
grad ChooseDest W: 3.3975186347961426
grad AddEdge W: 3.070810482965283e-16
grad ChooseDest W: 1.8991215229034424
grad AddEdge W: 2.611369753858302e-15
grad ChooseDest W: 4.159249782562256
grad AddEdge W: 2.08186888409935e-13
grad ChooseDest W: 5.704830169677734
grad AddEdge W: 4.477486886437327e-15
grad ChooseDest W: 4.34216833114624
grad AddEdge W: 2.2069432852798955e-15
grad ChooseDest W: 4.458963394165039
grad AddEdge W: 2.1067409816856062e-15
grad ChooseDest W: 3.424614906311035
grad AddEdge W: 1.416081857318356e-16
grad ChooseDest W: 5.499014854431152
grad AddEdge W: 2.0722666348532378e-16
grad ChooseDest W: 6.94730806350708
grad AddEdge W: 4.582516404328239e-17
grad ChooseDest W: 1.927781581878662
grad AddEdge W: 5.9488995828482945e-15
grad ChooseDest W: 3.741349935531616
grad AddEdge W: 1.578160785918343e-14
grad ChooseDest W: 4.9218831062316895
grad AddEdge W: 1.1871813677182485e-15
grad ChooseDest W: 5.335354328155518
grad AddEdge W: 6.983887235274193e-17
grad ChooseDest W: 4.164039134979248
grad AddEdge W: 3.87667590844735e-17
grad ChooseDest W: 3.4502291679382324
=== Epoch 42: Train Loss: 4.6331, Train Log Prob: 0.0246 ===
Total mismatches: 62819
Predicted valid destination but wrong order: 6093
Epoch 42: Validation Loss: 3.2595, Validation Log Prob: 0.0516
Epoch 42: Edge Precision: 0.3601, Recall: 0.3508, F1: 0.3551, Jaccard: 0.2332
Epoch 42: TP: 2.4565497494631354, FP: 4.3823908375089475, FN: 4.564924838940587
Epoch 42: Current Learning Rate: 6e-05
[Epoch 42] ‚è±Ô∏è Total: 3379.12s | Current time: 2025-07-16 03:26:49 | üèãÔ∏è Train: 2885.22s | ‚úÖ Val: 493.90s
grad AddEdge W: 4.9165017760102736e-14
grad ChooseDest W: 11.24727725982666
grad AddEdge W: 2.6016079307517675e-18
grad ChooseDest W: 5.473573684692383
grad AddEdge W: 1.8584035211657358e-16
grad ChooseDest W: 2.649531841278076
grad AddEdge W: 2.155851655505879e-14
grad ChooseDest W: 4.501044750213623
grad AddEdge W: 7.454328010690251e-17
grad ChooseDest W: 6.995481014251709
grad AddEdge W: 5.933570149975476e-14
grad ChooseDest W: 6.786159038543701
grad AddEdge W: 6.885820937014642e-15
grad ChooseDest W: 3.2050464153289795
grad AddEdge W: 5.567849529548212e-15
grad ChooseDest W: 5.08378267288208
grad AddEdge W: 1.5039362800436946e-17
grad ChooseDest W: 4.681804656982422
grad AddEdge W: 1.326690870504584e-15
grad ChooseDest W: 5.238387584686279
grad AddEdge W: 1.155001289032857e-16
grad ChooseDest W: 3.5912044048309326
grad AddEdge W: 6.648825353537625e-16
grad ChooseDest W: 7.2264556884765625
grad AddEdge W: 7.88577085981913e-18
grad ChooseDest W: 4.792481899261475
grad AddEdge W: 2.4684022390648007e-16
grad ChooseDest W: 4.23970365524292
grad AddEdge W: 2.6236525256868772e-16
grad ChooseDest W: 2.3595528602600098
grad AddEdge W: 5.20111221547436e-15
grad ChooseDest W: 6.5412678718566895
grad AddEdge W: 9.071262926203198e-15
grad ChooseDest W: 4.977226257324219
grad AddEdge W: 1.2552162716515756e-16
grad ChooseDest W: 6.257319450378418
grad AddEdge W: 2.6478699917422657e-17
grad ChooseDest W: 7.030272960662842
grad AddEdge W: 5.6923951365301165e-15
grad ChooseDest W: 4.006107330322266
grad AddEdge W: 2.1991826423622095e-14
grad ChooseDest W: 6.79135799407959
grad AddEdge W: 6.762683945824022e-15
grad ChooseDest W: 3.232818126678467
grad AddEdge W: 3.3721435127421844e-16
grad ChooseDest W: 4.11703634262085
grad AddEdge W: 5.784418701743955e-16
grad ChooseDest W: 3.4804887771606445
grad AddEdge W: 1.66557077972068e-16
grad ChooseDest W: 5.4160661697387695
grad AddEdge W: 2.3001409638900815e-17
grad ChooseDest W: 6.915666580200195
grad AddEdge W: 2.3727669253638698e-17
grad ChooseDest W: 3.983726739883423
grad AddEdge W: 1.3658066402505507e-15
grad ChooseDest W: 5.993178844451904
grad AddEdge W: 9.863168441703873e-12
grad ChooseDest W: 3.4153287410736084
grad AddEdge W: 1.7941059449713764e-17
grad ChooseDest W: 5.202760219573975
grad AddEdge W: 1.17145702161564e-16
grad ChooseDest W: 2.9184019565582275
grad AddEdge W: 4.131361642678875e-16
grad ChooseDest W: 4.634126663208008
grad AddEdge W: 2.875129037369713e-15
grad ChooseDest W: 3.140244245529175
grad AddEdge W: 5.767946190116113e-11
grad ChooseDest W: 2.4487123489379883
grad AddEdge W: 4.507487522879654e-15
grad ChooseDest W: 4.300781726837158
grad AddEdge W: 4.663063612783958e-18
grad ChooseDest W: 5.581613063812256
grad AddEdge W: 2.9523886594942314e-16
grad ChooseDest W: 6.090113162994385
grad AddEdge W: 2.059664505133768e-16
grad ChooseDest W: 3.594503879547119
grad AddEdge W: 1.9363019649511616e-16
grad ChooseDest W: 4.508285999298096
grad AddEdge W: 9.001314945418937e-15
grad ChooseDest W: 5.23838996887207
grad AddEdge W: 2.0726259290241063e-17
grad ChooseDest W: 4.83762788772583
grad AddEdge W: 2.64305477460855e-13
grad ChooseDest W: 5.224939823150635
grad AddEdge W: 1.4727994481643e-16
grad ChooseDest W: 5.3128581047058105
grad AddEdge W: 5.138054000683066e-15
grad ChooseDest W: 5.809804439544678
grad AddEdge W: 4.141597665269529e-15
grad ChooseDest W: 8.760454177856445
grad AddEdge W: 1.0277843518935497e-16
grad ChooseDest W: 4.207345485687256
grad AddEdge W: 2.045624934033028e-17
grad ChooseDest W: 3.8651747703552246
grad AddEdge W: 5.634406916853952e-17
grad ChooseDest W: 4.39918851852417
grad AddEdge W: 1.6391290580853609e-16
grad ChooseDest W: 7.367247104644775
grad AddEdge W: 1.406066486810462e-16
grad ChooseDest W: 2.932260036468506
grad AddEdge W: 1.8932402032819512e-13
grad ChooseDest W: 1.9728389978408813
grad AddEdge W: 5.2641064792781356e-14
grad ChooseDest W: 2.7933809757232666
grad AddEdge W: 2.875640129109152e-17
grad ChooseDest W: 6.533720016479492
grad AddEdge W: 1.708314576868194e-17
grad ChooseDest W: 4.370716571807861
grad AddEdge W: 1.2839469674779514e-16
grad ChooseDest W: 2.3480448722839355
grad AddEdge W: 2.4338552549220405e-13
grad ChooseDest W: 5.779219150543213
grad AddEdge W: 6.952838514673647e-18
grad ChooseDest W: 4.557499885559082
grad AddEdge W: 5.81578446412968e-17
grad ChooseDest W: 1.9086147546768188
grad AddEdge W: 3.3077824421640054e-17
grad ChooseDest W: 4.260359287261963
grad AddEdge W: 1.5971640676681886e-11
grad ChooseDest W: 2.4545555114746094
grad AddEdge W: 2.3788197973939607e-12
grad ChooseDest W: 2.6419613361358643
grad AddEdge W: 2.9329373419539244e-16
grad ChooseDest W: 2.5218982696533203
grad AddEdge W: 2.487825233940934e-16
grad ChooseDest W: 4.255183696746826
grad AddEdge W: 1.403762716012608e-15
grad ChooseDest W: 4.9005351066589355
grad AddEdge W: 3.096446888026e-15
grad ChooseDest W: 4.358086585998535
grad AddEdge W: 9.066424674008481e-15
grad ChooseDest W: 3.578108310699463
=== Epoch 43: Train Loss: 4.6007, Train Log Prob: 0.0253 ===
Total mismatches: 62163
Predicted valid destination but wrong order: 6119
Epoch 43: Validation Loss: 3.2957, Validation Log Prob: 0.0499
Epoch 43: Edge Precision: 0.3605, Recall: 0.3513, F1: 0.3555, Jaccard: 0.2337
Epoch 43: TP: 2.459699355762348, FP: 4.378525411596278, FN: 4.5617752326413745
Epoch 43: Current Learning Rate: 6e-05
[Epoch 43] ‚è±Ô∏è Total: 3386.45s | Current time: 2025-07-16 04:23:15 | üèãÔ∏è Train: 2891.43s | ‚úÖ Val: 495.02s
grad AddEdge W: 2.561143537646495e-14
grad ChooseDest W: 10.023775100708008
grad AddEdge W: 1.1347096883390943e-15
grad ChooseDest W: 4.606094837188721
grad AddEdge W: 5.107518297187141e-10
grad ChooseDest W: 3.8730859756469727
grad AddEdge W: 1.9090966431138928e-15
grad ChooseDest W: 3.018850326538086
grad AddEdge W: 1.367886974344831e-14
grad ChooseDest W: 5.646520137786865
grad AddEdge W: 1.5507363393045973e-17
grad ChooseDest W: 4.133884906768799
grad AddEdge W: 2.144887457748712e-13
grad ChooseDest W: 3.1299092769622803
grad AddEdge W: 1.6021084243344276e-16
grad ChooseDest W: 4.173526287078857
grad AddEdge W: 3.1127251926173216e-13
grad ChooseDest W: 4.016870498657227
grad AddEdge W: 2.982002651865916e-17
grad ChooseDest W: 6.841605186462402
grad AddEdge W: 7.58193150190295e-14
grad ChooseDest W: 5.673501491546631
grad AddEdge W: 1.8376734485728709e-16
grad ChooseDest W: 5.954669952392578
grad AddEdge W: 1.983387997093436e-15
grad ChooseDest W: 3.718895435333252
grad AddEdge W: 3.414478113566836e-15
grad ChooseDest W: 4.08177375793457
grad AddEdge W: 1.0324090856111092e-16
grad ChooseDest W: 5.3930840492248535
grad AddEdge W: 1.150164863252933e-15
grad ChooseDest W: 2.160252332687378
grad AddEdge W: 2.378179254138588e-15
grad ChooseDest W: 3.756129503250122
grad AddEdge W: 3.68483631313295e-16
grad ChooseDest W: 3.807715654373169
grad AddEdge W: 1.555829439890341e-14
grad ChooseDest W: 4.509138584136963
grad AddEdge W: 2.1894934324785675e-14
grad ChooseDest W: 5.006424427032471
grad AddEdge W: 4.960772532686693e-17
grad ChooseDest W: 3.9023098945617676
grad AddEdge W: 5.34172391988331e-15
grad ChooseDest W: 3.8963513374328613
grad AddEdge W: 3.733022463196789e-13
grad ChooseDest W: 3.4663565158843994
grad AddEdge W: 1.855494704145746e-15
grad ChooseDest W: 4.301881313323975
grad AddEdge W: 4.0791376277925643e-17
grad ChooseDest W: 5.558130741119385
grad AddEdge W: 1.560456399716365e-15
grad ChooseDest W: 3.7158334255218506
grad AddEdge W: 1.5340931345077854e-16
grad ChooseDest W: 4.211417198181152
grad AddEdge W: 1.659169301752026e-15
grad ChooseDest W: 2.4383111000061035
grad AddEdge W: 2.0565193659214943e-16
grad ChooseDest W: 5.567567825317383
grad AddEdge W: 1.0775583848604206e-14
grad ChooseDest W: 5.340340614318848
grad AddEdge W: 9.98743827296936e-17
grad ChooseDest W: 7.534749507904053
grad AddEdge W: 2.2481757903610507e-15
grad ChooseDest W: 5.510826110839844
grad AddEdge W: 6.54878493911538e-17
grad ChooseDest W: 3.117597818374634
grad AddEdge W: 3.5641531763905255e-17
grad ChooseDest W: 2.8102786540985107
grad AddEdge W: 2.3513626343973252e-17
grad ChooseDest W: 4.865042209625244
grad AddEdge W: 2.274753736070112e-13
grad ChooseDest W: 5.715606212615967
grad AddEdge W: 5.1226948030724806e-12
grad ChooseDest W: 2.8125882148742676
grad AddEdge W: 9.356147042012541e-14
grad ChooseDest W: 2.340974807739258
grad AddEdge W: 1.5081369745094798e-15
grad ChooseDest W: 4.431006908416748
grad AddEdge W: 2.427838042979029e-15
grad ChooseDest W: 3.515227794647217
grad AddEdge W: 9.65591471255127e-15
grad ChooseDest W: 5.52372932434082
grad AddEdge W: 2.9949827170985387e-15
grad ChooseDest W: 3.5569591522216797
grad AddEdge W: 2.067229579790636e-13
grad ChooseDest W: 2.1168904304504395
grad AddEdge W: 5.507701296447211e-15
grad ChooseDest W: 4.3212385177612305
grad AddEdge W: 1.6231048623194244e-14
grad ChooseDest W: 6.260242462158203
grad AddEdge W: 4.2440202010372494e-16
grad ChooseDest W: 3.0834808349609375
grad AddEdge W: 6.663624077917342e-17
grad ChooseDest W: 4.4649810791015625
grad AddEdge W: 1.9331788485955166e-15
grad ChooseDest W: 4.619491100311279
grad AddEdge W: 6.762052615110742e-17
grad ChooseDest W: 2.5510947704315186
grad AddEdge W: 6.536109832213548e-15
grad ChooseDest W: 5.529880523681641
grad AddEdge W: 1.6310359494419216e-15
grad ChooseDest W: 3.0241594314575195
grad AddEdge W: 7.711043844668328e-17
grad ChooseDest W: 4.788949489593506
grad AddEdge W: 1.714047434821554e-17
grad ChooseDest W: 2.0407772064208984
grad AddEdge W: 1.4743703634092118e-17
grad ChooseDest W: 4.506191730499268
grad AddEdge W: 6.339905661410404e-15
grad ChooseDest W: 2.9765162467956543
grad AddEdge W: 2.6430170223500906e-15
grad ChooseDest W: 5.0038371086120605
grad AddEdge W: 1.174684084795781e-16
grad ChooseDest W: 3.823730707168579
grad AddEdge W: 4.026916180474875e-15
grad ChooseDest W: 5.432534694671631
grad AddEdge W: 1.1031363234719534e-14
grad ChooseDest W: 3.4976589679718018
grad AddEdge W: 9.505036460601829e-14
grad ChooseDest W: 5.603652000427246
grad AddEdge W: 2.9277460887784396e-16
grad ChooseDest W: 5.477022647857666
grad AddEdge W: 1.4384143044891893e-15
grad ChooseDest W: 3.1611034870147705
grad AddEdge W: 2.1038781691425643e-16
grad ChooseDest W: 5.026750087738037
grad AddEdge W: 4.227555915406933e-18
grad ChooseDest W: 7.724316120147705
grad AddEdge W: 2.065827331569533e-17
grad ChooseDest W: 5.069404125213623
grad AddEdge W: 2.270846362496516e-16
grad ChooseDest W: 6.016655921936035
=== Epoch 44: Train Loss: 4.5579, Train Log Prob: 0.0264 ===
Total mismatches: 61730
Predicted valid destination but wrong order: 6092
Epoch 44: Validation Loss: 3.1995, Validation Log Prob: 0.0543
Epoch 44: Edge Precision: 0.3590, Recall: 0.3500, F1: 0.3542, Jaccard: 0.2328
Epoch 44: TP: 2.45025053686471, FP: 4.390694345025054, FN: 4.571224051539012
Epoch 44: Current Learning Rate: 6e-05
[Epoch 44] ‚è±Ô∏è Total: 3381.21s | Current time: 2025-07-16 05:19:36 | üèãÔ∏è Train: 2885.45s | ‚úÖ Val: 495.76s
grad AddEdge W: 2.3451504749098274e-14
grad ChooseDest W: 8.119609832763672
grad AddEdge W: 3.392059573437848e-17
grad ChooseDest W: 5.781893730163574
grad AddEdge W: 3.6064439432601566e-17
grad ChooseDest W: 5.145299911499023
grad AddEdge W: 2.769265959649364e-16
grad ChooseDest W: 3.7088005542755127
grad AddEdge W: 1.3598473611259668e-14
grad ChooseDest W: 5.366204738616943
grad AddEdge W: 3.8203494085950213e-16
grad ChooseDest W: 9.013954162597656
grad AddEdge W: 1.6224054513330088e-16
grad ChooseDest W: 3.3705554008483887
grad AddEdge W: 1.2649589207115109e-17
grad ChooseDest W: 2.539093255996704
grad AddEdge W: 5.6368035171688695e-15
grad ChooseDest W: 5.0963335037231445
grad AddEdge W: 5.490441425195018e-17
grad ChooseDest W: 1.6395933628082275
grad AddEdge W: 1.8089882476801855e-17
grad ChooseDest W: 5.07515811920166
grad AddEdge W: 5.98645101508958e-17
grad ChooseDest W: 5.0057759284973145
grad AddEdge W: 1.5334288743298896e-13
grad ChooseDest W: 2.807669162750244
grad AddEdge W: 2.6683811592578246e-16
grad ChooseDest W: 7.094040870666504
grad AddEdge W: 3.3193397435081473e-16
grad ChooseDest W: 5.381331443786621
grad AddEdge W: 1.4167524956543447e-15
grad ChooseDest W: 2.7954821586608887
grad AddEdge W: 1.6216362395377835e-16
grad ChooseDest W: 5.557596683502197
grad AddEdge W: 7.270506641012797e-17
grad ChooseDest W: 3.858686923980713
grad AddEdge W: 2.7073468453534498e-15
grad ChooseDest W: 4.804871559143066
grad AddEdge W: 8.075745475989715e-13
grad ChooseDest W: 3.6262733936309814
grad AddEdge W: 6.11639187783836e-15
grad ChooseDest W: 2.133951425552368
grad AddEdge W: 2.7924370091426484e-17
grad ChooseDest W: 4.817865371704102
grad AddEdge W: 2.887239848275106e-17
grad ChooseDest W: 3.4205031394958496
grad AddEdge W: 5.850553843125489e-17
grad ChooseDest W: 3.45438289642334
grad AddEdge W: 3.119078549585451e-14
grad ChooseDest W: 3.4027295112609863
grad AddEdge W: 4.0009243921532254e-17
grad ChooseDest W: 4.726165771484375
grad AddEdge W: 3.3333200752421388e-15
grad ChooseDest W: 4.488789081573486
grad AddEdge W: 1.2252029826545995e-16
grad ChooseDest W: 4.659053325653076
grad AddEdge W: 1.534648999879421e-16
grad ChooseDest W: 5.6026482582092285
grad AddEdge W: 1.3128042881124968e-17
grad ChooseDest W: 4.24028205871582
grad AddEdge W: 3.008010930860257e-15
grad ChooseDest W: 2.989267110824585
grad AddEdge W: 3.397730578133724e-15
grad ChooseDest W: 2.8276965618133545
grad AddEdge W: 2.5176862158260817e-15
grad ChooseDest W: 3.1727492809295654
grad AddEdge W: 4.5403387957664053e-17
grad ChooseDest W: 4.492387771606445
grad AddEdge W: 2.4519412125260974e-16
grad ChooseDest W: 6.260121822357178
grad AddEdge W: 2.0498280703359814e-16
grad ChooseDest W: 5.252459526062012
grad AddEdge W: 1.063856652850693e-15
grad ChooseDest W: 4.189805507659912
grad AddEdge W: 1.3168211367240584e-15
grad ChooseDest W: 3.5245070457458496
grad AddEdge W: 3.1649976879637642e-15
grad ChooseDest W: 4.034358978271484
grad AddEdge W: 3.2251722452605796e-17
grad ChooseDest W: 5.194425106048584
grad AddEdge W: 5.733847261372627e-17
grad ChooseDest W: 4.441261291503906
grad AddEdge W: 2.836079336193632e-15
grad ChooseDest W: 6.073799133300781
grad AddEdge W: 3.691712367780083e-16
grad ChooseDest W: 3.729266405105591
grad AddEdge W: 9.704287731847558e-17
grad ChooseDest W: 3.1979682445526123
grad AddEdge W: 4.93774426118458e-15
grad ChooseDest W: 5.843663692474365
grad AddEdge W: 3.007932117091493e-17
grad ChooseDest W: 4.887862205505371
grad AddEdge W: 2.7594444538072728e-15
grad ChooseDest W: 4.953611850738525
grad AddEdge W: 1.2130947790224973e-16
grad ChooseDest W: 3.0264732837677
grad AddEdge W: 1.845255515769452e-14
grad ChooseDest W: 5.266921520233154
grad AddEdge W: 8.999402464138045e-18
grad ChooseDest W: 5.08599853515625
grad AddEdge W: 1.3260343140913435e-16
grad ChooseDest W: 3.1968910694122314
grad AddEdge W: 2.4648407302193924e-16
grad ChooseDest W: 2.8454155921936035
grad AddEdge W: 1.3004929454655638e-17
grad ChooseDest W: 3.486091375350952
grad AddEdge W: 3.892549649986031e-15
grad ChooseDest W: 3.3570706844329834
grad AddEdge W: 6.695483104645944e-17
grad ChooseDest W: 4.921023368835449
grad AddEdge W: 3.764627610857693e-16
grad ChooseDest W: 5.171206951141357
grad AddEdge W: 3.929267720921227e-17
grad ChooseDest W: 3.0104446411132812
grad AddEdge W: 8.816626981627103e-17
grad ChooseDest W: 7.236457347869873
grad AddEdge W: 1.8094875338979225e-17
grad ChooseDest W: 7.089361190795898
grad AddEdge W: 4.585077434914042e-15
grad ChooseDest W: 5.537567138671875
grad AddEdge W: 2.348971089810312e-17
grad ChooseDest W: 4.09792947769165
grad AddEdge W: 2.4537774698414616e-13
grad ChooseDest W: 2.0451254844665527
grad AddEdge W: 1.2151156143461888e-16
grad ChooseDest W: 6.124481201171875
grad AddEdge W: 9.622993082990337e-17
grad ChooseDest W: 8.725852012634277
grad AddEdge W: 2.2201613667706968e-17
grad ChooseDest W: 4.35709810256958
grad AddEdge W: 2.470062423641419e-16
grad ChooseDest W: 4.687068939208984
=== Epoch 45: Train Loss: 4.5290, Train Log Prob: 0.0270 ===
Total mismatches: 61237
Predicted valid destination but wrong order: 6089
Epoch 45: Validation Loss: 3.1950, Validation Log Prob: 0.0550
Epoch 45: Edge Precision: 0.3587, Recall: 0.3489, F1: 0.3534, Jaccard: 0.2325
Epoch 45: TP: 2.443378668575519, FP: 4.385254115962778, FN: 4.578095919828203
Epoch 45: Current Learning Rate: 6e-05
[Epoch 45] ‚è±Ô∏è Total: 3376.24s | Current time: 2025-07-16 06:15:52 | üèãÔ∏è Train: 2879.66s | ‚úÖ Val: 496.58s
grad AddEdge W: 5.405392845429574e-15
grad ChooseDest W: 9.815747261047363
grad AddEdge W: 7.84719952050001e-15
grad ChooseDest W: 2.0602738857269287
grad AddEdge W: 9.224627532196229e-17
grad ChooseDest W: 2.1736209392547607
grad AddEdge W: 8.138776954186029e-17
grad ChooseDest W: 5.97307014465332
grad AddEdge W: 2.971986156392389e-17
grad ChooseDest W: 4.839990139007568
grad AddEdge W: 2.973720125479647e-16
grad ChooseDest W: 4.765257358551025
grad AddEdge W: 4.429879399636899e-15
grad ChooseDest W: 3.7219719886779785
grad AddEdge W: 2.9447765464508244e-17
grad ChooseDest W: 2.7061212062835693
grad AddEdge W: 4.1035851162326916e-17
grad ChooseDest W: 3.8306660652160645
grad AddEdge W: 4.091107877815525e-13
grad ChooseDest W: 3.7572836875915527
grad AddEdge W: 3.47914187930965e-15
grad ChooseDest W: 3.2634875774383545
grad AddEdge W: 7.464937760099101e-17
grad ChooseDest W: 9.305577278137207
grad AddEdge W: 5.733174351929549e-14
grad ChooseDest W: 5.687459945678711
grad AddEdge W: 1.8639094174349724e-13
grad ChooseDest W: 1.7556381225585938
grad AddEdge W: 1.1832519554061562e-16
grad ChooseDest W: 6.761574745178223
grad AddEdge W: 1.6016994662395814e-16
grad ChooseDest W: 4.415346145629883
grad AddEdge W: 4.7451332041436884e-15
grad ChooseDest W: 2.400047540664673
grad AddEdge W: 1.1302990289640635e-16
grad ChooseDest W: 5.2116475105285645
grad AddEdge W: 1.3923637436551536e-16
grad ChooseDest W: 3.5539863109588623
grad AddEdge W: 1.5782095750161047e-14
grad ChooseDest W: 3.040876626968384
grad AddEdge W: 9.517824896276839e-12
grad ChooseDest W: 1.2809576988220215
grad AddEdge W: 1.8340711233273167e-15
grad ChooseDest W: 3.5952963829040527
grad AddEdge W: 3.160426568784788e-16
grad ChooseDest W: 4.554543972015381
grad AddEdge W: 1.2738288942252027e-16
grad ChooseDest W: 4.832111358642578
grad AddEdge W: 6.017417348501116e-16
grad ChooseDest W: 4.108214378356934
grad AddEdge W: 4.743263074510159e-17
grad ChooseDest W: 5.176504135131836
grad AddEdge W: 3.676850645324914e-16
grad ChooseDest W: 4.291046142578125
grad AddEdge W: 3.189088194368271e-14
grad ChooseDest W: 1.901038408279419
grad AddEdge W: 3.4157496709569246e-13
grad ChooseDest W: 4.195619106292725
grad AddEdge W: 2.082103433610494e-17
grad ChooseDest W: 2.018749952316284
grad AddEdge W: 2.1651002812020067e-15
grad ChooseDest W: 2.658048152923584
grad AddEdge W: 4.376697589010591e-15
grad ChooseDest W: 3.7598776817321777
grad AddEdge W: 2.5376254772835664e-16
grad ChooseDest W: 2.828749418258667
grad AddEdge W: 1.4439176098963985e-16
grad ChooseDest W: 5.0940375328063965
grad AddEdge W: 1.7346020326279945e-15
grad ChooseDest W: 2.127683401107788
grad AddEdge W: 5.613530201682094e-17
grad ChooseDest W: 2.2819926738739014
grad AddEdge W: 6.759258862222681e-16
grad ChooseDest W: 4.82103157043457
grad AddEdge W: 5.976885763183813e-16
grad ChooseDest W: 4.000124454498291
grad AddEdge W: 1.770149781962771e-14
grad ChooseDest W: 3.136636734008789
grad AddEdge W: 2.965295313440107e-14
grad ChooseDest W: 3.334655523300171
grad AddEdge W: 3.860823554490588e-16
grad ChooseDest W: 7.03341007232666
grad AddEdge W: 2.383276585918601e-17
grad ChooseDest W: 5.635965347290039
grad AddEdge W: 2.2534405236447098e-14
grad ChooseDest W: 5.756048679351807
grad AddEdge W: 5.138632100669567e-15
grad ChooseDest W: 3.897940158843994
grad AddEdge W: 3.5525324137497885e-15
grad ChooseDest W: 3.977278232574463
grad AddEdge W: 4.514131256294629e-12
grad ChooseDest W: 1.4621001482009888
grad AddEdge W: 9.719361715465353e-15
grad ChooseDest W: 4.115761756896973
grad AddEdge W: 1.6274983692772733e-17
grad ChooseDest W: 6.420306205749512
grad AddEdge W: 2.288921251497535e-16
grad ChooseDest W: 6.215384483337402
grad AddEdge W: 4.052351732847974e-15
grad ChooseDest W: 3.6820690631866455
grad AddEdge W: 3.622019185094269e-15
grad ChooseDest W: 4.385718822479248
grad AddEdge W: 3.532387852681713e-16
grad ChooseDest W: 3.7840895652770996
grad AddEdge W: 5.586812479654868e-15
grad ChooseDest W: 2.578090190887451
grad AddEdge W: 6.899164088214061e-17
grad ChooseDest W: 4.680347442626953
grad AddEdge W: 3.956933471339777e-15
grad ChooseDest W: 3.4892072677612305
grad AddEdge W: 7.471121100614058e-17
grad ChooseDest W: 3.421962261199951
grad AddEdge W: 3.118285726746821e-15
grad ChooseDest W: 5.181646347045898
grad AddEdge W: 1.6645221463145342e-17
grad ChooseDest W: 7.063238143920898
grad AddEdge W: 3.6100478037529276e-17
grad ChooseDest W: 5.455521106719971
grad AddEdge W: 3.642049237895787e-16
grad ChooseDest W: 5.665898323059082
grad AddEdge W: 2.1405479819214257e-11
grad ChooseDest W: 3.4453749656677246
grad AddEdge W: 2.5486067300491263e-15
grad ChooseDest W: 4.960978984832764
grad AddEdge W: 8.05955422732713e-17
grad ChooseDest W: 4.46783447265625
grad AddEdge W: 1.2540582187940013e-16
grad ChooseDest W: 2.7458508014678955
grad AddEdge W: 3.194448441204645e-17
grad ChooseDest W: 3.970181941986084
grad AddEdge W: 1.8385487512447398e-15
grad ChooseDest W: 4.618912696838379
=== Epoch 46: Train Loss: 4.4949, Train Log Prob: 0.0277 ===
Total mismatches: 60772
Predicted valid destination but wrong order: 6104
Epoch 46: Validation Loss: 3.1683, Validation Log Prob: 0.0560
Epoch 46: Edge Precision: 0.3614, Recall: 0.3519, F1: 0.3563, Jaccard: 0.2343
Epoch 46: TP: 2.4631352899069436, FP: 4.37394416607015, FN: 4.5583392984967785
Epoch 46: Current Learning Rate: 6e-05
[Epoch 46] ‚è±Ô∏è Total: 3383.42s | Current time: 2025-07-16 07:12:16 | üèãÔ∏è Train: 2888.91s | ‚úÖ Val: 494.51s
grad AddEdge W: 3.796746771145276e-12
grad ChooseDest W: 8.022101402282715
grad AddEdge W: 1.773448869413208e-15
grad ChooseDest W: 4.965613842010498
grad AddEdge W: 1.3604817041001655e-14
grad ChooseDest W: 8.431990623474121
grad AddEdge W: 5.515051702779696e-17
grad ChooseDest W: 4.576254844665527
grad AddEdge W: 1.1558755858531012e-16
grad ChooseDest W: 3.598555326461792
grad AddEdge W: 3.249745036872781e-13
grad ChooseDest W: 5.540939807891846
grad AddEdge W: 4.535241827945862e-15
grad ChooseDest W: 3.0039689540863037
grad AddEdge W: 1.2123115217004708e-17
grad ChooseDest W: 4.481567859649658
grad AddEdge W: 1.0742686432274164e-17
grad ChooseDest W: 4.012533664703369
grad AddEdge W: 5.858759474802015e-17
grad ChooseDest W: 5.115995407104492
grad AddEdge W: 1.2937161028611006e-17
grad ChooseDest W: 3.8974530696868896
grad AddEdge W: 4.302827845680543e-15
grad ChooseDest W: 7.516409397125244
grad AddEdge W: 8.927316982476499e-17
grad ChooseDest W: 2.7363452911376953
grad AddEdge W: 5.772450126199252e-17
grad ChooseDest W: 4.017100811004639
grad AddEdge W: 5.257405178115933e-15
grad ChooseDest W: 3.9201292991638184
grad AddEdge W: 1.6018134186407667e-17
grad ChooseDest W: 4.082137584686279
grad AddEdge W: 3.976740807415727e-16
grad ChooseDest W: 4.713618755340576
grad AddEdge W: 9.192983406990768e-18
grad ChooseDest W: 4.844717979431152
grad AddEdge W: 5.5474278828272663e-17
grad ChooseDest W: 3.3283636569976807
grad AddEdge W: 1.2580707197442633e-15
grad ChooseDest W: 6.19276237487793
grad AddEdge W: 3.405984331869566e-17
grad ChooseDest W: 3.208116292953491
grad AddEdge W: 1.4882846398082072e-15
grad ChooseDest W: 7.687160015106201
grad AddEdge W: 3.119306841905395e-13
grad ChooseDest W: 5.299328804016113
grad AddEdge W: 5.772270682269376e-13
grad ChooseDest W: 3.5844409465789795
grad AddEdge W: 6.704290985218297e-13
grad ChooseDest W: 4.647573947906494
grad AddEdge W: 1.2321628363887865e-13
grad ChooseDest W: 4.60038948059082
grad AddEdge W: 7.639263096344447e-16
grad ChooseDest W: 4.062180042266846
grad AddEdge W: 5.269700668673607e-17
grad ChooseDest W: 2.467099666595459
grad AddEdge W: 2.4489773913040954e-16
grad ChooseDest W: 1.6965267658233643
grad AddEdge W: 3.091430970670597e-16
grad ChooseDest W: 3.816899061203003
grad AddEdge W: 1.4914530988963099e-16
grad ChooseDest W: 2.67165207862854
grad AddEdge W: 1.6918837258782368e-15
grad ChooseDest W: 4.7443623542785645
grad AddEdge W: 3.1214923224345825e-13
grad ChooseDest W: 2.964935302734375
grad AddEdge W: 2.1131019873612492e-15
grad ChooseDest W: 3.060277223587036
grad AddEdge W: 5.028900676418667e-15
grad ChooseDest W: 6.682288646697998
grad AddEdge W: 1.7304658648674334e-15
grad ChooseDest W: 5.284695148468018
grad AddEdge W: 1.8593254106497037e-15
grad ChooseDest W: 5.379742622375488
grad AddEdge W: 1.8533817804588203e-15
grad ChooseDest W: 4.847987174987793
grad AddEdge W: 4.0133757764778636e-17
grad ChooseDest W: 8.25653076171875
grad AddEdge W: 1.7265527928796848e-13
grad ChooseDest W: 3.171180248260498
grad AddEdge W: 2.0162272527002485e-14
grad ChooseDest W: 10.521036148071289
grad AddEdge W: 4.838931091623788e-15
grad ChooseDest W: 4.650689125061035
grad AddEdge W: 4.412160542406413e-17
grad ChooseDest W: 6.78759241104126
grad AddEdge W: 1.6396931621758975e-17
grad ChooseDest W: 7.348367691040039
grad AddEdge W: 8.657450300247809e-17
grad ChooseDest W: 6.411848068237305
grad AddEdge W: 1.0881484142834675e-14
grad ChooseDest W: 5.130130767822266
grad AddEdge W: 1.9975682550727592e-16
grad ChooseDest W: 4.887137413024902
grad AddEdge W: 2.5992481499002763e-17
grad ChooseDest W: 2.3260557651519775
grad AddEdge W: 4.1310984668951854e-17
grad ChooseDest W: 4.378845691680908
grad AddEdge W: 6.616621028534119e-17
grad ChooseDest W: 4.066690444946289
grad AddEdge W: 2.123548021183263e-15
grad ChooseDest W: 1.7979719638824463
grad AddEdge W: 1.9007119897004755e-17
grad ChooseDest W: 5.683507919311523
grad AddEdge W: 1.64456126566456e-15
grad ChooseDest W: 5.31913948059082
grad AddEdge W: 1.460974007952793e-17
grad ChooseDest W: 3.9362990856170654
grad AddEdge W: 3.1005201635902276e-16
grad ChooseDest W: 4.221428394317627
grad AddEdge W: 3.49019422990322e-16
grad ChooseDest W: 3.586862802505493
grad AddEdge W: 3.2360446939970868e-15
grad ChooseDest W: 2.8162684440612793
grad AddEdge W: 5.3147247711593585e-17
grad ChooseDest W: 3.014091730117798
grad AddEdge W: 1.820760745950209e-13
grad ChooseDest W: 2.3986189365386963
grad AddEdge W: 9.312910864612788e-17
grad ChooseDest W: 7.259159088134766
grad AddEdge W: 2.7694795707707497e-16
grad ChooseDest W: 3.8634727001190186
grad AddEdge W: 1.0425844791715853e-14
grad ChooseDest W: 5.326394557952881
grad AddEdge W: 4.2157969044160585e-15
grad ChooseDest W: 3.8902530670166016
grad AddEdge W: 2.0231397191762014e-14
grad ChooseDest W: 3.990802764892578
grad AddEdge W: 2.1025129902596068e-16
grad ChooseDest W: 2.732213258743286
grad AddEdge W: 6.937128369607795e-17
grad ChooseDest W: 3.492504358291626
=== Epoch 47: Train Loss: 4.4710, Train Log Prob: 0.0284 ===
Total mismatches: 60372
Predicted valid destination but wrong order: 6139
Epoch 47: Validation Loss: 3.1424, Validation Log Prob: 0.0574
Epoch 47: Edge Precision: 0.3615, Recall: 0.3521, F1: 0.3564, Jaccard: 0.2343
Epoch 47: TP: 2.4647100930565498, FP: 4.372226198997852, FN: 4.556764495347172
Epoch 47: Current Learning Rate: 6e-05
[Epoch 47] ‚è±Ô∏è Total: 3384.18s | Current time: 2025-07-16 08:08:40 | üèãÔ∏è Train: 2889.58s | ‚úÖ Val: 494.61s
grad AddEdge W: 4.325514352623329e-15
grad ChooseDest W: 9.897034645080566
grad AddEdge W: 5.965763558841874e-17
grad ChooseDest W: 4.159621238708496
grad AddEdge W: 3.860982637865994e-16
grad ChooseDest W: 5.479786396026611
grad AddEdge W: 2.158090448288767e-15
grad ChooseDest W: 3.958568811416626
grad AddEdge W: 4.835590327505368e-17
grad ChooseDest W: 3.418651819229126
grad AddEdge W: 7.439479787822679e-17
grad ChooseDest W: 4.731204986572266
grad AddEdge W: 5.055411507339804e-18
grad ChooseDest W: 3.5644943714141846
grad AddEdge W: 3.288448187223987e-16
grad ChooseDest W: 5.021394729614258
grad AddEdge W: 4.404863128572691e-15
grad ChooseDest W: 2.6639626026153564
grad AddEdge W: 7.737626491410247e-15
grad ChooseDest W: 3.98299503326416
grad AddEdge W: 5.006568483357718e-14
grad ChooseDest W: 3.531888961791992
grad AddEdge W: 6.086499661613282e-15
grad ChooseDest W: 2.8007965087890625
grad AddEdge W: 2.0033178353093825e-15
grad ChooseDest W: 4.595043182373047
grad AddEdge W: 1.0923557793984101e-13
grad ChooseDest W: 8.140809059143066
grad AddEdge W: 2.2172957484310171e-16
grad ChooseDest W: 7.033738613128662
grad AddEdge W: 1.1095977422565155e-16
grad ChooseDest W: 5.303074836730957
grad AddEdge W: 7.046246012609291e-15
grad ChooseDest W: 5.390933036804199
grad AddEdge W: 3.372547044532212e-17
grad ChooseDest W: 3.6822426319122314
grad AddEdge W: 3.5272724089550076e-15
grad ChooseDest W: 5.702573299407959
grad AddEdge W: 1.0283136680762448e-14
grad ChooseDest W: 2.337470054626465
grad AddEdge W: 7.10738397723938e-17
grad ChooseDest W: 3.647136926651001
grad AddEdge W: 9.49307199316692e-16
grad ChooseDest W: 3.809563398361206
grad AddEdge W: 4.176552372427219e-17
grad ChooseDest W: 4.914328575134277
grad AddEdge W: 6.222982318632384e-17
grad ChooseDest W: 4.688241481781006
grad AddEdge W: 3.7137026787092964e-10
grad ChooseDest W: 2.5795040130615234
grad AddEdge W: 1.7753127323264166e-17
grad ChooseDest W: 2.6239607334136963
grad AddEdge W: 3.9913301558387943e-16
grad ChooseDest W: 3.7087340354919434
grad AddEdge W: 5.1652833438453234e-17
grad ChooseDest W: 1.9262207746505737
grad AddEdge W: 9.843394232239458e-16
grad ChooseDest W: 5.536866664886475
grad AddEdge W: 1.4386893784388102e-15
grad ChooseDest W: 3.2257540225982666
grad AddEdge W: 2.6669917901726847e-13
grad ChooseDest W: 7.1439900398254395
grad AddEdge W: 1.4468519173141446e-16
grad ChooseDest W: 6.343164443969727
grad AddEdge W: 1.117314553866159e-14
grad ChooseDest W: 3.2965307235717773
grad AddEdge W: 5.811660472467735e-17
grad ChooseDest W: 5.685768127441406
grad AddEdge W: 3.3294766632439724e-15
grad ChooseDest W: 3.5242726802825928
grad AddEdge W: 7.644746787644971e-15
grad ChooseDest W: 3.1128039360046387
grad AddEdge W: 1.6143791193260597e-17
grad ChooseDest W: 4.405069828033447
grad AddEdge W: 1.1616374447587373e-17
grad ChooseDest W: 5.426567077636719
grad AddEdge W: 4.051127637890294e-17
grad ChooseDest W: 3.622295618057251
grad AddEdge W: 3.097840693975597e-17
grad ChooseDest W: 4.458484172821045
grad AddEdge W: 6.190038173876922e-14
grad ChooseDest W: 5.65396785736084
grad AddEdge W: 4.874890009280007e-17
grad ChooseDest W: 4.764914512634277
grad AddEdge W: 6.135496388326325e-17
grad ChooseDest W: 3.7002668380737305
grad AddEdge W: 6.396793479408966e-17
grad ChooseDest W: 4.2131500244140625
grad AddEdge W: 1.197740586317839e-14
grad ChooseDest W: 2.237661838531494
grad AddEdge W: 3.993247825196488e-17
grad ChooseDest W: 4.171414375305176
grad AddEdge W: 4.190871265877206e-15
grad ChooseDest W: 1.7986946105957031
grad AddEdge W: 1.3195735194641844e-13
grad ChooseDest W: 3.276787757873535
grad AddEdge W: 8.729307255067164e-15
grad ChooseDest W: 2.0345935821533203
grad AddEdge W: 2.5792027883017252e-14
grad ChooseDest W: 5.412510871887207
grad AddEdge W: 6.023288345616772e-17
grad ChooseDest W: 7.580813407897949
grad AddEdge W: 7.240302637253791e-17
grad ChooseDest W: 4.213339328765869
grad AddEdge W: 7.400597005076767e-17
grad ChooseDest W: 4.200277328491211
grad AddEdge W: 5.516622670964167e-15
grad ChooseDest W: 3.6425318717956543
grad AddEdge W: 2.7354058705224326e-15
grad ChooseDest W: 3.9553067684173584
grad AddEdge W: 3.168882869274142e-16
grad ChooseDest W: 5.548104763031006
grad AddEdge W: 1.065569234356033e-16
grad ChooseDest W: 7.3389668464660645
grad AddEdge W: 1.2391675913395075e-15
grad ChooseDest W: 5.270777702331543
grad AddEdge W: 2.7445546733857263e-15
grad ChooseDest W: 3.802189588546753
grad AddEdge W: 4.4036935216563205e-17
grad ChooseDest W: 3.9680936336517334
grad AddEdge W: 2.4691784653516205e-17
grad ChooseDest W: 6.769848346710205
grad AddEdge W: 5.4429480231446735e-17
grad ChooseDest W: 2.567138433456421
grad AddEdge W: 2.069959396514256e-16
grad ChooseDest W: 3.785996675491333
grad AddEdge W: 3.074323022718428e-15
grad ChooseDest W: 5.44927978515625
grad AddEdge W: 8.520850752681986e-16
grad ChooseDest W: 4.040167808532715
grad AddEdge W: 2.8875162589485966e-15
grad ChooseDest W: 4.940910339355469
=== Epoch 48: Train Loss: 4.4368, Train Log Prob: 0.0291 ===
Total mismatches: 59834
Predicted valid destination but wrong order: 6150
Epoch 48: Validation Loss: 3.1154, Validation Log Prob: 0.0590
Epoch 48: Edge Precision: 0.3597, Recall: 0.3500, F1: 0.3545, Jaccard: 0.2328
Epoch 48: TP: 2.449964209019327, FP: 4.383679312813171, FN: 4.571510379384395
Epoch 48: Current Learning Rate: 6e-05
[Epoch 48] ‚è±Ô∏è Total: 3386.98s | Current time: 2025-07-16 09:05:07 | üèãÔ∏è Train: 2887.96s | ‚úÖ Val: 499.03s
grad AddEdge W: 1.375611050850184e-13
grad ChooseDest W: 8.429936408996582
grad AddEdge W: 2.7163917808015864e-16
grad ChooseDest W: 2.358224630355835
grad AddEdge W: 8.535564244371385e-17
grad ChooseDest W: 4.625436305999756
grad AddEdge W: 1.2367459241433075e-15
grad ChooseDest W: 2.861590623855591
grad AddEdge W: 2.463205268416922e-15
grad ChooseDest W: 6.641304969787598
grad AddEdge W: 5.223032263478998e-16
grad ChooseDest W: 3.6450512409210205
grad AddEdge W: 9.961162516852144e-15
grad ChooseDest W: 5.2156171798706055
grad AddEdge W: 4.500668484137783e-15
grad ChooseDest W: 4.168220043182373
grad AddEdge W: 1.6527244662843844e-16
grad ChooseDest W: 4.351561546325684
grad AddEdge W: 6.847566388017796e-15
grad ChooseDest W: 3.6255176067352295
grad AddEdge W: 9.981111995644554e-18
grad ChooseDest W: 6.157435417175293
grad AddEdge W: 4.1252023234889074e-17
grad ChooseDest W: 3.6202659606933594
grad AddEdge W: 1.134019885882674e-15
grad ChooseDest W: 8.543752670288086
grad AddEdge W: 1.4586261411491004e-14
grad ChooseDest W: 4.486053466796875
grad AddEdge W: 8.824560239271528e-16
grad ChooseDest W: 6.057859420776367
grad AddEdge W: 3.8017399623949463e-17
grad ChooseDest W: 4.1239728927612305
grad AddEdge W: 1.6492818067493877e-16
grad ChooseDest W: 5.228875637054443
grad AddEdge W: 4.586475373457979e-18
grad ChooseDest W: 7.1216535568237305
grad AddEdge W: 1.1599150459562502e-12
grad ChooseDest W: 5.7132062911987305
grad AddEdge W: 5.7446482549391e-17
grad ChooseDest W: 2.8420474529266357
grad AddEdge W: 2.5716254856654724e-15
grad ChooseDest W: 1.847708821296692
grad AddEdge W: 1.3597902975751014e-17
grad ChooseDest W: 4.919572830200195
grad AddEdge W: 2.673938489485201e-16
grad ChooseDest W: 3.2337756156921387
grad AddEdge W: 2.7545445270260843e-17
grad ChooseDest W: 2.1299335956573486
grad AddEdge W: 7.875230097273366e-18
grad ChooseDest W: 4.785923004150391
grad AddEdge W: 3.4613745246783734e-13
grad ChooseDest W: 3.0988826751708984
grad AddEdge W: 1.7915195761890497e-15
grad ChooseDest W: 5.483717441558838
grad AddEdge W: 1.3631511324039044e-17
grad ChooseDest W: 5.319985866546631
grad AddEdge W: 7.0574954571817755e-15
grad ChooseDest W: 3.7420592308044434
grad AddEdge W: 1.9324990517157858e-17
grad ChooseDest W: 4.326422691345215
grad AddEdge W: 1.0260899551267961e-16
grad ChooseDest W: 5.150440216064453
grad AddEdge W: 9.77307461574959e-15
grad ChooseDest W: 1.5338618755340576
grad AddEdge W: 2.4558375640834672e-15
grad ChooseDest W: 2.889341354370117
grad AddEdge W: 3.041503738560325e-17
grad ChooseDest W: 3.7250657081604004
grad AddEdge W: 1.3531011460417362e-15
grad ChooseDest W: 4.756610870361328
grad AddEdge W: 1.6797598256668308e-15
grad ChooseDest W: 4.488631248474121
grad AddEdge W: 1.3018488976450967e-14
grad ChooseDest W: 7.936119556427002
grad AddEdge W: 1.1020606763322352e-14
grad ChooseDest W: 5.592135906219482
grad AddEdge W: 2.1424631337807334e-17
grad ChooseDest W: 4.641581058502197
grad AddEdge W: 8.806712725677288e-16
grad ChooseDest W: 2.785918712615967
grad AddEdge W: 2.7556140715581153e-17
grad ChooseDest W: 4.480088710784912
grad AddEdge W: 9.989498283566862e-17
grad ChooseDest W: 4.099971294403076
grad AddEdge W: 1.2678831199821716e-16
grad ChooseDest W: 4.309988498687744
grad AddEdge W: 2.3002430379776706e-17
grad ChooseDest W: 4.623391628265381
grad AddEdge W: 9.700955689521517e-15
grad ChooseDest W: 1.932814598083496
grad AddEdge W: 1.080404754376374e-14
grad ChooseDest W: 3.89385724067688
grad AddEdge W: 1.1289968746263377e-15
grad ChooseDest W: 3.1678717136383057
grad AddEdge W: 5.349641719176447e-17
grad ChooseDest W: 6.768810749053955
grad AddEdge W: 5.0545940047404175e-17
grad ChooseDest W: 5.522029876708984
grad AddEdge W: 4.2709151514737985e-17
grad ChooseDest W: 7.284916400909424
grad AddEdge W: 1.6549722746742046e-14
grad ChooseDest W: 3.4020488262176514
grad AddEdge W: 2.0140268305098713e-13
grad ChooseDest W: 2.1790266036987305
grad AddEdge W: 1.5581058568179548e-17
grad ChooseDest W: 1.6566060781478882
grad AddEdge W: 2.434821617870904e-16
grad ChooseDest W: 4.5369133949279785
grad AddEdge W: 3.2907968613559574e-14
grad ChooseDest W: 3.336301803588867
grad AddEdge W: 1.1134328824485563e-16
grad ChooseDest W: 6.389236927032471
grad AddEdge W: 1.409306970168861e-14
grad ChooseDest W: 4.774961948394775
grad AddEdge W: 1.5434696568849925e-16
grad ChooseDest W: 4.812039375305176
grad AddEdge W: 3.5397894468033875e-13
grad ChooseDest W: 3.1553454399108887
grad AddEdge W: 3.0743484337068458e-15
grad ChooseDest W: 6.086413383483887
grad AddEdge W: 4.860563042547242e-15
grad ChooseDest W: 2.3557417392730713
grad AddEdge W: 2.810123454128012e-17
grad ChooseDest W: 3.889685869216919
grad AddEdge W: 2.890382830200342e-15
grad ChooseDest W: 4.345860004425049
grad AddEdge W: 1.2258452718566347e-16
grad ChooseDest W: 3.863255500793457
grad AddEdge W: 4.019189201822886e-17
grad ChooseDest W: 4.491020679473877
grad AddEdge W: 2.3555810080289064e-13
grad ChooseDest W: 4.104408264160156
=== Epoch 49: Train Loss: 4.4087, Train Log Prob: 0.0298 ===
Total mismatches: 59516
Predicted valid destination but wrong order: 6180
Epoch 49: Validation Loss: 3.0995, Validation Log Prob: 0.0596
Epoch 49: Edge Precision: 0.3617, Recall: 0.3512, F1: 0.3561, Jaccard: 0.2338
Epoch 49: TP: 2.4589835361488905, FP: 4.360629921259843, FN: 4.562491052254832
Epoch 49: Current Learning Rate: 6e-05
[Epoch 49] ‚è±Ô∏è Total: 3375.25s | Current time: 2025-07-16 10:01:22 | üèãÔ∏è Train: 2882.15s | ‚úÖ Val: 493.10s
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:3638: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
grad AddEdge W: 1.6788296776116271e-15
grad ChooseDest W: 9.66429615020752
grad AddEdge W: 6.289481197137292e-14
grad ChooseDest W: 2.405463457107544
grad AddEdge W: 2.550736488515879e-16
grad ChooseDest W: 4.37080192565918
grad AddEdge W: 2.522318202263252e-17
grad ChooseDest W: 2.4489502906799316
grad AddEdge W: 5.2883956122617957e-17
grad ChooseDest W: 2.91233491897583
grad AddEdge W: 1.046316823974543e-15
grad ChooseDest W: 5.070481777191162
grad AddEdge W: 4.972666264929572e-16
grad ChooseDest W: 6.347212314605713
grad AddEdge W: 1.8844226580636697e-13
grad ChooseDest W: 2.4052376747131348
grad AddEdge W: 1.913103871284058e-14
grad ChooseDest W: 5.158458232879639
grad AddEdge W: 1.1647037205714101e-17
grad ChooseDest W: 7.865207672119141
grad AddEdge W: 9.11356290455613e-14
grad ChooseDest W: 2.9139437675476074
grad AddEdge W: 1.8180192137021373e-15
grad ChooseDest W: 3.0509936809539795
grad AddEdge W: 4.0486453707806735e-14
grad ChooseDest W: 3.0726795196533203
grad AddEdge W: 1.077772580302191e-17
grad ChooseDest W: 6.484435558319092
grad AddEdge W: 7.849977100352735e-17
grad ChooseDest W: 3.624558448791504
grad AddEdge W: 8.307779879497963e-17
grad ChooseDest W: 3.991121530532837
grad AddEdge W: 8.976715583971367e-14
grad ChooseDest W: 2.5297048091888428
grad AddEdge W: 2.1004606558981892e-15
grad ChooseDest W: 2.5286900997161865
grad AddEdge W: 1.539251763679911e-17
grad ChooseDest W: 2.3603880405426025
grad AddEdge W: 3.3520511633143734e-17
grad ChooseDest W: 3.6381020545959473
grad AddEdge W: 2.8752404354371667e-17
grad ChooseDest W: 4.1479949951171875
grad AddEdge W: 5.947113613879009e-17
grad ChooseDest W: 5.520861625671387
grad AddEdge W: 2.23024791451594e-15
grad ChooseDest W: 4.241443157196045
grad AddEdge W: 9.613790864111807e-18
grad ChooseDest W: 6.5237040519714355
grad AddEdge W: 5.988381323767034e-17
grad ChooseDest W: 3.05311918258667
grad AddEdge W: 1.418373875534067e-16
grad ChooseDest W: 2.9807322025299072
grad AddEdge W: 1.298378264847017e-15
grad ChooseDest W: 2.824495553970337
grad AddEdge W: 1.4484615763754594e-14
grad ChooseDest W: 4.54393196105957
grad AddEdge W: 2.9727148561899336e-15
grad ChooseDest W: 3.8326120376586914
grad AddEdge W: 2.9506574697338314e-17
grad ChooseDest W: 4.856445789337158
grad AddEdge W: 3.710298398813122e-14
grad ChooseDest W: 3.564161777496338
grad AddEdge W: 2.7124851589697312e-15
grad ChooseDest W: 4.1529645919799805
grad AddEdge W: 1.6924211947530492e-16
grad ChooseDest W: 4.7347588539123535
grad AddEdge W: 2.8181885180399635e-15
grad ChooseDest W: 2.6396396160125732
grad AddEdge W: 1.339041987304091e-15
grad ChooseDest W: 5.8063859939575195
grad AddEdge W: 4.0103615303257203e-17
grad ChooseDest W: 4.7716193199157715
grad AddEdge W: 8.237316637983976e-15
grad ChooseDest W: 2.4885988235473633
grad AddEdge W: 1.0068859367963739e-14
grad ChooseDest W: 5.7921929359436035
grad AddEdge W: 7.92789883754421e-17
grad ChooseDest W: 5.167319297790527
grad AddEdge W: 3.3667249370994802e-15
grad ChooseDest W: 2.7708587646484375
grad AddEdge W: 4.2592909477617133e-17
grad ChooseDest W: 4.846224784851074
grad AddEdge W: 1.841809285461187e-17
grad ChooseDest W: 4.7645182609558105
grad AddEdge W: 4.3910704675760755e-15
grad ChooseDest W: 7.716763973236084
grad AddEdge W: 4.973106209210165e-18
grad ChooseDest W: 4.310669898986816
grad AddEdge W: 3.5009334165343227e-17
grad ChooseDest W: 6.7910027503967285
grad AddEdge W: 3.287126418779576e-17
grad ChooseDest W: 7.124581813812256
grad AddEdge W: 2.2279537257783016e-15
grad ChooseDest W: 4.256412029266357
grad AddEdge W: 3.5150312211501864e-17
grad ChooseDest W: 4.493893623352051
grad AddEdge W: 1.6203326690668489e-18
grad ChooseDest W: 3.6412107944488525
grad AddEdge W: 5.279859703910289e-16
grad ChooseDest W: 4.582214832305908
grad AddEdge W: 4.777220294493339e-16
grad ChooseDest W: 3.0867185592651367
grad AddEdge W: 1.2824777789047714e-17
grad ChooseDest W: 3.894099473953247
grad AddEdge W: 2.3630174437920748e-17
grad ChooseDest W: 3.560509443283081
grad AddEdge W: 3.657831958332747e-13
grad ChooseDest W: 3.1752917766571045
grad AddEdge W: 1.545646531559436e-17
grad ChooseDest W: 6.127679347991943
grad AddEdge W: 4.2139749365465145e-15
grad ChooseDest W: 3.3754560947418213
grad AddEdge W: 2.968377835741755e-14
grad ChooseDest W: 5.469884395599365
grad AddEdge W: 3.20319442696196e-15
grad ChooseDest W: 4.7063188552856445
grad AddEdge W: 3.654739220813755e-15
grad ChooseDest W: 4.144829750061035
grad AddEdge W: 2.2219711320718444e-15
grad ChooseDest W: 3.6156225204467773
grad AddEdge W: 1.8627444591412957e-15
grad ChooseDest W: 4.763479232788086
grad AddEdge W: 1.8224317524315198e-16
grad ChooseDest W: 4.6244893074035645
grad AddEdge W: 9.872953829214061e-17
grad ChooseDest W: 3.649031400680542
grad AddEdge W: 1.3119130043111934e-14
grad ChooseDest W: 3.7664144039154053
grad AddEdge W: 3.164248077040334e-17
grad ChooseDest W: 4.662500858306885
grad AddEdge W: 1.1601147706871497e-17
grad ChooseDest W: 6.6815266609191895
=== Epoch 50: Train Loss: 4.3759, Train Log Prob: 0.0306 ===
Total mismatches: 59096
Predicted valid destination but wrong order: 6155
Epoch 50: Validation Loss: 3.0480, Validation Log Prob: 0.0625
Epoch 50: Edge Precision: 0.3622, Recall: 0.3518, F1: 0.3566, Jaccard: 0.2346
Epoch 50: TP: 2.4641374373657836, FP: 4.35748031496063, FN: 4.557337151037938
Epoch 50: Current Learning Rate: 6e-05
üíæ Checkpoint saved: /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/checkpoint_epoch_50.pth
[Epoch 50] ‚è±Ô∏è Total: 3377.58s | Current time: 2025-07-16 10:57:40 | üèãÔ∏è Train: 2884.77s | ‚úÖ Val: 492.81s
Training finished at: 2025-07-16 10:57:40
Training time: 170682.54184770584
‚úÖ Model saved to: /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/model.pth
üìà Metrics saved to: /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_ASC
Device for model: cuda:2

Epoch-wise Validation Metrics:

Epoch 1:
  Validation Loss: 6.1943, Validation Log Prob: 0.0035
  Edge Precision: 0.3609, Recall: 0.3593, F1: 0.3600, Jaccard: 0.2374
  TP: 2.5152469577666428, FP: 4.476879026485325, FN: 4.506227630637079

Epoch 2:
  Validation Loss: 5.6439, Validation Log Prob: 0.0058
  Edge Precision: 0.3649, Recall: 0.3643, F1: 0.3646, Jaccard: 0.2405
  TP: 2.5496062992125985, FP: 4.46184681460272, FN: 4.471868289191124

Epoch 3:
  Validation Loss: 5.2895, Validation Log Prob: 0.0082
  Edge Precision: 0.3693, Recall: 0.3687, F1: 0.3689, Jaccard: 0.2447
  TP: 2.5802433786685754, FP: 4.429921259842519, FN: 4.441231209735147

Epoch 4:
  Validation Loss: 5.1955, Validation Log Prob: 0.0090
  Edge Precision: 0.3681, Recall: 0.3673, F1: 0.3677, Jaccard: 0.2435
  TP: 2.5710808876163207, FP: 4.435647816750179, FN: 4.4503937007874015

Epoch 5:
  Validation Loss: 5.1495, Validation Log Prob: 0.0095
  Edge Precision: 0.3707, Recall: 0.3698, F1: 0.3702, Jaccard: 0.2458
  TP: 2.587258410880458, FP: 4.414602720114531, FN: 4.434216177523264

Epoch 6:
  Validation Loss: 5.1526, Validation Log Prob: 0.0095
  Edge Precision: 0.3736, Recall: 0.3727, F1: 0.3731, Jaccard: 0.2479
  TP: 2.6084466714387973, FP: 4.394989262705798, FN: 4.413027916964925

Epoch 7:
  Validation Loss: 5.0240, Validation Log Prob: 0.0106
  Edge Precision: 0.3737, Recall: 0.3729, F1: 0.3733, Jaccard: 0.2481
  TP: 2.6097351467430205, FP: 4.3932712956335, FN: 4.411739441660702

Epoch 8:
  Validation Loss: 5.0795, Validation Log Prob: 0.0099
  Edge Precision: 0.3680, Recall: 0.3669, F1: 0.3674, Jaccard: 0.2433
  TP: 2.567644953471725, FP: 4.432211882605583, FN: 4.4538296349319975

Epoch 9:
  Validation Loss: 5.0957, Validation Log Prob: 0.0098
  Edge Precision: 0.3704, Recall: 0.3694, F1: 0.3699, Jaccard: 0.2453
  TP: 2.585110952040086, FP: 4.416893342877595, FN: 4.4363636363636365

Epoch 10:
  Validation Loss: 5.0410, Validation Log Prob: 0.0102
  Edge Precision: 0.3688, Recall: 0.3677, F1: 0.3682, Jaccard: 0.2437
  TP: 2.574373657838225, FP: 4.425769506084467, FN: 4.447100930565497

Epoch 11:
  Validation Loss: 4.9650, Validation Log Prob: 0.0109
  Edge Precision: 0.3719, Recall: 0.3705, F1: 0.3711, Jaccard: 0.2466
  TP: 2.591982820329277, FP: 4.401145311381532, FN: 4.4294917680744454

Epoch 12:
  Validation Loss: 4.9585, Validation Log Prob: 0.0111
  Edge Precision: 0.3727, Recall: 0.3716, F1: 0.3721, Jaccard: 0.2469
  TP: 2.6010021474588405, FP: 4.398568360773085, FN: 4.420472440944882

Epoch 13:
  Validation Loss: 4.9878, Validation Log Prob: 0.0108
  Edge Precision: 0.3706, Recall: 0.3695, F1: 0.3700, Jaccard: 0.2449
  TP: 2.5871152469577665, FP: 4.413027916964925, FN: 4.434359341445956

Epoch 14:
  Validation Loss: 4.9144, Validation Log Prob: 0.0115
  Edge Precision: 0.3705, Recall: 0.3692, F1: 0.3698, Jaccard: 0.2451
  TP: 2.5838224767358624, FP: 4.412168933428776, FN: 4.43765211166786

Epoch 15:
  Validation Loss: 4.7985, Validation Log Prob: 0.0126
  Edge Precision: 0.3686, Recall: 0.3671, F1: 0.3678, Jaccard: 0.2435
  TP: 2.5693629205440227, FP: 4.420329277022191, FN: 4.4521116678596995

Epoch 16:
  Validation Loss: 4.7987, Validation Log Prob: 0.0128
  Edge Precision: 0.3686, Recall: 0.3666, F1: 0.3675, Jaccard: 0.2433
  TP: 2.5647816750178953, FP: 4.417609162491052, FN: 4.456692913385827

Epoch 17:
  Validation Loss: 4.7274, Validation Log Prob: 0.0133
  Edge Precision: 0.3702, Recall: 0.3686, F1: 0.3693, Jaccard: 0.2445
  TP: 2.578954903364352, FP: 4.410737294201861, FN: 4.44251968503937

Epoch 18:
  Validation Loss: 4.6238, Validation Log Prob: 0.0146
  Edge Precision: 0.3683, Recall: 0.3659, F1: 0.3670, Jaccard: 0.2427
  TP: 2.5617752326413745, FP: 4.414030064423765, FN: 4.459699355762348

Epoch 19:
  Validation Loss: 4.5423, Validation Log Prob: 0.0157
  Edge Precision: 0.3716, Recall: 0.3696, F1: 0.3705, Jaccard: 0.2456
  TP: 2.5859699355762347, FP: 4.395991410164639, FN: 4.435504652827487

Epoch 20:
  Validation Loss: 4.4803, Validation Log Prob: 0.0167
  Edge Precision: 0.3696, Recall: 0.3666, F1: 0.3680, Jaccard: 0.2437
  TP: 2.565926986399427, FP: 4.397852541159628, FN: 4.455547602004295

Epoch 21:
  Validation Loss: 4.4635, Validation Log Prob: 0.0168
  Edge Precision: 0.3691, Recall: 0.3657, F1: 0.3673, Jaccard: 0.2428
  TP: 2.5589119541875447, FP: 4.397566213314245, FN: 4.4625626342161775

Epoch 22:
  Validation Loss: 4.3166, Validation Log Prob: 0.0193
  Edge Precision: 0.3670, Recall: 0.3632, F1: 0.3649, Jaccard: 0.2410
  TP: 2.540586972083035, FP: 4.407301360057265, FN: 4.480887616320687

Epoch 23:
  Validation Loss: 4.2509, Validation Log Prob: 0.0206
  Edge Precision: 0.3696, Recall: 0.3657, F1: 0.3675, Jaccard: 0.2433
  TP: 2.5597709377236937, FP: 4.38840372226199, FN: 4.461703650680029

Epoch 24:
  Validation Loss: 4.2046, Validation Log Prob: 0.0214
  Edge Precision: 0.3687, Recall: 0.3646, F1: 0.3665, Jaccard: 0.2421
  TP: 2.5507516105941304, FP: 4.389119541875448, FN: 4.470722977809592

Epoch 25:
  Validation Loss: 4.1119, Validation Log Prob: 0.0233
  Edge Precision: 0.3684, Recall: 0.3634, F1: 0.3657, Jaccard: 0.2417
  TP: 2.5427344309234075, FP: 4.38453829634932, FN: 4.478740157480315

Epoch 26:
  Validation Loss: 4.0786, Validation Log Prob: 0.0241
  Edge Precision: 0.3680, Recall: 0.3632, F1: 0.3654, Jaccard: 0.2413
  TP: 2.5418754473872585, FP: 4.386685755189692, FN: 4.479599141016464

Epoch 27:
  Validation Loss: 3.9967, Validation Log Prob: 0.0260
  Edge Precision: 0.3672, Recall: 0.3624, F1: 0.3646, Jaccard: 0.2414
  TP: 2.537580529706514, FP: 4.393414459556192, FN: 4.483894058697208

Epoch 28:
  Validation Loss: 3.9192, Validation Log Prob: 0.0278
  Edge Precision: 0.3639, Recall: 0.3591, F1: 0.3613, Jaccard: 0.2381
  TP: 2.513242662848962, FP: 4.413027916964925, FN: 4.50823192555476

Epoch 29:
  Validation Loss: 3.8846, Validation Log Prob: 0.0287
  Edge Precision: 0.3670, Recall: 0.3615, F1: 0.3640, Jaccard: 0.2408
  TP: 2.53042233357194, FP: 4.384251968503937, FN: 4.491052254831782

Epoch 30:
  Validation Loss: 3.7633, Validation Log Prob: 0.0322
  Edge Precision: 0.3616, Recall: 0.3552, F1: 0.3581, Jaccard: 0.2361
  TP: 2.4866141732283467, FP: 4.412884753042233, FN: 4.534860415175376

Epoch 31:
  Validation Loss: 3.7789, Validation Log Prob: 0.0322
  Edge Precision: 0.3643, Recall: 0.3578, F1: 0.3608, Jaccard: 0.2379
  TP: 2.5047959914101647, FP: 4.39226914817466, FN: 4.5166785969935574

Epoch 32:
  Validation Loss: 3.6537, Validation Log Prob: 0.0356
  Edge Precision: 0.3642, Recall: 0.3574, F1: 0.3605, Jaccard: 0.2378
  TP: 2.5020758768790263, FP: 4.3859699355762345, FN: 4.519398711524696

Epoch 33:
  Validation Loss: 3.6589, Validation Log Prob: 0.0359
  Edge Precision: 0.3642, Recall: 0.3572, F1: 0.3604, Jaccard: 0.2373
  TP: 2.5006442376521116, FP: 4.386828919112384, FN: 4.520830350751611

Epoch 34:
  Validation Loss: 3.6148, Validation Log Prob: 0.0371
  Edge Precision: 0.3644, Recall: 0.3576, F1: 0.3607, Jaccard: 0.2375
  TP: 2.5029348604151753, FP: 4.386256263421617, FN: 4.518539727988547

Epoch 35:
  Validation Loss: 3.6055, Validation Log Prob: 0.0375
  Edge Precision: 0.3647, Recall: 0.3576, F1: 0.3609, Jaccard: 0.2377
  TP: 2.5035075161059415, FP: 4.382104509663565, FN: 4.517967072297781

Epoch 36:
  Validation Loss: 3.5316, Validation Log Prob: 0.0403
  Edge Precision: 0.3661, Recall: 0.3587, F1: 0.3621, Jaccard: 0.2390
  TP: 2.5100930565497497, FP: 4.370937723693629, FN: 4.5113815318539725

Epoch 37:
  Validation Loss: 3.4858, Validation Log Prob: 0.0420
  Edge Precision: 0.3646, Recall: 0.3571, F1: 0.3605, Jaccard: 0.2378
  TP: 2.501073729420186, FP: 4.375089477451682, FN: 4.520400858983536

Epoch 38:
  Validation Loss: 3.4762, Validation Log Prob: 0.0424
  Edge Precision: 0.3636, Recall: 0.3561, F1: 0.3596, Jaccard: 0.2367
  TP: 2.494774516821761, FP: 4.378382247673586, FN: 4.526700071581962

Epoch 39:
  Validation Loss: 3.3785, Validation Log Prob: 0.0463
  Edge Precision: 0.3608, Recall: 0.3526, F1: 0.3564, Jaccard: 0.2342
  TP: 2.468861846814603, FP: 4.389119541875448, FN: 4.55261274158912

Epoch 40:
  Validation Loss: 3.3465, Validation Log Prob: 0.0481
  Edge Precision: 0.3606, Recall: 0.3523, F1: 0.3561, Jaccard: 0.2342
  TP: 2.466571224051539, FP: 4.394416607015033, FN: 4.5549033643521835

Epoch 41:
  Validation Loss: 3.3356, Validation Log Prob: 0.0481
  Edge Precision: 0.3620, Recall: 0.3535, F1: 0.3574, Jaccard: 0.2353
  TP: 2.4755905511811025, FP: 4.37967072297781, FN: 4.54588403722262

Epoch 42:
  Validation Loss: 3.2595, Validation Log Prob: 0.0516
  Edge Precision: 0.3601, Recall: 0.3508, F1: 0.3551, Jaccard: 0.2332
  TP: 2.4565497494631354, FP: 4.3823908375089475, FN: 4.564924838940587

Epoch 43:
  Validation Loss: 3.2957, Validation Log Prob: 0.0499
  Edge Precision: 0.3605, Recall: 0.3513, F1: 0.3555, Jaccard: 0.2337
  TP: 2.459699355762348, FP: 4.378525411596278, FN: 4.5617752326413745

Epoch 44:
  Validation Loss: 3.1995, Validation Log Prob: 0.0543
  Edge Precision: 0.3590, Recall: 0.3500, F1: 0.3542, Jaccard: 0.2328
  TP: 2.45025053686471, FP: 4.390694345025054, FN: 4.571224051539012

Epoch 45:
  Validation Loss: 3.1950, Validation Log Prob: 0.0550
  Edge Precision: 0.3587, Recall: 0.3489, F1: 0.3534, Jaccard: 0.2325
  TP: 2.443378668575519, FP: 4.385254115962778, FN: 4.578095919828203

Epoch 46:
  Validation Loss: 3.1683, Validation Log Prob: 0.0560
  Edge Precision: 0.3614, Recall: 0.3519, F1: 0.3563, Jaccard: 0.2343
  TP: 2.4631352899069436, FP: 4.37394416607015, FN: 4.5583392984967785

Epoch 47:
  Validation Loss: 3.1424, Validation Log Prob: 0.0574
  Edge Precision: 0.3615, Recall: 0.3521, F1: 0.3564, Jaccard: 0.2343
  TP: 2.4647100930565498, FP: 4.372226198997852, FN: 4.556764495347172

Epoch 48:
  Validation Loss: 3.1154, Validation Log Prob: 0.0590
  Edge Precision: 0.3597, Recall: 0.3500, F1: 0.3545, Jaccard: 0.2328
  TP: 2.449964209019327, FP: 4.383679312813171, FN: 4.571510379384395

Epoch 49:
  Validation Loss: 3.0995, Validation Log Prob: 0.0596
  Edge Precision: 0.3617, Recall: 0.3512, F1: 0.3561, Jaccard: 0.2338
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4434: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4449: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
  TP: 2.4589835361488905, FP: 4.360629921259843, FN: 4.562491052254832

Epoch 50:
  Validation Loss: 3.0480, Validation Log Prob: 0.0625
  Edge Precision: 0.3622, Recall: 0.3518, F1: 0.3566, Jaccard: 0.2346
  TP: 2.4641374373657836, FP: 4.35748031496063, FN: 4.557337151037938
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.RANDOM

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 84.17%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 15.83%
  ‚ùå False Discovery rate (FP/TP+FP): 12.83%
  üéØ Precision (TP/TP+FP): 87.17%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 20.30%
  ‚ö†Ô∏è Std. False Negative rate: 20.30%
  ‚ùå Std. False Discovery rate: 17.07%
  üéØ Std. Precision: 17.07%
üìâ  Average detailed edge-metrics
  F1: 0.86
  Jaccard: 0.79
  TP: 4.85
  FP: 0.65
  FN: 0.90

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 55.49%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 44.51%
  ‚ùå False Discovery rate (FP/TP+FP): 42.62%
  üéØ Precision (TP/TP+FP): 57.38%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 22.38%
  ‚ö†Ô∏è Std. False Negative rate: 22.38%
  ‚ùå Std. False Discovery rate: 22.37%
  üéØ Std. Precision: 22.37%
üìâ  Average detailed edge-metrics
  F1: 0.56
  Jaccard: 0.43
  TP: 3.38
  FP: 2.45
  FN: 2.66

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 43.18%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 56.82%
  ‚ùå False Discovery rate (FP/TP+FP): 55.36%
  üéØ Precision (TP/TP+FP): 44.64%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.72%
  ‚ö†Ô∏è Std. False Negative rate: 18.72%
  ‚ùå Std. False Discovery rate: 19.03%
  üéØ Std. Precision: 19.03%
üìâ  Average detailed edge-metrics
  F1: 0.44
  Jaccard: 0.30
  TP: 2.84
  FP: 3.47
  FN: 3.70

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 37.84%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 62.16%
  ‚ùå False Discovery rate (FP/TP+FP): 61.45%
  üéØ Precision (TP/TP+FP): 38.55%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.55%
  ‚ö†Ô∏è Std. False Negative rate: 18.55%
  ‚ùå Std. False Discovery rate: 18.74%
  üéØ Std. Precision: 18.74%
üìâ  Average detailed edge-metrics
  F1: 0.38
  Jaccard: 0.25
  TP: 2.66
  FP: 4.23
  FN: 4.36

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 31.98%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 68.02%
  ‚ùå False Discovery rate (FP/TP+FP): 67.65%
  üéØ Precision (TP/TP+FP): 32.35%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.11%
  ‚ö†Ô∏è Std. False Negative rate: 17.11%
  ‚ùå Std. False Discovery rate: 17.28%
  üéØ Std. Precision: 17.28%
üìâ  Average detailed edge-metrics
  F1: 0.32
  Jaccard: 0.20
  TP: 2.28
  FP: 4.75
  FN: 4.84

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 35.36%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 64.64%
  ‚ùå False Discovery rate (FP/TP+FP): 64.05%
  üéØ Precision (TP/TP+FP): 35.95%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.35%
  ‚ö†Ô∏è Std. False Negative rate: 18.35%
  ‚ùå Std. False Discovery rate: 18.64%
  üéØ Std. Precision: 18.64%
üìâ  Average detailed edge-metrics
  F1: 0.36
  Jaccard: 0.23
  TP: 2.48
  FP: 4.44
  FN: 4.55
[6, 7, 8, 9, 10, 999]
[0.8416666666666666, 0.5549419767907163, 0.4318350754936121, 0.37841362665924066, 0.3197509564404423, 0.3535586460783311]
[np.float64(0.1707093045696885), np.float64(0.223707437531439), np.float64(0.19031419132948296), np.float64(0.18740186626457297), np.float64(0.17275086098583323), np.float64(0.18644959220384028)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.FIXED

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 75.50%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 24.50%
  ‚ùå False Discovery rate (FP/TP+FP): 18.67%
  üéØ Precision (TP/TP+FP): 81.33%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 21.17%
  ‚ö†Ô∏è Std. False Negative rate: 21.17%
  ‚ùå Std. False Discovery rate: 18.29%
  üéØ Std. Precision: 18.29%
üìâ  Average detailed edge-metrics
  F1: 0.78
  Jaccard: 0.68
  TP: 4.35
  FP: 0.95
  FN: 1.40

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 60.13%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 39.87%
  ‚ùå False Discovery rate (FP/TP+FP): 37.82%
  üéØ Precision (TP/TP+FP): 62.18%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 21.63%
  ‚ö†Ô∏è Std. False Negative rate: 21.63%
  ‚ùå Std. False Discovery rate: 21.85%
  üéØ Std. Precision: 21.85%
üìâ  Average detailed edge-metrics
  F1: 0.61
  Jaccard: 0.48
  TP: 3.66
  FP: 2.19
  FN: 2.38

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 46.33%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 53.67%
  ‚ùå False Discovery rate (FP/TP+FP): 52.80%
  üéØ Precision (TP/TP+FP): 47.20%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.74%
  ‚ö†Ô∏è Std. False Negative rate: 18.74%
  ‚ùå Std. False Discovery rate: 18.93%
  üéØ Std. Precision: 18.93%
üìâ  Average detailed edge-metrics
  F1: 0.47
  Jaccard: 0.33
  TP: 3.04
  FP: 3.38
  FN: 3.50

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 40.07%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 59.93%
  ‚ùå False Discovery rate (FP/TP+FP): 59.71%
  üéØ Precision (TP/TP+FP): 40.29%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.43%
  ‚ö†Ô∏è Std. False Negative rate: 18.43%
  ‚ùå Std. False Discovery rate: 18.45%
  üéØ Std. Precision: 18.45%
üìâ  Average detailed edge-metrics
  F1: 0.40
  Jaccard: 0.27
  TP: 2.81
  FP: 4.16
  FN: 4.20

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 32.75%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 67.25%
  ‚ùå False Discovery rate (FP/TP+FP): 67.10%
  üéØ Precision (TP/TP+FP): 32.90%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.28%
  ‚ö†Ô∏è Std. False Negative rate: 17.28%
  ‚ùå Std. False Discovery rate: 17.34%
  üéØ Std. Precision: 17.34%
üìâ  Average detailed edge-metrics
  F1: 0.33
  Jaccard: 0.21
  TP: 2.33
  FP: 4.75
  FN: 4.78

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 36.83%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 63.17%
  ‚ùå False Discovery rate (FP/TP+FP): 62.91%
  üéØ Precision (TP/TP+FP): 37.09%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.76%
  ‚ö†Ô∏è Std. False Negative rate: 18.76%
  ‚ùå Std. False Discovery rate: 18.91%
  üéØ Std. Precision: 18.91%
üìâ  Average detailed edge-metrics
  F1: 0.37
  Jaccard: 0.24
  TP: 2.58
  FP: 4.40
  FN: 4.44
[6, 7, 8, 9, 10, 999]
[0.755, 0.6013205282112845, 0.4633333333333333, 0.400682261208577, 0.3275470224256068, 0.3682617513719876]
[np.float64(0.18292378497918502), np.float64(0.21848238557081745), np.float64(0.18931907188514907), np.float64(0.18452252494064414), np.float64(0.17338561538342925), np.float64(0.18909309800567858)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_ASC

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 76.83%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 23.17%
  ‚ùå False Discovery rate (FP/TP+FP): 16.83%
  üéØ Precision (TP/TP+FP): 83.17%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 19.68%
  ‚ö†Ô∏è Std. False Negative rate: 19.68%
  ‚ùå Std. False Discovery rate: 15.17%
  üéØ Std. Precision: 15.17%
üìâ  Average detailed edge-metrics
  F1: 0.80
  Jaccard: 0.70
  TP: 4.40
  FP: 0.85
  FN: 1.35

Face Count 7: 119 graphs evaluated/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4477: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4491: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))

üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 55.07%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 44.93%
  ‚ùå False Discovery rate (FP/TP+FP): 41.63%
  üéØ Precision (TP/TP+FP): 58.37%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 20.90%
  ‚ö†Ô∏è Std. False Negative rate: 20.90%
  ‚ùå Std. False Discovery rate: 21.17%
  üéØ Std. Precision: 21.17%
üìâ  Average detailed edge-metrics
  F1: 0.57
  Jaccard: 0.43
  TP: 3.35
  FP: 2.33
  FN: 2.69

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 44.11%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 55.89%
  ‚ùå False Discovery rate (FP/TP+FP): 53.44%
  üéØ Precision (TP/TP+FP): 46.56%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 19.50%
  ‚ö†Ô∏è Std. False Negative rate: 19.50%
  ‚ùå Std. False Discovery rate: 20.32%
  üéØ Std. Precision: 20.32%
üìâ  Average detailed edge-metrics
  F1: 0.45
  Jaccard: 0.31
  TP: 2.90
  FP: 3.29
  FN: 3.64

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 38.23%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 61.77%
  ‚ùå False Discovery rate (FP/TP+FP): 60.58%
  üéØ Precision (TP/TP+FP): 39.42%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.37%
  ‚ö†Ô∏è Std. False Negative rate: 18.37%
  ‚ùå Std. False Discovery rate: 18.72%
  üéØ Std. Precision: 18.72%
üìâ  Average detailed edge-metrics
  F1: 0.39
  Jaccard: 0.26
  TP: 2.69
  FP: 4.11
  FN: 4.33

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 31.39%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 68.61%
  ‚ùå False Discovery rate (FP/TP+FP): 67.93%
  üéØ Precision (TP/TP+FP): 32.07%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.38%
  ‚ö†Ô∏è Std. False Negative rate: 17.38%
  ‚ùå Std. False Discovery rate: 17.62%
  üéØ Std. Precision: 17.62%
üìâ  Average detailed edge-metrics
  F1: 0.32
  Jaccard: 0.20
  TP: 2.23
  FP: 4.71
  FN: 4.88

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 35.18%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 64.82%
  ‚ùå False Discovery rate (FP/TP+FP): 63.78%
  üéØ Precision (TP/TP+FP): 36.22%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.70%
  ‚ö†Ô∏è Std. False Negative rate: 18.70%
  ‚ùå Std. False Discovery rate: 19.17%
  üéØ Std. Precision: 19.17%
üìâ  Average detailed edge-metrics
  F1: 0.36
  Jaccard: 0.23
  TP: 2.46
  FP: 4.36
  FN: 4.56
[6, 7, 8, 9, 10, 999]
[0.7683333333333333, 0.5507402961184473, 0.44109175377468063, 0.3822890559732665, 0.3139369671919401, 0.35183590687527694]
[np.float64(0.15173990905493517), np.float64(0.21168661603637437), np.float64(0.20320288181225346), np.float64(0.18724309228461197), np.float64(0.1761816408879861), np.float64(0.19171117351035155)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_DESC

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 70.50%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 29.50%
  ‚ùå False Discovery rate (FP/TP+FP): 23.92%
  üéØ Precision (TP/TP+FP): 76.08%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.57%
  ‚ö†Ô∏è Std. False Negative rate: 18.57%
  ‚ùå Std. False Discovery rate: 16.48%
  üéØ Std. Precision: 16.48%
üìâ  Average detailed edge-metrics
  F1: 0.73
  Jaccard: 0.61
  TP: 4.05
  FP: 1.25
  FN: 1.70

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 59.90%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 40.10%
  ‚ùå False Discovery rate (FP/TP+FP): 38.81%
  üéØ Precision (TP/TP+FP): 61.19%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 24.24%
  ‚ö†Ô∏è Std. False Negative rate: 24.24%
  ‚ùå Std. False Discovery rate: 24.26%
  üéØ Std. Precision: 24.26%
üìâ  Average detailed edge-metrics
  F1: 0.60
  Jaccard: 0.48
  TP: 3.66
  FP: 2.26
  FN: 2.39

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 46.66%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 53.34%
  ‚ùå False Discovery rate (FP/TP+FP): 52.88%
  üéØ Precision (TP/TP+FP): 47.12%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 19.20%
  ‚ö†Ô∏è Std. False Negative rate: 19.20%
  ‚ùå Std. False Discovery rate: 19.44%
  üéØ Std. Precision: 19.44%
üìâ  Average detailed edge-metrics
  F1: 0.47
  Jaccard: 0.33
  TP: 3.05
  FP: 3.43
  FN: 3.48

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 40.54%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 59.46%
  ‚ùå False Discovery rate (FP/TP+FP): 59.33%
  üéØ Precision (TP/TP+FP): 40.67%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.07%
  ‚ö†Ô∏è Std. False Negative rate: 18.07%
  ‚ùå Std. False Discovery rate: 18.11%
  üéØ Std. Precision: 18.11%
üìâ  Average detailed edge-metrics
  F1: 0.41
  Jaccard: 0.27
  TP: 2.85
  FP: 4.14
  FN: 4.17

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 33.53%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 66.47%
  ‚ùå False Discovery rate (FP/TP+FP): 66.40%
  üéØ Precision (TP/TP+FP): 33.60%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.19%
  ‚ö†Ô∏è Std. False Negative rate: 17.19%
  ‚ùå Std. False Discovery rate: 17.21%
  üéØ Std. Precision: 17.21%
üìâ  Average detailed edge-metrics
  F1: 0.34
  Jaccard: 0.22
  TP: 2.39
  FP: 4.71
  FN: 4.73

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 37.43%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 62.57%
  ‚ùå False Discovery rate (FP/TP+FP): 62.41%
  üéØ Precision (TP/TP+FP): 37.59%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.57%
  ‚ö†Ô∏è Std. False Negative rate: 18.57%
  ‚ùå Std. False Discovery rate: 18.68%
  üéØ Std. Precision: 18.68%
üìâ  Average detailed edge-metrics
  F1: 0.38
  Jaccard: 0.25
  TP: 2.62
  FP: 4.38
  FN: 4.40
[6, 7, 8, 9, 10, 999]
[0.705, 0.5990396158463385, 0.46662020905923346, 0.405395433027012, 0.3353369376683765, 0.37432048266693935]
[np.float64(0.16476203378745294), np.float64(0.24263292928079438), np.float64(0.1943934273064095), np.float64(0.1811246260910224), np.float64(0.17209383147392682), np.float64(0.18680169746233197)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.NEIGH_MIN_REM

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 79.33%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 20.67%
  ‚ùå False Discovery rate (FP/TP+FP): 16.00%
  üéØ Precision (TP/TP+FP): 84.00%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 19.28%
  ‚ö†Ô∏è Std. False Negative rate: 19.28%
  ‚ùå Std. False Discovery rate: 16.07%
  üéØ Std. Precision: 16.07%
üìâ  Average detailed edge-metrics
  F1: 0.81
  Jaccard: 0.72
  TP: 4.55
  FP: 0.85
  FN: 1.20

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 57.88%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 42.12%
  ‚ùå False Discovery rate (FP/TP+FP): 39.11%
  üéØ Precision (TP/TP+FP): 60.89%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 22.07%
  ‚ö†Ô∏è Std. False Negative rate: 22.07%
  ‚ùå Std. False Discovery rate: 22.27%
  üéØ Std. Precision: 22.27%
üìâ  Average detailed edge-metrics
  F1: 0.59
  Jaccard: 0.46
  TP: 3.54
  FP: 2.19
  FN: 2.50

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 44.68%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 55.32%
  ‚ùå False Discovery rate (FP/TP+FP): 53.47%
  üéØ Precision (TP/TP+FP): 46.53%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.94%
  ‚ö†Ô∏è Std. False Negative rate: 18.94%
  ‚ùå Std. False Discovery rate: 19.89%
  üéØ Std. Precision: 19.89%/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4505: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4525: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5344: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5361: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5377: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5409: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5425: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5663: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))

üìâ  Average detailed edge-metrics
  F1: 0.46
  Jaccard: 0.32
  TP: 2.93
  FP: 3.35
  FN: 3.60

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 38.00%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 62.00%
  ‚ùå False Discovery rate (FP/TP+FP): 61.07%
  üéØ Precision (TP/TP+FP): 38.93%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.33%
  ‚ö†Ô∏è Std. False Negative rate: 18.33%
  ‚ùå Std. False Discovery rate: 18.61%
  üéØ Std. Precision: 18.61%
üìâ  Average detailed edge-metrics
  F1: 0.38
  Jaccard: 0.26
  TP: 2.67
  FP: 4.18
  FN: 4.35

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 31.23%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 68.77%
  ‚ùå False Discovery rate (FP/TP+FP): 68.16%
  üéØ Precision (TP/TP+FP): 31.84%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.36%
  ‚ö†Ô∏è Std. False Negative rate: 17.36%
  ‚ùå Std. False Discovery rate: 17.61%
  üéØ Std. Precision: 17.61%
üìâ  Average detailed edge-metrics
  F1: 0.32
  Jaccard: 0.20
  TP: 2.22
  FP: 4.74
  FN: 4.89

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 35.10%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 64.90%
  ‚ùå False Discovery rate (FP/TP+FP): 64.05%
  üéØ Precision (TP/TP+FP): 35.95%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.76%
  ‚ö†Ô∏è Std. False Negative rate: 18.76%
  ‚ùå Std. False Discovery rate: 19.18%
  üéØ Std. Precision: 19.18%
üìâ  Average detailed edge-metrics
  F1: 0.35
  Jaccard: 0.23
  TP: 2.46
  FP: 4.40
  FN: 4.56
[6, 7, 8, 9, 10, 999]
[0.7933333333333333, 0.57875150060024, 0.4468060394889663, 0.3799730808502738, 0.3122793421165935, 0.3509510174864505]
[np.float64(0.16067565673326706), np.float64(0.22265956142027374), np.float64(0.19888401572439765), np.float64(0.18614861058212157), np.float64(0.17613720526524823), np.float64(0.19183086283051176)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.NEIGH_MAX_REM

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 74.67%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 25.33%
  ‚ùå False Discovery rate (FP/TP+FP): 21.33%
  üéØ Precision (TP/TP+FP): 78.67%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 19.82%
  ‚ö†Ô∏è Std. False Negative rate: 19.82%
  ‚ùå Std. False Discovery rate: 18.17%
  üéØ Std. Precision: 18.17%
üìâ  Average detailed edge-metrics
  F1: 0.76
  Jaccard: 0.66
  TP: 4.30
  FP: 1.15
  FN: 1.45

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 57.69%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 42.31%
  ‚ùå False Discovery rate (FP/TP+FP): 41.05%
  üéØ Precision (TP/TP+FP): 58.95%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 24.09%
  ‚ö†Ô∏è Std. False Negative rate: 24.09%
  ‚ùå Std. False Discovery rate: 24.30%
  üéØ Std. Precision: 24.30%
üìâ  Average detailed edge-metrics
  F1: 0.58
  Jaccard: 0.46
  TP: 3.53
  FP: 2.39
  FN: 2.51

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 46.06%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 53.94%
  ‚ùå False Discovery rate (FP/TP+FP): 53.40%
  üéØ Precision (TP/TP+FP): 46.60%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 19.47%
  ‚ö†Ô∏è Std. False Negative rate: 19.47%
  ‚ùå Std. False Discovery rate: 19.68%
  üéØ Std. Precision: 19.68%
üìâ  Average detailed edge-metrics
  F1: 0.46
  Jaccard: 0.32
  TP: 3.02
  FP: 3.44
  FN: 3.52

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 39.59%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 60.41%
  ‚ùå False Discovery rate (FP/TP+FP): 60.23%
  üéØ Precision (TP/TP+FP): 39.77%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.83%
  ‚ö†Ô∏è Std. False Negative rate: 17.83%
  ‚ùå Std. False Discovery rate: 17.89%
  üéØ Std. Precision: 17.89%
üìâ  Average detailed edge-metrics
  F1: 0.40
  Jaccard: 0.26
  TP: 2.78
  FP: 4.20
  FN: 4.23

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 32.67%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 67.33%
  ‚ùå False Discovery rate (FP/TP+FP): 67.26%
  üéØ Precision (TP/TP+FP): 32.74%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 16.99%
  ‚ö†Ô∏è Std. False Negative rate: 16.99%
  ‚ùå Std. False Discovery rate: 17.04%
  üéØ Std. Precision: 17.04%
üìâ  Average detailed edge-metrics
  F1: 0.33
  Jaccard: 0.21
  TP: 2.33
  FP: 4.77
  FN: 4.79

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 36.54%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 63.46%
  ‚ùå False Discovery rate (FP/TP+FP): 63.28%
  üéØ Precision (TP/TP+FP): 36.72%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.41%
  ‚ö†Ô∏è Std. False Negative rate: 18.41%
  ‚ùå Std. False Discovery rate: 18.53%
  üéØ Std. Precision: 18.53%
üìâ  Average detailed edge-metrics
  F1: 0.37
  Jaccard: 0.24
  TP: 2.56
  FP: 4.43
  FN: 4.46
[6, 7, 8, 9, 10, 999]
[0.7466666666666667, 0.5769107643057223, 0.4606039488966318, 0.39592035644667223, 0.3267012953463483, 0.3654444898933088]
[np.float64(0.1817048889454179), np.float64(0.24303838683457996), np.float64(0.19684801512931333), np.float64(0.17886204623152122), np.float64(0.17036024791888843), np.float64(0.18532310818610873)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_ASC
Device for model: cuda:2
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.RANDOM
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/random
0
0
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.FIXED
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/fixed
0
0
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_ASC
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/deg_asc
0
0
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_DESC
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/deg_desc
0
0
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.NEIGH_MIN_REM
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/neigh_min_rem
56595
6074
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.NEIGH_MAX_REM
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_deg_asc__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/neigh_max_rem
56208
7016
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_ASC
Device for model: cuda:2
‚úÖ Code finished successfully at: 2025-07-16 14:01:52
