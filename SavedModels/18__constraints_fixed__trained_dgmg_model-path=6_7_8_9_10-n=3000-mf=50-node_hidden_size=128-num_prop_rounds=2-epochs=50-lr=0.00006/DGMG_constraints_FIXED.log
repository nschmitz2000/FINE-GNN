nohup: ignoring input
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:2859: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  metadata = torch.load(load_path_metadata)
/home/nschmitz/.pyenv/versions/3.12.9/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
‚úÖ Using device: cuda:4
/home/nschmitz/GNNs/kirigami-database/data/cleaned
Model without constraints:  False
üíø Folder that model data gets saved into:  18__constraints_fixed__
Metrics---
Amount unfoldings:  3000
Max files per dir:  50
Batch size:  1
Num prop rounds:  2
Learning rate:  6e-05
Num epochs:  50
Accum steps:  4
Training node ordering strategy:  NodeOrder.FIXED
Add edge is deterministic:  True
Add edge is deterministic threshold:  0.5
Calc PR-Curve:  False
---------------
6_7_8_9_10
Found existing dataset files; skipping save.
Loading dataset from disk‚Ä¶
6_7_8_9_10
Max amount of features per node in a graph:  128
Loaded 46571 graphs with actions!
Train size: 32599, Validation size: 6985, Test size: 6987
Graph(num_nodes=10, num_edges=18,
      ndata_schemes={'a': Scheme(shape=(256,), dtype=torch.float32), 'hv': Scheme(shape=(128,), dtype=torch.float32), 'deg_rem': Scheme(shape=(1,), dtype=torch.int16), 'deg_target': Scheme(shape=(1,), dtype=torch.int16)}
      edata_schemes={'he': Scheme(shape=(1,), dtype=torch.float32)})
[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 0. 1. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]]
--------
Graph(num_nodes=10, num_edges=32,
      ndata_schemes={'deg_target': Scheme(shape=(1,), dtype=torch.int16), 'hv': Scheme(shape=(128,), dtype=torch.float32)}
      edata_schemes={})
[[0. 1. 0. 1. 0. 0. 0. 1. 0. 1.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 1. 0. 0. 0. 1.]
 [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]
 [0. 0. 1. 0. 0. 1. 0. 1. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 1. 0. 1.]
 [1. 0. 0. 1. 0. 0. 0. 0. 1. 0.]]
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.FIXED
Device for model: cuda:4
Dir_name to save to:  6_7_8_9_10
Training started at: 2025-07-14 11:32:25
grad AddEdge W: 32.25539016723633
grad ChooseDest W: 4.270893096923828
grad AddEdge W: 1.0554090738296509
grad ChooseDest W: 5.305445194244385
grad AddEdge W: 0.6345314979553223
grad ChooseDest W: 1.4969512224197388
grad AddEdge W: 0.1341496706008911
grad ChooseDest W: 4.746758937835693
grad AddEdge W: 0.09086934477090836
grad ChooseDest W: 2.5035383701324463
grad AddEdge W: 0.05997334420681
grad ChooseDest W: 3.6113572120666504
grad AddEdge W: 0.10883645713329315
grad ChooseDest W: 4.183071613311768
grad AddEdge W: 0.023811139166355133
grad ChooseDest W: 3.706925630569458
grad AddEdge W: 0.0159003846347332
grad ChooseDest W: 3.064316511154175
grad AddEdge W: 0.03493771329522133
grad ChooseDest W: 4.551120281219482
grad AddEdge W: 0.04899954795837402
grad ChooseDest W: 3.2783238887786865
grad AddEdge W: 0.028298862278461456
grad ChooseDest W: 3.6604230403900146
grad AddEdge W: 0.008640346117317677
grad ChooseDest W: 4.3128342628479
grad AddEdge W: 0.022888358682394028
grad ChooseDest W: 2.3683066368103027
grad AddEdge W: 0.011757326312363148
grad ChooseDest W: 3.8496317863464355
grad AddEdge W: 0.0069183106534183025
grad ChooseDest W: 3.327502489089966
grad AddEdge W: 0.015319804660975933
grad ChooseDest W: 4.579501152038574
grad AddEdge W: 0.01245741918683052
grad ChooseDest W: 3.2739176750183105
grad AddEdge W: 0.006588221061974764
grad ChooseDest W: 3.15293550491333
grad AddEdge W: 0.009973268955945969
grad ChooseDest W: 3.8130524158477783
grad AddEdge W: 0.002657693112269044
grad ChooseDest W: 5.028003692626953
grad AddEdge W: 0.007402261719107628
grad ChooseDest W: 5.441175937652588
grad AddEdge W: 0.002156156348064542
grad ChooseDest W: 4.059884548187256
grad AddEdge W: 0.07406114041805267
grad ChooseDest W: 1.9363908767700195
grad AddEdge W: 0.0027752364985644817
grad ChooseDest W: 2.9300436973571777
grad AddEdge W: 0.004087989218533039
grad ChooseDest W: 7.109340667724609
grad AddEdge W: 0.0018229461275041103
grad ChooseDest W: 2.9968318939208984
grad AddEdge W: 0.0020547055173665285
grad ChooseDest W: 2.823662042617798
grad AddEdge W: 0.009717031382024288
grad ChooseDest W: 5.095152378082275
grad AddEdge W: 0.001390741323120892
grad ChooseDest W: 3.2866122722625732
grad AddEdge W: 0.002945710439234972
grad ChooseDest W: 3.755011796951294
grad AddEdge W: 0.010560260154306889
grad ChooseDest W: 3.646237850189209
grad AddEdge W: 0.002831796882674098
grad ChooseDest W: 3.7949562072753906
grad AddEdge W: 0.0031414879485964775
grad ChooseDest W: 2.433075428009033
grad AddEdge W: 0.001044158823788166
grad ChooseDest W: 2.622539758682251
grad AddEdge W: 0.0016858732560649514
grad ChooseDest W: 4.15020227432251
grad AddEdge W: 0.0010623395210132003
grad ChooseDest W: 3.2109222412109375
grad AddEdge W: 0.002432150999084115
grad ChooseDest W: 4.994176864624023
grad AddEdge W: 0.0008189902873709798
grad ChooseDest W: 4.867084503173828
grad AddEdge W: 0.0008418506477028131
grad ChooseDest W: 2.5117998123168945
grad AddEdge W: 0.0009895856492221355
grad ChooseDest W: 1.6505757570266724
grad AddEdge W: 0.0005602735909633338
grad ChooseDest W: 6.284114360809326
grad AddEdge W: 0.0005015216884203255
grad ChooseDest W: 4.796999931335449
grad AddEdge W: 0.009406687691807747
grad ChooseDest W: 2.263625144958496
grad AddEdge W: 0.000528982374817133
grad ChooseDest W: 1.2739124298095703
grad AddEdge W: 0.0003707243886310607
grad ChooseDest W: 3.1467971801757812
grad AddEdge W: 0.0013358277501538396
grad ChooseDest W: 4.978312015533447
grad AddEdge W: 0.00021161416952963918
grad ChooseDest W: 3.706773281097412
grad AddEdge W: 0.0029101266991347075
grad ChooseDest W: 1.9541178941726685
grad AddEdge W: 0.00020626561308745295
grad ChooseDest W: 2.168463706970215
grad AddEdge W: 0.0008909829193726182
grad ChooseDest W: 3.2959401607513428
grad AddEdge W: 9.33170085772872e-05
grad ChooseDest W: 4.553665637969971
grad AddEdge W: 0.00034207271528430283
grad ChooseDest W: 3.4840474128723145
grad AddEdge W: 0.0011908137239515781
grad ChooseDest W: 2.9446017742156982
grad AddEdge W: 0.00048529449850320816
grad ChooseDest W: 3.4534356594085693
grad AddEdge W: 0.00020317269081715494
grad ChooseDest W: 4.638100624084473
grad AddEdge W: 0.0008981740102171898
grad ChooseDest W: 4.190774440765381
grad AddEdge W: 0.0008840100490488112
grad ChooseDest W: 2.529676675796509
grad AddEdge W: 0.00013484332885127515
grad ChooseDest W: 2.8054444789886475
grad AddEdge W: 0.00011480075772851706
grad ChooseDest W: 3.8130695819854736
grad AddEdge W: 0.00047194011858664453
grad ChooseDest W: 5.21481990814209
grad AddEdge W: 0.000348704430507496
grad ChooseDest W: 4.407732963562012
grad AddEdge W: 0.0002487369056325406
grad ChooseDest W: 3.507422685623169
grad AddEdge W: 4.95672102260869e-05
grad ChooseDest W: 2.624523401260376
grad AddEdge W: 0.0004937360645271838
grad ChooseDest W: 3.7725775241851807
grad AddEdge W: 0.00010379192099208012
grad ChooseDest W: 5.4854865074157715
=== Epoch 1: Train Loss: 5.9743, Train Log Prob: 0.0080 ===
Total mismatches: 93183
Predicted valid destination but wrong order: 24141
Epoch 1: Validation Loss: 6.5919, Validation Log Prob: 0.0023
Epoch 1: Edge Precision: 0.3717, Recall: 0.3709, F1: 0.3712, Jaccard: 0.2461
Epoch 1: TP: 2.5954187544738727, FP: 4.41159627773801, FN: 4.4260558339298495
Epoch 1: warmup, skipping learning rate scheduler
Epoch 1: Current Learning Rate: 6e-05
[Epoch 1] ‚è±Ô∏è Total: 1945.79s | Current time: 2025-07-14 12:04:50 | üèãÔ∏è Train: 1705.36s | ‚úÖ Val: 240.43s
grad AddEdge W: 0.0009072846150957048
grad ChooseDest W: 5.285541534423828
grad AddEdge W: 0.0002822871319949627
grad ChooseDest W: 2.6070053577423096
grad AddEdge W: 9.919861622620374e-05
grad ChooseDest W: 3.1411213874816895
grad AddEdge W: 7.214674405986443e-05
grad ChooseDest W: 4.64331579208374
grad AddEdge W: 5.8401554269948974e-05
grad ChooseDest W: 4.858207702636719
grad AddEdge W: 4.4621952838497236e-05
grad ChooseDest W: 4.0748186111450195
grad AddEdge W: 8.969513146439567e-05
grad ChooseDest W: 2.248324394226074
grad AddEdge W: 4.679921403294429e-05
grad ChooseDest W: 5.93991756439209
grad AddEdge W: 9.925264748744667e-05
grad ChooseDest W: 2.8001766204833984
grad AddEdge W: 0.0003530973626766354
grad ChooseDest W: 4.198456287384033
grad AddEdge W: 0.0001695822284091264
grad ChooseDest W: 2.5467042922973633
grad AddEdge W: 0.00011951882333960384
grad ChooseDest W: 4.552649974822998
grad AddEdge W: 2.2326348698697984e-05
grad ChooseDest W: 4.381234169006348
grad AddEdge W: 3.740127067430876e-05
grad ChooseDest W: 4.597083568572998
grad AddEdge W: 0.00011785376409534365
grad ChooseDest W: 4.90733528137207
grad AddEdge W: 2.2780017388868146e-05
grad ChooseDest W: 3.0752580165863037
grad AddEdge W: 1.326810524915345e-05
grad ChooseDest W: 2.6635794639587402
grad AddEdge W: 5.303731086314656e-05
grad ChooseDest W: 4.838711261749268
grad AddEdge W: 2.3669361326028593e-05
grad ChooseDest W: 3.433466672897339
grad AddEdge W: 3.725542774191126e-05
grad ChooseDest W: 4.365933418273926
grad AddEdge W: 4.8607198550598696e-05
grad ChooseDest W: 3.364597797393799
grad AddEdge W: 1.2663008419622201e-05
grad ChooseDest W: 5.813122749328613
grad AddEdge W: 8.174665708793327e-05
grad ChooseDest W: 3.965787410736084
grad AddEdge W: 6.312541518127546e-05
grad ChooseDest W: 4.449702262878418
grad AddEdge W: 1.7921312974067405e-05
grad ChooseDest W: 4.303685665130615
grad AddEdge W: 1.2430845345079433e-05
grad ChooseDest W: 6.612270355224609
grad AddEdge W: 2.9670494768652134e-05
grad ChooseDest W: 4.068291187286377
grad AddEdge W: 5.9120443438587245e-06
grad ChooseDest W: 6.03316593170166
grad AddEdge W: 3.099033347098157e-05
grad ChooseDest W: 2.4506592750549316
grad AddEdge W: 1.0822427611856256e-05
grad ChooseDest W: 4.2089619636535645
grad AddEdge W: 2.6994282961823046e-05
grad ChooseDest W: 4.6241278648376465
grad AddEdge W: 6.769272658857517e-06
grad ChooseDest W: 4.981727123260498
grad AddEdge W: 3.778333484660834e-05
grad ChooseDest W: 3.6849474906921387
grad AddEdge W: 5.150314245838672e-05
grad ChooseDest W: 4.621917724609375
grad AddEdge W: 3.0080429496592842e-05
grad ChooseDest W: 3.3007285594940186
grad AddEdge W: 2.3022723325993866e-05
grad ChooseDest W: 2.174863338470459
grad AddEdge W: 4.217185050947592e-06
grad ChooseDest W: 4.104828834533691
grad AddEdge W: 2.3088030502549373e-05
grad ChooseDest W: 4.872224807739258
grad AddEdge W: 6.376887176884338e-05
grad ChooseDest W: 4.284668445587158
grad AddEdge W: 1.6364367183996364e-05
grad ChooseDest W: 3.5768167972564697
grad AddEdge W: 4.268592419975903e-06
grad ChooseDest W: 4.126267910003662
grad AddEdge W: 3.89054275728995e-06
grad ChooseDest W: 3.453301429748535
grad AddEdge W: 6.355770892696455e-05
grad ChooseDest W: 2.6035799980163574
grad AddEdge W: 1.458617475691426e-06
grad ChooseDest W: 5.477848529815674
grad AddEdge W: 1.2700258594122715e-05
grad ChooseDest W: 3.5531368255615234
grad AddEdge W: 2.5575488962203963e-06
grad ChooseDest W: 7.7528910636901855
grad AddEdge W: 2.7249570848653093e-06
grad ChooseDest W: 2.687746286392212
grad AddEdge W: 1.2063175063303788e-06
grad ChooseDest W: 5.50432825088501
grad AddEdge W: 1.4109781659499276e-05
grad ChooseDest W: 1.50547456741333
grad AddEdge W: 1.1590636859182268e-06
grad ChooseDest W: 3.8544538021087646
grad AddEdge W: 9.573590432410128e-06
grad ChooseDest W: 5.287919521331787
grad AddEdge W: 5.379531557991868e-06
grad ChooseDest W: 3.4416744709014893
grad AddEdge W: 1.6172305095096817e-06
grad ChooseDest W: 4.701046943664551
grad AddEdge W: 6.662785381195135e-06
grad ChooseDest W: 5.150599002838135
grad AddEdge W: 1.3511408724298235e-05
grad ChooseDest W: 4.0692138671875
grad AddEdge W: 2.5694509531604126e-05
grad ChooseDest W: 2.965472936630249
grad AddEdge W: 2.512891342121293e-06
grad ChooseDest W: 6.55656623840332
grad AddEdge W: 5.847526836078032e-07
grad ChooseDest W: 3.593517303466797
grad AddEdge W: 2.659911899627332e-07
grad ChooseDest W: 5.719132423400879
grad AddEdge W: 2.0878064788121264e-06
grad ChooseDest W: 3.8768229484558105
grad AddEdge W: 4.897114536106528e-07
grad ChooseDest W: 2.61069393157959
grad AddEdge W: 4.968621396983508e-06
grad ChooseDest W: 5.983094692230225
grad AddEdge W: 5.220494472268911e-07
grad ChooseDest W: 5.360944747924805
grad AddEdge W: 1.8565579296137003e-07
grad ChooseDest W: 3.6889374256134033
grad AddEdge W: 1.1298228628220386e-06
grad ChooseDest W: 4.321892738342285
grad AddEdge W: 3.4676901350394473e-07
grad ChooseDest W: 3.9113516807556152
=== Epoch 2: Train Loss: 5.8012, Train Log Prob: 0.0092 ===
Total mismatches: 89488
Predicted valid destination but wrong order: 24658
Epoch 2: Validation Loss: 6.4952, Validation Log Prob: 0.0026
Epoch 2: Edge Precision: 0.3865, Recall: 0.3861, F1: 0.3862, Jaccard: 0.2588
Epoch 2: TP: 2.7047959914101645, FP: 4.310665712240516, FN: 4.316678596993557
Epoch 2: warmup, skipping learning rate scheduler
Epoch 2: Current Learning Rate: 6e-05
[Epoch 2] ‚è±Ô∏è Total: 1960.52s | Current time: 2025-07-14 12:37:31 | üèãÔ∏è Train: 1718.08s | ‚úÖ Val: 242.43s
grad AddEdge W: 7.7237846198841e-06
grad ChooseDest W: 9.598997116088867
grad AddEdge W: 2.6962501920024806e-07
grad ChooseDest W: 4.068998336791992
grad AddEdge W: 3.2030454804043984e-06
grad ChooseDest W: 5.207004547119141
grad AddEdge W: 4.6536953846043616e-07
grad ChooseDest W: 2.968981981277466
grad AddEdge W: 2.238571852331006e-07
grad ChooseDest W: 4.306681156158447
grad AddEdge W: 3.020442704837478e-07
grad ChooseDest W: 3.7805073261260986
grad AddEdge W: 2.5491010546829784e-07
grad ChooseDest W: 4.067770481109619
grad AddEdge W: 1.5886747917193134e-07
grad ChooseDest W: 4.681489944458008
grad AddEdge W: 1.1356823961250484e-06
grad ChooseDest W: 4.437676429748535
grad AddEdge W: 9.088444130611606e-06
grad ChooseDest W: 3.566504955291748
grad AddEdge W: 1.295116703659005e-06
grad ChooseDest W: 3.5200037956237793
grad AddEdge W: 9.568517356228767e-08
grad ChooseDest W: 3.726222515106201
grad AddEdge W: 2.2638863583779312e-07
grad ChooseDest W: 4.000808238983154
grad AddEdge W: 9.407072809608508e-08
grad ChooseDest W: 2.1549696922302246
grad AddEdge W: 1.345280224995804e-07
grad ChooseDest W: 6.037960052490234
grad AddEdge W: 7.684041491984317e-08
grad ChooseDest W: 4.929455757141113
grad AddEdge W: 9.702678198664216e-07
grad ChooseDest W: 4.546238422393799
grad AddEdge W: 4.1190625665876723e-07
grad ChooseDest W: 3.278937339782715
grad AddEdge W: 3.168121622820763e-07
grad ChooseDest W: 3.3592824935913086
grad AddEdge W: 5.79316406401631e-07
grad ChooseDest W: 3.4112508296966553
grad AddEdge W: 3.550291083342927e-08
grad ChooseDest W: 2.4858341217041016
grad AddEdge W: 2.9892291308897256e-07
grad ChooseDest W: 3.3460371494293213
grad AddEdge W: 9.89501387493874e-08
grad ChooseDest W: 2.747020959854126
grad AddEdge W: 1.99153493696258e-08
grad ChooseDest W: 9.516351699829102
grad AddEdge W: 3.225454747735057e-08
grad ChooseDest W: 4.6269211769104
grad AddEdge W: 3.6137259940005606e-07
grad ChooseDest W: 2.4724624156951904
grad AddEdge W: 5.6213671939531196e-08
grad ChooseDest W: 10.57363224029541
grad AddEdge W: 3.0836996955940776e-08
grad ChooseDest W: 2.3187639713287354
grad AddEdge W: 2.1188421328588447e-07
grad ChooseDest W: 3.636709690093994
grad AddEdge W: 2.398488447852287e-07
grad ChooseDest W: 4.4770588874816895
grad AddEdge W: 1.3267592358090496e-08
grad ChooseDest W: 3.0701401233673096
grad AddEdge W: 3.9995757816768673e-08
grad ChooseDest W: 4.0181732177734375
grad AddEdge W: 1.7893535186885856e-07
grad ChooseDest W: 2.2534446716308594
grad AddEdge W: 1.4245679835767078e-07
grad ChooseDest W: 2.6733927726745605
grad AddEdge W: 4.275358023164699e-08
grad ChooseDest W: 3.807419538497925
grad AddEdge W: 2.3598502707500302e-08
grad ChooseDest W: 5.352114200592041
grad AddEdge W: 1.1124289933661657e-08
grad ChooseDest W: 4.408609390258789
grad AddEdge W: 6.334141744446242e-07
grad ChooseDest W: 2.7181642055511475
grad AddEdge W: 3.2364713575816495e-08
grad ChooseDest W: 3.4222350120544434
grad AddEdge W: 1.787840346878511e-06
grad ChooseDest W: 2.8833224773406982
grad AddEdge W: 8.673847418094738e-09
grad ChooseDest W: 3.958265781402588
grad AddEdge W: 2.219913319834177e-08
grad ChooseDest W: 3.906134605407715
grad AddEdge W: 1.268418969857521e-08
grad ChooseDest W: 3.1563162803649902
grad AddEdge W: 1.6568202809708055e-08
grad ChooseDest W: 3.4991729259490967
grad AddEdge W: 1.1539491140410973e-08
grad ChooseDest W: 3.9781980514526367
grad AddEdge W: 2.6267400698998244e-08
grad ChooseDest W: 4.713552951812744
grad AddEdge W: 9.646231546867057e-08
grad ChooseDest W: 2.985821008682251
grad AddEdge W: 3.974942899276357e-07
grad ChooseDest W: 1.9504855871200562
grad AddEdge W: 1.7288390719016888e-09
grad ChooseDest W: 3.940610408782959
grad AddEdge W: 3.0506008830144538e-09
grad ChooseDest W: 4.719128131866455
grad AddEdge W: 5.024210825155251e-09
grad ChooseDest W: 6.249795913696289
grad AddEdge W: 5.53934107472287e-08
grad ChooseDest W: 4.149186134338379
grad AddEdge W: 8.471149470778983e-08
grad ChooseDest W: 2.896268606185913
grad AddEdge W: 1.5044202550384966e-09
grad ChooseDest W: 7.156851768493652
grad AddEdge W: 4.3210789613112865e-08
grad ChooseDest W: 4.944715976715088
grad AddEdge W: 1.9549279528519037e-08
grad ChooseDest W: 4.91816520690918
grad AddEdge W: 8.235206294671116e-09
grad ChooseDest W: 2.461700439453125
grad AddEdge W: 1.702416341231583e-08
grad ChooseDest W: 3.521135091781616
grad AddEdge W: 8.681340979421748e-09
grad ChooseDest W: 2.6157166957855225
grad AddEdge W: 2.6083694137923885e-07
grad ChooseDest W: 3.1126503944396973
grad AddEdge W: 6.9732566387870065e-09
grad ChooseDest W: 3.208646059036255
grad AddEdge W: 3.0502811387833617e-09
grad ChooseDest W: 3.5074832439422607
grad AddEdge W: 1.6064960917105964e-08
grad ChooseDest W: 4.351429462432861
grad AddEdge W: 3.110725010913029e-09
grad ChooseDest W: 5.658099174499512
grad AddEdge W: 3.5502720763247453e-09
grad ChooseDest W: 8.32673168182373
grad AddEdge W: 1.4384906421582855e-07
grad ChooseDest W: 3.2626094818115234
=== Epoch 3: Train Loss: 5.7012, Train Log Prob: 0.0103 ===
Total mismatches: 86965
Predicted valid destination but wrong order: 24891
Epoch 3: Validation Loss: 6.1395, Validation Log Prob: 0.0036
Epoch 3: Edge Precision: 0.3885, Recall: 0.3880, F1: 0.3883, Jaccard: 0.2609
Epoch 3: TP: 2.7175375805297066, FP: 4.295919828203293, FN: 4.303937007874016
Epoch 3: warmup, skipping learning rate scheduler
Epoch 3: Current Learning Rate: 6e-05
[Epoch 3] ‚è±Ô∏è Total: 1969.12s | Current time: 2025-07-14 13:10:20 | üèãÔ∏è Train: 1724.19s | ‚úÖ Val: 244.92s
grad AddEdge W: 4.153555721586599e-08
grad ChooseDest W: 9.728360176086426
grad AddEdge W: 1.1870155525173232e-08
grad ChooseDest W: 3.6222198009490967
grad AddEdge W: 6.009412412133486e-10
grad ChooseDest W: 6.888528347015381
grad AddEdge W: 5.957092596986513e-09
grad ChooseDest W: 3.8665542602539062
grad AddEdge W: 7.19703352469736e-10
grad ChooseDest W: 3.628864288330078
grad AddEdge W: 6.337276259316127e-10
grad ChooseDest W: 4.787974834442139
grad AddEdge W: 6.414038744573247e-10
grad ChooseDest W: 5.5189104080200195
grad AddEdge W: 8.686824592984976e-09
grad ChooseDest W: 5.523718357086182
grad AddEdge W: 1.2442777919119408e-09
grad ChooseDest W: 4.390044689178467
grad AddEdge W: 1.162109555252755e-07
grad ChooseDest W: 3.3250997066497803
grad AddEdge W: 3.4408613736047755e-09
grad ChooseDest W: 3.3202927112579346
grad AddEdge W: 3.2624740686770792e-09
grad ChooseDest W: 3.752859592437744
grad AddEdge W: 9.232591224872522e-08
grad ChooseDest W: 3.7329912185668945
grad AddEdge W: 4.1997152422368345e-09
grad ChooseDest W: 3.849079132080078
grad AddEdge W: 5.721387252854981e-10
grad ChooseDest W: 3.3873517513275146
grad AddEdge W: 2.3761299594582397e-09
grad ChooseDest W: 2.984778642654419
grad AddEdge W: 1.4166871842302697e-10
grad ChooseDest W: 4.092528343200684
grad AddEdge W: 4.32063412825201e-10
grad ChooseDest W: 3.6124427318573
grad AddEdge W: 4.794926677931244e-09
grad ChooseDest W: 3.2093493938446045
grad AddEdge W: 1.549438771730749e-10
grad ChooseDest W: 5.377131938934326
grad AddEdge W: 1.069872412884365e-09
grad ChooseDest W: 2.9212231636047363
grad AddEdge W: 1.738005295237599e-09
grad ChooseDest W: 2.7729523181915283
grad AddEdge W: 1.6138356428996303e-08
grad ChooseDest W: 2.996786594390869
grad AddEdge W: 2.865123693851501e-10
grad ChooseDest W: 5.194371223449707
grad AddEdge W: 2.0388243870961276e-10
grad ChooseDest W: 3.967316150665283
grad AddEdge W: 3.520371216758633e-10
grad ChooseDest W: 3.110245943069458
grad AddEdge W: 1.3857094638414225e-10
grad ChooseDest W: 5.438425540924072
grad AddEdge W: 5.906942990296926e-11
grad ChooseDest W: 6.135936737060547
grad AddEdge W: 3.318710639632627e-09
grad ChooseDest W: 3.8264946937561035
grad AddEdge W: 1.2325416243186282e-09
grad ChooseDest W: 4.109245777130127
grad AddEdge W: 1.7317527967186663e-10
grad ChooseDest W: 5.458907127380371
grad AddEdge W: 6.070061675522709e-10
grad ChooseDest W: 4.262142658233643
grad AddEdge W: 5.190060048398948e-10
grad ChooseDest W: 4.075985908508301
grad AddEdge W: 3.1515201559528805e-10
grad ChooseDest W: 3.8495116233825684
grad AddEdge W: 5.714496098541133e-10
grad ChooseDest W: 3.467949628829956
grad AddEdge W: 4.139743409181662e-11
grad ChooseDest W: 4.0411834716796875
grad AddEdge W: 1.9164893672041217e-08
grad ChooseDest W: 2.0714125633239746
grad AddEdge W: 9.276242884936892e-09
grad ChooseDest W: 4.6994123458862305
grad AddEdge W: 1.1899136120874232e-09
grad ChooseDest W: 4.984166622161865
grad AddEdge W: 3.1907054776070254e-10
grad ChooseDest W: 3.6578619480133057
grad AddEdge W: 6.427819387866407e-10
grad ChooseDest W: 3.505615472793579
grad AddEdge W: 2.2093006590839792e-10
grad ChooseDest W: 5.754528045654297
grad AddEdge W: 3.486631816596031e-11
grad ChooseDest W: 3.4797794818878174
grad AddEdge W: 8.590825828491688e-10
grad ChooseDest W: 4.433653354644775
grad AddEdge W: 2.0032496494959418e-11
grad ChooseDest W: 4.234407424926758
grad AddEdge W: 1.4690976213316276e-10
grad ChooseDest W: 5.5921454429626465
grad AddEdge W: 2.686438745069797e-11
grad ChooseDest W: 2.7817418575286865
grad AddEdge W: 1.482333526758861e-11
grad ChooseDest W: 3.684849262237549
grad AddEdge W: 2.0143095524893795e-10
grad ChooseDest W: 3.67586088180542
grad AddEdge W: 1.5542794828959927e-10
grad ChooseDest W: 4.113709926605225
grad AddEdge W: 3.386028610274927e-11
grad ChooseDest W: 5.369385242462158
grad AddEdge W: 1.6627452886774918e-11
grad ChooseDest W: 5.92948055267334
grad AddEdge W: 6.864753032687076e-08
grad ChooseDest W: 2.38175368309021
grad AddEdge W: 4.825689847720582e-10
grad ChooseDest W: 3.5409257411956787
grad AddEdge W: 9.458610977786108e-12
grad ChooseDest W: 4.321621894836426
grad AddEdge W: 3.188829755806921e-10
grad ChooseDest W: 3.848661422729492
grad AddEdge W: 1.8165305414388766e-12
grad ChooseDest W: 4.378868579864502
grad AddEdge W: 5.828919291683832e-11
grad ChooseDest W: 3.2965612411499023
grad AddEdge W: 2.982100330561899e-11
grad ChooseDest W: 3.9561455249786377
grad AddEdge W: 1.9590915695255617e-11
grad ChooseDest W: 3.3915605545043945
grad AddEdge W: 3.461926967318618e-09
grad ChooseDest W: 2.8054845333099365
grad AddEdge W: 3.6479159970514985e-11
grad ChooseDest W: 2.0428056716918945
grad AddEdge W: 2.1160920238294523e-11
grad ChooseDest W: 4.0426836013793945
grad AddEdge W: 6.259784357531828e-12
grad ChooseDest W: 5.290638446807861
grad AddEdge W: 3.195091413665807e-11
grad ChooseDest W: 3.8929760456085205
grad AddEdge W: 2.6063047119800897e-12
grad ChooseDest W: 4.495265960693359
=== Epoch 4: Train Loss: 5.6373, Train Log Prob: 0.0112 ===
Total mismatches: 85469
Predicted valid destination but wrong order: 24833
Epoch 4: Validation Loss: 5.8290, Validation Log Prob: 0.0048
Epoch 4: Edge Precision: 0.3890, Recall: 0.3884, F1: 0.3887, Jaccard: 0.2610
Epoch 4: TP: 2.7211166785969936, FP: 4.290622763063708, FN: 4.300357909806729
Epoch 4: warmup, skipping learning rate scheduler
Epoch 4: Current Learning Rate: 6e-05
[Epoch 4] ‚è±Ô∏è Total: 1975.77s | Current time: 2025-07-14 13:43:16 | üèãÔ∏è Train: 1729.34s | ‚úÖ Val: 246.44s
grad AddEdge W: 1.1080879547265e-09
grad ChooseDest W: 8.078941345214844
grad AddEdge W: 9.206212875367825e-11
grad ChooseDest W: 3.2398526668548584
grad AddEdge W: 1.9330802583650275e-11
grad ChooseDest W: 6.949904918670654
grad AddEdge W: 2.1986065312090686e-12
grad ChooseDest W: 3.7068028450012207
grad AddEdge W: 4.933366215542634e-12
grad ChooseDest W: 5.8066205978393555
grad AddEdge W: 4.267604498953137e-12
grad ChooseDest W: 4.270539283752441
grad AddEdge W: 2.1021651086527982e-10
grad ChooseDest W: 5.2472991943359375
grad AddEdge W: 3.1770265671721143e-12
grad ChooseDest W: 4.300229549407959
grad AddEdge W: 4.936226982721337e-10
grad ChooseDest W: 2.3208281993865967
grad AddEdge W: 1.1387283477271026e-10
grad ChooseDest W: 2.8381729125976562
grad AddEdge W: 6.435221799883095e-11
grad ChooseDest W: 3.046734571456909
grad AddEdge W: 5.409014555701752e-11
grad ChooseDest W: 8.595274925231934
grad AddEdge W: 8.937182049105485e-13
grad ChooseDest W: 4.231658935546875
grad AddEdge W: 1.1199517008231297e-10
grad ChooseDest W: 2.8041844367980957
grad AddEdge W: 3.705747167459528e-11
grad ChooseDest W: 5.416131019592285
grad AddEdge W: 1.9615583463084008e-11
grad ChooseDest W: 3.8971903324127197
grad AddEdge W: 2.0264149733217884e-11
grad ChooseDest W: 2.5007617473602295
grad AddEdge W: 8.668277684184544e-13
grad ChooseDest W: 4.039376735687256
grad AddEdge W: 2.7178168569841343e-12
grad ChooseDest W: 2.8088555335998535
grad AddEdge W: 3.06372700646651e-12
grad ChooseDest W: 3.520409107208252
grad AddEdge W: 2.990364249624844e-12
grad ChooseDest W: 6.214251518249512
grad AddEdge W: 4.074602254992149e-13
grad ChooseDest W: 4.670524597167969
grad AddEdge W: 3.9646812308863355e-13
grad ChooseDest W: 4.663228511810303
grad AddEdge W: 3.932885701135591e-12
grad ChooseDest W: 3.3451907634735107
grad AddEdge W: 8.118080318218757e-13
grad ChooseDest W: 3.2641005516052246
grad AddEdge W: 1.0478056139753833e-12
grad ChooseDest W: 3.983938694000244
grad AddEdge W: 6.0360249784507936e-12
grad ChooseDest W: 4.858641147613525
grad AddEdge W: 7.817354619535366e-13
grad ChooseDest W: 3.782416343688965
grad AddEdge W: 3.536787290987775e-13
grad ChooseDest W: 3.2981793880462646
grad AddEdge W: 1.4156985479740758e-11
grad ChooseDest W: 2.1601479053497314
grad AddEdge W: 2.21929669086407e-10
grad ChooseDest W: 3.129671096801758
grad AddEdge W: 8.464721978906908e-13
grad ChooseDest W: 4.313131332397461
grad AddEdge W: 1.7536291863073927e-10
grad ChooseDest W: 3.285484790802002
grad AddEdge W: 1.420337778597e-13
grad ChooseDest W: 3.7456014156341553
grad AddEdge W: 1.487476634920437e-11
grad ChooseDest W: 3.266974925994873
grad AddEdge W: 1.565156749865071e-12
grad ChooseDest W: 2.960557222366333
grad AddEdge W: 1.1309285756141985e-12
grad ChooseDest W: 6.428213596343994
grad AddEdge W: 8.068412474596109e-13
grad ChooseDest W: 4.453372478485107
grad AddEdge W: 3.1994159925552434e-12
grad ChooseDest W: 3.515787124633789
grad AddEdge W: 1.8862376125004104e-13
grad ChooseDest W: 4.069236755371094
grad AddEdge W: 1.1372585544729835e-13
grad ChooseDest W: 4.675077438354492
grad AddEdge W: 1.4507001502850336e-11
grad ChooseDest W: 4.356869220733643
grad AddEdge W: 1.4419696448171593e-13
grad ChooseDest W: 4.863631248474121
grad AddEdge W: 2.0320233343196215e-11
grad ChooseDest W: 3.7571141719818115
grad AddEdge W: 1.9376747724246003e-14
grad ChooseDest W: 5.389371871948242
grad AddEdge W: 1.8489987319014745e-11
grad ChooseDest W: 3.4928908348083496
grad AddEdge W: 2.828063954893323e-12
grad ChooseDest W: 3.596583366394043
grad AddEdge W: 6.076611002575616e-12
grad ChooseDest W: 4.307976245880127
grad AddEdge W: 2.297851579152743e-13
grad ChooseDest W: 4.147112846374512
grad AddEdge W: 2.9778850826195358e-12
grad ChooseDest W: 3.021322250366211
grad AddEdge W: 1.1988515377907988e-13
grad ChooseDest W: 4.705536365509033
grad AddEdge W: 2.499685029279386e-13
grad ChooseDest W: 7.008719444274902
grad AddEdge W: 1.4361125136308495e-14
grad ChooseDest W: 4.3429999351501465
grad AddEdge W: 7.647408503978423e-14
grad ChooseDest W: 3.029832601547241
grad AddEdge W: 3.579996271218383e-13
grad ChooseDest W: 5.562283039093018
grad AddEdge W: 6.325299225368175e-12
grad ChooseDest W: 4.719985485076904
grad AddEdge W: 2.379434472263124e-14
grad ChooseDest W: 5.309743404388428
grad AddEdge W: 1.0498380458153975e-13
grad ChooseDest W: 5.139810085296631
grad AddEdge W: 5.186306570835464e-13
grad ChooseDest W: 3.8445920944213867
grad AddEdge W: 1.8255346236409342e-13
grad ChooseDest W: 3.9195258617401123
grad AddEdge W: 2.8510681229082513e-12
grad ChooseDest W: 2.006633758544922
grad AddEdge W: 3.776296495557746e-14
grad ChooseDest W: 5.256415843963623
grad AddEdge W: 8.997704382777971e-14
grad ChooseDest W: 5.879971027374268
grad AddEdge W: 5.318046784191788e-12
grad ChooseDest W: 3.001765489578247
grad AddEdge W: 7.345490860531656e-13
grad ChooseDest W: 6.174545764923096
grad AddEdge W: 5.439304402395963e-14
grad ChooseDest W: 4.594200134277344
=== Epoch 5: Train Loss: 5.5919, Train Log Prob: 0.0119 ===
Total mismatches: 84291
Predicted valid destination but wrong order: 24940
Epoch 5: Validation Loss: 5.7733, Validation Log Prob: 0.0051
Epoch 5: Edge Precision: 0.3937, Recall: 0.3932, F1: 0.3934, Jaccard: 0.2654
Epoch 5: TP: 2.755762347888332, FP: 4.258554044380816, FN: 4.26571224051539
Epoch 5: warmup, skipping learning rate scheduler
Epoch 5: Current Learning Rate: 6e-05
[Epoch 5] ‚è±Ô∏è Total: 1979.02s | Current time: 2025-07-14 14:16:15 | üèãÔ∏è Train: 1732.84s | ‚úÖ Val: 246.18s
grad AddEdge W: 6.545568340815544e-12
grad ChooseDest W: 11.466517448425293
grad AddEdge W: 8.028853867554989e-14
grad ChooseDest W: 7.228694915771484
grad AddEdge W: 3.115519994767446e-14
grad ChooseDest W: 3.3684628009796143
grad AddEdge W: 4.787701946050785e-14
grad ChooseDest W: 3.8081696033477783
grad AddEdge W: 8.437493054496564e-14
grad ChooseDest W: 3.0701260566711426
grad AddEdge W: 1.5792431246183444e-14
grad ChooseDest W: 4.324533462524414
grad AddEdge W: 2.241848633816046e-12
grad ChooseDest W: 4.735897064208984
grad AddEdge W: 2.2996588764116407e-14
grad ChooseDest W: 3.77762508392334
grad AddEdge W: 1.033198930599534e-14
grad ChooseDest W: 4.456574440002441
grad AddEdge W: 1.361744240589366e-13
grad ChooseDest W: 3.123319625854492
grad AddEdge W: 2.6671895215438918e-14
grad ChooseDest W: 4.112562656402588
grad AddEdge W: 1.8341539224919767e-12
grad ChooseDest W: 3.3924005031585693
grad AddEdge W: 8.844565162723084e-13
grad ChooseDest W: 5.237710952758789
grad AddEdge W: 1.0779785267547859e-12
grad ChooseDest W: 3.3618252277374268
grad AddEdge W: 3.3606201588903817e-14
grad ChooseDest W: 5.391411781311035
grad AddEdge W: 3.3849601588495024e-14
grad ChooseDest W: 5.74924898147583
grad AddEdge W: 6.773544263460538e-14
grad ChooseDest W: 4.293329238891602
grad AddEdge W: 4.5141008173186364e-14
grad ChooseDest W: 5.167651176452637
grad AddEdge W: 1.1338297651024981e-13
grad ChooseDest W: 7.9644455909729
grad AddEdge W: 1.485969686057867e-13
grad ChooseDest W: 6.10227108001709
grad AddEdge W: 1.2673483986704818e-14
grad ChooseDest W: 3.785003423690796
grad AddEdge W: 2.1963526917329057e-12
grad ChooseDest W: 3.6344709396362305
grad AddEdge W: 3.7848016387620476e-11
grad ChooseDest W: 6.502889633178711
grad AddEdge W: 2.7985622987839603e-14
grad ChooseDest W: 2.7727489471435547
grad AddEdge W: 8.688576659358904e-14
grad ChooseDest W: 4.146541595458984
grad AddEdge W: 1.6599534247152548e-12
grad ChooseDest W: 3.7794132232666016
grad AddEdge W: 2.046233394856732e-14
grad ChooseDest W: 4.220293045043945
grad AddEdge W: 6.678350635089952e-14
grad ChooseDest W: 4.102531909942627
grad AddEdge W: 7.899190190840955e-10
grad ChooseDest W: 1.2451186180114746
grad AddEdge W: 3.911587986024992e-14
grad ChooseDest W: 2.414799213409424
grad AddEdge W: 9.126688120530968e-13
grad ChooseDest W: 4.482168674468994
grad AddEdge W: 4.260609606007021e-15
grad ChooseDest W: 3.541794776916504
grad AddEdge W: 3.706100096950715e-13
grad ChooseDest W: 5.064136028289795
grad AddEdge W: 2.524157749136946e-12
grad ChooseDest W: 3.958606004714966
grad AddEdge W: 5.341604979516856e-13
grad ChooseDest W: 3.2549991607666016
grad AddEdge W: 3.2176657307559156e-14
grad ChooseDest W: 4.357822418212891
grad AddEdge W: 1.7200321028587595e-12
grad ChooseDest W: 5.52255392074585
grad AddEdge W: 8.017923246183851e-15
grad ChooseDest W: 5.630396842956543
grad AddEdge W: 1.1931801033315814e-12
grad ChooseDest W: 5.710383892059326
grad AddEdge W: 4.302144035982225e-13
grad ChooseDest W: 2.538783311843872
grad AddEdge W: 1.7772387294473502e-12
grad ChooseDest W: 4.647697448730469
grad AddEdge W: 5.957648924973663e-14
grad ChooseDest W: 6.290731430053711
grad AddEdge W: 3.2846766756175483e-13
grad ChooseDest W: 3.258519172668457
grad AddEdge W: 9.431978115204132e-11
grad ChooseDest W: 3.1811697483062744
grad AddEdge W: 5.906973993058048e-14
grad ChooseDest W: 3.931946039199829
grad AddEdge W: 2.8716165187923914e-13
grad ChooseDest W: 4.2620697021484375
grad AddEdge W: 2.3789896105592262e-14
grad ChooseDest W: 5.170675754547119
grad AddEdge W: 5.507908582350063e-13
grad ChooseDest W: 5.254781246185303
grad AddEdge W: 2.4061514499601477e-13
grad ChooseDest W: 6.5466694831848145
grad AddEdge W: 1.1074207956901505e-12
grad ChooseDest W: 1.8994202613830566
grad AddEdge W: 5.620378294712847e-13
grad ChooseDest W: 5.536259174346924
grad AddEdge W: 8.662181757469745e-13
grad ChooseDest W: 6.5536346435546875
grad AddEdge W: 1.7879962579416507e-14
grad ChooseDest W: 6.423641204833984
grad AddEdge W: 3.11619341442082e-11
grad ChooseDest W: 3.3220736980438232
grad AddEdge W: 8.996550385090632e-15
grad ChooseDest W: 3.6797494888305664
grad AddEdge W: 9.557934006971039e-14
grad ChooseDest W: 9.01363468170166
grad AddEdge W: 1.210328681760164e-14
grad ChooseDest W: 6.147517204284668
grad AddEdge W: 9.493401277225165e-15
grad ChooseDest W: 6.536083221435547
grad AddEdge W: 3.430715523407464e-15
grad ChooseDest W: 5.8473029136657715
grad AddEdge W: 3.9201541318645283e-13
grad ChooseDest W: 7.094928741455078
grad AddEdge W: 7.984508236871801e-13
grad ChooseDest W: 4.116602420806885
grad AddEdge W: 3.06078879147402e-14
grad ChooseDest W: 4.473631381988525
grad AddEdge W: 3.2972373610737e-14
grad ChooseDest W: 5.8167924880981445
grad AddEdge W: 1.2577508479161281e-12
grad ChooseDest W: 5.816706657409668
grad AddEdge W: 1.0013536224165454e-12
grad ChooseDest W: 5.8467278480529785
grad AddEdge W: 8.6420382975445e-15
grad ChooseDest W: 2.629653215408325
=== Epoch 6: Train Loss: 5.5577, Train Log Prob: 0.0126 ===
Total mismatches: 83417
Predicted valid destination but wrong order: 24927
Epoch 6: Validation Loss: 5.6883, Validation Log Prob: 0.0056
Epoch 6: Edge Precision: 0.3972, Recall: 0.3967, F1: 0.3969, Jaccard: 0.2683
Epoch 6: TP: 2.7808160343593413, FP: 4.234073013600573, FN: 4.240658554044381
Epoch 6: Current Learning Rate: 6e-05
[Epoch 6] ‚è±Ô∏è Total: 1974.24s | Current time: 2025-07-14 14:49:09 | üèãÔ∏è Train: 1727.98s | ‚úÖ Val: 246.26s
grad AddEdge W: 1.8522442260526795e-11
grad ChooseDest W: 10.383450508117676
grad AddEdge W: 2.6219584703802805e-14
grad ChooseDest W: 3.1238672733306885
grad AddEdge W: 2.5335485594776656e-14
grad ChooseDest W: 4.160973072052002
grad AddEdge W: 3.5302893285548906e-14
grad ChooseDest W: 5.018664836883545
grad AddEdge W: 6.014256475651847e-14
grad ChooseDest W: 2.9829862117767334
grad AddEdge W: 1.1955124390450322e-12
grad ChooseDest W: 4.623043537139893
grad AddEdge W: 1.3453113406267092e-12
grad ChooseDest W: 3.464883327484131
grad AddEdge W: 8.509057174144186e-14
grad ChooseDest W: 4.896256923675537
grad AddEdge W: 9.157590830121461e-15
grad ChooseDest W: 5.44975471496582
grad AddEdge W: 1.2169255945819468e-13
grad ChooseDest W: 4.720359802246094
grad AddEdge W: 2.628826044110029e-14
grad ChooseDest W: 3.4980435371398926
grad AddEdge W: 1.476076544521844e-14
grad ChooseDest W: 5.010447025299072
grad AddEdge W: 5.529221862538101e-15
grad ChooseDest W: 7.9397478103637695
grad AddEdge W: 2.3405924212140626e-14
grad ChooseDest W: 4.061706066131592
grad AddEdge W: 6.504836816759174e-13
grad ChooseDest W: 3.977019786834717
grad AddEdge W: 1.0544264029618833e-12
grad ChooseDest W: 6.934308052062988
grad AddEdge W: 3.87161396014522e-15
grad ChooseDest W: 3.6939287185668945
grad AddEdge W: 3.8128023958569623e-13
grad ChooseDest W: 4.814708709716797
grad AddEdge W: 1.1487072144183985e-12
grad ChooseDest W: 4.729799270629883
grad AddEdge W: 4.787683379088581e-13
grad ChooseDest W: 6.610011100769043
grad AddEdge W: 2.080487746056875e-14
grad ChooseDest W: 4.962658405303955
grad AddEdge W: 8.370133945212292e-15
grad ChooseDest W: 7.263347625732422
grad AddEdge W: 3.482055545593263e-14
grad ChooseDest W: 4.454368591308594
grad AddEdge W: 8.293855917806611e-14
grad ChooseDest W: 5.521191596984863
grad AddEdge W: 1.143069522363668e-14
grad ChooseDest W: 3.3109207153320312
grad AddEdge W: 2.879788421616958e-13
grad ChooseDest W: 10.296382904052734
grad AddEdge W: 4.319369975623946e-15
grad ChooseDest W: 5.39285135269165
grad AddEdge W: 7.335659382994193e-15
grad ChooseDest W: 8.97423267364502
grad AddEdge W: 2.754837102793978e-13
grad ChooseDest W: 2.9532697200775146
grad AddEdge W: 3.8181531368660857e-14
grad ChooseDest W: 4.113445281982422
grad AddEdge W: 3.880840690039661e-15
grad ChooseDest W: 3.8319168090820312
grad AddEdge W: 1.8955343750789305e-13
grad ChooseDest W: 5.6114501953125
grad AddEdge W: 1.5093005648449467e-14
grad ChooseDest W: 4.999723434448242
grad AddEdge W: 2.31648128955729e-14
grad ChooseDest W: 6.334328651428223
grad AddEdge W: 1.5657366082919705e-13
grad ChooseDest W: 3.8306589126586914
grad AddEdge W: 2.694285173790315e-15
grad ChooseDest W: 3.5728261470794678
grad AddEdge W: 1.0942084268013037e-14
grad ChooseDest W: 8.546355247497559
grad AddEdge W: 2.380579660807812e-14
grad ChooseDest W: 5.848103046417236
grad AddEdge W: 2.325522011016514e-14
grad ChooseDest W: 7.521879196166992
grad AddEdge W: 1.5844156498953654e-13
grad ChooseDest W: 6.645980358123779
grad AddEdge W: 6.39234013486735e-14
grad ChooseDest W: 4.620599746704102
grad AddEdge W: 4.3175006755533096e-13
grad ChooseDest W: 5.012217998504639
grad AddEdge W: 2.5714536836668467e-12
grad ChooseDest W: 3.1330394744873047
grad AddEdge W: 1.1015236466016542e-11
grad ChooseDest W: 3.88318133354187
grad AddEdge W: 1.086256261263914e-13
grad ChooseDest W: 4.175151348114014
grad AddEdge W: 8.638640848393064e-15
grad ChooseDest W: 7.674437999725342
grad AddEdge W: 2.0854457687103332e-14
grad ChooseDest W: 4.768368721008301
grad AddEdge W: 3.0726847932358026e-13
grad ChooseDest W: 9.398833274841309
grad AddEdge W: 2.1237291168273859e-13
grad ChooseDest W: 3.7535693645477295
grad AddEdge W: 6.436098399023593e-13
grad ChooseDest W: 5.543287754058838
grad AddEdge W: 1.3687361248744534e-14
grad ChooseDest W: 2.406970739364624
grad AddEdge W: 3.1831652656626186e-13
grad ChooseDest W: 5.682638168334961
grad AddEdge W: 1.6890192044462238e-13
grad ChooseDest W: 7.75053071975708
grad AddEdge W: 3.723165083391799e-15
grad ChooseDest W: 5.397188186645508
grad AddEdge W: 1.691369890281444e-13
grad ChooseDest W: 6.129971027374268
grad AddEdge W: 6.342664447719611e-15
grad ChooseDest W: 5.931928634643555
grad AddEdge W: 1.2108525716380408e-14
grad ChooseDest W: 4.136620998382568
grad AddEdge W: 8.502557382120135e-14
grad ChooseDest W: 5.659159183502197
grad AddEdge W: 9.014252018435531e-14
grad ChooseDest W: 5.262323379516602
grad AddEdge W: 3.2609290396797604e-15
grad ChooseDest W: 3.3970091342926025
grad AddEdge W: 8.231200551885032e-14
grad ChooseDest W: 6.563736438751221
grad AddEdge W: 1.218261331658449e-13
grad ChooseDest W: 2.9708797931671143
grad AddEdge W: 1.1208445001463702e-15
grad ChooseDest W: 7.048764705657959
grad AddEdge W: 1.4155562098471137e-14
grad ChooseDest W: 4.511659622192383
grad AddEdge W: 7.192554013588526e-15
grad ChooseDest W: 3.616042137145996
grad AddEdge W: 1.8232446531273733e-13
grad ChooseDest W: 1.8704546689987183
=== Epoch 7: Train Loss: 5.5277, Train Log Prob: 0.0131 ===
Total mismatches: 82734
Predicted valid destination but wrong order: 24837
Epoch 7: Validation Loss: 5.6416, Validation Log Prob: 0.0059
Epoch 7: Edge Precision: 0.3957, Recall: 0.3952, F1: 0.3954, Jaccard: 0.2664
Epoch 7: TP: 2.7696492483894057, FP: 4.2446671438797425, FN: 4.2518253400143164
Epoch 7: Current Learning Rate: 6e-05
[Epoch 7] ‚è±Ô∏è Total: 1955.39s | Current time: 2025-07-14 15:21:44 | üèãÔ∏è Train: 1713.44s | ‚úÖ Val: 241.94s
grad AddEdge W: 8.5580316167011e-09
grad ChooseDest W: 5.343287944793701
grad AddEdge W: 1.8562893057535654e-14
grad ChooseDest W: 4.2967963218688965
grad AddEdge W: 1.3419128276018905e-13
grad ChooseDest W: 4.236490726470947
grad AddEdge W: 9.54050393238903e-15
grad ChooseDest W: 5.654794216156006
grad AddEdge W: 9.737301026255252e-15
grad ChooseDest W: 4.573598384857178
grad AddEdge W: 9.256763988684837e-15
grad ChooseDest W: 3.3074986934661865
grad AddEdge W: 6.475570947517273e-14
grad ChooseDest W: 2.5841174125671387
grad AddEdge W: 4.457656574592683e-15
grad ChooseDest W: 3.993473768234253
grad AddEdge W: 1.2358912890753516e-14
grad ChooseDest W: 4.9746880531311035
grad AddEdge W: 4.99869080589771e-13
grad ChooseDest W: 5.033842086791992
grad AddEdge W: 6.667770939468862e-15
grad ChooseDest W: 6.607146263122559
grad AddEdge W: 8.614630005437246e-15
grad ChooseDest W: 3.440823554992676
grad AddEdge W: 1.2801415607893371e-14
grad ChooseDest W: 4.542044639587402
grad AddEdge W: 6.666166659066762e-15
grad ChooseDest W: 5.82342529296875
grad AddEdge W: 1.773255745901234e-15
grad ChooseDest W: 3.2451388835906982
grad AddEdge W: 9.361488770591106e-14
grad ChooseDest W: 4.400127410888672
grad AddEdge W: 9.612113791815802e-15
grad ChooseDest W: 4.403897762298584
grad AddEdge W: 7.026212942252898e-16
grad ChooseDest W: 4.643685817718506
grad AddEdge W: 1.4381061619328506e-10
grad ChooseDest W: 1.8897671699523926
grad AddEdge W: 9.747994647807748e-14
grad ChooseDest W: 6.04243278503418
grad AddEdge W: 3.6995596473451964e-13
grad ChooseDest W: 2.204602003097534
grad AddEdge W: 5.709746182938147e-15
grad ChooseDest W: 4.498199462890625
grad AddEdge W: 3.1341063963774e-15
grad ChooseDest W: 6.774682521820068
grad AddEdge W: 3.5855595836159493e-13
grad ChooseDest W: 4.374943733215332
grad AddEdge W: 7.470036077878404e-15
grad ChooseDest W: 3.1607987880706787
grad AddEdge W: 1.9273157722543566e-11
grad ChooseDest W: 2.633014440536499
grad AddEdge W: 1.4653668928708212e-15
grad ChooseDest W: 4.66340446472168
grad AddEdge W: 1.909129253882362e-14
grad ChooseDest W: 4.025491237640381
grad AddEdge W: 1.9323764119329352e-14
grad ChooseDest W: 3.157433271408081
grad AddEdge W: 7.526241796126411e-15
grad ChooseDest W: 4.166049957275391
grad AddEdge W: 4.684191724687583e-15
grad ChooseDest W: 8.603626251220703
grad AddEdge W: 1.0940520645192405e-14
grad ChooseDest W: 7.073728561401367
grad AddEdge W: 1.4637237548322662e-14
grad ChooseDest W: 5.945903778076172
grad AddEdge W: 2.4000517285377443e-13
grad ChooseDest W: 2.609639883041382
grad AddEdge W: 7.995323560118159e-15
grad ChooseDest W: 4.645031452178955
grad AddEdge W: 5.4756312738114474e-14
grad ChooseDest W: 5.679396629333496
grad AddEdge W: 4.964707860994526e-15
grad ChooseDest W: 7.597987174987793
grad AddEdge W: 6.3948958873791e-15
grad ChooseDest W: 6.868700981140137
grad AddEdge W: 1.3063593480892258e-14
grad ChooseDest W: 6.450916290283203
grad AddEdge W: 3.485957833157527e-12
grad ChooseDest W: 2.4257609844207764
grad AddEdge W: 1.3545219802832843e-14
grad ChooseDest W: 5.996043682098389
grad AddEdge W: 4.30342881555662e-14
grad ChooseDest W: 5.882194995880127
grad AddEdge W: 9.06615362346536e-15
grad ChooseDest W: 3.5727901458740234
grad AddEdge W: 2.7576592471676396e-14
grad ChooseDest W: 4.301327705383301
grad AddEdge W: 2.0757919648038865e-14
grad ChooseDest W: 5.139936923980713
grad AddEdge W: 2.8492447692928056e-15
grad ChooseDest W: 4.400566577911377
grad AddEdge W: 3.260453642438114e-15
grad ChooseDest W: 6.102298736572266
grad AddEdge W: 2.6815419866153475e-15
grad ChooseDest W: 5.4697136878967285
grad AddEdge W: 2.251249249410163e-15
grad ChooseDest W: 5.122691631317139
grad AddEdge W: 2.0709672312550081e-13
grad ChooseDest W: 4.797582149505615
grad AddEdge W: 1.0478166016867751e-14
grad ChooseDest W: 6.390842437744141
grad AddEdge W: 2.658734235376492e-13
grad ChooseDest W: 4.646985054016113
grad AddEdge W: 8.244776118337266e-14
grad ChooseDest W: 5.248627662658691
grad AddEdge W: 9.550616658746298e-15
grad ChooseDest W: 6.660438537597656
grad AddEdge W: 2.0633415545671377e-15
grad ChooseDest W: 6.367423057556152
grad AddEdge W: 1.051103936555069e-14
grad ChooseDest W: 3.7237186431884766
grad AddEdge W: 2.893232799606321e-13
grad ChooseDest W: 6.313450813293457
grad AddEdge W: 1.0590135302165297e-14
grad ChooseDest W: 7.607761383056641
grad AddEdge W: 2.632340688740048e-13
grad ChooseDest W: 8.94674301147461
grad AddEdge W: 9.237217761526306e-12
grad ChooseDest W: 3.185680389404297
grad AddEdge W: 4.500066243712285e-15
grad ChooseDest W: 7.372112274169922
grad AddEdge W: 1.3485820770373688e-14
grad ChooseDest W: 5.004930019378662
grad AddEdge W: 1.9117525149200086e-15
grad ChooseDest W: 5.598556041717529
grad AddEdge W: 1.1409574457096894e-13
grad ChooseDest W: 4.19492769241333
grad AddEdge W: 4.9681993308031084e-15
grad ChooseDest W: 5.48910665512085
grad AddEdge W: 2.846784985613979e-15
grad ChooseDest W: 3.9410061836242676
=== Epoch 8: Train Loss: 5.5035, Train Log Prob: 0.0135 ===
Total mismatches: 82197
Predicted valid destination but wrong order: 24891
Epoch 8: Validation Loss: 5.5350, Validation Log Prob: 0.0065
Epoch 8: Edge Precision: 0.3954, Recall: 0.3947, F1: 0.3950, Jaccard: 0.2669
Epoch 8: TP: 2.7675017895490335, FP: 4.243664996420902, FN: 4.253972798854688
Epoch 8: Current Learning Rate: 6e-05
[Epoch 8] ‚è±Ô∏è Total: 1972.02s | Current time: 2025-07-14 15:54:36 | üèãÔ∏è Train: 1724.54s | ‚úÖ Val: 247.48s
grad AddEdge W: 1.1404601221731703e-11
grad ChooseDest W: 7.146924018859863
grad AddEdge W: 4.73814984101005e-15
grad ChooseDest W: 8.726858139038086
grad AddEdge W: 1.3566165064145957e-13
grad ChooseDest W: 5.232494831085205
grad AddEdge W: 7.223690097696647e-14
grad ChooseDest W: 5.1979475021362305
grad AddEdge W: 2.9413412216917553e-14
grad ChooseDest W: 3.6244146823883057
grad AddEdge W: 2.8839550783284554e-14
grad ChooseDest W: 4.247127056121826
grad AddEdge W: 2.7163488997586317e-15
grad ChooseDest W: 4.563118934631348
grad AddEdge W: 1.2278177606572793e-13
grad ChooseDest W: 4.50662088394165
grad AddEdge W: 8.172602134967621e-14
grad ChooseDest W: 4.645664691925049
grad AddEdge W: 2.3441732106469328e-15
grad ChooseDest W: 4.8399858474731445
grad AddEdge W: 3.704020868234431e-13
grad ChooseDest W: 3.195880174636841
grad AddEdge W: 6.346849108116402e-16
grad ChooseDest W: 5.399989604949951
grad AddEdge W: 2.0118406808246553e-15
grad ChooseDest W: 5.032731056213379
grad AddEdge W: 2.2182102888453764e-13
grad ChooseDest W: 2.920226812362671
grad AddEdge W: 2.1190987265179255e-14
grad ChooseDest W: 6.8685760498046875
grad AddEdge W: 3.666615080132052e-13
grad ChooseDest W: 6.792204856872559
grad AddEdge W: 1.7819870674006498e-14
grad ChooseDest W: 3.089775800704956
grad AddEdge W: 2.3770675233953167e-15
grad ChooseDest W: 4.464884281158447
grad AddEdge W: 3.976942083619818e-15
grad ChooseDest W: 3.7099125385284424
grad AddEdge W: 7.710075897767853e-15
grad ChooseDest W: 6.605318069458008
grad AddEdge W: 3.074078751968967e-12
grad ChooseDest W: 7.18565034866333
grad AddEdge W: 1.6278274301423368e-12
grad ChooseDest W: 6.05698299407959
grad AddEdge W: 3.780077650634289e-14
grad ChooseDest W: 7.181545734405518
grad AddEdge W: 4.180995827329781e-12
grad ChooseDest W: 4.8826494216918945
grad AddEdge W: 4.644876266924301e-15
grad ChooseDest W: 4.249394416809082
grad AddEdge W: 6.310148237265167e-11
grad ChooseDest W: 5.138731956481934
grad AddEdge W: 1.3317449920613456e-10
grad ChooseDest W: 2.640716314315796
grad AddEdge W: 3.1269542619290214e-15
grad ChooseDest W: 4.254119396209717
grad AddEdge W: 7.567109124128181e-16
grad ChooseDest W: 4.857558250427246
grad AddEdge W: 1.0933423356127361e-13
grad ChooseDest W: 4.797290802001953
grad AddEdge W: 3.870686459067976e-15
grad ChooseDest W: 4.228399276733398
grad AddEdge W: 9.048767594596607e-14
grad ChooseDest W: 4.824258327484131
grad AddEdge W: 1.0414812187577865e-15
grad ChooseDest W: 5.401333808898926
grad AddEdge W: 1.685753113164247e-14
grad ChooseDest W: 4.748664855957031
grad AddEdge W: 1.891633153082114e-15
grad ChooseDest W: 3.2568273544311523
grad AddEdge W: 1.459425299794176e-13
grad ChooseDest W: 3.0339913368225098
grad AddEdge W: 3.005451096327327e-11
grad ChooseDest W: 3.394690990447998
grad AddEdge W: 1.9928970007175497e-15
grad ChooseDest W: 4.352766036987305
grad AddEdge W: 4.466912516959409e-12
grad ChooseDest W: 4.987259387969971
grad AddEdge W: 4.0843052037501954e-15
grad ChooseDest W: 6.068437576293945
grad AddEdge W: 2.545015630531222e-12
grad ChooseDest W: 5.18279504776001
grad AddEdge W: 5.3250932309512056e-12
grad ChooseDest W: 5.396299839019775
grad AddEdge W: 8.741584362362905e-16
grad ChooseDest W: 8.52368450164795
grad AddEdge W: 1.6641171388342936e-15
grad ChooseDest W: 4.027037620544434
grad AddEdge W: 5.085018303240159e-14
grad ChooseDest W: 4.959242820739746
grad AddEdge W: 1.3601516365364442e-15
grad ChooseDest W: 3.8529295921325684
grad AddEdge W: 3.027115775926237e-13
grad ChooseDest W: 4.386374473571777
grad AddEdge W: 9.4703306408408e-15
grad ChooseDest W: 4.947139263153076
grad AddEdge W: 2.26754256342531e-15
grad ChooseDest W: 4.554772853851318
grad AddEdge W: 2.2196881665207573e-15
grad ChooseDest W: 2.7421958446502686
grad AddEdge W: 1.1485716620417835e-13
grad ChooseDest W: 5.590173721313477
grad AddEdge W: 1.0815704072370674e-13
grad ChooseDest W: 6.630739212036133
grad AddEdge W: 2.1505125458176622e-10
grad ChooseDest W: 3.433509111404419
grad AddEdge W: 6.836963314287361e-14
grad ChooseDest W: 5.818892002105713
grad AddEdge W: 3.6153708065506107e-13
grad ChooseDest W: 4.592230319976807
grad AddEdge W: 1.753145383788404e-15
grad ChooseDest W: 5.730576038360596
grad AddEdge W: 5.9422232759343e-12
grad ChooseDest W: 3.077761173248291
grad AddEdge W: 1.6192710150172984e-12
grad ChooseDest W: 1.6916204690933228
grad AddEdge W: 1.092494983367942e-10
grad ChooseDest W: 1.1974456310272217
grad AddEdge W: 7.618715554269517e-12
grad ChooseDest W: 4.915857791900635
grad AddEdge W: 1.8048527895744154e-13
grad ChooseDest W: 5.561753749847412
grad AddEdge W: 3.77542540687479e-14
grad ChooseDest W: 7.12629508972168
grad AddEdge W: 9.348174937319573e-15
grad ChooseDest W: 3.334547758102417
grad AddEdge W: 3.62508205623154e-15
grad ChooseDest W: 3.9314892292022705
grad AddEdge W: 1.540317759408591e-13
grad ChooseDest W: 4.978902816772461
grad AddEdge W: 5.213857520231695e-15
grad ChooseDest W: 6.585093975067139
=== Epoch 9: Train Loss: 5.4751, Train Log Prob: 0.0140 ===
Total mismatches: 81509
Predicted valid destination but wrong order: 24963
Epoch 9: Validation Loss: 5.4975, Validation Log Prob: 0.0067
Epoch 9: Edge Precision: 0.3956, Recall: 0.3948, F1: 0.3952, Jaccard: 0.2664
Epoch 9: TP: 2.767072297780959, FP: 4.241660701503221, FN: 4.254402290622763
Epoch 9: Current Learning Rate: 6e-05
[Epoch 9] ‚è±Ô∏è Total: 1952.80s | Current time: 2025-07-14 16:27:09 | üèãÔ∏è Train: 1709.87s | ‚úÖ Val: 242.93s
grad AddEdge W: 3.168871686321656e-13
grad ChooseDest W: 8.23663330078125
grad AddEdge W: 7.760850440758065e-15
grad ChooseDest W: 3.132746458053589
grad AddEdge W: 5.712762890779793e-15
grad ChooseDest W: 4.85127067565918
grad AddEdge W: 4.812939868696631e-13
grad ChooseDest W: 3.0844156742095947
grad AddEdge W: 1.0628649043244003e-14
grad ChooseDest W: 6.790689468383789
grad AddEdge W: 5.0423875585213235e-15
grad ChooseDest W: 5.113333702087402
grad AddEdge W: 6.04019565263956e-16
grad ChooseDest W: 7.767160415649414
grad AddEdge W: 2.9006799979818757e-15
grad ChooseDest W: 4.681890964508057
grad AddEdge W: 3.5049057840047526e-13
grad ChooseDest W: 3.210634469985962
grad AddEdge W: 1.1579631779609482e-15
grad ChooseDest W: 4.283492565155029
grad AddEdge W: 1.721541525735162e-15
grad ChooseDest W: 11.256058692932129
grad AddEdge W: 5.804844105394835e-11
grad ChooseDest W: 2.7295634746551514
grad AddEdge W: 4.7247089053625846e-12
grad ChooseDest W: 4.028993606567383
grad AddEdge W: 5.860587189154831e-12
grad ChooseDest W: 6.060261249542236
grad AddEdge W: 2.0121311561371868e-10
grad ChooseDest W: 0.8796902894973755
grad AddEdge W: 1.1058111476402641e-15
grad ChooseDest W: 1.9718623161315918
grad AddEdge W: 7.981267471874947e-16
grad ChooseDest W: 3.6871755123138428
grad AddEdge W: 1.0758848383390592e-15
grad ChooseDest W: 5.228518009185791
grad AddEdge W: 1.2801151757130301e-15
grad ChooseDest W: 6.568238735198975
grad AddEdge W: 3.201734989193841e-15
grad ChooseDest W: 6.689175605773926
grad AddEdge W: 5.789346951189317e-15
grad ChooseDest W: 6.256196975708008
grad AddEdge W: 5.336836116261179e-15
grad ChooseDest W: 5.708297252655029
grad AddEdge W: 5.988119325888537e-15
grad ChooseDest W: 2.392364263534546
grad AddEdge W: 3.909974811776946e-15
grad ChooseDest W: 6.700533390045166
grad AddEdge W: 7.089298897373214e-16
grad ChooseDest W: 4.8274946212768555
grad AddEdge W: 1.2141162742871064e-15
grad ChooseDest W: 4.289098262786865
grad AddEdge W: 3.5850261561470864e-13
grad ChooseDest W: 6.479687213897705
grad AddEdge W: 9.97604844327378e-14
grad ChooseDest W: 3.645050525665283
grad AddEdge W: 5.4164971932581935e-14
grad ChooseDest W: 3.5373871326446533
grad AddEdge W: 6.383324993803133e-15
grad ChooseDest W: 8.981593132019043
grad AddEdge W: 2.7167091005194516e-15
grad ChooseDest W: 4.600714206695557
grad AddEdge W: 3.265155310570086e-16
grad ChooseDest W: 3.958554744720459
grad AddEdge W: 2.329123764514829e-15
grad ChooseDest W: 2.7279677391052246
grad AddEdge W: 7.375252244047701e-15
grad ChooseDest W: 6.6143364906311035
grad AddEdge W: 9.765475671421535e-16
grad ChooseDest W: 5.811856746673584
grad AddEdge W: 1.2336558844242528e-14
grad ChooseDest W: 5.420020580291748
grad AddEdge W: 7.26774851644808e-15
grad ChooseDest W: 6.334117889404297
grad AddEdge W: 2.2521502891781342e-13
grad ChooseDest W: 5.091569423675537
grad AddEdge W: 2.1692100427104372e-13
grad ChooseDest W: 5.892611980438232
grad AddEdge W: 3.767616440727463e-14
grad ChooseDest W: 7.006714344024658
grad AddEdge W: 4.9628388827964096e-15
grad ChooseDest W: 3.437669038772583
grad AddEdge W: 1.5784792364251926e-13
grad ChooseDest W: 8.011106491088867
grad AddEdge W: 5.604727836353018e-13
grad ChooseDest W: 3.623194694519043
grad AddEdge W: 7.633439215436481e-16
grad ChooseDest W: 4.883875846862793
grad AddEdge W: 1.5459009940210766e-13
grad ChooseDest W: 9.742481231689453
grad AddEdge W: 2.9202706333837647e-13
grad ChooseDest W: 4.750753879547119
grad AddEdge W: 1.4441303708423447e-10
grad ChooseDest W: 2.624354362487793
grad AddEdge W: 2.575688787416746e-14
grad ChooseDest W: 3.905552625656128
grad AddEdge W: 1.6331729076887258e-15
grad ChooseDest W: 7.621865749359131
grad AddEdge W: 2.7835821399469418e-15
grad ChooseDest W: 5.101141929626465
grad AddEdge W: 1.2060687201343617e-15
grad ChooseDest W: 5.756861209869385
grad AddEdge W: 5.64360017052401e-12
grad ChooseDest W: 3.874105215072632
grad AddEdge W: 7.121764251461285e-14
grad ChooseDest W: 4.8080902099609375
grad AddEdge W: 1.6800377583526486e-15
grad ChooseDest W: 5.80747652053833
grad AddEdge W: 8.581033968243709e-14
grad ChooseDest W: 7.147388458251953
grad AddEdge W: 5.580356394530896e-15
grad ChooseDest W: 4.67210578918457
grad AddEdge W: 4.582485937611918e-15
grad ChooseDest W: 5.555398941040039
grad AddEdge W: 1.760350118982807e-14
grad ChooseDest W: 4.888965129852295
grad AddEdge W: 9.390883253315718e-13
grad ChooseDest W: 4.033565044403076
grad AddEdge W: 4.038943624809412e-15
grad ChooseDest W: 5.43536901473999
grad AddEdge W: 6.06274037050214e-13
grad ChooseDest W: 3.778144121170044
grad AddEdge W: 5.391329472703016e-14
grad ChooseDest W: 8.552116394042969
grad AddEdge W: 1.0544402129870553e-13
grad ChooseDest W: 4.206908226013184
grad AddEdge W: 5.96158322360707e-14
grad ChooseDest W: 5.542002201080322
grad AddEdge W: 2.743717579523075e-12
grad ChooseDest W: 3.136125326156616
grad AddEdge W: 2.2833693740447565e-15
grad ChooseDest W: 12.093805313110352
=== Epoch 10: Train Loss: 5.4522, Train Log Prob: 0.0143 ===
Total mismatches: 81065
Predicted valid destination but wrong order: 24992
Epoch 10: Validation Loss: 5.4824, Validation Log Prob: 0.0068
Epoch 10: Edge Precision: 0.3948, Recall: 0.3943, F1: 0.3945, Jaccard: 0.2660
Epoch 10: TP: 2.7627773801002147, FP: 4.250536864710093, FN: 4.2586972083035075
Epoch 10: Current Learning Rate: 6e-05
[Epoch 10] ‚è±Ô∏è Total: 1961.35s | Current time: 2025-07-14 16:59:51 | üèãÔ∏è Train: 1717.12s | ‚úÖ Val: 244.22s
grad AddEdge W: 6.366977691601994e-12
grad ChooseDest W: 7.800185203552246
grad AddEdge W: 2.4541715561553364e-16
grad ChooseDest W: 4.903164386749268
grad AddEdge W: 1.0714856329670577e-13
grad ChooseDest W: 4.66493558883667
grad AddEdge W: 4.459976280197858e-16
grad ChooseDest W: 5.388361930847168
grad AddEdge W: 2.008791150456303e-15
grad ChooseDest W: 4.552079200744629
grad AddEdge W: 3.3347231853192655e-15
grad ChooseDest W: 6.41553258895874
grad AddEdge W: 1.216522000323239e-13
grad ChooseDest W: 6.335509777069092
grad AddEdge W: 1.1217906359484533e-15
grad ChooseDest W: 4.7281293869018555
grad AddEdge W: 3.5014050686621445e-11
grad ChooseDest W: 4.77960205078125
grad AddEdge W: 4.720502200933341e-12
grad ChooseDest W: 2.4061291217803955
grad AddEdge W: 2.7788082622562165e-15
grad ChooseDest W: 3.9521431922912598
grad AddEdge W: 1.2915377326441096e-15
grad ChooseDest W: 5.272672653198242
grad AddEdge W: 3.3989486115118756e-15
grad ChooseDest W: 4.6759209632873535
grad AddEdge W: 1.6702275286366677e-15
grad ChooseDest W: 3.5844242572784424
grad AddEdge W: 1.4222065365665504e-12
grad ChooseDest W: 2.708859920501709
grad AddEdge W: 1.111199280918844e-13
grad ChooseDest W: 5.219287395477295
grad AddEdge W: 6.115634524504396e-16
grad ChooseDest W: 5.103328704833984
grad AddEdge W: 2.540890641064466e-14
grad ChooseDest W: 4.673328399658203
grad AddEdge W: 5.862630547719865e-15
grad ChooseDest W: 4.977306365966797
grad AddEdge W: 1.5559638428432466e-15
grad ChooseDest W: 5.06921911239624
grad AddEdge W: 9.473755406804786e-16
grad ChooseDest W: 4.794336318969727
grad AddEdge W: 6.698569480947502e-15
grad ChooseDest W: 8.333791732788086
grad AddEdge W: 4.370416585596816e-14
grad ChooseDest W: 5.122801780700684
grad AddEdge W: 4.178382032732353e-12
grad ChooseDest W: 2.7380237579345703
grad AddEdge W: 2.53352022622558e-15
grad ChooseDest W: 2.3046867847442627
grad AddEdge W: 5.526231836234293e-15
grad ChooseDest W: 4.591761589050293
grad AddEdge W: 9.575527897725047e-15
grad ChooseDest W: 5.232362270355225
grad AddEdge W: 6.155466354728148e-14
grad ChooseDest W: 5.250278472900391
grad AddEdge W: 4.642773592336037e-14
grad ChooseDest W: 6.636253356933594
grad AddEdge W: 5.358172929142074e-17
grad ChooseDest W: 4.7698588371276855
grad AddEdge W: 3.2856890832774245e-15
grad ChooseDest W: 4.940937519073486
grad AddEdge W: 3.2858207969007226e-15
grad ChooseDest W: 4.983799457550049
grad AddEdge W: 5.276527370416673e-15
grad ChooseDest W: 5.7361531257629395
grad AddEdge W: 2.393534055648177e-15
grad ChooseDest W: 4.097690582275391
grad AddEdge W: 4.242797773675684e-15
grad ChooseDest W: 6.211890697479248
grad AddEdge W: 3.977871278762956e-15
grad ChooseDest W: 4.941493034362793
grad AddEdge W: 1.3019134923776543e-13
grad ChooseDest W: 5.0500593185424805
grad AddEdge W: 1.1078902552308367e-11
grad ChooseDest W: 1.8078877925872803
grad AddEdge W: 2.6059277789304298e-15
grad ChooseDest W: 3.350896120071411
grad AddEdge W: 7.234437992885239e-16
grad ChooseDest W: 5.178488731384277
grad AddEdge W: 1.2377203211996757e-13
grad ChooseDest W: 3.9211480617523193
grad AddEdge W: 3.2666676031941136e-14
grad ChooseDest W: 5.558034896850586
grad AddEdge W: 9.170268372243016e-15
grad ChooseDest W: 7.768505096435547
grad AddEdge W: 8.73912487514561e-14
grad ChooseDest W: 4.8052659034729
grad AddEdge W: 4.380014824141923e-14
grad ChooseDest W: 3.2575197219848633
grad AddEdge W: 8.11417805860658e-16
grad ChooseDest W: 6.272403240203857
grad AddEdge W: 5.290290978183197e-14
grad ChooseDest W: 7.84477424621582
grad AddEdge W: 7.680140059345992e-15
grad ChooseDest W: 4.461734294891357
grad AddEdge W: 1.1205146866925331e-15
grad ChooseDest W: 7.080218315124512
grad AddEdge W: 9.681595396259304e-14
grad ChooseDest W: 4.637698650360107
grad AddEdge W: 1.2961881552827725e-15
grad ChooseDest W: 6.093823432922363
grad AddEdge W: 5.095011218481105e-12
grad ChooseDest W: 4.394659042358398
grad AddEdge W: 1.0898652314829393e-13
grad ChooseDest W: 7.518843650817871
grad AddEdge W: 7.849272210121942e-16
grad ChooseDest W: 4.556861400604248
grad AddEdge W: 2.8441055557040177e-16
grad ChooseDest W: 5.3040618896484375
grad AddEdge W: 6.722385929841925e-15
grad ChooseDest W: 4.274942398071289
grad AddEdge W: 7.21734666795466e-15
grad ChooseDest W: 7.929891109466553
grad AddEdge W: 8.847118187788744e-14
grad ChooseDest W: 2.8086445331573486
grad AddEdge W: 5.897674926549912e-14
grad ChooseDest W: 3.5792415142059326
grad AddEdge W: 1.167253007574795e-13
grad ChooseDest W: 5.646504878997803
grad AddEdge W: 4.273072781030285e-12
grad ChooseDest W: 3.2952780723571777
grad AddEdge W: 7.611999223354699e-16
grad ChooseDest W: 5.4004292488098145
grad AddEdge W: 1.2084486243710973e-13
grad ChooseDest W: 2.25620698928833
grad AddEdge W: 3.585418976146705e-14
grad ChooseDest W: 4.387149810791016
grad AddEdge W: 2.351187278724909e-14
grad ChooseDest W: 6.471944332122803
grad AddEdge W: 9.470657764965029e-14
grad ChooseDest W: 7.955147743225098
=== Epoch 11: Train Loss: 5.4216, Train Log Prob: 0.0148 ===
Total mismatches: 80671
Predicted valid destination but wrong order: 25044
Epoch 11: Validation Loss: 5.4076, Validation Log Prob: 0.0073
Epoch 11: Edge Precision: 0.3944, Recall: 0.3938, F1: 0.3941, Jaccard: 0.2660
Epoch 11: TP: 2.760200429491768, FP: 4.251109520400859, FN: 4.261274158911954
Epoch 11: Current Learning Rate: 6e-05
[Epoch 11] ‚è±Ô∏è Total: 1967.86s | Current time: 2025-07-14 17:32:38 | üèãÔ∏è Train: 1723.77s | ‚úÖ Val: 244.10s
grad AddEdge W: 1.4486656774344298e-13
grad ChooseDest W: 9.75160026550293
grad AddEdge W: 9.32138794387913e-16
grad ChooseDest W: 6.3031487464904785
grad AddEdge W: 3.674713528259432e-15
grad ChooseDest W: 5.586198329925537
grad AddEdge W: 1.3500311810035314e-15
grad ChooseDest W: 5.342378616333008
grad AddEdge W: 1.4881735726129984e-15
grad ChooseDest W: 4.710211753845215
grad AddEdge W: 1.5363075962692633e-15
grad ChooseDest W: 6.254237174987793
grad AddEdge W: 1.8854883525662577e-15
grad ChooseDest W: 6.372591495513916
grad AddEdge W: 2.543203506878591e-15
grad ChooseDest W: 5.176751136779785
grad AddEdge W: 3.1894832399469587e-16
grad ChooseDest W: 3.942511796951294
grad AddEdge W: 2.53705910446822e-13
grad ChooseDest W: 4.8383870124816895
grad AddEdge W: 2.2712295369084479e-13
grad ChooseDest W: 3.674560546875
grad AddEdge W: 7.881353582999198e-15
grad ChooseDest W: 4.4828619956970215
grad AddEdge W: 4.60792064295207e-16
grad ChooseDest W: 4.547411918640137
grad AddEdge W: 4.8867024792995095e-15
grad ChooseDest W: 5.513117790222168
grad AddEdge W: 1.365050379589089e-13
grad ChooseDest W: 4.519804000854492
grad AddEdge W: 3.1764957417884654e-12
grad ChooseDest W: 3.228585720062256
grad AddEdge W: 4.974900631965311e-15
grad ChooseDest W: 5.925411701202393
grad AddEdge W: 2.992259717931353e-15
grad ChooseDest W: 4.892937183380127
grad AddEdge W: 8.08267902088056e-16
grad ChooseDest W: 6.846164703369141
grad AddEdge W: 3.082636862853966e-15
grad ChooseDest W: 4.464890956878662
grad AddEdge W: 7.981634872415819e-16
grad ChooseDest W: 6.0876874923706055
grad AddEdge W: 3.6335371560516916e-13
grad ChooseDest W: 3.5473837852478027
grad AddEdge W: 4.7695317340794643e-14
grad ChooseDest W: 5.080160617828369
grad AddEdge W: 1.2637027476896756e-15
grad ChooseDest W: 2.8386669158935547
grad AddEdge W: 1.6788148291240618e-13
grad ChooseDest W: 6.511042594909668
grad AddEdge W: 6.963312804985386e-16
grad ChooseDest W: 5.043667316436768
grad AddEdge W: 2.677827144054179e-12
grad ChooseDest W: 6.00993013381958
grad AddEdge W: 1.658024854361167e-15
grad ChooseDest W: 6.224182605743408
grad AddEdge W: 8.190381695343668e-14
grad ChooseDest W: 4.035974502563477
grad AddEdge W: 3.79549280324137e-15
grad ChooseDest W: 4.391077518463135
grad AddEdge W: 2.4722985906221705e-15
grad ChooseDest W: 8.02370834350586
grad AddEdge W: 6.22784320248866e-15
grad ChooseDest W: 3.3538331985473633
grad AddEdge W: 4.97587228463493e-16
grad ChooseDest W: 7.757327556610107
grad AddEdge W: 1.0954650848818501e-14
grad ChooseDest W: 8.254250526428223
grad AddEdge W: 4.2610527736450243e-13
grad ChooseDest W: 4.840291976928711
grad AddEdge W: 4.0947381932648214e-14
grad ChooseDest W: 4.681774616241455
grad AddEdge W: 6.690548587156772e-14
grad ChooseDest W: 9.482053756713867
grad AddEdge W: 1.1431128396285906e-13
grad ChooseDest W: 7.902544975280762
grad AddEdge W: 9.446281647521038e-13
grad ChooseDest W: 3.8770744800567627
grad AddEdge W: 5.1458972716647566e-14
grad ChooseDest W: 8.324254035949707
grad AddEdge W: 1.5797790593047312e-13
grad ChooseDest W: 4.854798316955566
grad AddEdge W: 3.6755534461299297e-14
grad ChooseDest W: 5.403073310852051
grad AddEdge W: 7.407844166033915e-16
grad ChooseDest W: 4.44735050201416
grad AddEdge W: 1.9323498150983914e-15
grad ChooseDest W: 3.690185546875
grad AddEdge W: 7.056577544517495e-12
grad ChooseDest W: 3.1751811504364014
grad AddEdge W: 1.3663165922012804e-13
grad ChooseDest W: 5.279066562652588
grad AddEdge W: 2.909605607663568e-13
grad ChooseDest W: 4.519643306732178
grad AddEdge W: 1.0178357180527786e-13
grad ChooseDest W: 3.5829291343688965
grad AddEdge W: 2.2746254529302503e-15
grad ChooseDest W: 9.247532844543457
grad AddEdge W: 2.937859132773064e-16
grad ChooseDest W: 10.050315856933594
grad AddEdge W: 1.8161621024356117e-13
grad ChooseDest W: 4.37291955947876
grad AddEdge W: 1.0503692201766206e-14
grad ChooseDest W: 3.333545684814453
grad AddEdge W: 1.7018885216033008e-12
grad ChooseDest W: 4.0969977378845215
grad AddEdge W: 2.3132372380726008e-15
grad ChooseDest W: 8.379685401916504
grad AddEdge W: 1.9094265624468483e-15
grad ChooseDest W: 4.549753189086914
grad AddEdge W: 3.5775355028637554e-16
grad ChooseDest W: 5.868627548217773
grad AddEdge W: 1.4072170857781004e-14
grad ChooseDest W: 3.4046630859375
grad AddEdge W: 1.2820405239537865e-14
grad ChooseDest W: 8.150660514831543
grad AddEdge W: 1.5474573027122085e-15
grad ChooseDest W: 3.166839361190796
grad AddEdge W: 4.73027975296525e-13
grad ChooseDest W: 3.213261604309082
grad AddEdge W: 2.4047309841779317e-15
grad ChooseDest W: 5.5587263107299805
grad AddEdge W: 1.2908702495058495e-14
grad ChooseDest W: 5.818563938140869
grad AddEdge W: 1.553804827858496e-13
grad ChooseDest W: 4.3189849853515625
grad AddEdge W: 1.41954495575837e-13
grad ChooseDest W: 7.684887886047363
grad AddEdge W: 4.2955270145982744e-14
grad ChooseDest W: 5.936189651489258
grad AddEdge W: 1.7567403694934702e-12
grad ChooseDest W: 6.4255452156066895
=== Epoch 12: Train Loss: 5.3950, Train Log Prob: 0.0152 ===
Total mismatches: 80124
Predicted valid destination but wrong order: 25015
Epoch 12: Validation Loss: 5.4308, Validation Log Prob: 0.0072
Epoch 12: Edge Precision: 0.3973, Recall: 0.3965, F1: 0.3969, Jaccard: 0.2685
Epoch 12: TP: 2.7802433786685756, FP: 4.228203292770222, FN: 4.241231209735147
Epoch 12: Current Learning Rate: 6e-05
[Epoch 12] ‚è±Ô∏è Total: 1967.14s | Current time: 2025-07-14 18:05:26 | üèãÔ∏è Train: 1723.99s | ‚úÖ Val: 243.15s
grad AddEdge W: 1.3483759248034133e-11
grad ChooseDest W: 8.497393608093262
grad AddEdge W: 8.121251934833928e-12
grad ChooseDest W: 8.290904998779297
grad AddEdge W: 3.8314733334726344e-16
grad ChooseDest W: 7.153221130371094
grad AddEdge W: 6.807979202085035e-14
grad ChooseDest W: 4.5642242431640625
grad AddEdge W: 1.2804527606941583e-14
grad ChooseDest W: 4.75126838684082
grad AddEdge W: 2.7577105773642432e-15
grad ChooseDest W: 5.902068614959717
grad AddEdge W: 1.4753230240119666e-15
grad ChooseDest W: 3.87522029876709
grad AddEdge W: 3.337897653047338e-15
grad ChooseDest W: 3.606687068939209
grad AddEdge W: 2.5136849592381945e-14
grad ChooseDest W: 6.046935081481934
grad AddEdge W: 4.586706702788086e-16
grad ChooseDest W: 5.806096076965332
grad AddEdge W: 8.86249149696823e-14
grad ChooseDest W: 4.537387847900391
grad AddEdge W: 1.3066847993233846e-15
grad ChooseDest W: 6.593696117401123
grad AddEdge W: 5.0013229777219614e-14
grad ChooseDest W: 5.735309600830078
grad AddEdge W: 1.3575950259803182e-12
grad ChooseDest W: 2.284823179244995
grad AddEdge W: 7.528964837645244e-14
grad ChooseDest W: 4.952048301696777
grad AddEdge W: 5.662183588883924e-15
grad ChooseDest W: 9.126346588134766
grad AddEdge W: 7.302050809713037e-14
grad ChooseDest W: 5.376229763031006
grad AddEdge W: 5.642725548019598e-15
grad ChooseDest W: 2.3780107498168945
grad AddEdge W: 4.8637627942087897e-14
grad ChooseDest W: 2.7242581844329834
grad AddEdge W: 2.484245143310245e-15
grad ChooseDest W: 3.8925726413726807
grad AddEdge W: 3.047285731042071e-14
grad ChooseDest W: 4.724308967590332
grad AddEdge W: 3.782718699363828e-14
grad ChooseDest W: 5.259474754333496
grad AddEdge W: 1.3089388598751467e-15
grad ChooseDest W: 4.436061859130859
grad AddEdge W: 2.566536122083213e-13
grad ChooseDest W: 4.389394283294678
grad AddEdge W: 5.357925436702798e-16
grad ChooseDest W: 5.352992534637451
grad AddEdge W: 7.91323325615589e-16
grad ChooseDest W: 4.696217060089111
grad AddEdge W: 1.8695130994228048e-15
grad ChooseDest W: 7.819094181060791
grad AddEdge W: 3.447062297060044e-12
grad ChooseDest W: 2.566399097442627
grad AddEdge W: 1.1330888484428758e-13
grad ChooseDest W: 5.46343469619751
grad AddEdge W: 2.6837243670039482e-15
grad ChooseDest W: 6.080653667449951
grad AddEdge W: 3.345290980127447e-15
grad ChooseDest W: 3.939642906188965
grad AddEdge W: 6.8274493555205065e-15
grad ChooseDest W: 3.256319284439087
grad AddEdge W: 4.583809783934027e-17
grad ChooseDest W: 9.124713897705078
grad AddEdge W: 1.7706707072253323e-15
grad ChooseDest W: 5.346359729766846
grad AddEdge W: 2.9264890918847142e-15
grad ChooseDest W: 7.620194911956787
grad AddEdge W: 2.7096209170585908e-15
grad ChooseDest W: 6.078817367553711
grad AddEdge W: 3.160194428817681e-16
grad ChooseDest W: 5.794336318969727
grad AddEdge W: 4.722011322266014e-15
grad ChooseDest W: 3.9055237770080566
grad AddEdge W: 5.496391500777235e-16
grad ChooseDest W: 6.920386791229248
grad AddEdge W: 2.8578886346404173e-16
grad ChooseDest W: 7.1415581703186035
grad AddEdge W: 4.6041953073467506e-14
grad ChooseDest W: 7.581141471862793
grad AddEdge W: 4.2137046483330456e-14
grad ChooseDest W: 7.777013778686523
grad AddEdge W: 8.413157395581298e-16
grad ChooseDest W: 4.418281078338623
grad AddEdge W: 5.29207008618561e-14
grad ChooseDest W: 4.645458221435547
grad AddEdge W: 2.8758223338370406e-15
grad ChooseDest W: 11.040891647338867
grad AddEdge W: 4.356583995467067e-13
grad ChooseDest W: 3.7471275329589844
grad AddEdge W: 2.0300753265922733e-13
grad ChooseDest W: 5.73280143737793
grad AddEdge W: 5.615747125133075e-14
grad ChooseDest W: 5.422749042510986
grad AddEdge W: 2.6589068945724603e-14
grad ChooseDest W: 5.61300802230835
grad AddEdge W: 6.092119831097433e-16
grad ChooseDest W: 5.598438739776611
grad AddEdge W: 2.0051671994008143e-16
grad ChooseDest W: 3.5462048053741455
grad AddEdge W: 4.381352458572227e-14
grad ChooseDest W: 3.7159156799316406
grad AddEdge W: 5.456272844021719e-16
grad ChooseDest W: 7.0839080810546875
grad AddEdge W: 4.445609394390475e-14
grad ChooseDest W: 6.028528213500977
grad AddEdge W: 1.2971392674034207e-15
grad ChooseDest W: 4.048953533172607
grad AddEdge W: 1.769175799952547e-15
grad ChooseDest W: 3.954634189605713
grad AddEdge W: 6.8344134486545945e-16
grad ChooseDest W: 6.873020172119141
grad AddEdge W: 4.161289698985534e-16
grad ChooseDest W: 5.924337387084961
grad AddEdge W: 5.146351958950843e-16
grad ChooseDest W: 4.871798038482666
grad AddEdge W: 1.3454346508361375e-15
grad ChooseDest W: 6.396539688110352
grad AddEdge W: 3.82632257905994e-16
grad ChooseDest W: 7.778259754180908
grad AddEdge W: 5.121623890846938e-16
grad ChooseDest W: 5.514512062072754
grad AddEdge W: 9.067938321885224e-14
grad ChooseDest W: 4.165159702301025
grad AddEdge W: 3.5357404090869456e-15
grad ChooseDest W: 5.011964797973633
grad AddEdge W: 5.4804507286509985e-12
grad ChooseDest W: 3.475196123123169
grad AddEdge W: 1.603988916886671e-15
grad ChooseDest W: 5.559376239776611
=== Epoch 13: Train Loss: 5.3676, Train Log Prob: 0.0154 ===
Total mismatches: 79560
Predicted valid destination but wrong order: 25060
Epoch 13: Validation Loss: 5.3034, Validation Log Prob: 0.0082
Epoch 13: Edge Precision: 0.3946, Recall: 0.3940, F1: 0.3943, Jaccard: 0.2664
Epoch 13: TP: 2.7614889047959914, FP: 4.24924838940587, FN: 4.259985683607731
Epoch 13: Current Learning Rate: 6e-05
[Epoch 13] ‚è±Ô∏è Total: 1964.81s | Current time: 2025-07-14 18:38:10 | üèãÔ∏è Train: 1720.97s | ‚úÖ Val: 243.84s
grad AddEdge W: 1.1052739127583033e-13
grad ChooseDest W: 8.942671775817871
grad AddEdge W: 7.902102184437784e-16
grad ChooseDest W: 5.0864787101745605
grad AddEdge W: 6.338323149755049e-14
grad ChooseDest W: 5.247263431549072
grad AddEdge W: 6.192527116664957e-16
grad ChooseDest W: 4.410481929779053
grad AddEdge W: 4.4750095691764927e-14
grad ChooseDest W: 7.245316505432129
grad AddEdge W: 2.684295182507103e-14
grad ChooseDest W: 3.6662001609802246
grad AddEdge W: 1.2743581045287795e-14
grad ChooseDest W: 6.196742534637451
grad AddEdge W: 2.3059589719480467e-13
grad ChooseDest W: 6.470407009124756
grad AddEdge W: 2.392823161834201e-10
grad ChooseDest W: 4.709468841552734
grad AddEdge W: 2.6951942519009555e-16
grad ChooseDest W: 9.431489944458008
grad AddEdge W: 7.38261312976593e-14
grad ChooseDest W: 3.098392963409424
grad AddEdge W: 3.140631673505251e-16
grad ChooseDest W: 6.987302303314209
grad AddEdge W: 8.691950878631763e-16
grad ChooseDest W: 6.215890884399414
grad AddEdge W: 5.064051527290184e-14
grad ChooseDest W: 6.594611167907715
grad AddEdge W: 3.567266551867277e-15
grad ChooseDest W: 4.404417037963867
grad AddEdge W: 4.505358488626071e-13
grad ChooseDest W: 5.243921756744385
grad AddEdge W: 8.884390940896427e-16
grad ChooseDest W: 5.385702133178711
grad AddEdge W: 1.6101570489250594e-13
grad ChooseDest W: 4.274509906768799
grad AddEdge W: 3.579028027856377e-15
grad ChooseDest W: 7.580665588378906
grad AddEdge W: 1.7045364922860847e-15
grad ChooseDest W: 4.373147010803223
grad AddEdge W: 9.947071107335032e-14
grad ChooseDest W: 3.6882784366607666
grad AddEdge W: 4.583157041816027e-14
grad ChooseDest W: 2.369222640991211
grad AddEdge W: 5.4416066379466e-14
grad ChooseDest W: 3.8654725551605225
grad AddEdge W: 4.321334245028629e-15
grad ChooseDest W: 7.875528812408447
grad AddEdge W: 4.584222270450494e-14
grad ChooseDest W: 4.176083564758301
grad AddEdge W: 9.089731844343367e-16
grad ChooseDest W: 4.721784591674805
grad AddEdge W: 1.0973379594315241e-15
grad ChooseDest W: 8.707646369934082
grad AddEdge W: 1.9890535887193833e-14
grad ChooseDest W: 3.6196398735046387
grad AddEdge W: 2.7917337732730804e-15
grad ChooseDest W: 4.560413837432861
grad AddEdge W: 1.141362390985948e-15
grad ChooseDest W: 7.249514102935791
grad AddEdge W: 5.780977503340792e-14
grad ChooseDest W: 5.426011562347412
grad AddEdge W: 8.643191427023069e-16
grad ChooseDest W: 5.358886241912842
grad AddEdge W: 2.2848725610646013e-14
grad ChooseDest W: 5.764368534088135
grad AddEdge W: 5.779257094721624e-15
grad ChooseDest W: 4.8844313621521
grad AddEdge W: 1.759547470561989e-14
grad ChooseDest W: 6.832345962524414
grad AddEdge W: 7.133119913965355e-14
grad ChooseDest W: 3.851536750793457
grad AddEdge W: 9.734207450173642e-16
grad ChooseDest W: 5.040118217468262
grad AddEdge W: 6.66902179537372e-16
grad ChooseDest W: 8.130277633666992
grad AddEdge W: 5.4327825875152835e-14
grad ChooseDest W: 8.00502872467041
grad AddEdge W: 3.909613382818353e-14
grad ChooseDest W: 3.020097494125366
grad AddEdge W: 7.965394603838994e-16
grad ChooseDest W: 5.44781494140625
grad AddEdge W: 2.9102161066603014e-15
grad ChooseDest W: 6.839649200439453
grad AddEdge W: 1.2084231540903734e-15
grad ChooseDest W: 5.156114101409912
grad AddEdge W: 1.1713114378278307e-16
grad ChooseDest W: 5.2734575271606445
grad AddEdge W: 4.5535949143304943e-14
grad ChooseDest W: 7.32504415512085
grad AddEdge W: 5.686220266344633e-14
grad ChooseDest W: 5.318909168243408
grad AddEdge W: 1.0201511292009103e-15
grad ChooseDest W: 6.054835319519043
grad AddEdge W: 1.6183774020342087e-14
grad ChooseDest W: 3.805097818374634
grad AddEdge W: 5.160574912684663e-15
grad ChooseDest W: 5.17079496383667
grad AddEdge W: 1.301590425541242e-15
grad ChooseDest W: 7.805482387542725
grad AddEdge W: 8.09584403046326e-16
grad ChooseDest W: 7.322244167327881
grad AddEdge W: 6.129097880266943e-14
grad ChooseDest W: 6.321811199188232
grad AddEdge W: 1.844514404292252e-15
grad ChooseDest W: 5.634664535522461
grad AddEdge W: 2.484115970785789e-15
grad ChooseDest W: 7.019376754760742
grad AddEdge W: 2.766708714242044e-16
grad ChooseDest W: 5.026390075683594
grad AddEdge W: 4.920702911197889e-16
grad ChooseDest W: 4.21540641784668
grad AddEdge W: 1.346559192952736e-15
grad ChooseDest W: 3.866422414779663
grad AddEdge W: 4.180137505550922e-16
grad ChooseDest W: 5.802143573760986
grad AddEdge W: 5.074807321061008e-16
grad ChooseDest W: 9.884308815002441
grad AddEdge W: 8.466107542696533e-16
grad ChooseDest W: 3.4736647605895996
grad AddEdge W: 1.123944111337729e-15
grad ChooseDest W: 5.383779048919678
grad AddEdge W: 1.5242079423759725e-15
grad ChooseDest W: 4.945093154907227
grad AddEdge W: 9.899397924659215e-13
grad ChooseDest W: 3.4311487674713135
grad AddEdge W: 2.3847645117870166e-14
grad ChooseDest W: 10.223265647888184
grad AddEdge W: 3.42004595759067e-14
grad ChooseDest W: 11.018366813659668
grad AddEdge W: 2.4229576508951866e-15
grad ChooseDest W: 5.693854331970215
=== Epoch 14: Train Loss: 5.3379, Train Log Prob: 0.0159 ===
Total mismatches: 79232
Predicted valid destination but wrong order: 25142
Epoch 14: Validation Loss: 5.2743, Validation Log Prob: 0.0083
Epoch 14: Edge Precision: 0.3946, Recall: 0.3936, F1: 0.3940, Jaccard: 0.2661
Epoch 14: TP: 2.7579098067287044, FP: 4.247530422333572, FN: 4.263564781675018
Epoch 14: Current Learning Rate: 6e-05
[Epoch 14] ‚è±Ô∏è Total: 1968.68s | Current time: 2025-07-14 19:10:59 | üèãÔ∏è Train: 1727.38s | ‚úÖ Val: 241.30s
grad AddEdge W: 1.146354333073779e-13
grad ChooseDest W: 12.128218650817871
grad AddEdge W: 1.2406760246696694e-16
grad ChooseDest W: 5.873691082000732
grad AddEdge W: 3.860233013707674e-16
grad ChooseDest W: 5.460033893585205
grad AddEdge W: 8.670723915336215e-14
grad ChooseDest W: 2.8692452907562256
grad AddEdge W: 3.4796563459459887e-16
grad ChooseDest W: 7.246358871459961
grad AddEdge W: 1.4228140751831333e-15
grad ChooseDest W: 4.776869297027588
grad AddEdge W: 6.819096445990277e-16
grad ChooseDest W: 5.937190532684326
grad AddEdge W: 8.947023733389963e-16
grad ChooseDest W: 6.164055824279785
grad AddEdge W: 1.6224177491926117e-14
grad ChooseDest W: 3.598637342453003
grad AddEdge W: 1.7955783463140555e-15
grad ChooseDest W: 10.216035842895508
grad AddEdge W: 5.764237611532996e-12
grad ChooseDest W: 3.598332166671753
grad AddEdge W: 1.83554083391102e-12
grad ChooseDest W: 4.637598514556885
grad AddEdge W: 1.7049012987885553e-16
grad ChooseDest W: 4.631577014923096
grad AddEdge W: 4.960008098686686e-13
grad ChooseDest W: 7.989150047302246
grad AddEdge W: 1.2368729790853956e-15
grad ChooseDest W: 5.727146148681641
grad AddEdge W: 2.775706851119845e-16
grad ChooseDest W: 7.39844274520874
grad AddEdge W: 4.555482421374332e-16
grad ChooseDest W: 4.7336225509643555
grad AddEdge W: 9.144100136370542e-15
grad ChooseDest W: 8.89281177520752
grad AddEdge W: 1.567855126631513e-15
grad ChooseDest W: 8.758018493652344
grad AddEdge W: 2.1049380720573755e-15
grad ChooseDest W: 4.911120414733887
grad AddEdge W: 3.9092505456674845e-16
grad ChooseDest W: 6.362368583679199
grad AddEdge W: 1.315280349911685e-13
grad ChooseDest W: 2.8596372604370117
grad AddEdge W: 5.082214962997926e-14
grad ChooseDest W: 8.051353454589844
grad AddEdge W: 9.143992393779651e-14
grad ChooseDest W: 5.439727783203125
grad AddEdge W: 1.062402720796731e-15
grad ChooseDest W: 5.669877529144287
grad AddEdge W: 1.4882579582703686e-15
grad ChooseDest W: 4.5168352127075195
grad AddEdge W: 2.533622183581441e-13
grad ChooseDest W: 1.9218485355377197
grad AddEdge W: 1.8314385449272504e-15
grad ChooseDest W: 9.235241889953613
grad AddEdge W: 4.591396978326917e-14
grad ChooseDest W: 6.96502685546875
grad AddEdge W: 9.179274873571171e-16
grad ChooseDest W: 7.849493026733398
grad AddEdge W: 4.242027397210156e-15
grad ChooseDest W: 3.802216053009033
grad AddEdge W: 2.8098213148287487e-15
grad ChooseDest W: 4.722926616668701
grad AddEdge W: 1.2104396219004307e-15
grad ChooseDest W: 5.151361465454102
grad AddEdge W: 5.835336499181371e-16
grad ChooseDest W: 5.5554094314575195
grad AddEdge W: 3.2342273848087527e-15
grad ChooseDest W: 5.424785137176514
grad AddEdge W: 8.728322155749507e-14
grad ChooseDest W: 3.3332107067108154
grad AddEdge W: 2.1609156472749948e-16
grad ChooseDest W: 7.135544776916504
grad AddEdge W: 5.376271005670024e-15
grad ChooseDest W: 5.354958534240723
grad AddEdge W: 2.2059058816777458e-14
grad ChooseDest W: 4.007843971252441
grad AddEdge W: 1.2476045858304113e-13
grad ChooseDest W: 6.761229515075684
grad AddEdge W: 7.320896276349909e-13
grad ChooseDest W: 6.249824523925781
grad AddEdge W: 6.592984177094293e-16
grad ChooseDest W: 5.881666660308838
grad AddEdge W: 3.870289412373951e-16
grad ChooseDest W: 9.351288795471191
grad AddEdge W: 2.7420688434437717e-15
grad ChooseDest W: 4.170534610748291
grad AddEdge W: 1.1855566949979437e-14
grad ChooseDest W: 4.837382793426514
grad AddEdge W: 7.486469999362796e-16
grad ChooseDest W: 7.087216377258301
grad AddEdge W: 1.9470854355235377e-15
grad ChooseDest W: 6.342973232269287
grad AddEdge W: 4.034219722062575e-15
grad ChooseDest W: 6.575389385223389
grad AddEdge W: 1.7087323758694273e-15
grad ChooseDest W: 5.320164203643799
grad AddEdge W: 4.0796759145835665e-14
grad ChooseDest W: 5.289048671722412
grad AddEdge W: 1.6946144330452426e-14
grad ChooseDest W: 5.044454097747803
grad AddEdge W: 1.680686975225401e-13
grad ChooseDest W: 5.95318078994751
grad AddEdge W: 3.9198863678092423e-16
grad ChooseDest W: 5.483715534210205
grad AddEdge W: 4.439403967491419e-16
grad ChooseDest W: 5.116510391235352
grad AddEdge W: 7.551142553072438e-16
grad ChooseDest W: 6.0048065185546875
grad AddEdge W: 4.174579180059833e-14
grad ChooseDest W: 7.0169148445129395
grad AddEdge W: 2.262982720372444e-16
grad ChooseDest W: 5.730377674102783
grad AddEdge W: 3.3234679385710925e-14
grad ChooseDest W: 4.707421779632568
grad AddEdge W: 3.6625193031375805e-14
grad ChooseDest W: 9.576577186584473
grad AddEdge W: 2.7767237141730237e-15
grad ChooseDest W: 6.448945999145508
grad AddEdge W: 9.556017129059755e-16
grad ChooseDest W: 4.917668342590332
grad AddEdge W: 5.530907458103137e-15
grad ChooseDest W: 4.130425453186035
grad AddEdge W: 2.3434276098951122e-15
grad ChooseDest W: 5.828543663024902
grad AddEdge W: 2.467562151787714e-14
grad ChooseDest W: 8.039676666259766
grad AddEdge W: 1.559082554627566e-14
grad ChooseDest W: 3.8361053466796875
grad AddEdge W: 4.060706018806743e-15
grad ChooseDest W: 6.234729766845703
=== Epoch 15: Train Loss: 5.3092, Train Log Prob: 0.0164 ===
Total mismatches: 78559
Predicted valid destination but wrong order: 25142
Epoch 15: Validation Loss: 5.2279, Validation Log Prob: 0.0086
Epoch 15: Edge Precision: 0.3940, Recall: 0.3931, F1: 0.3935, Jaccard: 0.2660
Epoch 15: TP: 2.7543307086614175, FP: 4.251682176091625, FN: 4.267143879742305
Epoch 15: Current Learning Rate: 6e-05
[Epoch 15] ‚è±Ô∏è Total: 1968.87s | Current time: 2025-07-14 19:43:48 | üèãÔ∏è Train: 1723.49s | ‚úÖ Val: 245.38s
grad AddEdge W: 1.0157545919826927e-13
grad ChooseDest W: 12.81185531616211
grad AddEdge W: 3.581913953810967e-14
grad ChooseDest W: 4.173293113708496
grad AddEdge W: 4.3401368517983693e-14
grad ChooseDest W: 4.812673091888428
grad AddEdge W: 3.3419691710182e-14
grad ChooseDest W: 2.2057790756225586
grad AddEdge W: 7.662743188455515e-14
grad ChooseDest W: 6.093931674957275
grad AddEdge W: 2.2485914717799158e-15
grad ChooseDest W: 8.762691497802734
grad AddEdge W: 1.7513952866644346e-14
grad ChooseDest W: 7.514773845672607
grad AddEdge W: 4.1177138243162403e-16
grad ChooseDest W: 5.267168045043945
grad AddEdge W: 1.2857487156122532e-13
grad ChooseDest W: 8.503694534301758
grad AddEdge W: 4.045918782311374e-16
grad ChooseDest W: 4.3300886154174805
grad AddEdge W: 3.043797344962812e-17
grad ChooseDest W: 6.396411418914795
grad AddEdge W: 6.848413437905709e-13
grad ChooseDest W: 4.881326675415039
grad AddEdge W: 2.881628056476199e-16
grad ChooseDest W: 6.195242881774902
grad AddEdge W: 1.2476381960977584e-13
grad ChooseDest W: 4.498965263366699
grad AddEdge W: 3.2218556215811564e-15
grad ChooseDest W: 3.7555456161499023
grad AddEdge W: 1.0200805586509099e-13
grad ChooseDest W: 3.0458710193634033
grad AddEdge W: 1.5409809946766205e-15
grad ChooseDest W: 4.006450176239014
grad AddEdge W: 1.3019242624015786e-15
grad ChooseDest W: 5.669963359832764
grad AddEdge W: 8.367503907911068e-16
grad ChooseDest W: 5.621227741241455
grad AddEdge W: 8.777986662062342e-16
grad ChooseDest W: 3.8877720832824707
grad AddEdge W: 1.3050376908178894e-16
grad ChooseDest W: 7.510375022888184
grad AddEdge W: 2.238163649166268e-15
grad ChooseDest W: 5.358554840087891
grad AddEdge W: 1.4845812079666842e-10
grad ChooseDest W: 2.0402605533599854
grad AddEdge W: 1.624154776598205e-13
grad ChooseDest W: 4.260636806488037
grad AddEdge W: 3.600897317411651e-14
grad ChooseDest W: 4.086604118347168
grad AddEdge W: 1.3492824208188176e-13
grad ChooseDest W: 3.5140349864959717
grad AddEdge W: 2.8269862257466203e-15
grad ChooseDest W: 5.206015110015869
grad AddEdge W: 2.1893258470099533e-15
grad ChooseDest W: 3.580883502960205
grad AddEdge W: 2.0836207938738265e-15
grad ChooseDest W: 5.438719749450684
grad AddEdge W: 4.0972060978720296e-16
grad ChooseDest W: 5.842006683349609
grad AddEdge W: 1.1703930688245498e-15
grad ChooseDest W: 6.719595432281494
grad AddEdge W: 3.1934891763918795e-16
grad ChooseDest W: 4.852876663208008
grad AddEdge W: 2.125673015089687e-15
grad ChooseDest W: 3.5850820541381836
grad AddEdge W: 7.499603965187979e-14
grad ChooseDest W: 4.575396537780762
grad AddEdge W: 3.934729603770337e-14
grad ChooseDest W: 7.549393653869629
grad AddEdge W: 2.127126947143649e-15
grad ChooseDest W: 5.214743614196777
grad AddEdge W: 3.923347175025134e-14
grad ChooseDest W: 6.354066848754883
grad AddEdge W: 2.1400739727973732e-14
grad ChooseDest W: 4.265463352203369
grad AddEdge W: 3.533899721789267e-14
grad ChooseDest W: 3.846203088760376
grad AddEdge W: 2.6365054142164258e-14
grad ChooseDest W: 8.187625885009766
grad AddEdge W: 2.5306263381612857e-16
grad ChooseDest W: 5.666386127471924
grad AddEdge W: 5.0573501414246866e-14
grad ChooseDest W: 5.667325496673584
grad AddEdge W: 5.254190433971219e-14
grad ChooseDest W: 4.065746784210205
grad AddEdge W: 1.239022748705527e-15
grad ChooseDest W: 6.005475997924805
grad AddEdge W: 1.875764626090015e-15
grad ChooseDest W: 6.769778728485107
grad AddEdge W: 6.875235142756331e-16
grad ChooseDest W: 4.237085342407227
grad AddEdge W: 4.781303522694697e-16
grad ChooseDest W: 4.157811164855957
grad AddEdge W: 1.3656919562246572e-12
grad ChooseDest W: 1.5077537298202515
grad AddEdge W: 4.95366111140632e-14
grad ChooseDest W: 5.598235607147217
grad AddEdge W: 9.923631333992253e-15
grad ChooseDest W: 3.6173770427703857
grad AddEdge W: 1.4401093232957636e-14
grad ChooseDest W: 6.889503479003906
grad AddEdge W: 6.451074924089268e-16
grad ChooseDest W: 6.497184753417969
grad AddEdge W: 2.5820491578176785e-14
grad ChooseDest W: 2.749577760696411
grad AddEdge W: 3.472363794610779e-14
grad ChooseDest W: 4.842903137207031
grad AddEdge W: 1.3902510327852557e-13
grad ChooseDest W: 8.256875991821289
grad AddEdge W: 2.6784808095439705e-13
grad ChooseDest W: 5.246654033660889
grad AddEdge W: 4.108808088145073e-14
grad ChooseDest W: 8.703303337097168
grad AddEdge W: 6.324542601329579e-15
grad ChooseDest W: 5.287450790405273
grad AddEdge W: 4.3820423669077655e-16
grad ChooseDest W: 5.827178001403809
grad AddEdge W: 3.771662748880232e-16
grad ChooseDest W: 5.1116108894348145
grad AddEdge W: 1.50677393967867e-16
grad ChooseDest W: 3.9299988746643066
grad AddEdge W: 4.917024903558498e-14
grad ChooseDest W: 4.370513439178467
grad AddEdge W: 2.6369019738665066e-16
grad ChooseDest W: 3.5840229988098145
grad AddEdge W: 5.725214804500024e-16
grad ChooseDest W: 8.698174476623535
grad AddEdge W: 5.748072517977273e-16
grad ChooseDest W: 6.1812334060668945
grad AddEdge W: 1.4988431966633076e-16
grad ChooseDest W: 6.314967632293701
=== Epoch 16: Train Loss: 5.2807, Train Log Prob: 0.0168 ===
Total mismatches: 78199
Predicted valid destination but wrong order: 25110
Epoch 16: Validation Loss: 5.1532, Validation Log Prob: 0.0090
Epoch 16: Edge Precision: 0.3963, Recall: 0.3954, F1: 0.3958, Jaccard: 0.2675
Epoch 16: TP: 2.7712240515390123, FP: 4.2342161775232645, FN: 4.25025053686471
Epoch 16: Current Learning Rate: 6e-05
[Epoch 16] ‚è±Ô∏è Total: 1969.25s | Current time: 2025-07-14 20:16:37 | üèãÔ∏è Train: 1725.35s | ‚úÖ Val: 243.90s
grad AddEdge W: 8.110899511705114e-14
grad ChooseDest W: 10.0303316116333
grad AddEdge W: 8.459684640088269e-14
grad ChooseDest W: 5.356328964233398
grad AddEdge W: 3.208731566041456e-14
grad ChooseDest W: 6.984006881713867
grad AddEdge W: 3.71135575004118e-15
grad ChooseDest W: 5.4418864250183105
grad AddEdge W: 1.7502923385940352e-16
grad ChooseDest W: 6.033473014831543
grad AddEdge W: 6.699354045214896e-16
grad ChooseDest W: 6.543032646179199
grad AddEdge W: 2.7246259786642586e-14
grad ChooseDest W: 5.267800807952881
grad AddEdge W: 5.125209487191783e-16
grad ChooseDest W: 4.781247138977051
grad AddEdge W: 2.0088851446436686e-16
grad ChooseDest W: 6.057505130767822
grad AddEdge W: 9.596551758401712e-17
grad ChooseDest W: 4.758801460266113
grad AddEdge W: 9.250537003069326e-10
grad ChooseDest W: 1.4705510139465332
grad AddEdge W: 2.7671658473357654e-16
grad ChooseDest W: 4.567232131958008
grad AddEdge W: 9.373683334526137e-15
grad ChooseDest W: 7.154837608337402
grad AddEdge W: 1.29539882645505e-15
grad ChooseDest W: 3.878917932510376
grad AddEdge W: 9.896078490418593e-17
grad ChooseDest W: 7.4260783195495605
grad AddEdge W: 5.439791700450518e-15
grad ChooseDest W: 6.483412265777588
grad AddEdge W: 1.2347869486945451e-15
grad ChooseDest W: 4.835428237915039
grad AddEdge W: 2.6002670577439293e-15
grad ChooseDest W: 6.269688606262207
grad AddEdge W: 6.361565776179354e-16
grad ChooseDest W: 5.550745010375977
grad AddEdge W: 2.6101013220197885e-16
grad ChooseDest W: 5.814119338989258
grad AddEdge W: 8.112529880721989e-14
grad ChooseDest W: 7.692685127258301
grad AddEdge W: 1.1683255884552442e-14
grad ChooseDest W: 5.007776737213135
grad AddEdge W: 1.5511192908409849e-16
grad ChooseDest W: 6.078160285949707
grad AddEdge W: 1.3096346923591184e-12
grad ChooseDest W: 2.8984224796295166
grad AddEdge W: 3.0077392399602276e-12
grad ChooseDest W: 6.437572479248047
grad AddEdge W: 2.1824786444225863e-14
grad ChooseDest W: 3.9207592010498047
grad AddEdge W: 5.757622285061973e-16
grad ChooseDest W: 5.186885356903076
grad AddEdge W: 2.2259973337800283e-14
grad ChooseDest W: 6.597271919250488
grad AddEdge W: 1.615130338500359e-12
grad ChooseDest W: 3.008824586868286
grad AddEdge W: 5.173851052990043e-14
grad ChooseDest W: 5.980876922607422
grad AddEdge W: 8.364695654877741e-14
grad ChooseDest W: 4.341885089874268
grad AddEdge W: 2.5768568670268333e-16
grad ChooseDest W: 5.683631420135498
grad AddEdge W: 6.090293416304916e-16
grad ChooseDest W: 5.642952919006348
grad AddEdge W: 1.4212650425050183e-14
grad ChooseDest W: 5.583917617797852
grad AddEdge W: 1.943264173436942e-14
grad ChooseDest W: 7.707036972045898
grad AddEdge W: 8.047413545275457e-15
grad ChooseDest W: 7.007376670837402
grad AddEdge W: 5.069302136299447e-16
grad ChooseDest W: 4.790785312652588
grad AddEdge W: 2.8313614156169847e-16
grad ChooseDest W: 5.361607074737549
grad AddEdge W: 3.2348106199324965e-16
grad ChooseDest W: 6.091887474060059
grad AddEdge W: 3.210048141115109e-16
grad ChooseDest W: 4.662332534790039
grad AddEdge W: 4.3248472294740714e-14
grad ChooseDest W: 3.468590021133423
grad AddEdge W: 4.695464145028762e-16
grad ChooseDest W: 6.741065502166748
grad AddEdge W: 5.217862186127195e-16
grad ChooseDest W: 5.0472493171691895
grad AddEdge W: 3.9713661186676025e-16
grad ChooseDest W: 6.49596643447876
grad AddEdge W: 7.991000409834491e-16
grad ChooseDest W: 3.771468162536621
grad AddEdge W: 5.199127871388827e-14
grad ChooseDest W: 5.793368816375732
grad AddEdge W: 1.6410292653294516e-14
grad ChooseDest W: 3.942662477493286
grad AddEdge W: 6.768133649927538e-16
grad ChooseDest W: 4.6153764724731445
grad AddEdge W: 2.8784564792480594e-14
grad ChooseDest W: 4.581149578094482
grad AddEdge W: 1.3690033637693121e-14
grad ChooseDest W: 7.8847174644470215
grad AddEdge W: 4.685552800754703e-16
grad ChooseDest W: 5.613833427429199
grad AddEdge W: 7.246243117540901e-17
grad ChooseDest W: 11.427982330322266
grad AddEdge W: 2.149285964318532e-14
grad ChooseDest W: 5.718618392944336
grad AddEdge W: 4.433642512911666e-14
grad ChooseDest W: 5.036193370819092
grad AddEdge W: 1.2871586358342759e-14
grad ChooseDest W: 4.641177654266357
grad AddEdge W: 4.3326551791818615e-14
grad ChooseDest W: 4.508527755737305
grad AddEdge W: 4.78107005923861e-16
grad ChooseDest W: 3.7492992877960205
grad AddEdge W: 3.1287965056497403e-16
grad ChooseDest W: 5.251067161560059
grad AddEdge W: 4.128455102059931e-15
grad ChooseDest W: 3.985374689102173
grad AddEdge W: 2.807312032662067e-16
grad ChooseDest W: 5.554762363433838
grad AddEdge W: 1.9114960756952274e-15
grad ChooseDest W: 5.064004421234131
grad AddEdge W: 1.0332936627643549e-13
grad ChooseDest W: 6.570346355438232
grad AddEdge W: 1.4805409322555103e-16
grad ChooseDest W: 8.042937278747559
grad AddEdge W: 1.265866616173214e-13
grad ChooseDest W: 5.547082901000977
grad AddEdge W: 2.7038967107526936e-14
grad ChooseDest W: 2.4380152225494385
grad AddEdge W: 8.146806932405118e-14
grad ChooseDest W: 6.011343479156494
=== Epoch 17: Train Loss: 5.2462, Train Log Prob: 0.0172 ===
Total mismatches: 77324
Predicted valid destination but wrong order: 25371
Epoch 17: Validation Loss: 5.0753, Validation Log Prob: 0.0098
Epoch 17: Edge Precision: 0.3950, Recall: 0.3941, F1: 0.3945, Jaccard: 0.2662
Epoch 17: TP: 2.7626342161775232, FP: 4.242233357193987, FN: 4.258840372226199
Epoch 17: Current Learning Rate: 6e-05
[Epoch 17] ‚è±Ô∏è Total: 1974.37s | Current time: 2025-07-14 20:49:32 | üèãÔ∏è Train: 1730.61s | ‚úÖ Val: 243.76s
grad AddEdge W: 7.849254422430049e-14
grad ChooseDest W: 14.319111824035645
grad AddEdge W: 1.1090818594869682e-15
grad ChooseDest W: 5.8436994552612305
grad AddEdge W: 2.2931379085639088e-14
grad ChooseDest W: 3.8385422229766846
grad AddEdge W: 7.523723397767634e-14
grad ChooseDest W: 5.896594047546387
grad AddEdge W: 2.8646638394272676e-16
grad ChooseDest W: 6.097510814666748
grad AddEdge W: 3.134939612099702e-16
grad ChooseDest W: 7.147819995880127
grad AddEdge W: 2.0041347985870093e-15
grad ChooseDest W: 5.018367767333984
grad AddEdge W: 5.587741935819679e-10
grad ChooseDest W: 5.86630392074585
grad AddEdge W: 1.4726686874530677e-16
grad ChooseDest W: 4.532641887664795
grad AddEdge W: 1.2507244453443742e-14
grad ChooseDest W: 5.024514675140381
grad AddEdge W: 2.5110859233428394e-14
grad ChooseDest W: 9.72015380859375
grad AddEdge W: 1.0268948349500347e-16
grad ChooseDest W: 3.253333330154419
grad AddEdge W: 5.446644726389397e-16
grad ChooseDest W: 6.33441686630249
grad AddEdge W: 1.699391217117768e-16
grad ChooseDest W: 4.2746758460998535
grad AddEdge W: 6.367387539504951e-17
grad ChooseDest W: 3.8362202644348145
grad AddEdge W: 3.5854003414218655e-14
grad ChooseDest W: 6.289034366607666
grad AddEdge W: 5.253510097107984e-16
grad ChooseDest W: 6.498168468475342
grad AddEdge W: 1.2476406524933054e-14
grad ChooseDest W: 5.345149040222168
grad AddEdge W: 9.429825101786625e-16
grad ChooseDest W: 4.602641582489014
grad AddEdge W: 3.652688977564926e-14
grad ChooseDest W: 10.602835655212402
grad AddEdge W: 2.896445426168667e-14
grad ChooseDest W: 3.925861358642578
grad AddEdge W: 1.897363966245e-15
grad ChooseDest W: 8.031846046447754
grad AddEdge W: 2.1026891995824153e-15
grad ChooseDest W: 4.448407173156738
grad AddEdge W: 1.0710834188426584e-16
grad ChooseDest W: 7.097561836242676
grad AddEdge W: 1.174622807256003e-16
grad ChooseDest W: 6.675947666168213
grad AddEdge W: 1.2178588099552107e-16
grad ChooseDest W: 4.969651699066162
grad AddEdge W: 3.4441384015830437e-16
grad ChooseDest W: 7.106227874755859
grad AddEdge W: 1.5578982543365386e-15
grad ChooseDest W: 6.005363464355469
grad AddEdge W: 6.568611862828235e-16
grad ChooseDest W: 4.003288745880127
grad AddEdge W: 1.3843890608056524e-15
grad ChooseDest W: 6.7309889793396
grad AddEdge W: 1.5682931908960092e-14
grad ChooseDest W: 4.3543620109558105
grad AddEdge W: 1.5093434670637252e-15
grad ChooseDest W: 7.277359485626221
grad AddEdge W: 7.136386914748959e-17
grad ChooseDest W: 5.3067169189453125
grad AddEdge W: 1.5124493251230699e-15
grad ChooseDest W: 3.55184268951416
grad AddEdge W: 5.590402099406213e-16
grad ChooseDest W: 7.706689357757568
grad AddEdge W: 4.284757985937649e-16
grad ChooseDest W: 4.52374267578125
grad AddEdge W: 8.213094036791345e-16
grad ChooseDest W: 6.626644134521484
grad AddEdge W: 2.0684515455192452e-16
grad ChooseDest W: 6.958637237548828
grad AddEdge W: 5.949962609197099e-14
grad ChooseDest W: 10.443682670593262
grad AddEdge W: 3.8979172130694864e-14
grad ChooseDest W: 6.947165489196777
grad AddEdge W: 5.956815317498623e-16
grad ChooseDest W: 8.218938827514648
grad AddEdge W: 1.0262266053639898e-16
grad ChooseDest W: 6.474581241607666
grad AddEdge W: 6.26654138499163e-16
grad ChooseDest W: 5.483890056610107
grad AddEdge W: 2.254794029354863e-16
grad ChooseDest W: 6.011195659637451
grad AddEdge W: 2.9132150025645842e-09
grad ChooseDest W: 0.08330965787172318
grad AddEdge W: 1.0403619833026026e-13
grad ChooseDest W: 4.414368629455566
grad AddEdge W: 1.0063692466985488e-14
grad ChooseDest W: 5.387174129486084
grad AddEdge W: 2.4630532260028898e-15
grad ChooseDest W: 9.52037525177002
grad AddEdge W: 4.937674275087313e-16
grad ChooseDest W: 4.916813850402832
grad AddEdge W: 8.269548253330252e-17
grad ChooseDest W: 4.387109756469727
grad AddEdge W: 2.1767247231421083e-16
grad ChooseDest W: 4.206024646759033
grad AddEdge W: 9.793387482264285e-14
grad ChooseDest W: 5.12131929397583
grad AddEdge W: 1.731451895921332e-14
grad ChooseDest W: 3.9571378231048584
grad AddEdge W: 1.8345312739759126e-15
grad ChooseDest W: 6.783558368682861
grad AddEdge W: 8.941400916927852e-15
grad ChooseDest W: 4.630959510803223
grad AddEdge W: 1.5329397297435092e-14
grad ChooseDest W: 4.418376445770264
grad AddEdge W: 1.4648331032953734e-16
grad ChooseDest W: 5.425978183746338
grad AddEdge W: 1.5837888751605504e-15
grad ChooseDest W: 4.622513294219971
grad AddEdge W: 6.192858518305571e-16
grad ChooseDest W: 3.7566983699798584
grad AddEdge W: 2.191703680251133e-15
grad ChooseDest W: 3.8776049613952637
grad AddEdge W: 5.2241435310011267e-17
grad ChooseDest W: 4.371450901031494
grad AddEdge W: 3.5148311890257364e-15
grad ChooseDest W: 4.818089008331299
grad AddEdge W: 2.810429113907963e-16
grad ChooseDest W: 4.644593238830566
grad AddEdge W: 4.437268830365451e-14
grad ChooseDest W: 4.682525634765625
grad AddEdge W: 8.977906851108386e-14
grad ChooseDest W: 5.00060510635376
grad AddEdge W: 3.1930225607643137e-13
grad ChooseDest W: 4.137421131134033
=== Epoch 18: Train Loss: 5.2176, Train Log Prob: 0.0178 ===
Total mismatches: 77138
Predicted valid destination but wrong order: 25323
Epoch 18: Validation Loss: 5.1047, Validation Log Prob: 0.0098
Epoch 18: Edge Precision: 0.3962, Recall: 0.3952, F1: 0.3956, Jaccard: 0.2676
Epoch 18: TP: 2.7705082319255547, FP: 4.234931997136721, FN: 4.250966356478168
Epoch 18: Current Learning Rate: 6e-05
[Epoch 18] ‚è±Ô∏è Total: 1974.98s | Current time: 2025-07-14 21:22:27 | üèãÔ∏è Train: 1728.63s | ‚úÖ Val: 246.35s
grad AddEdge W: 7.927149605138628e-14
grad ChooseDest W: 9.621705055236816
grad AddEdge W: 2.592727405722182e-15
grad ChooseDest W: 5.88213586807251
grad AddEdge W: 2.8096757839804986e-16
grad ChooseDest W: 4.719411849975586
grad AddEdge W: 7.301236599292489e-16
grad ChooseDest W: 3.1313469409942627
grad AddEdge W: 7.442201939956918e-16
grad ChooseDest W: 2.5937469005584717
grad AddEdge W: 4.527193638518407e-16
grad ChooseDest W: 3.1496684551239014
grad AddEdge W: 1.9917996695343818e-15
grad ChooseDest W: 6.654224872589111
grad AddEdge W: 8.678694945356131e-17
grad ChooseDest W: 4.894798755645752
grad AddEdge W: 4.51588662297997e-11
grad ChooseDest W: 4.534273147583008
grad AddEdge W: 2.785130622053641e-16
grad ChooseDest W: 6.505095481872559
grad AddEdge W: 8.023651052379774e-14
grad ChooseDest W: 6.344242572784424
grad AddEdge W: 9.157008494970224e-16
grad ChooseDest W: 7.19943380355835
grad AddEdge W: 1.3850616049657723e-15
grad ChooseDest W: 6.886235237121582
grad AddEdge W: 1.885668558825786e-15
grad ChooseDest W: 4.513144493103027
grad AddEdge W: 5.451954246540143e-15
grad ChooseDest W: 5.593938827514648
grad AddEdge W: 1.4330889554102424e-16
grad ChooseDest W: 6.40186882019043
grad AddEdge W: 9.086039839484522e-16
grad ChooseDest W: 4.652170181274414
grad AddEdge W: 2.1775744030673227e-16
grad ChooseDest W: 4.894124507904053
grad AddEdge W: 1.4876475651527535e-15
grad ChooseDest W: 5.870069980621338
grad AddEdge W: 2.7282314485196294e-16
grad ChooseDest W: 5.999048233032227
grad AddEdge W: 3.1413693862627503e-16
grad ChooseDest W: 7.409391403198242
grad AddEdge W: 4.70320708495785e-16
grad ChooseDest W: 3.8346238136291504
grad AddEdge W: 1.36223332588344e-15
grad ChooseDest W: 6.763729572296143
grad AddEdge W: 1.7991494372196796e-15
grad ChooseDest W: 5.2165985107421875
grad AddEdge W: 1.9376082485745053e-16
grad ChooseDest W: 5.827780246734619
grad AddEdge W: 2.6194178374066386e-15
grad ChooseDest W: 8.9786958694458
grad AddEdge W: 1.8803237809286114e-15
grad ChooseDest W: 3.5732955932617188
grad AddEdge W: 4.240812593145116e-16
grad ChooseDest W: 3.2510321140289307
grad AddEdge W: 6.172829852520503e-14
grad ChooseDest W: 4.583563327789307
grad AddEdge W: 7.017830598327751e-14
grad ChooseDest W: 3.878042221069336
grad AddEdge W: 1.7510924935616149e-15
grad ChooseDest W: 5.271475315093994
grad AddEdge W: 8.957339535896336e-15
grad ChooseDest W: 4.425868511199951
grad AddEdge W: 2.6477559069921824e-16
grad ChooseDest W: 9.421287536621094
grad AddEdge W: 2.2609416780190045e-14
grad ChooseDest W: 9.496967315673828
grad AddEdge W: 1.623281071642233e-16
grad ChooseDest W: 3.679384231567383
grad AddEdge W: 4.2513533887781035e-16
grad ChooseDest W: 4.033239841461182
grad AddEdge W: 3.940957106465581e-16
grad ChooseDest W: 7.731189727783203
grad AddEdge W: 1.069179407891239e-15
grad ChooseDest W: 5.747146129608154
grad AddEdge W: 2.6296101848609496e-15
grad ChooseDest W: 5.565206050872803
grad AddEdge W: 7.198882196737463e-16
grad ChooseDest W: 6.290378570556641
grad AddEdge W: 4.101754082463634e-15
grad ChooseDest W: 3.4281039237976074
grad AddEdge W: 1.514975516184961e-14
grad ChooseDest W: 5.05521297454834
grad AddEdge W: 1.760536466231203e-14
grad ChooseDest W: 3.1726481914520264
grad AddEdge W: 4.642037012485105e-16
grad ChooseDest W: 11.08765697479248
grad AddEdge W: 4.566401734855624e-16
grad ChooseDest W: 7.337673187255859
grad AddEdge W: 6.656870557173941e-14
grad ChooseDest W: 7.817171573638916
grad AddEdge W: 9.057084018182634e-16
grad ChooseDest W: 7.844388484954834
grad AddEdge W: 6.132237958457356e-16
grad ChooseDest W: 6.773916721343994
grad AddEdge W: 9.27070890385372e-16
grad ChooseDest W: 4.017336368560791
grad AddEdge W: 7.843250864658148e-16
grad ChooseDest W: 5.592917442321777
grad AddEdge W: 5.932744229324432e-16
grad ChooseDest W: 3.474454402923584
grad AddEdge W: 4.560302038844209e-16
grad ChooseDest W: 7.1748504638671875
grad AddEdge W: 1.2097655742568294e-14
grad ChooseDest W: 7.222570896148682
grad AddEdge W: 1.990329299747287e-16
grad ChooseDest W: 7.943517208099365
grad AddEdge W: 1.6998315419014423e-16
grad ChooseDest W: 7.552351951599121
grad AddEdge W: 7.178325236503193e-16
grad ChooseDest W: 4.667707443237305
grad AddEdge W: 5.282320736962713e-14
grad ChooseDest W: 6.956928253173828
grad AddEdge W: 3.098272032269096e-14
grad ChooseDest W: 6.010329723358154
grad AddEdge W: 4.363261921908057e-12
grad ChooseDest W: 5.73009729385376
grad AddEdge W: 1.3011327312881932e-14
grad ChooseDest W: 4.537670135498047
grad AddEdge W: 7.897159217794963e-15
grad ChooseDest W: 5.685651779174805
grad AddEdge W: 9.560575357456065e-17
grad ChooseDest W: 8.78016185760498
grad AddEdge W: 1.3528774499343223e-16
grad ChooseDest W: 4.410690784454346
grad AddEdge W: 1.85840256825367e-15
grad ChooseDest W: 6.165332794189453
grad AddEdge W: 1.9833828354864138e-16
grad ChooseDest W: 6.777914047241211
grad AddEdge W: 3.164391477071326e-16
grad ChooseDest W: 5.106075286865234
=== Epoch 19: Train Loss: 5.1811, Train Log Prob: 0.0184 ===
Total mismatches: 76482
Predicted valid destination but wrong order: 25423
Epoch 19: Validation Loss: 4.9734, Validation Log Prob: 0.0107
Epoch 19: Edge Precision: 0.3947, Recall: 0.3936, F1: 0.3941, Jaccard: 0.2658
Epoch 19: TP: 2.7586256263421616, FP: 4.241947029348604, FN: 4.26284896206156
Epoch 19: Current Learning Rate: 6e-05
[Epoch 19] ‚è±Ô∏è Total: 1998.81s | Current time: 2025-07-14 21:55:45 | üèãÔ∏è Train: 1754.93s | ‚úÖ Val: 243.88s
grad AddEdge W: 2.800106439846805e-14
grad ChooseDest W: 8.46498966217041
grad AddEdge W: 5.626440174938332e-16
grad ChooseDest W: 7.69206428527832
grad AddEdge W: 1.3824508376640977e-15
grad ChooseDest W: 7.5178656578063965
grad AddEdge W: 9.868186996719874e-13
grad ChooseDest W: 4.964005470275879
grad AddEdge W: 5.928503537698179e-14
grad ChooseDest W: 4.6279144287109375
grad AddEdge W: 3.117760989835997e-15
grad ChooseDest W: 5.348152160644531
grad AddEdge W: 5.211452539584556e-14
grad ChooseDest W: 4.469338417053223
grad AddEdge W: 3.1512237887469305e-14
grad ChooseDest W: 5.564609527587891
grad AddEdge W: 1.8758859635597093e-15
grad ChooseDest W: 5.806860446929932
grad AddEdge W: 5.979270626798455e-14
grad ChooseDest W: 9.526991844177246
grad AddEdge W: 8.847208312094332e-16
grad ChooseDest W: 9.791664123535156
grad AddEdge W: 7.710756382861854e-16
grad ChooseDest W: 3.346724271774292
grad AddEdge W: 6.903631922313032e-16
grad ChooseDest W: 7.571119785308838
grad AddEdge W: 1.3421533510775928e-14
grad ChooseDest W: 5.745492935180664
grad AddEdge W: 7.683811100139392e-15
grad ChooseDest W: 3.7859842777252197
grad AddEdge W: 6.043180279108329e-14
grad ChooseDest W: 3.458118438720703
grad AddEdge W: 5.238840015857132e-16
grad ChooseDest W: 4.570101261138916
grad AddEdge W: 2.0660900494260358e-14
grad ChooseDest W: 3.1646230220794678
grad AddEdge W: 9.825894531549184e-16
grad ChooseDest W: 8.140713691711426
grad AddEdge W: 1.1250915699307154e-13
grad ChooseDest W: 4.647810459136963
grad AddEdge W: 6.122476962531435e-15
grad ChooseDest W: 3.6772682666778564
grad AddEdge W: 2.245619868442711e-16
grad ChooseDest W: 6.859412670135498
grad AddEdge W: 1.9150063072835913e-14
grad ChooseDest W: 7.189282417297363
grad AddEdge W: 8.107557437332603e-16
grad ChooseDest W: 15.075494766235352
grad AddEdge W: 4.719819624514994e-15
grad ChooseDest W: 6.110132217407227
grad AddEdge W: 6.906078576981176e-15
grad ChooseDest W: 5.871423721313477
grad AddEdge W: 7.355306418084875e-16
grad ChooseDest W: 9.198084831237793
grad AddEdge W: 1.5405635344885663e-14
grad ChooseDest W: 5.594181537628174
grad AddEdge W: 9.222511670363767e-15
grad ChooseDest W: 4.002182483673096
grad AddEdge W: 9.039490720351689e-15
grad ChooseDest W: 5.781882286071777
grad AddEdge W: 1.427559344336065e-14
grad ChooseDest W: 4.222663879394531
grad AddEdge W: 2.7345994951566465e-15
grad ChooseDest W: 4.6648736000061035
grad AddEdge W: 1.5573239448224765e-14
grad ChooseDest W: 3.546401262283325
grad AddEdge W: 2.2456256917942233e-16
grad ChooseDest W: 3.776742935180664
grad AddEdge W: 7.249713173297786e-16
grad ChooseDest W: 5.792198181152344
grad AddEdge W: 4.522659915844052e-14
grad ChooseDest W: 3.3344335556030273
grad AddEdge W: 2.9534980079573385e-15
grad ChooseDest W: 10.411144256591797
grad AddEdge W: 4.936785419888288e-16
grad ChooseDest W: 5.8785505294799805
grad AddEdge W: 9.517525569656355e-17
grad ChooseDest W: 3.8991966247558594
grad AddEdge W: 5.779324857357404e-16
grad ChooseDest W: 4.976413249969482
grad AddEdge W: 1.477750112219029e-14
grad ChooseDest W: 4.202018737792969
grad AddEdge W: 4.1701279583945404e-16
grad ChooseDest W: 7.9692864418029785
grad AddEdge W: 7.272648707927064e-16
grad ChooseDest W: 4.752420902252197
grad AddEdge W: 1.32465331157414e-14
grad ChooseDest W: 6.845539569854736
grad AddEdge W: 2.0146852027499925e-16
grad ChooseDest W: 6.93505859375
grad AddEdge W: 8.463030081416745e-13
grad ChooseDest W: 3.858626365661621
grad AddEdge W: 2.9557765265854526e-16
grad ChooseDest W: 4.983994483947754
grad AddEdge W: 1.7671531488019747e-14
grad ChooseDest W: 7.409982681274414
grad AddEdge W: 2.4533446402405794e-16
grad ChooseDest W: 5.240890979766846
grad AddEdge W: 2.3034485018176565e-15
grad ChooseDest W: 7.090755462646484
grad AddEdge W: 1.3798721252655208e-16
grad ChooseDest W: 5.653624534606934
grad AddEdge W: 3.1760764130457295e-14
grad ChooseDest W: 8.289082527160645
grad AddEdge W: 3.2354043370889625e-16
grad ChooseDest W: 5.057451248168945
grad AddEdge W: 3.609506761457869e-16
grad ChooseDest W: 7.716435432434082
grad AddEdge W: 4.735897262765946e-16
grad ChooseDest W: 7.120558738708496
grad AddEdge W: 8.88579828613829e-15
grad ChooseDest W: 4.48824405670166
grad AddEdge W: 2.4204181614160235e-14
grad ChooseDest W: 5.501434326171875
grad AddEdge W: 1.8745836927549532e-14
grad ChooseDest W: 6.3489885330200195
grad AddEdge W: 5.554616333813258e-15
grad ChooseDest W: 8.418318748474121
grad AddEdge W: 7.204465202651053e-16
grad ChooseDest W: 6.466113090515137
grad AddEdge W: 7.737062579225612e-16
grad ChooseDest W: 11.496706008911133
grad AddEdge W: 2.245765187532724e-16
grad ChooseDest W: 6.734847068786621
grad AddEdge W: 2.93776437096209e-14
grad ChooseDest W: 5.422604084014893
grad AddEdge W: 2.5750343697616973e-15
grad ChooseDest W: 9.354207992553711
grad AddEdge W: 2.8133360780433804e-14
grad ChooseDest W: 5.390008449554443
grad AddEdge W: 6.4879518587007e-14
grad ChooseDest W: 2.343787431716919
=== Epoch 20: Train Loss: 5.1423, Train Log Prob: 0.0189 ===
Total mismatches: 75774
Predicted valid destination but wrong order: 25445
Epoch 20: Validation Loss: 4.9759, Validation Log Prob: 0.0107
Epoch 20: Edge Precision: 0.3921, Recall: 0.3909, F1: 0.3914, Jaccard: 0.2636
Epoch 20: TP: 2.7395848246241945, FP: 4.260844667143879, FN: 4.281889763779527
Epoch 20: Current Learning Rate: 6e-05
[Epoch 20] ‚è±Ô∏è Total: 2003.30s | Current time: 2025-07-14 22:29:09 | üèãÔ∏è Train: 1757.70s | ‚úÖ Val: 245.60s
grad AddEdge W: 5.755486555012942e-14
grad ChooseDest W: 10.334230422973633
grad AddEdge W: 2.8957165966692023e-16
grad ChooseDest W: 5.728255271911621
grad AddEdge W: 1.5543438393920636e-16
grad ChooseDest W: 6.506126880645752
grad AddEdge W: 2.0879178184850272e-16
grad ChooseDest W: 7.143601417541504
grad AddEdge W: 3.335229499263487e-14
grad ChooseDest W: 8.747554779052734
grad AddEdge W: 1.3842355572597862e-14
grad ChooseDest W: 7.88854455947876
grad AddEdge W: 1.6960581424703224e-16
grad ChooseDest W: 6.642587661743164
grad AddEdge W: 3.0716138407761945e-16
grad ChooseDest W: 4.914678573608398
grad AddEdge W: 1.0682729238189993e-16
grad ChooseDest W: 6.241859436035156
grad AddEdge W: 2.2014886048578146e-15
grad ChooseDest W: 6.220361709594727
grad AddEdge W: 3.325960364782124e-16
grad ChooseDest W: 5.657536029815674
grad AddEdge W: 2.9799491528341958e-15
grad ChooseDest W: 5.768125534057617
grad AddEdge W: 6.272497170105307e-13
grad ChooseDest W: 5.45855712890625
grad AddEdge W: 1.6814393861221176e-15
grad ChooseDest W: 6.433383464813232
grad AddEdge W: 8.835154186221956e-15
grad ChooseDest W: 2.245331287384033
grad AddEdge W: 1.5021099327491155e-14
grad ChooseDest W: 8.47270679473877
grad AddEdge W: 4.811405485453338e-16
grad ChooseDest W: 6.322968006134033
grad AddEdge W: 6.913230076154844e-15
grad ChooseDest W: 11.010427474975586
grad AddEdge W: 1.1072477155188074e-15
grad ChooseDest W: 4.631904602050781
grad AddEdge W: 1.068439881953837e-16
grad ChooseDest W: 9.709604263305664
grad AddEdge W: 1.3503494536334622e-15
grad ChooseDest W: 8.483205795288086
grad AddEdge W: 6.15452784222259e-14
grad ChooseDest W: 3.666818857192993
grad AddEdge W: 1.2962091828756881e-14
grad ChooseDest W: 4.967653751373291
grad AddEdge W: 1.1929062516505035e-15
grad ChooseDest W: 5.251401901245117
grad AddEdge W: 1.169648341575456e-16
grad ChooseDest W: 7.7181782722473145
grad AddEdge W: 4.058431650640071e-14
grad ChooseDest W: 4.238937854766846
grad AddEdge W: 6.852332642411996e-15
grad ChooseDest W: 8.536357879638672
grad AddEdge W: 1.0782967646563659e-15
grad ChooseDest W: 8.383299827575684
grad AddEdge W: 6.0695378268445146e-15
grad ChooseDest W: 8.49459457397461
grad AddEdge W: 3.966598646663541e-16
grad ChooseDest W: 5.572958469390869
grad AddEdge W: 9.731612352981492e-14
grad ChooseDest W: 3.7412302494049072
grad AddEdge W: 7.436596064153752e-15
grad ChooseDest W: 3.7799861431121826
grad AddEdge W: 5.4911136808345404e-14
grad ChooseDest W: 5.10502290725708
grad AddEdge W: 6.020880654464202e-16
grad ChooseDest W: 5.6208815574646
grad AddEdge W: 1.156072176906203e-15
grad ChooseDest W: 7.61057710647583
grad AddEdge W: 1.1502104336254954e-14
grad ChooseDest W: 8.862366676330566
grad AddEdge W: 3.671327461113224e-16
grad ChooseDest W: 4.888187885284424
grad AddEdge W: 1.3232551142881074e-14
grad ChooseDest W: 6.78093957901001
grad AddEdge W: 1.0287167498800195e-15
grad ChooseDest W: 5.625212669372559
grad AddEdge W: 7.595206795175382e-16
grad ChooseDest W: 4.892373085021973
grad AddEdge W: 2.8220427297082074e-14
grad ChooseDest W: 5.0983099937438965
grad AddEdge W: 8.653966744903328e-16
grad ChooseDest W: 6.249546527862549
grad AddEdge W: 1.6005942205923125e-16
grad ChooseDest W: 5.895365238189697
grad AddEdge W: 1.1912272205908086e-15
grad ChooseDest W: 7.388175010681152
grad AddEdge W: 4.3485096030753886e-14
grad ChooseDest W: 11.506749153137207
grad AddEdge W: 7.663395594407314e-16
grad ChooseDest W: 3.604130268096924
grad AddEdge W: 3.4461685807389347e-15
grad ChooseDest W: 5.7115092277526855
grad AddEdge W: 6.647664389004295e-16
grad ChooseDest W: 4.909486770629883
grad AddEdge W: 1.5794836184478936e-15
grad ChooseDest W: 5.8430280685424805
grad AddEdge W: 1.031312503522704e-14
grad ChooseDest W: 4.335594654083252
grad AddEdge W: 2.454989472345029e-16
grad ChooseDest W: 7.089568614959717
grad AddEdge W: 2.700607681818505e-14
grad ChooseDest W: 4.524892330169678
grad AddEdge W: 1.524649775937084e-16
grad ChooseDest W: 4.148512840270996
grad AddEdge W: 9.947297646296775e-16
grad ChooseDest W: 6.30817174911499
grad AddEdge W: 1.0612060750004974e-14
grad ChooseDest W: 7.9258012771606445
grad AddEdge W: 1.4885275900333034e-14
grad ChooseDest W: 3.916694402694702
grad AddEdge W: 1.5725713849060012e-14
grad ChooseDest W: 2.6080589294433594
grad AddEdge W: 1.453275772834474e-14
grad ChooseDest W: 7.136145114898682
grad AddEdge W: 1.5442857201901128e-16
grad ChooseDest W: 7.559621810913086
grad AddEdge W: 2.555069633788324e-14
grad ChooseDest W: 5.125169277191162
grad AddEdge W: 4.679782494680651e-14
grad ChooseDest W: 10.293767929077148
grad AddEdge W: 4.040147682143934e-15
grad ChooseDest W: 3.8143310546875
grad AddEdge W: 3.138416718347081e-13
grad ChooseDest W: 3.6715891361236572
grad AddEdge W: 4.667839753640839e-15
grad ChooseDest W: 4.470874786376953
grad AddEdge W: 6.235790150303094e-14
grad ChooseDest W: 8.386048316955566
grad AddEdge W: 9.27331935351804e-17
grad ChooseDest W: 5.075616836547852
=== Epoch 21: Train Loss: 5.1058, Train Log Prob: 0.0196 ===
Total mismatches: 75137
Predicted valid destination but wrong order: 25544
Epoch 21: Validation Loss: 4.8548, Validation Log Prob: 0.0119
Epoch 21: Edge Precision: 0.3920, Recall: 0.3909, F1: 0.3914, Jaccard: 0.2634
Epoch 21: TP: 2.740586972083035, FP: 4.260987831066571, FN: 4.280887616320687
Epoch 21: Current Learning Rate: 6e-05
[Epoch 21] ‚è±Ô∏è Total: 1994.79s | Current time: 2025-07-14 23:02:23 | üèãÔ∏è Train: 1752.84s | ‚úÖ Val: 241.95s
grad AddEdge W: 2.2367881947148692e-14
grad ChooseDest W: 10.495233535766602
grad AddEdge W: 6.929278491769116e-16
grad ChooseDest W: 4.7425360679626465
grad AddEdge W: 1.7970669537792957e-16
grad ChooseDest W: 5.456523418426514
grad AddEdge W: 7.386173886869598e-15
grad ChooseDest W: 4.173229694366455
grad AddEdge W: 2.515984314876811e-15
grad ChooseDest W: 5.679325580596924
grad AddEdge W: 8.79077633017029e-16
grad ChooseDest W: 7.84223747253418
grad AddEdge W: 5.981219480203498e-14
grad ChooseDest W: 2.5391018390655518
grad AddEdge W: 3.743376348304471e-16
grad ChooseDest W: 7.324833869934082
grad AddEdge W: 1.7664764912381047e-16
grad ChooseDest W: 8.797530174255371
grad AddEdge W: 4.962591210362632e-13
grad ChooseDest W: 5.8456196784973145
grad AddEdge W: 5.114140651219477e-14
grad ChooseDest W: 3.3716213703155518
grad AddEdge W: 3.1758745968581343e-16
grad ChooseDest W: 6.215112686157227
grad AddEdge W: 3.977975093238554e-17
grad ChooseDest W: 6.761885643005371
grad AddEdge W: 1.1564872230503576e-15
grad ChooseDest W: 5.427948474884033
grad AddEdge W: 3.1431177152054424e-16
grad ChooseDest W: 4.527307033538818
grad AddEdge W: 9.34147506552547e-17
grad ChooseDest W: 7.302097797393799
grad AddEdge W: 1.4306472876485753e-14
grad ChooseDest W: 3.97983717918396
grad AddEdge W: 1.9451786373043262e-14
grad ChooseDest W: 7.437327861785889
grad AddEdge W: 6.518038701921233e-16
grad ChooseDest W: 4.286296367645264
grad AddEdge W: 1.7646618216161924e-13
grad ChooseDest W: 2.388319969177246
grad AddEdge W: 1.3555286365894486e-15
grad ChooseDest W: 4.654783248901367
grad AddEdge W: 5.98969181545006e-12
grad ChooseDest W: 5.327356338500977
grad AddEdge W: 3.315846336111698e-14
grad ChooseDest W: 4.250144958496094
grad AddEdge W: 1.3567753896784682e-16
grad ChooseDest W: 6.63302755355835
grad AddEdge W: 1.2733117647290362e-14
grad ChooseDest W: 8.162718772888184
grad AddEdge W: 4.857739881734043e-15
grad ChooseDest W: 4.686859607696533
grad AddEdge W: 6.885805055146881e-16
grad ChooseDest W: 2.5820717811584473
grad AddEdge W: 2.0521124123156078e-16
grad ChooseDest W: 6.150042533874512
grad AddEdge W: 6.7830927811716405e-15
grad ChooseDest W: 5.196185111999512
grad AddEdge W: 1.0136500030999678e-14
grad ChooseDest W: 4.445180892944336
grad AddEdge W: 4.95325650494324e-16
grad ChooseDest W: 6.028151512145996
grad AddEdge W: 4.44837351700725e-16
grad ChooseDest W: 7.40398645401001
grad AddEdge W: 6.309514013383801e-16
grad ChooseDest W: 6.285983562469482
grad AddEdge W: 1.0512407323760506e-14
grad ChooseDest W: 7.365919589996338
grad AddEdge W: 1.5219784457796807e-14
grad ChooseDest W: 7.87378454208374
grad AddEdge W: 4.3016598004811695e-17
grad ChooseDest W: 4.7098612785339355
grad AddEdge W: 1.0035877969640465e-16
grad ChooseDest W: 3.6631240844726562
grad AddEdge W: 3.328838490092665e-17
grad ChooseDest W: 4.802944183349609
grad AddEdge W: 6.938552443750366e-16
grad ChooseDest W: 5.302640438079834
grad AddEdge W: 3.968143952396688e-15
grad ChooseDest W: 5.735109806060791
grad AddEdge W: 3.313064023462381e-16
grad ChooseDest W: 3.4248452186584473
grad AddEdge W: 3.820375412506502e-14
grad ChooseDest W: 5.639195919036865
grad AddEdge W: 2.8128220984509865e-14
grad ChooseDest W: 7.036331653594971
grad AddEdge W: 1.0385689500785368e-14
grad ChooseDest W: 2.546882152557373
grad AddEdge W: 1.5132346834838522e-16
grad ChooseDest W: 4.348982810974121
grad AddEdge W: 1.2140191037261885e-16
grad ChooseDest W: 5.212541103363037
grad AddEdge W: 9.30915175674507e-13
grad ChooseDest W: 4.913676738739014
grad AddEdge W: 4.738792230797248e-14
grad ChooseDest W: 6.281529426574707
grad AddEdge W: 6.969511773258219e-14
grad ChooseDest W: 7.023911476135254
grad AddEdge W: 6.12586456492486e-16
grad ChooseDest W: 6.527928352355957
grad AddEdge W: 2.0030541963045496e-14
grad ChooseDest W: 6.091259479522705
grad AddEdge W: 9.606883702179686e-14
grad ChooseDest W: 9.598474502563477
grad AddEdge W: 1.7162756277812005e-16
grad ChooseDest W: 11.856385231018066
grad AddEdge W: 3.802047938280612e-16
grad ChooseDest W: 5.5732293128967285
grad AddEdge W: 7.852932713825478e-12
grad ChooseDest W: 0.6129277348518372
grad AddEdge W: 1.2329017709913122e-15
grad ChooseDest W: 5.484780788421631
grad AddEdge W: 4.504965482279204e-15
grad ChooseDest W: 3.691502809524536
grad AddEdge W: 6.802065657445647e-17
grad ChooseDest W: 7.4778618812561035
grad AddEdge W: 1.1121196194854854e-12
grad ChooseDest W: 5.600829124450684
grad AddEdge W: 1.2517667193859706e-14
grad ChooseDest W: 4.855049133300781
grad AddEdge W: 4.769296301271775e-16
grad ChooseDest W: 5.021709442138672
grad AddEdge W: 4.0789091274201527e-16
grad ChooseDest W: 4.643703937530518
grad AddEdge W: 5.95401278193769e-14
grad ChooseDest W: 2.88865327835083
grad AddEdge W: 4.937519493051092e-17
grad ChooseDest W: 6.446034908294678
grad AddEdge W: 4.810789960840722e-11
grad ChooseDest W: 2.992105722427368
grad AddEdge W: 9.487732864979503e-13
grad ChooseDest W: 4.617709636688232
=== Epoch 22: Train Loss: 5.0644, Train Log Prob: 0.0203 ===
Total mismatches: 74634
Predicted valid destination but wrong order: 25482
Epoch 22: Validation Loss: 4.8338, Validation Log Prob: 0.0122
Epoch 22: Edge Precision: 0.3917, Recall: 0.3904, F1: 0.3910, Jaccard: 0.2630
Epoch 22: TP: 2.7360057265569075, FP: 4.263421617752327, FN: 4.285468861846814
Epoch 22: Current Learning Rate: 6e-05
[Epoch 22] ‚è±Ô∏è Total: 1958.40s | Current time: 2025-07-14 23:35:02 | üèãÔ∏è Train: 1716.56s | ‚úÖ Val: 241.84s
grad AddEdge W: 9.927656570082877e-13
grad ChooseDest W: 9.442275047302246
grad AddEdge W: 1.3965952079162368e-14
grad ChooseDest W: 7.385162830352783
grad AddEdge W: 5.116876271177577e-16
grad ChooseDest W: 4.640216827392578
grad AddEdge W: 1.6154489285558868e-16
grad ChooseDest W: 6.8842549324035645
grad AddEdge W: 2.44458290415972e-11
grad ChooseDest W: 2.8936045169830322
grad AddEdge W: 1.0215119765691338e-12
grad ChooseDest W: 5.1153178215026855
grad AddEdge W: 1.7876354219061204e-14
grad ChooseDest W: 5.842919826507568
grad AddEdge W: 1.869018855698082e-14
grad ChooseDest W: 4.269344806671143
grad AddEdge W: 7.414119091986293e-16
grad ChooseDest W: 3.762655258178711
grad AddEdge W: 4.8376317430827e-16
grad ChooseDest W: 7.379014492034912
grad AddEdge W: 9.209075610237946e-16
grad ChooseDest W: 6.0526323318481445
grad AddEdge W: 6.219754800172034e-14
grad ChooseDest W: 3.113696575164795
grad AddEdge W: 1.520555261021704e-14
grad ChooseDest W: 6.855589389801025
grad AddEdge W: 1.1688530358714994e-14
grad ChooseDest W: 3.866302490234375
grad AddEdge W: 2.4907377037905085e-16
grad ChooseDest W: 5.408596038818359
grad AddEdge W: 3.2047698023647347e-16
grad ChooseDest W: 5.800657749176025
grad AddEdge W: 1.3161622128537304e-13
grad ChooseDest W: 3.672187089920044
grad AddEdge W: 2.0495944745309964e-16
grad ChooseDest W: 3.5952188968658447
grad AddEdge W: 6.376942431138982e-14
grad ChooseDest W: 6.808597087860107
grad AddEdge W: 1.5337847615754256e-16
grad ChooseDest W: 4.1660051345825195
grad AddEdge W: 3.2412713637376786e-16
grad ChooseDest W: 7.38998556137085
grad AddEdge W: 1.2801532921956566e-15
grad ChooseDest W: 4.091233253479004
grad AddEdge W: 5.206035594480275e-14
grad ChooseDest W: 7.074016094207764
grad AddEdge W: 1.883664563575877e-14
grad ChooseDest W: 7.419098854064941
grad AddEdge W: 5.403970147715542e-16
grad ChooseDest W: 5.024099349975586
grad AddEdge W: 1.6452176738470346e-14
grad ChooseDest W: 8.816865921020508
grad AddEdge W: 5.713920678939572e-16
grad ChooseDest W: 7.337666988372803
grad AddEdge W: 6.34238407981407e-15
grad ChooseDest W: 6.6762871742248535
grad AddEdge W: 1.8494920728161305e-16
grad ChooseDest W: 5.4207587242126465
grad AddEdge W: 1.420657846936779e-15
grad ChooseDest W: 4.488083839416504
grad AddEdge W: 7.059294343403507e-16
grad ChooseDest W: 4.9233574867248535
grad AddEdge W: 3.174838569684524e-16
grad ChooseDest W: 4.1277360916137695
grad AddEdge W: 1.1514841170682816e-15
grad ChooseDest W: 7.56182336807251
grad AddEdge W: 1.7335243949608502e-16
grad ChooseDest W: 8.257781982421875
grad AddEdge W: 1.3052707572272824e-16
grad ChooseDest W: 4.077387809753418
grad AddEdge W: 1.8783361916480996e-16
grad ChooseDest W: 4.658266067504883
grad AddEdge W: 1.141757134809148e-16
grad ChooseDest W: 6.285975933074951
grad AddEdge W: 2.8681570562413036e-16
grad ChooseDest W: 4.279900550842285
grad AddEdge W: 2.1605955482302715e-15
grad ChooseDest W: 8.808051109313965
grad AddEdge W: 4.492776241416851e-17
grad ChooseDest W: 9.102294921875
grad AddEdge W: 2.2982007621325017e-16
grad ChooseDest W: 4.627241611480713
grad AddEdge W: 1.050687141457285e-11
grad ChooseDest W: 5.115043640136719
grad AddEdge W: 2.880494440519153e-14
grad ChooseDest W: 3.3273849487304688
grad AddEdge W: 1.309905417641588e-12
grad ChooseDest W: 3.224066972732544
grad AddEdge W: 2.696653477910838e-15
grad ChooseDest W: 11.833200454711914
grad AddEdge W: 1.6108554953527063e-16
grad ChooseDest W: 4.161076545715332
grad AddEdge W: 8.870442028790823e-17
grad ChooseDest W: 5.884016990661621
grad AddEdge W: 2.4536634422661022e-15
grad ChooseDest W: 3.791590929031372
grad AddEdge W: 4.569234199796353e-17
grad ChooseDest W: 4.235438346862793
grad AddEdge W: 2.3066052242054838e-14
grad ChooseDest W: 2.875934600830078
grad AddEdge W: 2.7459740888470877e-14
grad ChooseDest W: 4.313892841339111
grad AddEdge W: 5.130604621705892e-11
grad ChooseDest W: 3.5017735958099365
grad AddEdge W: 1.4288666285170777e-16
grad ChooseDest W: 5.923513412475586
grad AddEdge W: 2.7831427416055536e-16
grad ChooseDest W: 7.84802770614624
grad AddEdge W: 3.233164993734659e-16
grad ChooseDest W: 6.17142391204834
grad AddEdge W: 2.0527288934825313e-16
grad ChooseDest W: 6.177831172943115
grad AddEdge W: 1.675986823282405e-14
grad ChooseDest W: 8.554935455322266
grad AddEdge W: 1.419888343973978e-16
grad ChooseDest W: 7.050360679626465
grad AddEdge W: 7.599835406715653e-15
grad ChooseDest W: 9.75532054901123
grad AddEdge W: 2.235818341990263e-14
grad ChooseDest W: 6.441513538360596
grad AddEdge W: 1.456760805192657e-14
grad ChooseDest W: 6.715916633605957
grad AddEdge W: 3.713981975694142e-15
grad ChooseDest W: 5.0011820793151855
grad AddEdge W: 4.7028052737034965e-16
grad ChooseDest W: 6.8173112869262695
grad AddEdge W: 2.016267433825684e-16
grad ChooseDest W: 7.63496732711792
grad AddEdge W: 8.979174589438674e-17
grad ChooseDest W: 5.644682884216309
grad AddEdge W: 3.096064505589874e-16
grad ChooseDest W: 4.186232566833496
=== Epoch 23: Train Loss: 5.0209, Train Log Prob: 0.0211 ===
Total mismatches: 73888
Predicted valid destination but wrong order: 25660
Epoch 23: Validation Loss: 4.8292, Validation Log Prob: 0.0122
Epoch 23: Edge Precision: 0.3898, Recall: 0.3885, F1: 0.3891, Jaccard: 0.2617
Epoch 23: TP: 2.7222619899785254, FP: 4.276735862562634, FN: 4.299212598425197
Epoch 23: Current Learning Rate: 6e-05
[Epoch 23] ‚è±Ô∏è Total: 1948.60s | Current time: 2025-07-15 00:07:30 | üèãÔ∏è Train: 1706.05s | ‚úÖ Val: 242.55s
grad AddEdge W: 2.3663009485891395e-12
grad ChooseDest W: 7.510309219360352
grad AddEdge W: 3.569155858856128e-15
grad ChooseDest W: 5.0049519538879395
grad AddEdge W: 9.986266879342866e-15
grad ChooseDest W: 3.762258768081665
grad AddEdge W: 1.050236879219546e-16
grad ChooseDest W: 7.418475151062012
grad AddEdge W: 9.889438307977491e-15
grad ChooseDest W: 4.845260143280029
grad AddEdge W: 6.377602862727956e-15
grad ChooseDest W: 3.2691304683685303
grad AddEdge W: 6.215169980235136e-14
grad ChooseDest W: 4.4428935050964355
grad AddEdge W: 1.0543138526119839e-14
grad ChooseDest W: 4.227712631225586
grad AddEdge W: 1.0059897971140025e-16
grad ChooseDest W: 10.153406143188477
grad AddEdge W: 3.5225633292847473e-16
grad ChooseDest W: 4.449641704559326
grad AddEdge W: 3.704644443302288e-16
grad ChooseDest W: 5.005878448486328
grad AddEdge W: 1.015700434284232e-16
grad ChooseDest W: 5.015209197998047
grad AddEdge W: 3.4535772137044007e-13
grad ChooseDest W: 5.938342094421387
grad AddEdge W: 1.1861757913790918e-14
grad ChooseDest W: 3.2500152587890625
grad AddEdge W: 1.0508870961205719e-14
grad ChooseDest W: 4.5061163902282715
grad AddEdge W: 2.180673176754855e-12
grad ChooseDest W: 3.485567808151245
grad AddEdge W: 2.5236788151092283e-16
grad ChooseDest W: 4.209597110748291
grad AddEdge W: 3.0181677029307834e-15
grad ChooseDest W: 5.914383888244629
grad AddEdge W: 1.0131649073310753e-15
grad ChooseDest W: 9.925592422485352
grad AddEdge W: 7.705244315957596e-16
grad ChooseDest W: 5.378117084503174
grad AddEdge W: 1.900088871236317e-14
grad ChooseDest W: 5.25170373916626
grad AddEdge W: 2.3617280955337203e-14
grad ChooseDest W: 4.6387176513671875
grad AddEdge W: 2.5993712674626487e-16
grad ChooseDest W: 7.243468284606934
grad AddEdge W: 1.811265608255442e-16
grad ChooseDest W: 6.372529983520508
grad AddEdge W: 7.799201551510898e-15
grad ChooseDest W: 7.730173110961914
grad AddEdge W: 1.6129648615012537e-14
grad ChooseDest W: 6.875456809997559
grad AddEdge W: 1.6062580916825856e-16
grad ChooseDest W: 8.312744140625
grad AddEdge W: 1.7415034664998094e-14
grad ChooseDest W: 8.131980895996094
grad AddEdge W: 3.1282197291522193e-16
grad ChooseDest W: 4.357020378112793
grad AddEdge W: 1.1273901801803383e-14
grad ChooseDest W: 5.7191877365112305
grad AddEdge W: 9.373776931666808e-16
grad ChooseDest W: 5.151428699493408
grad AddEdge W: 8.753390942856445e-15
grad ChooseDest W: 5.165724754333496
grad AddEdge W: 1.0357645730679765e-12
grad ChooseDest W: 5.603105068206787
grad AddEdge W: 3.453067692893441e-12
grad ChooseDest W: 7.487362384796143
grad AddEdge W: 1.9941982974344165e-14
grad ChooseDest W: 8.41453742980957
grad AddEdge W: 1.7743566557986042e-14
grad ChooseDest W: 5.8278398513793945
grad AddEdge W: 9.473671847004539e-12
grad ChooseDest W: 5.508970260620117
grad AddEdge W: 1.3354738345440026e-16
grad ChooseDest W: 6.141611576080322
grad AddEdge W: 6.298400115258701e-14
grad ChooseDest W: 4.283605575561523
grad AddEdge W: 1.3904547431502792e-16
grad ChooseDest W: 4.898610591888428
grad AddEdge W: 6.698719696946742e-17
grad ChooseDest W: 8.247498512268066
grad AddEdge W: 1.190830253306122e-16
grad ChooseDest W: 3.2807605266571045
grad AddEdge W: 7.426635803726989e-15
grad ChooseDest W: 7.898061275482178
grad AddEdge W: 4.75086962889985e-16
grad ChooseDest W: 6.883918762207031
grad AddEdge W: 8.679199856402033e-17
grad ChooseDest W: 5.719884395599365
grad AddEdge W: 3.086313282306581e-14
grad ChooseDest W: 4.62051248550415
grad AddEdge W: 6.824476958089914e-17
grad ChooseDest W: 9.137796401977539
grad AddEdge W: 2.5611951795512233e-12
grad ChooseDest W: 5.450606822967529
grad AddEdge W: 9.079127785937131e-17
grad ChooseDest W: 6.846194267272949
grad AddEdge W: 2.3542454911809705e-16
grad ChooseDest W: 6.4643354415893555
grad AddEdge W: 6.696342710738509e-17
grad ChooseDest W: 6.900667667388916
grad AddEdge W: 3.869530682611448e-15
grad ChooseDest W: 4.161834716796875
grad AddEdge W: 1.7132567811813625e-14
grad ChooseDest W: 10.647859573364258
grad AddEdge W: 2.618520300119904e-16
grad ChooseDest W: 6.679978370666504
grad AddEdge W: 6.547959081991807e-16
grad ChooseDest W: 5.709392070770264
grad AddEdge W: 3.088064411751955e-17
grad ChooseDest W: 6.315485954284668
grad AddEdge W: 8.334678469529207e-17
grad ChooseDest W: 6.062599182128906
grad AddEdge W: 2.6150597073092274e-17
grad ChooseDest W: 4.251348495483398
grad AddEdge W: 2.2101391829415333e-14
grad ChooseDest W: 3.0332095623016357
grad AddEdge W: 1.755521861776868e-14
grad ChooseDest W: 6.1410441398620605
grad AddEdge W: 5.377646084250552e-17
grad ChooseDest W: 5.055044651031494
grad AddEdge W: 5.900475847454289e-17
grad ChooseDest W: 6.936774730682373
grad AddEdge W: 5.061214030444353e-16
grad ChooseDest W: 4.247823715209961
grad AddEdge W: 1.8927054438537788e-16
grad ChooseDest W: 3.835906744003296
grad AddEdge W: 7.049704024616457e-15
grad ChooseDest W: 4.478625774383545
grad AddEdge W: 5.969092424794363e-15
grad ChooseDest W: 4.513601303100586
=== Epoch 24: Train Loss: 4.9806, Train Log Prob: 0.0220 ===
Total mismatches: 73232
Predicted valid destination but wrong order: 25675
Epoch 24: Validation Loss: 4.7617, Validation Log Prob: 0.0131
Epoch 24: Edge Precision: 0.3898, Recall: 0.3884, F1: 0.3890, Jaccard: 0.2616
Epoch 24: TP: 2.7225483178239083, FP: 4.275161059413028, FN: 4.2989262705798135
Epoch 24: Current Learning Rate: 6e-05
[Epoch 24] ‚è±Ô∏è Total: 1943.29s | Current time: 2025-07-15 00:39:54 | üèãÔ∏è Train: 1698.55s | ‚úÖ Val: 244.74s
grad AddEdge W: 8.736365580616634e-15
grad ChooseDest W: 11.890732765197754
grad AddEdge W: 3.406162367607167e-15
grad ChooseDest W: 4.074794292449951
grad AddEdge W: 1.6289777652592121e-15
grad ChooseDest W: 6.496689319610596
grad AddEdge W: 5.731687300887349e-15
grad ChooseDest W: 6.144866943359375
grad AddEdge W: 5.422634624587409e-15
grad ChooseDest W: 2.6541709899902344
grad AddEdge W: 7.907154206572564e-15
grad ChooseDest W: 4.466172695159912
grad AddEdge W: 6.010190039878668e-14
grad ChooseDest W: 8.907177925109863
grad AddEdge W: 1.885686431220973e-14
grad ChooseDest W: 5.388262748718262
grad AddEdge W: 6.674904836239095e-17
grad ChooseDest W: 4.1533403396606445
grad AddEdge W: 2.3235122159626087e-11
grad ChooseDest W: 4.311352252960205
grad AddEdge W: 4.3131427217446306e-17
grad ChooseDest W: 6.1892595291137695
grad AddEdge W: 2.0963974388502104e-15
grad ChooseDest W: 3.489447832107544
grad AddEdge W: 1.157322414985229e-11
grad ChooseDest W: 6.1689372062683105
grad AddEdge W: 8.34866271879058e-16
grad ChooseDest W: 5.925856590270996
grad AddEdge W: 5.893315163267099e-15
grad ChooseDest W: 4.06595516204834
grad AddEdge W: 8.452574073781777e-16
grad ChooseDest W: 6.18539571762085
grad AddEdge W: 1.0178062243655552e-14
grad ChooseDest W: 7.245612621307373
grad AddEdge W: 6.042709884655027e-17
grad ChooseDest W: 6.4039626121521
grad AddEdge W: 7.057854387393175e-17
grad ChooseDest W: 6.679530143737793
grad AddEdge W: 3.33007039098835e-14
grad ChooseDest W: 5.725635528564453
grad AddEdge W: 6.875668188350615e-17
grad ChooseDest W: 9.167863845825195
grad AddEdge W: 1.2657154038514702e-14
grad ChooseDest W: 7.077940464019775
grad AddEdge W: 4.665104565669542e-13
grad ChooseDest W: 3.0438497066497803
grad AddEdge W: 8.091889048344073e-17
grad ChooseDest W: 4.729734420776367
grad AddEdge W: 3.685664647827894e-14
grad ChooseDest W: 3.2204511165618896
grad AddEdge W: 2.0583958085974586e-16
grad ChooseDest W: 6.273744106292725
grad AddEdge W: 1.247406760226789e-16
grad ChooseDest W: 4.532894134521484
grad AddEdge W: 1.6796880184487273e-14
grad ChooseDest W: 5.488613605499268
grad AddEdge W: 1.0550305563054133e-16
grad ChooseDest W: 4.838807106018066
grad AddEdge W: 6.240694571652859e-17
grad ChooseDest W: 4.969865798950195
grad AddEdge W: 3.252733640161237e-13
grad ChooseDest W: 4.990118026733398
grad AddEdge W: 1.8466658679782777e-15
grad ChooseDest W: 4.789472579956055
grad AddEdge W: 3.9683546518423174e-16
grad ChooseDest W: 5.0673298835754395
grad AddEdge W: 2.226497305565057e-16
grad ChooseDest W: 6.684996128082275
grad AddEdge W: 6.112907078414237e-17
grad ChooseDest W: 4.427380084991455
grad AddEdge W: 2.6417634135881543e-16
grad ChooseDest W: 4.935490608215332
grad AddEdge W: 3.568049263250099e-16
grad ChooseDest W: 6.050053596496582
grad AddEdge W: 2.8602394687064032e-15
grad ChooseDest W: 4.603198051452637
grad AddEdge W: 5.850832437555797e-16
grad ChooseDest W: 4.59426736831665
grad AddEdge W: 1.1199427276948996e-14
grad ChooseDest W: 5.561395168304443
grad AddEdge W: 2.975306226437116e-14
grad ChooseDest W: 5.218680381774902
grad AddEdge W: 7.177235210979196e-16
grad ChooseDest W: 6.637007236480713
grad AddEdge W: 6.883613357395861e-16
grad ChooseDest W: 6.123237609863281
grad AddEdge W: 3.1475071987567917e-16
grad ChooseDest W: 7.49798059463501
grad AddEdge W: 1.9659579119235147e-16
grad ChooseDest W: 10.480295181274414
grad AddEdge W: 1.7676873513059843e-16
grad ChooseDest W: 6.968066215515137
grad AddEdge W: 2.349199631210882e-14
grad ChooseDest W: 5.517159938812256
grad AddEdge W: 2.7224777337034323e-14
grad ChooseDest W: 3.7207393646240234
grad AddEdge W: 4.4963968969847796e-15
grad ChooseDest W: 4.400664329528809
grad AddEdge W: 5.3863556952367386e-14
grad ChooseDest W: 3.6990222930908203
grad AddEdge W: 3.577932814255577e-15
grad ChooseDest W: 6.690091133117676
grad AddEdge W: 1.5108340068228763e-16
grad ChooseDest W: 5.565352439880371
grad AddEdge W: 3.67361450301037e-15
grad ChooseDest W: 7.434763431549072
grad AddEdge W: 9.786488229502309e-15
grad ChooseDest W: 3.17155122756958
grad AddEdge W: 3.0378186555488464e-15
grad ChooseDest W: 9.246265411376953
grad AddEdge W: 5.2441696818394945e-12
grad ChooseDest W: 4.227731227874756
grad AddEdge W: 1.2118845118776807e-14
grad ChooseDest W: 3.9598517417907715
grad AddEdge W: 6.392668164258042e-17
grad ChooseDest W: 6.742807388305664
grad AddEdge W: 1.1607219378003759e-16
grad ChooseDest W: 3.60074782371521
grad AddEdge W: 3.380824859297712e-15
grad ChooseDest W: 5.494296073913574
grad AddEdge W: 1.3574132848970894e-15
grad ChooseDest W: 10.976339340209961
grad AddEdge W: 3.038084920355816e-13
grad ChooseDest W: 3.3849644660949707
grad AddEdge W: 2.127769130466566e-16
grad ChooseDest W: 4.79664421081543
grad AddEdge W: 1.9209656922872936e-14
grad ChooseDest W: 7.329874038696289
grad AddEdge W: 3.630829492416016e-16
grad ChooseDest W: 7.23240327835083
grad AddEdge W: 1.8180543126298891e-16
grad ChooseDest W: 7.5816731452941895
=== Epoch 25: Train Loss: 4.9391, Train Log Prob: 0.0228 ===
Total mismatches: 72428
Predicted valid destination but wrong order: 25859
Epoch 25: Validation Loss: 4.6886, Validation Log Prob: 0.0138
Epoch 25: Edge Precision: 0.3906, Recall: 0.3893, F1: 0.3899, Jaccard: 0.2624
Epoch 25: TP: 2.7294201861130993, FP: 4.268432355046528, FN: 4.292054402290622
Epoch 25: Current Learning Rate: 6e-05
üíæ Checkpoint saved: /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/checkpoint_epoch_25.pth
[Epoch 25] ‚è±Ô∏è Total: 1930.65s | Current time: 2025-07-15 01:12:04 | üèãÔ∏è Train: 1684.41s | ‚úÖ Val: 246.25s
grad AddEdge W: 1.8995860724788267e-14
grad ChooseDest W: 12.133565902709961
grad AddEdge W: 1.2076451543283203e-15
grad ChooseDest W: 4.640346527099609
grad AddEdge W: 6.020147044522541e-17
grad ChooseDest W: 10.041884422302246
grad AddEdge W: 7.0017005499131875e-15
grad ChooseDest W: 6.808473587036133
grad AddEdge W: 1.7184114848851732e-14
grad ChooseDest W: 6.107247352600098
grad AddEdge W: 1.506085593060128e-16
grad ChooseDest W: 3.3841710090637207
grad AddEdge W: 4.778706307920178e-16
grad ChooseDest W: 6.059175968170166
grad AddEdge W: 3.6305488068731195e-15
grad ChooseDest W: 4.66383695602417
grad AddEdge W: 3.950904979035491e-16
grad ChooseDest W: 3.889090061187744
grad AddEdge W: 4.312376736086143e-13
grad ChooseDest W: 5.4917497634887695
grad AddEdge W: 2.7869243201985704e-15
grad ChooseDest W: 4.85560417175293
grad AddEdge W: 4.678089381698208e-16
grad ChooseDest W: 8.285215377807617
grad AddEdge W: 2.2602415772343676e-10
grad ChooseDest W: 2.729393482208252
grad AddEdge W: 2.949432911555008e-17
grad ChooseDest W: 4.440005779266357
grad AddEdge W: 2.5062400478515975e-14
grad ChooseDest W: 4.991046905517578
grad AddEdge W: 6.466586744331454e-16
grad ChooseDest W: 6.6025309562683105
grad AddEdge W: 8.106073541488132e-17
grad ChooseDest W: 9.522377967834473
grad AddEdge W: 4.223955102247538e-14
grad ChooseDest W: 3.366978645324707
grad AddEdge W: 3.198972126538575e-16
grad ChooseDest W: 5.094055652618408
grad AddEdge W: 5.232353861063532e-16
grad ChooseDest W: 10.492865562438965
grad AddEdge W: 9.140109525928011e-17
grad ChooseDest W: 4.6304144859313965
grad AddEdge W: 7.531388707127107e-14
grad ChooseDest W: 2.1617860794067383
grad AddEdge W: 7.939529658701196e-17
grad ChooseDest W: 8.363261222839355
grad AddEdge W: 3.260169727582106e-16
grad ChooseDest W: 5.953456401824951
grad AddEdge W: 9.010194391805004e-15
grad ChooseDest W: 4.545234680175781
grad AddEdge W: 6.604565235065628e-16
grad ChooseDest W: 4.839438438415527
grad AddEdge W: 1.3768243948421814e-16
grad ChooseDest W: 4.607614517211914
grad AddEdge W: 1.850934543455525e-16
grad ChooseDest W: 8.989867210388184
grad AddEdge W: 1.065853660078787e-14
grad ChooseDest W: 5.374544143676758
grad AddEdge W: 8.697533487498659e-17
grad ChooseDest W: 4.361739635467529
grad AddEdge W: 1.2999400083132966e-16
grad ChooseDest W: 5.401260852813721
grad AddEdge W: 1.3110775651274046e-16
grad ChooseDest W: 7.555948734283447
grad AddEdge W: 8.185178477827803e-16
grad ChooseDest W: 7.266189098358154
grad AddEdge W: 8.534740398951062e-15
grad ChooseDest W: 4.501486778259277
grad AddEdge W: 4.985282555981129e-17
grad ChooseDest W: 9.38082504272461
grad AddEdge W: 7.717751710335872e-15
grad ChooseDest W: 5.9817118644714355
grad AddEdge W: 2.1649865670288378e-15
grad ChooseDest W: 5.32300329208374
grad AddEdge W: 1.0469278258970889e-16
grad ChooseDest W: 6.37091064453125
grad AddEdge W: 4.996113301579874e-15
grad ChooseDest W: 3.7966365814208984
grad AddEdge W: 8.405717402279751e-17
grad ChooseDest W: 4.575240135192871
grad AddEdge W: 3.033919889947577e-14
grad ChooseDest W: 8.555597305297852
grad AddEdge W: 1.5630467058784075e-16
grad ChooseDest W: 6.5236101150512695
grad AddEdge W: 4.261686131943422e-17
grad ChooseDest W: 2.9583468437194824
grad AddEdge W: 4.593812885699076e-15
grad ChooseDest W: 6.447299003601074
grad AddEdge W: 5.769162579572721e-15
grad ChooseDest W: 4.777820110321045
grad AddEdge W: 1.030643220439431e-15
grad ChooseDest W: 5.374978542327881
grad AddEdge W: 2.5182845387241985e-16
grad ChooseDest W: 10.164457321166992
grad AddEdge W: 6.070763880565886e-17
grad ChooseDest W: 5.4296746253967285
grad AddEdge W: 3.4109415392538124e-15
grad ChooseDest W: 7.7362380027771
grad AddEdge W: 1.605267873109554e-14
grad ChooseDest W: 3.0584917068481445
grad AddEdge W: 5.880154812365609e-15
grad ChooseDest W: 7.738195896148682
grad AddEdge W: 9.331283406285428e-15
grad ChooseDest W: 6.839643955230713
grad AddEdge W: 2.047182681621379e-13
grad ChooseDest W: 5.606813907623291
grad AddEdge W: 6.076116202350247e-16
grad ChooseDest W: 7.161709308624268
grad AddEdge W: 2.609111352262685e-16
grad ChooseDest W: 6.193718910217285
grad AddEdge W: 1.6348289100401672e-16
grad ChooseDest W: 9.10007381439209
grad AddEdge W: 1.4636699550052258e-17
grad ChooseDest W: 5.665091037750244
grad AddEdge W: 1.0368137892857295e-16
grad ChooseDest W: 8.042712211608887
grad AddEdge W: 2.7254807619629803e-15
grad ChooseDest W: 4.530529499053955
grad AddEdge W: 4.76272544318345e-16
grad ChooseDest W: 6.0555806159973145
grad AddEdge W: 1.0920545914230254e-15
grad ChooseDest W: 4.488899230957031
grad AddEdge W: 1.1938407619253855e-13
grad ChooseDest W: 5.96415901184082
grad AddEdge W: 2.869243706868402e-17
grad ChooseDest W: 4.828976631164551
grad AddEdge W: 2.6364323999763725e-16
grad ChooseDest W: 4.909396171569824
grad AddEdge W: 7.822155509106779e-16
grad ChooseDest W: 4.8424530029296875
grad AddEdge W: 1.0021591964891633e-15
grad ChooseDest W: 5.187839031219482
=== Epoch 26: Train Loss: 4.8884, Train Log Prob: 0.0238 ===
Total mismatches: 71466
Predicted valid destination but wrong order: 26013
Epoch 26: Validation Loss: 4.6525, Validation Log Prob: 0.0144
Epoch 26: Edge Precision: 0.3865, Recall: 0.3849, F1: 0.3857, Jaccard: 0.2583
Epoch 26: TP: 2.697494631352899, FP: 4.296349319971367, FN: 4.323979957050823
Epoch 26: Current Learning Rate: 6e-05
[Epoch 26] ‚è±Ô∏è Total: 1941.84s | Current time: 2025-07-15 01:44:26 | üèãÔ∏è Train: 1695.70s | ‚úÖ Val: 246.14s
grad AddEdge W: 1.0343941279694277e-13
grad ChooseDest W: 12.422935485839844
grad AddEdge W: 7.713884157898709e-15
grad ChooseDest W: 8.888870239257812
grad AddEdge W: 6.626269395547835e-16
grad ChooseDest W: 4.443708896636963
grad AddEdge W: 3.4030468480782675e-17
grad ChooseDest W: 6.9171061515808105
grad AddEdge W: 7.308095236824644e-15
grad ChooseDest W: 6.076071262359619
grad AddEdge W: 2.579248246177724e-17
grad ChooseDest W: 4.727444171905518
grad AddEdge W: 2.6759126056478955e-15
grad ChooseDest W: 7.02470064163208
grad AddEdge W: 2.374237056922948e-16
grad ChooseDest W: 6.547085762023926
grad AddEdge W: 1.4228816260606768e-15
grad ChooseDest W: 4.635250568389893
grad AddEdge W: 2.519838050089022e-16
grad ChooseDest W: 5.351097583770752
grad AddEdge W: 2.3306130072547795e-16
grad ChooseDest W: 4.731548309326172
grad AddEdge W: 4.670417910174044e-17
grad ChooseDest W: 7.001489639282227
grad AddEdge W: 2.385855172585725e-16
grad ChooseDest W: 6.852614402770996
grad AddEdge W: 2.326942442917412e-16
grad ChooseDest W: 4.03774881362915
grad AddEdge W: 5.690557922067522e-16
grad ChooseDest W: 4.205685615539551
grad AddEdge W: 1.1210535538069832e-12
grad ChooseDest W: 4.001483917236328
grad AddEdge W: 8.210164149826792e-15
grad ChooseDest W: 2.9383387565612793
grad AddEdge W: 4.4777423992198225e-17
grad ChooseDest W: 5.8675537109375
grad AddEdge W: 1.5859717849447431e-16
grad ChooseDest W: 6.588278293609619
grad AddEdge W: 8.418531422584933e-17
grad ChooseDest W: 4.224165916442871
grad AddEdge W: 1.2556867438201502e-12
grad ChooseDest W: 4.410515785217285
grad AddEdge W: 9.031684464709793e-15
grad ChooseDest W: 6.335582733154297
grad AddEdge W: 2.787156618984355e-17
grad ChooseDest W: 5.491881370544434
grad AddEdge W: 3.57015387542623e-16
grad ChooseDest W: 7.110065460205078
grad AddEdge W: 5.123097939933397e-15
grad ChooseDest W: 4.003103733062744
grad AddEdge W: 1.2359144130748116e-14
grad ChooseDest W: 6.036403656005859
grad AddEdge W: 2.74413708614273e-15
grad ChooseDest W: 6.887387752532959
grad AddEdge W: 1.7898687619144103e-16
grad ChooseDest W: 6.079872131347656
grad AddEdge W: 2.4094817802208443e-14
grad ChooseDest W: 5.450533390045166
grad AddEdge W: 3.792951704399607e-15
grad ChooseDest W: 5.4257354736328125
grad AddEdge W: 1.2880482745387771e-14
grad ChooseDest W: 3.2900969982147217
grad AddEdge W: 8.778066706675858e-15
grad ChooseDest W: 5.064239025115967
grad AddEdge W: 2.3247500251883865e-14
grad ChooseDest W: 8.041829109191895
grad AddEdge W: 2.4547433245705567e-14
grad ChooseDest W: 4.375014305114746
grad AddEdge W: 1.2774738325071932e-17
grad ChooseDest W: 6.656708717346191
grad AddEdge W: 1.0138234622126757e-16
grad ChooseDest W: 6.443552494049072
grad AddEdge W: 3.047431285183727e-13
grad ChooseDest W: 5.72197961807251
grad AddEdge W: 5.161587434693987e-16
grad ChooseDest W: 6.711706638336182
grad AddEdge W: 3.2703069649552864e-15
grad ChooseDest W: 3.9901516437530518
grad AddEdge W: 1.0736146841612993e-14
grad ChooseDest W: 2.6244864463806152
grad AddEdge W: 5.022279366930421e-17
grad ChooseDest W: 8.578446388244629
grad AddEdge W: 6.138262268536466e-15
grad ChooseDest W: 3.2998600006103516
grad AddEdge W: 1.2436255522106865e-16
grad ChooseDest W: 6.6555070877075195
grad AddEdge W: 4.772182036643952e-16
grad ChooseDest W: 5.747817516326904
grad AddEdge W: 2.0143403015217824e-16
grad ChooseDest W: 6.431197166442871
grad AddEdge W: 5.985347834085121e-15
grad ChooseDest W: 10.916848182678223
grad AddEdge W: 1.3940142138226582e-14
grad ChooseDest W: 4.936686038970947
grad AddEdge W: 1.2434536839317327e-14
grad ChooseDest W: 4.360766887664795
grad AddEdge W: 5.833192002341336e-12
grad ChooseDest W: 5.02048397064209
grad AddEdge W: 3.8957056947475e-15
grad ChooseDest W: 6.432894706726074
grad AddEdge W: 1.284128417817121e-16
grad ChooseDest W: 9.565115928649902
grad AddEdge W: 1.1032176386348898e-15
grad ChooseDest W: 6.206725597381592
grad AddEdge W: 2.4334378370856335e-13
grad ChooseDest W: 5.488025665283203
grad AddEdge W: 8.674300300197759e-17
grad ChooseDest W: 5.162430286407471
grad AddEdge W: 1.5617834356469165e-16
grad ChooseDest W: 5.8685994148254395
grad AddEdge W: 4.1506509058757135e-13
grad ChooseDest W: 1.7600916624069214
grad AddEdge W: 1.0107995170038908e-12
grad ChooseDest W: 2.874704599380493
grad AddEdge W: 1.8385314664786599e-16
grad ChooseDest W: 6.108063697814941
grad AddEdge W: 1.2432086796517394e-15
grad ChooseDest W: 5.579597473144531
grad AddEdge W: 6.022726551014506e-15
grad ChooseDest W: 5.4634599685668945
grad AddEdge W: 1.8723454928951284e-14
grad ChooseDest W: 7.760451793670654
grad AddEdge W: 5.4268274376763175e-15
grad ChooseDest W: 10.329894065856934
grad AddEdge W: 7.233699486034351e-15
grad ChooseDest W: 5.525273323059082
grad AddEdge W: 2.1521655375260178e-14
grad ChooseDest W: 5.935189723968506
grad AddEdge W: 1.6226927807905852e-15
grad ChooseDest W: 4.321841239929199
grad AddEdge W: 2.2797464950153416e-17
grad ChooseDest W: 7.415994167327881
=== Epoch 27: Train Loss: 4.8448, Train Log Prob: 0.0249 ===
Total mismatches: 70852
Predicted valid destination but wrong order: 26048
Epoch 27: Validation Loss: 4.5932, Validation Log Prob: 0.0152
Epoch 27: Edge Precision: 0.3868, Recall: 0.3849, F1: 0.3858, Jaccard: 0.2588
Epoch 27: TP: 2.6990694345025052, FP: 4.288188976377953, FN: 4.322405153901217
Epoch 27: Current Learning Rate: 6e-05
[Epoch 27] ‚è±Ô∏è Total: 1937.66s | Current time: 2025-07-15 02:16:44 | üèãÔ∏è Train: 1694.54s | ‚úÖ Val: 243.11s
grad AddEdge W: 1.6784539253258957e-12
grad ChooseDest W: 11.377805709838867
grad AddEdge W: 6.711601506357483e-15
grad ChooseDest W: 5.737153053283691
grad AddEdge W: 2.017304890367393e-15
grad ChooseDest W: 3.8610246181488037
grad AddEdge W: 9.094835006092337e-15
grad ChooseDest W: 5.865433216094971
grad AddEdge W: 5.94058748971821e-17
grad ChooseDest W: 6.893646717071533
grad AddEdge W: 7.539681800249393e-17
grad ChooseDest W: 3.5143425464630127
grad AddEdge W: 6.980462045793733e-17
grad ChooseDest W: 6.968574047088623
grad AddEdge W: 5.631671344541456e-15
grad ChooseDest W: 4.75288200378418
grad AddEdge W: 3.0694594654144124e-16
grad ChooseDest W: 5.282863140106201
grad AddEdge W: 4.0899978474908956e-16
grad ChooseDest W: 8.381675720214844
grad AddEdge W: 1.2131003376762136e-16
grad ChooseDest W: 7.242805004119873
grad AddEdge W: 4.0701055264817654e-13
grad ChooseDest W: 4.424898147583008
grad AddEdge W: 1.1356137636613903e-16
grad ChooseDest W: 7.243294715881348
grad AddEdge W: 9.625139782116034e-17
grad ChooseDest W: 5.766979694366455
grad AddEdge W: 7.31563563000022e-16
grad ChooseDest W: 5.026167869567871
grad AddEdge W: 5.0284349141767955e-17
grad ChooseDest W: 5.112468242645264
grad AddEdge W: 8.523812323972722e-17
grad ChooseDest W: 2.3314833641052246
grad AddEdge W: 3.288623628923187e-15
grad ChooseDest W: 5.801506042480469
grad AddEdge W: 3.82261822022556e-13
grad ChooseDest W: 3.322188377380371
grad AddEdge W: 2.098571375379118e-16
grad ChooseDest W: 8.717041969299316
grad AddEdge W: 1.18446453600971e-16
grad ChooseDest W: 4.443909168243408
grad AddEdge W: 8.478021590495257e-17
grad ChooseDest W: 3.9661848545074463
grad AddEdge W: 2.9844787673987566e-16
grad ChooseDest W: 5.810880661010742
grad AddEdge W: 8.603577019568965e-17
grad ChooseDest W: 6.640020847320557
grad AddEdge W: 5.33737550684199e-13
grad ChooseDest W: 5.327023983001709
grad AddEdge W: 5.2402391422324285e-17
grad ChooseDest W: 5.373690605163574
grad AddEdge W: 1.6422577595645018e-15
grad ChooseDest W: 2.5155160427093506
grad AddEdge W: 2.475583225572945e-16
grad ChooseDest W: 5.271029949188232
grad AddEdge W: 2.27031511401991e-14
grad ChooseDest W: 5.246951103210449
grad AddEdge W: 1.0848287651082358e-15
grad ChooseDest W: 4.892916202545166
grad AddEdge W: 3.662344475537267e-14
grad ChooseDest W: 6.056159496307373
grad AddEdge W: 4.0641727721939247e-13
grad ChooseDest W: 6.3132829666137695
grad AddEdge W: 5.2137336284282693e-17
grad ChooseDest W: 5.521768569946289
grad AddEdge W: 7.473724403437885e-17
grad ChooseDest W: 6.206390380859375
grad AddEdge W: 4.7883993426869726e-17
grad ChooseDest W: 5.0835137367248535
grad AddEdge W: 2.8750523808879864e-15
grad ChooseDest W: 6.611029624938965
grad AddEdge W: 3.182695535071389e-13
grad ChooseDest W: 4.936470031738281
grad AddEdge W: 1.541407009897442e-14
grad ChooseDest W: 5.784450054168701
grad AddEdge W: 1.5602083514117175e-16
grad ChooseDest W: 8.035829544067383
grad AddEdge W: 2.086923163576934e-15
grad ChooseDest W: 5.045292377471924
grad AddEdge W: 8.990261588973742e-16
grad ChooseDest W: 7.246764183044434
grad AddEdge W: 2.758158975430696e-16
grad ChooseDest W: 8.07781982421875
grad AddEdge W: 4.124056883481313e-15
grad ChooseDest W: 5.939769268035889
grad AddEdge W: 2.048870843696245e-15
grad ChooseDest W: 2.7528176307678223
grad AddEdge W: 1.5223645075151715e-16
grad ChooseDest W: 6.9034647941589355
grad AddEdge W: 9.549929715026075e-15
grad ChooseDest W: 3.2512991428375244
grad AddEdge W: 1.873888838541096e-17
grad ChooseDest W: 6.423160552978516
grad AddEdge W: 1.0992542655955686e-15
grad ChooseDest W: 5.8865580558776855
grad AddEdge W: 4.0849292155694156e-17
grad ChooseDest W: 6.633146286010742
grad AddEdge W: 7.777937609933247e-17
grad ChooseDest W: 8.150193214416504
grad AddEdge W: 1.3342754152725358e-17
grad ChooseDest W: 3.8062353134155273
grad AddEdge W: 6.200337289834234e-16
grad ChooseDest W: 4.452686786651611
grad AddEdge W: 8.811033228982995e-15
grad ChooseDest W: 4.464066982269287
grad AddEdge W: 1.2449443772156055e-14
grad ChooseDest W: 7.425092697143555
grad AddEdge W: 5.180012201241781e-15
grad ChooseDest W: 3.7326791286468506
grad AddEdge W: 2.7483886489074646e-17
grad ChooseDest W: 11.230236053466797
grad AddEdge W: 1.7159080154820921e-15
grad ChooseDest W: 4.420729160308838
grad AddEdge W: 2.0013380149091838e-17
grad ChooseDest W: 4.698047161102295
grad AddEdge W: 4.27925793758388e-12
grad ChooseDest W: 7.4515790939331055
grad AddEdge W: 5.582630042719563e-17
grad ChooseDest W: 5.59263801574707
grad AddEdge W: 5.46349327050147e-16
grad ChooseDest W: 3.8068535327911377
grad AddEdge W: 2.3890323402313166e-16
grad ChooseDest W: 5.849160194396973
grad AddEdge W: 5.6895080247294e-15
grad ChooseDest W: 10.404379844665527
grad AddEdge W: 1.0363991057775555e-14
grad ChooseDest W: 4.298664093017578
grad AddEdge W: 2.713933002974385e-16
grad ChooseDest W: 4.351502418518066
grad AddEdge W: 1.0987941017120829e-16
grad ChooseDest W: 5.161208629608154
=== Epoch 28: Train Loss: 4.8017, Train Log Prob: 0.0256 ===
Total mismatches: 70214
Predicted valid destination but wrong order: 26045
Epoch 28: Validation Loss: 4.4945, Validation Log Prob: 0.0164
Epoch 28: Edge Precision: 0.3836, Recall: 0.3820, F1: 0.3828, Jaccard: 0.2556
Epoch 28: TP: 2.677165354330709, FP: 4.314101646385111, FN: 4.344309234073013
Epoch 28: Current Learning Rate: 6e-05
[Epoch 28] ‚è±Ô∏è Total: 1940.86s | Current time: 2025-07-15 02:49:05 | üèãÔ∏è Train: 1698.29s | ‚úÖ Val: 242.56s
grad AddEdge W: 3.276306075804215e-15
grad ChooseDest W: 10.911142349243164
grad AddEdge W: 5.69676243840616e-17
grad ChooseDest W: 4.446415901184082
grad AddEdge W: 1.858189380648758e-16
grad ChooseDest W: 9.594033241271973
grad AddEdge W: 2.2025475813303397e-16
grad ChooseDest W: 6.038347244262695
grad AddEdge W: 3.3452207610961196e-14
grad ChooseDest W: 2.9539241790771484
grad AddEdge W: 4.865117962221102e-16
grad ChooseDest W: 6.22588586807251
grad AddEdge W: 6.858994344783914e-16
grad ChooseDest W: 3.8565523624420166
grad AddEdge W: 1.1524214119639777e-16
grad ChooseDest W: 6.2989349365234375
grad AddEdge W: 6.24457358550459e-16
grad ChooseDest W: 7.50779390335083
grad AddEdge W: 1.9837623856561225e-15
grad ChooseDest W: 5.635929107666016
grad AddEdge W: 4.777809511787273e-16
grad ChooseDest W: 6.3878302574157715
grad AddEdge W: 2.41262793163749e-13
grad ChooseDest W: 3.9371938705444336
grad AddEdge W: 3.8505358840659754e-13
grad ChooseDest W: 3.7826051712036133
grad AddEdge W: 5.512592488201131e-15
grad ChooseDest W: 4.630966663360596
grad AddEdge W: 3.3637598982676166e-15
grad ChooseDest W: 5.071864604949951
grad AddEdge W: 1.2736061510298545e-16
grad ChooseDest W: 5.773775577545166
grad AddEdge W: 8.853934150742225e-17
grad ChooseDest W: 4.96337890625
grad AddEdge W: 5.437261968790907e-13
grad ChooseDest W: 4.184520721435547
grad AddEdge W: 9.14017075052823e-15
grad ChooseDest W: 3.2037453651428223
grad AddEdge W: 4.672336969195167e-17
grad ChooseDest W: 3.260378837585449
grad AddEdge W: 8.583103439140441e-15
grad ChooseDest W: 6.875834941864014
grad AddEdge W: 3.61833543880666e-15
grad ChooseDest W: 7.136198043823242
grad AddEdge W: 7.913092966324001e-17
grad ChooseDest W: 5.553213119506836
grad AddEdge W: 3.1948632226510036e-16
grad ChooseDest W: 6.1445631980896
grad AddEdge W: 9.567532277279881e-17
grad ChooseDest W: 11.055195808410645
grad AddEdge W: 1.1971286050134478e-15
grad ChooseDest W: 4.664722442626953
grad AddEdge W: 2.1568076698297094e-16
grad ChooseDest W: 4.52137565612793
grad AddEdge W: 4.748778833948671e-15
grad ChooseDest W: 3.6509082317352295
grad AddEdge W: 7.136314784599544e-17
grad ChooseDest W: 4.964142799377441
grad AddEdge W: 8.347298598698806e-17
grad ChooseDest W: 5.871548652648926
grad AddEdge W: 7.816681558685148e-16
grad ChooseDest W: 6.585987091064453
grad AddEdge W: 2.443260183607925e-15
grad ChooseDest W: 4.653676986694336
grad AddEdge W: 2.9024090039854586e-15
grad ChooseDest W: 7.42583703994751
grad AddEdge W: 7.289349550668959e-15
grad ChooseDest W: 5.0302510261535645
grad AddEdge W: 7.293827813861092e-15
grad ChooseDest W: 5.081005096435547
grad AddEdge W: 2.8875063063114664e-15
grad ChooseDest W: 8.245647430419922
grad AddEdge W: 2.4189503380217265e-16
grad ChooseDest W: 5.119882583618164
grad AddEdge W: 1.615047117301533e-16
grad ChooseDest W: 3.786121129989624
grad AddEdge W: 7.626344255712042e-16
grad ChooseDest W: 7.2522196769714355
grad AddEdge W: 6.580169495044622e-17
grad ChooseDest W: 7.702882766723633
grad AddEdge W: 2.524492529221409e-17
grad ChooseDest W: 9.473128318786621
grad AddEdge W: 9.165984079595804e-15
grad ChooseDest W: 6.740261077880859
grad AddEdge W: 5.889212559187073e-16
grad ChooseDest W: 7.498108386993408
grad AddEdge W: 1.8163646142490148e-16
grad ChooseDest W: 6.4348978996276855
grad AddEdge W: 1.2023360047544896e-16
grad ChooseDest W: 5.001117706298828
grad AddEdge W: 1.3711731233669987e-14
grad ChooseDest W: 3.4215891361236572
grad AddEdge W: 1.0048653608765224e-15
grad ChooseDest W: 6.696837902069092
grad AddEdge W: 1.9010802174219596e-16
grad ChooseDest W: 4.431723594665527
grad AddEdge W: 5.3962129802799175e-17
grad ChooseDest W: 2.4500811100006104
grad AddEdge W: 3.115861518451779e-15
grad ChooseDest W: 3.0524256229400635
grad AddEdge W: 1.0113280899151747e-16
grad ChooseDest W: 5.58272123336792
grad AddEdge W: 2.9683809724106376e-17
grad ChooseDest W: 7.858269691467285
grad AddEdge W: 3.9090030532282086e-16
grad ChooseDest W: 6.165126323699951
grad AddEdge W: 1.194731634121616e-16
grad ChooseDest W: 7.376749038696289
grad AddEdge W: 2.6862512780438446e-15
grad ChooseDest W: 3.888293981552124
grad AddEdge W: 1.5453660486691723e-12
grad ChooseDest W: 2.664041042327881
grad AddEdge W: 2.8146086264620174e-13
grad ChooseDest W: 4.816346168518066
grad AddEdge W: 4.399871309304637e-13
grad ChooseDest W: 4.173273086547852
grad AddEdge W: 1.2032009842123138e-14
grad ChooseDest W: 6.179346084594727
grad AddEdge W: 4.66778787287282e-16
grad ChooseDest W: 4.6305694580078125
grad AddEdge W: 8.987868297381275e-15
grad ChooseDest W: 5.576724052429199
grad AddEdge W: 7.0662394841754e-16
grad ChooseDest W: 9.17215633392334
grad AddEdge W: 7.356330269159869e-17
grad ChooseDest W: 7.486429214477539
grad AddEdge W: 5.252003225494819e-15
grad ChooseDest W: 6.503408432006836
grad AddEdge W: 3.3555426198880658e-15
grad ChooseDest W: 2.9664418697357178
grad AddEdge W: 1.6471386810439363e-16
grad ChooseDest W: 6.5009660720825195
=== Epoch 29: Train Loss: 4.7501, Train Log Prob: 0.0269 ===
Total mismatches: 69267
Predicted valid destination but wrong order: 26215
Epoch 29: Validation Loss: 4.4597, Validation Log Prob: 0.0170
Epoch 29: Edge Precision: 0.3836, Recall: 0.3818, F1: 0.3826, Jaccard: 0.2561
Epoch 29: TP: 2.6758768790264855, FP: 4.315103793843951, FN: 4.345597709377237
Epoch 29: Current Learning Rate: 6e-05
[Epoch 29] ‚è±Ô∏è Total: 1935.17s | Current time: 2025-07-15 03:21:20 | üèãÔ∏è Train: 1692.83s | ‚úÖ Val: 242.34s
grad AddEdge W: 6.402277355997948e-15
grad ChooseDest W: 9.77588939666748
grad AddEdge W: 2.3137039135218685e-17
grad ChooseDest W: 6.861935138702393
grad AddEdge W: 3.216226452371941e-17
grad ChooseDest W: 5.5003790855407715
grad AddEdge W: 1.8695176853121208e-17
grad ChooseDest W: 4.989673137664795
grad AddEdge W: 1.7437217121162814e-17
grad ChooseDest W: 4.191381931304932
grad AddEdge W: 2.040587073230335e-15
grad ChooseDest W: 4.022190570831299
grad AddEdge W: 7.497453899106316e-17
grad ChooseDest W: 6.895146369934082
grad AddEdge W: 2.431955734833428e-16
grad ChooseDest W: 7.6876301765441895
grad AddEdge W: 1.5529641021303251e-16
grad ChooseDest W: 5.681685447692871
grad AddEdge W: 1.628481149842237e-14
grad ChooseDest W: 5.221228122711182
grad AddEdge W: 7.985145612223951e-15
grad ChooseDest W: 4.640134334564209
grad AddEdge W: 5.0073077737140814e-14
grad ChooseDest W: 4.443808555603027
grad AddEdge W: 4.558398861690847e-15
grad ChooseDest W: 2.635453224182129
grad AddEdge W: 1.6175737371738538e-15
grad ChooseDest W: 5.166407108306885
grad AddEdge W: 1.0471070421868602e-14
grad ChooseDest W: 7.343647480010986
grad AddEdge W: 6.6568454849987024e-15
grad ChooseDest W: 5.227038860321045
grad AddEdge W: 9.144961436529002e-17
grad ChooseDest W: 4.0985107421875
grad AddEdge W: 5.099635444931808e-16
grad ChooseDest W: 3.889317274093628
grad AddEdge W: 4.805171322961547e-16
grad ChooseDest W: 5.72572660446167
grad AddEdge W: 2.5871492702480388e-15
grad ChooseDest W: 4.103199005126953
grad AddEdge W: 7.294053495201976e-17
grad ChooseDest W: 4.670165061950684
grad AddEdge W: 1.096347036762355e-15
grad ChooseDest W: 3.835463762283325
grad AddEdge W: 2.069436202262187e-13
grad ChooseDest W: 2.547827959060669
grad AddEdge W: 1.26944361936881e-15
grad ChooseDest W: 5.392154693603516
grad AddEdge W: 6.993420988142234e-17
grad ChooseDest W: 6.053648471832275
grad AddEdge W: 2.890970069672344e-13
grad ChooseDest W: 8.415199279785156
grad AddEdge W: 9.84752166497275e-17
grad ChooseDest W: 6.729111194610596
grad AddEdge W: 1.3760813881287618e-16
grad ChooseDest W: 5.010611057281494
grad AddEdge W: 2.590140196524353e-16
grad ChooseDest W: 6.894844055175781
grad AddEdge W: 1.255442191220476e-16
grad ChooseDest W: 4.975170135498047
grad AddEdge W: 1.3130876696024456e-14
grad ChooseDest W: 6.359745502471924
grad AddEdge W: 3.2661158988718313e-16
grad ChooseDest W: 4.704405784606934
grad AddEdge W: 2.455046746330642e-17
grad ChooseDest W: 7.845859527587891
grad AddEdge W: 3.2086997705421986e-17
grad ChooseDest W: 7.473784923553467
grad AddEdge W: 6.935742014901156e-17
grad ChooseDest W: 4.506348133087158
grad AddEdge W: 2.1101713592428678e-16
grad ChooseDest W: 3.6518783569335938
grad AddEdge W: 1.3432625407220223e-14
grad ChooseDest W: 4.494048595428467
grad AddEdge W: 2.480421128366571e-14
grad ChooseDest W: 5.011496543884277
grad AddEdge W: 1.3945382095796534e-15
grad ChooseDest W: 3.624392509460449
grad AddEdge W: 1.4722420475454475e-15
grad ChooseDest W: 4.987612247467041
grad AddEdge W: 8.068383222313276e-16
grad ChooseDest W: 4.890231609344482
grad AddEdge W: 2.1419535389073305e-14
grad ChooseDest W: 6.62835693359375
grad AddEdge W: 3.1497341542542417e-15
grad ChooseDest W: 4.4828691482543945
grad AddEdge W: 2.565046316066352e-16
grad ChooseDest W: 2.7911460399627686
grad AddEdge W: 8.271043134133258e-17
grad ChooseDest W: 6.3661322593688965
grad AddEdge W: 2.022406146292232e-15
grad ChooseDest W: 3.365548610687256
grad AddEdge W: 4.66824705737446e-17
grad ChooseDest W: 4.945765495300293
grad AddEdge W: 4.357916221592003e-16
grad ChooseDest W: 4.92197322845459
grad AddEdge W: 1.502569446799512e-17
grad ChooseDest W: 14.809287071228027
grad AddEdge W: 1.895714369580222e-15
grad ChooseDest W: 5.9902825355529785
grad AddEdge W: 1.0878964219816593e-14
grad ChooseDest W: 9.150111198425293
grad AddEdge W: 3.4950288292683518e-15
grad ChooseDest W: 2.1897335052490234
grad AddEdge W: 3.1829749034780527e-15
grad ChooseDest W: 5.712181091308594
grad AddEdge W: 2.886667770163464e-17
grad ChooseDest W: 7.993768692016602
grad AddEdge W: 8.233505942633397e-16
grad ChooseDest W: 5.395951271057129
grad AddEdge W: 2.5979184894910773e-14
grad ChooseDest W: 3.98451566696167
grad AddEdge W: 9.979334761702537e-15
grad ChooseDest W: 2.833277940750122
grad AddEdge W: 3.367408069171441e-16
grad ChooseDest W: 7.0235700607299805
grad AddEdge W: 5.7748982631750535e-15
grad ChooseDest W: 6.288010120391846
grad AddEdge W: 1.110604983544809e-16
grad ChooseDest W: 3.9451675415039062
grad AddEdge W: 2.512474686799422e-16
grad ChooseDest W: 5.617161750793457
grad AddEdge W: 2.398072246421329e-14
grad ChooseDest W: 6.286410331726074
grad AddEdge W: 4.593280340203269e-17
grad ChooseDest W: 9.304338455200195
grad AddEdge W: 4.4167381069767225e-14
grad ChooseDest W: 7.205591201782227
grad AddEdge W: 2.6557560008301013e-17
grad ChooseDest W: 6.843332290649414
grad AddEdge W: 3.7692645868483185e-16
grad ChooseDest W: 7.605151653289795
=== Epoch 30: Train Loss: 4.7112, Train Log Prob: 0.0278 ===
Total mismatches: 68630
Predicted valid destination but wrong order: 26249
Epoch 30: Validation Loss: 4.4136, Validation Log Prob: 0.0176
Epoch 30: Edge Precision: 0.3846, Recall: 0.3825, F1: 0.3835, Jaccard: 0.2564
Epoch 30: TP: 2.681746599856836, FP: 4.305368647100931, FN: 4.339727988546886
Epoch 30: Current Learning Rate: 6e-05
[Epoch 30] ‚è±Ô∏è Total: 1939.62s | Current time: 2025-07-15 03:53:40 | üèãÔ∏è Train: 1693.04s | ‚úÖ Val: 246.58s
grad AddEdge W: 1.1450658307895806e-15
grad ChooseDest W: 21.21047592163086
grad AddEdge W: 3.7695266376663753e-16
grad ChooseDest W: 3.9901561737060547
grad AddEdge W: 9.452577677299297e-15
grad ChooseDest W: 5.118635177612305
grad AddEdge W: 1.6240664141211475e-14
grad ChooseDest W: 3.4615120887756348
grad AddEdge W: 3.317294357463875e-17
grad ChooseDest W: 7.612317085266113
grad AddEdge W: 6.733388040793811e-15
grad ChooseDest W: 6.6202006340026855
grad AddEdge W: 2.3219637950116882e-15
grad ChooseDest W: 2.7393763065338135
grad AddEdge W: 3.8841090196062007e-16
grad ChooseDest W: 5.407231330871582
grad AddEdge W: 3.563728336427918e-16
grad ChooseDest W: 6.162098407745361
grad AddEdge W: 2.887809891390092e-13
grad ChooseDest W: 6.282135009765625
grad AddEdge W: 8.34142561634968e-17
grad ChooseDest W: 4.660794258117676
grad AddEdge W: 2.778617891601321e-15
grad ChooseDest W: 5.299821376800537
grad AddEdge W: 1.807381962192281e-16
grad ChooseDest W: 7.434251308441162
grad AddEdge W: 4.21535221211875e-15
grad ChooseDest W: 1.770402431488037
grad AddEdge W: 1.7317832128586506e-15
grad ChooseDest W: 4.081719398498535
grad AddEdge W: 1.116246901261625e-17
grad ChooseDest W: 9.329639434814453
grad AddEdge W: 2.533273341532444e-13
grad ChooseDest W: 3.326289415359497
grad AddEdge W: 2.431864709606657e-09
grad ChooseDest W: 1.3393288850784302
grad AddEdge W: 6.922723515548552e-17
grad ChooseDest W: 8.688953399658203
grad AddEdge W: 7.711489198710127e-17
grad ChooseDest W: 2.5963802337646484
grad AddEdge W: 2.415198236175274e-14
grad ChooseDest W: 3.7204132080078125
grad AddEdge W: 1.2163578411028965e-16
grad ChooseDest W: 7.06898832321167
grad AddEdge W: 1.1878025181542937e-14
grad ChooseDest W: 3.9727861881256104
grad AddEdge W: 6.289038977117398e-17
grad ChooseDest W: 5.997216701507568
grad AddEdge W: 3.3645509211612337e-16
grad ChooseDest W: 6.354690074920654
grad AddEdge W: 6.8088751935366405e-15
grad ChooseDest W: 5.244664192199707
grad AddEdge W: 8.569117336994496e-17
grad ChooseDest W: 7.368501663208008
grad AddEdge W: 1.4814363996054798e-14
grad ChooseDest W: 5.300380706787109
grad AddEdge W: 1.243456987360227e-14
grad ChooseDest W: 3.2392756938934326
grad AddEdge W: 7.367516427665699e-13
grad ChooseDest W: 6.693437576293945
grad AddEdge W: 1.2214341307316152e-14
grad ChooseDest W: 5.281687259674072
grad AddEdge W: 1.1864547987379615e-16
grad ChooseDest W: 6.150158882141113
grad AddEdge W: 9.334339474689342e-17
grad ChooseDest W: 7.693920135498047
grad AddEdge W: 9.278024356842242e-17
grad ChooseDest W: 7.3009352684021
grad AddEdge W: 2.0269663863917918e-16
grad ChooseDest W: 2.423051357269287
grad AddEdge W: 1.737921687097182e-17
grad ChooseDest W: 7.723427772521973
grad AddEdge W: 4.2949054406457555e-16
grad ChooseDest W: 6.715406894683838
grad AddEdge W: 3.956761100135011e-15
grad ChooseDest W: 4.3974385261535645
grad AddEdge W: 7.20005533736941e-17
grad ChooseDest W: 5.330716133117676
grad AddEdge W: 3.361746183314638e-16
grad ChooseDest W: 7.576843738555908
grad AddEdge W: 3.9951904089695345e-13
grad ChooseDest W: 5.655948638916016
grad AddEdge W: 2.680313835163943e-17
grad ChooseDest W: 3.641486883163452
grad AddEdge W: 9.996599463689507e-17
grad ChooseDest W: 4.2693657875061035
grad AddEdge W: 4.458692919403649e-15
grad ChooseDest W: 6.477409362792969
grad AddEdge W: 3.969649129943959e-15
grad ChooseDest W: 4.943239212036133
grad AddEdge W: 3.2001362145058984e-15
grad ChooseDest W: 4.406987190246582
grad AddEdge W: 7.674858994208319e-17
grad ChooseDest W: 4.669290065765381
grad AddEdge W: 8.969318614649585e-14
grad ChooseDest W: 5.010021209716797
grad AddEdge W: 3.930383422131438e-17
grad ChooseDest W: 10.94964599609375
grad AddEdge W: 1.0540826973206782e-14
grad ChooseDest W: 10.211153030395508
grad AddEdge W: 2.7058878311018043e-15
grad ChooseDest W: 6.673027038574219
grad AddEdge W: 1.6005987204548448e-16
grad ChooseDest W: 4.297463893890381
grad AddEdge W: 4.657904321867342e-17
grad ChooseDest W: 5.179326057434082
grad AddEdge W: 1.0237038606674027e-14
grad ChooseDest W: 6.3838958740234375
grad AddEdge W: 7.846266301950373e-16
grad ChooseDest W: 5.787530422210693
grad AddEdge W: 1.6452062151853242e-12
grad ChooseDest W: 5.798062801361084
grad AddEdge W: 4.708057301492947e-15
grad ChooseDest W: 4.754292011260986
grad AddEdge W: 2.234965379812378e-14
grad ChooseDest W: 4.386699199676514
grad AddEdge W: 4.967081433659981e-13
grad ChooseDest W: 5.6595587730407715
grad AddEdge W: 4.999800012482798e-15
grad ChooseDest W: 6.2501420974731445
grad AddEdge W: 2.7803800245340755e-17
grad ChooseDest W: 9.682367324829102
grad AddEdge W: 4.957003672822775e-15
grad ChooseDest W: 8.793050765991211
grad AddEdge W: 2.1495150139388704e-17
grad ChooseDest W: 3.8418757915496826
grad AddEdge W: 3.047426550269552e-16
grad ChooseDest W: 5.547041416168213
grad AddEdge W: 6.327034360502164e-17
grad ChooseDest W: 4.48207426071167
grad AddEdge W: 1.0395685654233271e-16
grad ChooseDest W: 5.785442352294922
=== Epoch 31: Train Loss: 4.6631, Train Log Prob: 0.0290 ===
Total mismatches: 68122
Predicted valid destination but wrong order: 26293
Epoch 31: Validation Loss: 4.3506, Validation Log Prob: 0.0188
Epoch 31: Edge Precision: 0.3856, Recall: 0.3839, F1: 0.3847, Jaccard: 0.2574
Epoch 31: TP: 2.6911954187544738, FP: 4.3006442376521115, FN: 4.330279169649248
Epoch 31: Current Learning Rate: 6e-05
[Epoch 31] ‚è±Ô∏è Total: 1937.79s | Current time: 2025-07-15 04:25:57 | üèãÔ∏è Train: 1693.01s | ‚úÖ Val: 244.77s
grad AddEdge W: 1.7181548339021552e-14
grad ChooseDest W: 10.342090606689453
grad AddEdge W: 6.952432878536141e-15
grad ChooseDest W: 6.815163612365723
grad AddEdge W: 1.277911090105156e-15
grad ChooseDest W: 4.671812534332275
grad AddEdge W: 6.096431546436312e-14
grad ChooseDest W: 4.586700916290283
grad AddEdge W: 1.42244347179893e-16
grad ChooseDest W: 7.822325706481934
grad AddEdge W: 6.871628052950449e-15
grad ChooseDest W: 5.690187454223633
grad AddEdge W: 3.8839852998563424e-15
grad ChooseDest W: 5.958714962005615
grad AddEdge W: 1.431221479372118e-17
grad ChooseDest W: 3.575761079788208
grad AddEdge W: 1.0065887420519399e-16
grad ChooseDest W: 4.55508279800415
grad AddEdge W: 2.449629341975685e-16
grad ChooseDest W: 4.631196975708008
grad AddEdge W: 3.578191345651738e-13
grad ChooseDest W: 6.234403133392334
grad AddEdge W: 5.581235747079044e-17
grad ChooseDest W: 5.229250907897949
grad AddEdge W: 2.4654693874849327e-16
grad ChooseDest W: 3.9431228637695312
grad AddEdge W: 4.03771368003044e-16
grad ChooseDest W: 5.33169412612915
grad AddEdge W: 6.601088694212741e-16
grad ChooseDest W: 6.296100616455078
grad AddEdge W: 1.1238978421629852e-16
grad ChooseDest W: 4.591140270233154
grad AddEdge W: 2.7786570668751316e-15
grad ChooseDest W: 1.5202476978302002
grad AddEdge W: 1.4114916004887278e-16
grad ChooseDest W: 6.774327278137207
grad AddEdge W: 6.930139289001763e-16
grad ChooseDest W: 2.0268707275390625
grad AddEdge W: 5.587722193040219e-15
grad ChooseDest W: 6.903753757476807
grad AddEdge W: 5.877542430407379e-17
grad ChooseDest W: 11.648846626281738
grad AddEdge W: 1.528150436053144e-14
grad ChooseDest W: 7.565581321716309
grad AddEdge W: 1.262291511390211e-16
grad ChooseDest W: 7.597306251525879
grad AddEdge W: 8.844581550428333e-18
grad ChooseDest W: 5.5189127922058105
grad AddEdge W: 6.414671565598646e-15
grad ChooseDest W: 11.084824562072754
grad AddEdge W: 1.6580188523386423e-17
grad ChooseDest W: 6.947708606719971
grad AddEdge W: 2.5341375544254508e-16
grad ChooseDest W: 5.444632053375244
grad AddEdge W: 3.0208255467354796e-17
grad ChooseDest W: 7.018123149871826
grad AddEdge W: 2.213701125891327e-15
grad ChooseDest W: 4.218038082122803
grad AddEdge W: 2.909568973488599e-15
grad ChooseDest W: 4.217273712158203
grad AddEdge W: 9.89822055733286e-17
grad ChooseDest W: 6.398575305938721
grad AddEdge W: 2.6088548600983446e-16
grad ChooseDest W: 4.833404541015625
grad AddEdge W: 1.2941200978722715e-16
grad ChooseDest W: 7.4003987312316895
grad AddEdge W: 2.1153724062368052e-16
grad ChooseDest W: 4.978984355926514
grad AddEdge W: 6.527390051538039e-15
grad ChooseDest W: 4.754787445068359
grad AddEdge W: 1.1158998659074345e-16
grad ChooseDest W: 7.968873023986816
grad AddEdge W: 5.731886512448631e-17
grad ChooseDest W: 5.3736395835876465
grad AddEdge W: 1.4753710406156806e-12
grad ChooseDest W: 7.694072723388672
grad AddEdge W: 5.793656654824947e-16
grad ChooseDest W: 5.142005920410156
grad AddEdge W: 5.3768394177171905e-17
grad ChooseDest W: 7.9608154296875
grad AddEdge W: 6.103945575711405e-15
grad ChooseDest W: 4.159759044647217
grad AddEdge W: 5.2154673989921805e-17
grad ChooseDest W: 3.062155246734619
grad AddEdge W: 2.1363158583404843e-17
grad ChooseDest W: 7.650523662567139
grad AddEdge W: 8.866466929639138e-17
grad ChooseDest W: 5.7913665771484375
grad AddEdge W: 1.124612658561129e-16
grad ChooseDest W: 5.739740371704102
grad AddEdge W: 1.4282725804883666e-17
grad ChooseDest W: 8.860311508178711
grad AddEdge W: 1.4556615893611814e-16
grad ChooseDest W: 4.395603656768799
grad AddEdge W: 5.839686013365522e-17
grad ChooseDest W: 5.705454349517822
grad AddEdge W: 3.9126844701752126e-16
grad ChooseDest W: 6.57542610168457
grad AddEdge W: 9.285719809986725e-15
grad ChooseDest W: 7.354057788848877
grad AddEdge W: 5.711134046422223e-15
grad ChooseDest W: 5.982010364532471
grad AddEdge W: 3.4069160681115456e-17
grad ChooseDest W: 6.802602767944336
grad AddEdge W: 2.6261028331846063e-16
grad ChooseDest W: 8.46782398223877
grad AddEdge W: 1.4488986665520663e-15
grad ChooseDest W: 5.607386589050293
grad AddEdge W: 6.884721488249106e-15
grad ChooseDest W: 3.827627658843994
grad AddEdge W: 1.0423289002146411e-16
grad ChooseDest W: 5.863094329833984
grad AddEdge W: 4.8248724622817346e-14
grad ChooseDest W: 3.2102131843566895
grad AddEdge W: 1.2210853225639359e-14
grad ChooseDest W: 2.9650213718414307
grad AddEdge W: 2.568322215989858e-16
grad ChooseDest W: 6.156177997589111
grad AddEdge W: 8.928069465371016e-14
grad ChooseDest W: 4.6718339920043945
grad AddEdge W: 8.514745762714651e-17
grad ChooseDest W: 6.697248458862305
grad AddEdge W: 2.0635261812798595e-16
grad ChooseDest W: 6.890439987182617
grad AddEdge W: 6.594275240594366e-17
grad ChooseDest W: 7.511906147003174
grad AddEdge W: 2.2791416208467734e-15
grad ChooseDest W: 7.470949649810791
grad AddEdge W: 3.083959345982426e-16
grad ChooseDest W: 5.842720031738281
grad AddEdge W: 2.1650279022366638e-14
grad ChooseDest W: 6.190134525299072
=== Epoch 32: Train Loss: 4.6220, Train Log Prob: 0.0303 ===
Total mismatches: 67337
Predicted valid destination but wrong order: 26329
Epoch 32: Validation Loss: 4.3411, Validation Log Prob: 0.0191
Epoch 32: Edge Precision: 0.3826, Recall: 0.3808, F1: 0.3816, Jaccard: 0.2549
Epoch 32: TP: 2.6692913385826773, FP: 4.319112383679313, FN: 4.352183249821045
Epoch 32: Current Learning Rate: 6e-05
[Epoch 32] ‚è±Ô∏è Total: 1936.21s | Current time: 2025-07-15 04:58:14 | üèãÔ∏è Train: 1692.42s | ‚úÖ Val: 243.79s
grad AddEdge W: 4.3933677903356186e-14
grad ChooseDest W: 12.796874046325684
grad AddEdge W: 3.835997817135117e-13
grad ChooseDest W: 1.5469751358032227
grad AddEdge W: 1.1974667564478594e-16
grad ChooseDest W: 4.833847522735596
grad AddEdge W: 9.955260357394358e-13
grad ChooseDest W: 2.0867459774017334
grad AddEdge W: 2.73135620600161e-16
grad ChooseDest W: 6.142416954040527
grad AddEdge W: 1.0371562420593265e-16
grad ChooseDest W: 3.9321610927581787
grad AddEdge W: 9.939959760170041e-18
grad ChooseDest W: 4.986362457275391
grad AddEdge W: 2.3663767126369528e-11
grad ChooseDest W: 2.1304523944854736
grad AddEdge W: 8.305495166941422e-15
grad ChooseDest W: 4.6225504875183105
grad AddEdge W: 3.3904001432499484e-15
grad ChooseDest W: 7.658026218414307
grad AddEdge W: 3.756279307069114e-16
grad ChooseDest W: 4.972455978393555
grad AddEdge W: 1.2237705705314537e-16
grad ChooseDest W: 3.8052775859832764
grad AddEdge W: 3.9829577645507776e-16
grad ChooseDest W: 5.787172794342041
grad AddEdge W: 2.951258486726116e-13
grad ChooseDest W: 7.067059516906738
grad AddEdge W: 5.9828355343635644e-15
grad ChooseDest W: 5.6991658210754395
grad AddEdge W: 1.5145086316244345e-14
grad ChooseDest W: 5.417656421661377
grad AddEdge W: 1.067581533175803e-16
grad ChooseDest W: 4.152101516723633
grad AddEdge W: 4.111986240466466e-15
grad ChooseDest W: 4.757657051086426
grad AddEdge W: 1.7329218368979972e-15
grad ChooseDest W: 5.031914234161377
grad AddEdge W: 2.283964520569321e-16
grad ChooseDest W: 6.096281051635742
grad AddEdge W: 6.017699251653874e-17
grad ChooseDest W: 4.908524036407471
grad AddEdge W: 6.687177311323405e-15
grad ChooseDest W: 6.524024486541748
grad AddEdge W: 2.3997595360522594e-13
grad ChooseDest W: 5.665092945098877
grad AddEdge W: 4.2784816488283806e-12
grad ChooseDest W: 2.694739818572998
grad AddEdge W: 2.6195232930085717e-15
grad ChooseDest W: 9.21216869354248
grad AddEdge W: 2.433168315436982e-16
grad ChooseDest W: 6.699690341949463
grad AddEdge W: 3.109886759800084e-17
grad ChooseDest W: 5.177628993988037
grad AddEdge W: 6.967572677672729e-13
grad ChooseDest W: 3.77121639251709
grad AddEdge W: 1.0162818826978527e-15
grad ChooseDest W: 11.086904525756836
grad AddEdge W: 2.0667063929501054e-16
grad ChooseDest W: 3.90718412399292
grad AddEdge W: 1.1405457453456764e-16
grad ChooseDest W: 4.755519866943359
grad AddEdge W: 1.5289116751507532e-17
grad ChooseDest W: 11.344585418701172
grad AddEdge W: 1.0624246245393514e-16
grad ChooseDest W: 3.234560251235962
grad AddEdge W: 1.8902815849598277e-14
grad ChooseDest W: 3.005540609359741
grad AddEdge W: 5.33963184114782e-17
grad ChooseDest W: 5.434191703796387
grad AddEdge W: 3.2429384304569935e-16
grad ChooseDest W: 5.735054969787598
grad AddEdge W: 3.806879202453514e-16
grad ChooseDest W: 1.6868505477905273
grad AddEdge W: 1.4997382404968035e-14
grad ChooseDest W: 2.554081916809082
grad AddEdge W: 5.89909544844806e-17
grad ChooseDest W: 6.333438873291016
grad AddEdge W: 1.5068001447604757e-17
grad ChooseDest W: 5.127335071563721
grad AddEdge W: 8.584202887905977e-15
grad ChooseDest W: 6.820521354675293
grad AddEdge W: 2.9109655190603847e-15
grad ChooseDest W: 2.5614938735961914
grad AddEdge W: 3.26472438255817e-17
grad ChooseDest W: 9.310685157775879
grad AddEdge W: 7.70696440693941e-14
grad ChooseDest W: 4.8069891929626465
grad AddEdge W: 2.088646773980643e-13
grad ChooseDest W: 10.044189453125
grad AddEdge W: 4.3866142272405706e-17
grad ChooseDest W: 5.993521690368652
grad AddEdge W: 1.5044594750898569e-15
grad ChooseDest W: 6.224470138549805
grad AddEdge W: 8.60466194966039e-18
grad ChooseDest W: 5.395712852478027
grad AddEdge W: 1.3077741200895006e-17
grad ChooseDest W: 5.447227954864502
grad AddEdge W: 1.717281238001675e-13
grad ChooseDest W: 7.692185878753662
grad AddEdge W: 1.0081865902975963e-16
grad ChooseDest W: 6.8184590339660645
grad AddEdge W: 8.146175892859413e-15
grad ChooseDest W: 8.657183647155762
grad AddEdge W: 2.7227090373949103e-11
grad ChooseDest W: 7.343832492828369
grad AddEdge W: 7.986675247847574e-16
grad ChooseDest W: 5.926087856292725
grad AddEdge W: 2.6294433193703405e-16
grad ChooseDest W: 7.094259738922119
grad AddEdge W: 1.020067947918512e-16
grad ChooseDest W: 6.989553928375244
grad AddEdge W: 1.980204609049638e-16
grad ChooseDest W: 4.8741583824157715
grad AddEdge W: 1.5794434902620174e-15
grad ChooseDest W: 4.910027980804443
grad AddEdge W: 2.352334637791524e-16
grad ChooseDest W: 6.8486809730529785
grad AddEdge W: 6.051715565420014e-17
grad ChooseDest W: 6.363214492797852
grad AddEdge W: 7.410393470507355e-17
grad ChooseDest W: 6.1918768882751465
grad AddEdge W: 1.5571091372670529e-16
grad ChooseDest W: 5.693992614746094
grad AddEdge W: 1.0509247890867247e-14
grad ChooseDest W: 4.2464599609375
grad AddEdge W: 2.9884884096128216e-17
grad ChooseDest W: 3.2471795082092285
grad AddEdge W: 9.22338072616765e-15
grad ChooseDest W: 8.102926254272461
grad AddEdge W: 3.9174559126462145e-17
grad ChooseDest W: 9.227815628051758
=== Epoch 33: Train Loss: 4.5708, Train Log Prob: 0.0315 ===
Total mismatches: 66434
Predicted valid destination but wrong order: 26413
Epoch 33: Validation Loss: 4.2896, Validation Log Prob: 0.0199
Epoch 33: Edge Precision: 0.3818, Recall: 0.3793, F1: 0.3805, Jaccard: 0.2538
Epoch 33: TP: 2.6586972083035074, FP: 4.320257695060844, FN: 4.362777380100215
Epoch 33: Current Learning Rate: 6e-05
[Epoch 33] ‚è±Ô∏è Total: 1935.43s | Current time: 2025-07-15 05:30:29 | üèãÔ∏è Train: 1693.37s | ‚úÖ Val: 242.07s
grad AddEdge W: 2.966477093808116e-14
grad ChooseDest W: 11.635175704956055
grad AddEdge W: 2.5025505840915946e-15
grad ChooseDest W: 8.057168960571289
grad AddEdge W: 1.431079866051249e-17
grad ChooseDest W: 5.493927001953125
grad AddEdge W: 5.763138057735375e-17
grad ChooseDest W: 4.774845600128174
grad AddEdge W: 4.414572277611911e-13
grad ChooseDest W: 2.092891216278076
grad AddEdge W: 8.740385598984303e-15
grad ChooseDest W: 5.5109381675720215
grad AddEdge W: 1.723760836760263e-14
grad ChooseDest W: 3.5531983375549316
grad AddEdge W: 3.081173004632653e-17
grad ChooseDest W: 5.2486724853515625
grad AddEdge W: 4.899679701677803e-14
grad ChooseDest W: 6.442963123321533
grad AddEdge W: 1.2909917140304858e-15
grad ChooseDest W: 7.130886554718018
grad AddEdge W: 4.477013818536286e-15
grad ChooseDest W: 2.9986743927001953
grad AddEdge W: 9.825486778358705e-13
grad ChooseDest W: 4.520766735076904
grad AddEdge W: 3.830248428539698e-14
grad ChooseDest W: 4.325596332550049
grad AddEdge W: 5.745824174897905e-17
grad ChooseDest W: 2.436363935470581
grad AddEdge W: 2.1551079129325865e-16
grad ChooseDest W: 4.906078338623047
grad AddEdge W: 6.415752459048682e-17
grad ChooseDest W: 12.025374412536621
grad AddEdge W: 1.0572972131635434e-17
grad ChooseDest W: 6.125833034515381
grad AddEdge W: 4.243929833209689e-15
grad ChooseDest W: 4.40964937210083
grad AddEdge W: 8.963286554219008e-15
grad ChooseDest W: 3.892340660095215
grad AddEdge W: 1.3410429438233016e-16
grad ChooseDest W: 2.8663833141326904
grad AddEdge W: 9.571531860977698e-18
grad ChooseDest W: 2.6503183841705322
grad AddEdge W: 2.7218421201798126e-15
grad ChooseDest W: 4.849527835845947
grad AddEdge W: 1.203966278480158e-16
grad ChooseDest W: 7.259461879730225
grad AddEdge W: 7.909585720526776e-17
grad ChooseDest W: 5.360997200012207
grad AddEdge W: 9.641431931460879e-17
grad ChooseDest W: 9.388459205627441
grad AddEdge W: 7.328859402493636e-15
grad ChooseDest W: 3.037386894226074
grad AddEdge W: 9.30061432849882e-17
grad ChooseDest W: 5.559167861938477
grad AddEdge W: 6.839305275683225e-15
grad ChooseDest W: 2.6813461780548096
grad AddEdge W: 3.788210265423784e-17
grad ChooseDest W: 3.1975090503692627
grad AddEdge W: 1.532306755256916e-17
grad ChooseDest W: 6.616876125335693
grad AddEdge W: 1.2627415803615012e-17
grad ChooseDest W: 5.194350242614746
grad AddEdge W: 5.870571905116848e-14
grad ChooseDest W: 2.544853687286377
grad AddEdge W: 7.811290193975875e-17
grad ChooseDest W: 4.116985321044922
grad AddEdge W: 6.065041775960489e-17
grad ChooseDest W: 4.203536033630371
grad AddEdge W: 1.3545192909536767e-15
grad ChooseDest W: 4.063416004180908
grad AddEdge W: 8.222903525353497e-15
grad ChooseDest W: 6.313406467437744
grad AddEdge W: 6.882469862917067e-16
grad ChooseDest W: 8.349721908569336
grad AddEdge W: 2.357184166112351e-17
grad ChooseDest W: 4.511507034301758
grad AddEdge W: 5.31552084978088e-16
grad ChooseDest W: 4.916580677032471
grad AddEdge W: 2.463860448401623e-15
grad ChooseDest W: 4.110414981842041
grad AddEdge W: 2.847179957077284e-14
grad ChooseDest W: 6.152823448181152
grad AddEdge W: 4.71305596055205e-16
grad ChooseDest W: 2.1402976512908936
grad AddEdge W: 2.293062395576661e-15
grad ChooseDest W: 4.899571895599365
grad AddEdge W: 3.116279275101365e-14
grad ChooseDest W: 2.7584750652313232
grad AddEdge W: 6.44956826423434e-17
grad ChooseDest W: 4.7271294593811035
grad AddEdge W: 5.860819485399517e-17
grad ChooseDest W: 5.156208038330078
grad AddEdge W: 4.1965045643720393e-16
grad ChooseDest W: 6.000159740447998
grad AddEdge W: 2.599158715132447e-16
grad ChooseDest W: 5.922990798950195
grad AddEdge W: 1.4924374941178292e-13
grad ChooseDest W: 2.9982659816741943
grad AddEdge W: 2.3147924832079883e-17
grad ChooseDest W: 4.193657875061035
grad AddEdge W: 3.4344155221397484e-17
grad ChooseDest W: 8.371610641479492
grad AddEdge W: 6.116435923551617e-15
grad ChooseDest W: 7.442249298095703
grad AddEdge W: 1.1929960272167451e-17
grad ChooseDest W: 6.212845325469971
grad AddEdge W: 1.1164527401939751e-15
grad ChooseDest W: 4.605017185211182
grad AddEdge W: 8.354275794373797e-15
grad ChooseDest W: 4.46104621887207
grad AddEdge W: 1.528689064304303e-16
grad ChooseDest W: 4.3557448387146
grad AddEdge W: 3.2938176349557504e-15
grad ChooseDest W: 4.944310665130615
grad AddEdge W: 2.849043429561243e-14
grad ChooseDest W: 4.082620143890381
grad AddEdge W: 1.3817210393706993e-16
grad ChooseDest W: 4.937394142150879
grad AddEdge W: 2.0254757936930814e-15
grad ChooseDest W: 4.438527584075928
grad AddEdge W: 3.021250717570332e-17
grad ChooseDest W: 4.294985294342041
grad AddEdge W: 8.931869255172399e-15
grad ChooseDest W: 3.7290661334991455
grad AddEdge W: 7.229395499871115e-16
grad ChooseDest W: 3.593238115310669
grad AddEdge W: 4.2014508397373104e-17
grad ChooseDest W: 7.658590316772461
grad AddEdge W: 2.4162597378647732e-15
grad ChooseDest W: 5.115997791290283
grad AddEdge W: 1.4684846093914274e-16
grad ChooseDest W: 6.894566535949707
=== Epoch 34: Train Loss: 4.5306, Train Log Prob: 0.0328 ===
Total mismatches: 66005
Predicted valid destination but wrong order: 26546
Epoch 34: Validation Loss: 4.1799, Validation Log Prob: 0.0220
Epoch 34: Edge Precision: 0.3847, Recall: 0.3825, F1: 0.3835, Jaccard: 0.2564
Epoch 34: TP: 2.6807444523979957, FP: 4.299355762347888, FN: 4.340730136005726
Epoch 34: Current Learning Rate: 6e-05
[Epoch 34] ‚è±Ô∏è Total: 1944.23s | Current time: 2025-07-15 06:02:53 | üèãÔ∏è Train: 1700.46s | ‚úÖ Val: 243.77s
grad AddEdge W: 1.8404918024740938e-14
grad ChooseDest W: 8.926850318908691
grad AddEdge W: 3.4321493130179404e-13
grad ChooseDest W: 4.27440881729126
grad AddEdge W: 3.935842814174288e-17
grad ChooseDest W: 7.989466667175293
grad AddEdge W: 2.2410689721753503e-15
grad ChooseDest W: 3.241307497024536
grad AddEdge W: 8.033275030138565e-17
grad ChooseDest W: 7.4773149490356445
grad AddEdge W: 1.2776941437915405e-16
grad ChooseDest W: 7.901727199554443
grad AddEdge W: 3.206882620172542e-17
grad ChooseDest W: 4.357569694519043
grad AddEdge W: 8.587320850066138e-13
grad ChooseDest W: 3.9688284397125244
grad AddEdge W: 1.3245669618591234e-16
grad ChooseDest W: 4.107994556427002
grad AddEdge W: 9.837379438046115e-18
grad ChooseDest W: 3.9578139781951904
grad AddEdge W: 3.507789420323407e-17
grad ChooseDest W: 6.657664775848389
grad AddEdge W: 1.1725079830389017e-14
grad ChooseDest W: 6.356504440307617
grad AddEdge W: 2.5994331538073574e-15
grad ChooseDest W: 3.4302022457122803
grad AddEdge W: 5.047786440648004e-16
grad ChooseDest W: 6.873154163360596
grad AddEdge W: 3.1528041987017853e-17
grad ChooseDest W: 6.888346195220947
grad AddEdge W: 4.489121625121694e-16
grad ChooseDest W: 2.941798686981201
grad AddEdge W: 1.601280889026828e-14
grad ChooseDest W: 9.651467323303223
grad AddEdge W: 1.1182824107693832e-16
grad ChooseDest W: 8.033574104309082
grad AddEdge W: 1.6496276013326594e-17
grad ChooseDest W: 3.2086966037750244
grad AddEdge W: 2.2186969600955508e-13
grad ChooseDest W: 3.9319193363189697
grad AddEdge W: 2.0668477415731784e-16
grad ChooseDest W: 7.337645053863525
grad AddEdge W: 2.764790714012105e-16
grad ChooseDest W: 6.502686977386475
grad AddEdge W: 1.3347357412834215e-17
grad ChooseDest W: 4.895162105560303
grad AddEdge W: 3.727682151280829e-17
grad ChooseDest W: 3.306732416152954
grad AddEdge W: 1.6951320718199686e-13
grad ChooseDest W: 2.365558624267578
grad AddEdge W: 2.306402444517911e-14
grad ChooseDest W: 4.628964424133301
grad AddEdge W: 6.640504843017628e-16
grad ChooseDest W: 12.42454719543457
grad AddEdge W: 8.250072451243813e-17
grad ChooseDest W: 6.261486530303955
grad AddEdge W: 2.1462640895759076e-14
grad ChooseDest W: 2.392829179763794
grad AddEdge W: 4.278396450866414e-15
grad ChooseDest W: 5.2136640548706055
grad AddEdge W: 2.591867713602833e-17
grad ChooseDest W: 5.280953407287598
grad AddEdge W: 2.199636567318643e-16
grad ChooseDest W: 4.213426113128662
grad AddEdge W: 1.7440103452105032e-14
grad ChooseDest W: 6.641271114349365
grad AddEdge W: 1.5012434180440744e-14
grad ChooseDest W: 3.5379738807678223
grad AddEdge W: 4.347258535412294e-15
grad ChooseDest W: 4.689077854156494
grad AddEdge W: 2.7596030183749988e-14
grad ChooseDest W: 6.593769550323486
grad AddEdge W: 1.0166803481720648e-14
grad ChooseDest W: 5.382770538330078
grad AddEdge W: 4.8023227511599306e-14
grad ChooseDest W: 4.168020248413086
grad AddEdge W: 1.59128850487554e-16
grad ChooseDest W: 5.843061447143555
grad AddEdge W: 7.2446615482097e-17
grad ChooseDest W: 5.3865156173706055
grad AddEdge W: 3.157514787149483e-15
grad ChooseDest W: 4.968437194824219
grad AddEdge W: 7.107782347422385e-17
grad ChooseDest W: 7.3848419189453125
grad AddEdge W: 3.86296447989561e-18
grad ChooseDest W: 5.173233985900879
grad AddEdge W: 6.168218859265535e-16
grad ChooseDest W: 4.711006164550781
grad AddEdge W: 1.9935920971298903e-16
grad ChooseDest W: 5.170724868774414
grad AddEdge W: 4.506596444219142e-16
grad ChooseDest W: 7.896514415740967
grad AddEdge W: 1.9667025915270052e-14
grad ChooseDest W: 3.8176262378692627
grad AddEdge W: 1.3191641357352822e-15
grad ChooseDest W: 4.335254669189453
grad AddEdge W: 4.377310099710574e-17
grad ChooseDest W: 5.371796131134033
grad AddEdge W: 4.408206155857267e-16
grad ChooseDest W: 2.3261711597442627
grad AddEdge W: 1.4298923102420286e-13
grad ChooseDest W: 2.021920680999756
grad AddEdge W: 7.58412497842316e-14
grad ChooseDest W: 6.689432144165039
grad AddEdge W: 3.4037188496079056e-17
grad ChooseDest W: 5.382339954376221
grad AddEdge W: 9.494291058866476e-17
grad ChooseDest W: 9.794123649597168
grad AddEdge W: 3.199461908517248e-13
grad ChooseDest W: 4.298194408416748
grad AddEdge W: 3.470527342477837e-15
grad ChooseDest W: 2.8806495666503906
grad AddEdge W: 5.979738371131305e-10
grad ChooseDest W: 0.49962106347084045
grad AddEdge W: 3.653432248976142e-15
grad ChooseDest W: 6.105925559997559
grad AddEdge W: 5.985879267850184e-17
grad ChooseDest W: 7.1093316078186035
grad AddEdge W: 1.4210086244560607e-15
grad ChooseDest W: 5.167301654815674
grad AddEdge W: 1.0937664450094264e-15
grad ChooseDest W: 4.9052252769470215
grad AddEdge W: 2.427752863228271e-16
grad ChooseDest W: 7.094357490539551
grad AddEdge W: 3.3849522390914455e-15
grad ChooseDest W: 5.287611961364746
grad AddEdge W: 6.798112395862133e-17
grad ChooseDest W: 7.7222137451171875
grad AddEdge W: 6.143550480514632e-17
grad ChooseDest W: 4.949394702911377
grad AddEdge W: 5.090102194989579e-15
grad ChooseDest W: 3.9579696655273438
=== Epoch 35: Train Loss: 4.4915, Train Log Prob: 0.0337 ===
Total mismatches: 65169
Predicted valid destination but wrong order: 26578
Epoch 35: Validation Loss: 4.1700, Validation Log Prob: 0.0220
Epoch 35: Edge Precision: 0.3818, Recall: 0.3798, F1: 0.3807, Jaccard: 0.2546
Epoch 35: TP: 2.660987831066571, FP: 4.323836793128132, FN: 4.360486757337151
Epoch 35: Current Learning Rate: 6e-05
[Epoch 35] ‚è±Ô∏è Total: 1936.39s | Current time: 2025-07-15 06:35:10 | üèãÔ∏è Train: 1692.27s | ‚úÖ Val: 244.12s
grad AddEdge W: 1.2829136455158163e-14
grad ChooseDest W: 8.990189552307129
grad AddEdge W: 1.281896618350004e-16
grad ChooseDest W: 8.079963684082031
grad AddEdge W: 4.956987685075895e-17
grad ChooseDest W: 7.826999664306641
grad AddEdge W: 7.903600903358832e-15
grad ChooseDest W: 8.084787368774414
grad AddEdge W: 6.4317938072318e-17
grad ChooseDest W: 5.011072158813477
grad AddEdge W: 8.22990247918732e-17
grad ChooseDest W: 5.893376350402832
grad AddEdge W: 3.900727753091771e-15
grad ChooseDest W: 7.127420425415039
grad AddEdge W: 1.1683297389166857e-14
grad ChooseDest W: 8.278040885925293
grad AddEdge W: 6.058321840073447e-14
grad ChooseDest W: 3.001471519470215
grad AddEdge W: 6.912102516483371e-17
grad ChooseDest W: 7.61622953414917
grad AddEdge W: 2.792165363029486e-17
grad ChooseDest W: 3.626394510269165
grad AddEdge W: 1.0281710753735305e-16
grad ChooseDest W: 10.415181159973145
grad AddEdge W: 1.0039944543056498e-13
grad ChooseDest W: 2.65139102935791
grad AddEdge W: 4.838879859365369e-17
grad ChooseDest W: 5.170184135437012
grad AddEdge W: 1.1958646624495549e-14
grad ChooseDest W: 2.3231539726257324
grad AddEdge W: 1.784046204495425e-15
grad ChooseDest W: 6.729490756988525
grad AddEdge W: 1.6844135305581643e-15
grad ChooseDest W: 4.160035133361816
grad AddEdge W: 2.3189428520053058e-15
grad ChooseDest W: 4.564725399017334
grad AddEdge W: 9.238279982770294e-17
grad ChooseDest W: 6.126025676727295
grad AddEdge W: 1.942344221540841e-16
grad ChooseDest W: 5.838165760040283
grad AddEdge W: 7.003577574924303e-16
grad ChooseDest W: 4.212405204772949
grad AddEdge W: 2.53041405052888e-16
grad ChooseDest W: 6.232362270355225
grad AddEdge W: 1.0177393087627221e-15
grad ChooseDest W: 6.79679536819458
grad AddEdge W: 3.14515277803567e-17
grad ChooseDest W: 6.342983245849609
grad AddEdge W: 4.662232395530016e-16
grad ChooseDest W: 3.197524070739746
grad AddEdge W: 7.280892059039523e-17
grad ChooseDest W: 5.975579261779785
grad AddEdge W: 2.2328946807178727e-15
grad ChooseDest W: 8.852472305297852
grad AddEdge W: 3.1431567316605753e-15
grad ChooseDest W: 6.868752479553223
grad AddEdge W: 1.1516464932842703e-14
grad ChooseDest W: 1.998948335647583
grad AddEdge W: 2.7997111295703214e-15
grad ChooseDest W: 4.993879318237305
grad AddEdge W: 1.608999857923509e-15
grad ChooseDest W: 5.520437240600586
grad AddEdge W: 2.0797615198602338e-17
grad ChooseDest W: 4.29901123046875
grad AddEdge W: 3.522369636672512e-17
grad ChooseDest W: 4.532999038696289
grad AddEdge W: 5.036534560855796e-15
grad ChooseDest W: 4.719086170196533
grad AddEdge W: 1.4464227429251276e-17
grad ChooseDest W: 7.059671878814697
grad AddEdge W: 1.2980210816410716e-16
grad ChooseDest W: 4.233479976654053
grad AddEdge W: 2.968824539742313e-16
grad ChooseDest W: 8.131996154785156
grad AddEdge W: 9.16252496247534e-18
grad ChooseDest W: 3.893331527709961
grad AddEdge W: 5.207939393673458e-17
grad ChooseDest W: 8.300162315368652
grad AddEdge W: 8.251245724224659e-17
grad ChooseDest W: 4.59816837310791
grad AddEdge W: 2.1441617326249988e-16
grad ChooseDest W: 4.163020133972168
grad AddEdge W: 6.949904654595176e-14
grad ChooseDest W: 5.887605667114258
grad AddEdge W: 2.0826916580229948e-13
grad ChooseDest W: 4.375895977020264
grad AddEdge W: 1.0683000818128706e-15
grad ChooseDest W: 3.260896682739258
grad AddEdge W: 1.1992599516669764e-16
grad ChooseDest W: 7.407480716705322
grad AddEdge W: 3.081040258687951e-16
grad ChooseDest W: 4.92717170715332
grad AddEdge W: 1.622159150033815e-16
grad ChooseDest W: 5.152629852294922
grad AddEdge W: 1.2232172363324925e-17
grad ChooseDest W: 9.123260498046875
grad AddEdge W: 7.962572263588963e-17
grad ChooseDest W: 6.365416049957275
grad AddEdge W: 5.690923840300736e-15
grad ChooseDest W: 6.527760982513428
grad AddEdge W: 1.4997828738391679e-16
grad ChooseDest W: 4.62229585647583
grad AddEdge W: 6.56297803493781e-17
grad ChooseDest W: 5.353448867797852
grad AddEdge W: 1.8778507358902045e-16
grad ChooseDest W: 6.343630790710449
grad AddEdge W: 5.286151041126021e-16
grad ChooseDest W: 4.165894985198975
grad AddEdge W: 6.14929905489963e-17
grad ChooseDest W: 6.2577691078186035
grad AddEdge W: 3.244327405671813e-15
grad ChooseDest W: 5.328866004943848
grad AddEdge W: 9.817296511859842e-15
grad ChooseDest W: 6.563087463378906
grad AddEdge W: 6.532030892116486e-17
grad ChooseDest W: 6.135133266448975
grad AddEdge W: 1.757527455801465e-16
grad ChooseDest W: 7.625175476074219
grad AddEdge W: 2.8590786497568606e-17
grad ChooseDest W: 7.273682117462158
grad AddEdge W: 1.9371906878012886e-16
grad ChooseDest W: 5.233928203582764
grad AddEdge W: 1.345103408014202e-16
grad ChooseDest W: 8.847749710083008
grad AddEdge W: 3.074647542216345e-16
grad ChooseDest W: 5.525444030761719
grad AddEdge W: 4.6672716459961376e-17
grad ChooseDest W: 6.753361701965332
grad AddEdge W: 3.843948593538473e-15
grad ChooseDest W: 3.373810052871704
grad AddEdge W: 3.2072634541265615e-17
grad ChooseDest W: 5.586735248565674
=== Epoch 36: Train Loss: 4.4466, Train Log Prob: 0.0353 ===
Total mismatches: 64650
Predicted valid destination but wrong order: 26649
Epoch 36: Validation Loss: 4.0889, Validation Log Prob: 0.0238
Epoch 36: Edge Precision: 0.3810, Recall: 0.3789, F1: 0.3799, Jaccard: 0.2537
Epoch 36: TP: 2.65411596277738, FP: 4.327702219040802, FN: 4.367358625626342
Epoch 36: Current Learning Rate: 6e-05
[Epoch 36] ‚è±Ô∏è Total: 1941.45s | Current time: 2025-07-15 07:07:31 | üèãÔ∏è Train: 1698.55s | ‚úÖ Val: 242.89s
grad AddEdge W: 2.780931646800041e-14
grad ChooseDest W: 10.143985748291016
grad AddEdge W: 1.3442924480825888e-14
grad ChooseDest W: 9.79726791381836
grad AddEdge W: 2.5615440995272517e-15
grad ChooseDest W: 2.4750547409057617
grad AddEdge W: 8.880945104987879e-16
grad ChooseDest W: 4.770357608795166
grad AddEdge W: 2.0385948914430622e-17
grad ChooseDest W: 5.082115173339844
grad AddEdge W: 1.3486925943229062e-17
grad ChooseDest W: 3.8198587894439697
grad AddEdge W: 1.082090148771085e-16
grad ChooseDest W: 6.703207492828369
grad AddEdge W: 5.995164866534459e-17
grad ChooseDest W: 4.918178558349609
grad AddEdge W: 8.140783363479837e-17
grad ChooseDest W: 5.480712890625
grad AddEdge W: 7.457021111711981e-13
grad ChooseDest W: 3.590998888015747
grad AddEdge W: 3.4448873391814554e-18
grad ChooseDest W: 6.667126655578613
grad AddEdge W: 3.6234768440931986e-13
grad ChooseDest W: 4.409420013427734
grad AddEdge W: 2.7532556075781593e-15
grad ChooseDest W: 6.913173675537109
grad AddEdge W: 6.8966375477510795e-15
grad ChooseDest W: 3.9873197078704834
grad AddEdge W: 2.632712019513795e-15
grad ChooseDest W: 5.9765305519104
grad AddEdge W: 1.6163338132879715e-16
grad ChooseDest W: 5.807389736175537
grad AddEdge W: 8.245254183732696e-15
grad ChooseDest W: 4.196264266967773
grad AddEdge W: 2.320650576306089e-16
grad ChooseDest W: 4.123697280883789
grad AddEdge W: 7.907054547852364e-17
grad ChooseDest W: 3.5156478881835938
grad AddEdge W: 7.212322094981327e-17
grad ChooseDest W: 4.326542854309082
grad AddEdge W: 6.036250279050368e-15
grad ChooseDest W: 3.659414768218994
grad AddEdge W: 6.5007317839445206e-18
grad ChooseDest W: 3.6542248725891113
grad AddEdge W: 5.204157722436212e-16
grad ChooseDest W: 6.275135517120361
grad AddEdge W: 7.874580098748022e-17
grad ChooseDest W: 6.257907867431641
grad AddEdge W: 2.1576830600000818e-11
grad ChooseDest W: 4.798801422119141
grad AddEdge W: 6.080730414330414e-17
grad ChooseDest W: 4.421154022216797
grad AddEdge W: 3.331904683187277e-15
grad ChooseDest W: 5.232854843139648
grad AddEdge W: 5.729026452762668e-17
grad ChooseDest W: 4.60952091217041
grad AddEdge W: 1.073649730149492e-16
grad ChooseDest W: 3.8971776962280273
grad AddEdge W: 1.4168541396080152e-15
grad ChooseDest W: 2.843522548675537
grad AddEdge W: 1.2088305183233228e-11
grad ChooseDest W: 0.010643808171153069
grad AddEdge W: 3.637084698382591e-17
grad ChooseDest W: 5.00247049331665
grad AddEdge W: 4.773738393510083e-17
grad ChooseDest W: 8.533270835876465
grad AddEdge W: 2.1764369966378378e-16
grad ChooseDest W: 2.9449918270111084
grad AddEdge W: 3.711132583329358e-17
grad ChooseDest W: 10.307141304016113
grad AddEdge W: 2.0775575202791434e-15
grad ChooseDest W: 8.130132675170898
grad AddEdge W: 1.7865762919088736e-15
grad ChooseDest W: 4.297652244567871
grad AddEdge W: 1.187414592946319e-16
grad ChooseDest W: 6.035643100738525
grad AddEdge W: 2.056898909473758e-17
grad ChooseDest W: 5.2062530517578125
grad AddEdge W: 7.387581814446612e-17
grad ChooseDest W: 6.632040500640869
grad AddEdge W: 1.6170502708124507e-15
grad ChooseDest W: 4.474837303161621
grad AddEdge W: 6.6554334810756295e-15
grad ChooseDest W: 6.257074356079102
grad AddEdge W: 4.031518533993781e-15
grad ChooseDest W: 5.2089033126831055
grad AddEdge W: 2.256994726830948e-16
grad ChooseDest W: 5.5054402351379395
grad AddEdge W: 2.0323331606758154e-15
grad ChooseDest W: 5.9780120849609375
grad AddEdge W: 1.218860558764237e-16
grad ChooseDest W: 4.802638530731201
grad AddEdge W: 3.83711176710471e-15
grad ChooseDest W: 6.179727077484131
grad AddEdge W: 4.186703016743768e-15
grad ChooseDest W: 3.4291703701019287
grad AddEdge W: 3.130664213298436e-17
grad ChooseDest W: 5.992449760437012
grad AddEdge W: 9.47045091951931e-16
grad ChooseDest W: 6.279302597045898
grad AddEdge W: 8.825865728801484e-16
grad ChooseDest W: 4.79651403427124
grad AddEdge W: 3.0635887859361112e-15
grad ChooseDest W: 4.243150234222412
grad AddEdge W: 7.739586869757328e-17
grad ChooseDest W: 3.9099297523498535
grad AddEdge W: 4.055772898921934e-15
grad ChooseDest W: 6.945828914642334
grad AddEdge W: 1.1830583289683698e-16
grad ChooseDest W: 3.8565587997436523
grad AddEdge W: 5.0053451136719985e-15
grad ChooseDest W: 5.215320587158203
grad AddEdge W: 1.1594289684761718e-15
grad ChooseDest W: 5.372168064117432
grad AddEdge W: 7.36539484518447e-17
grad ChooseDest W: 5.861357688903809
grad AddEdge W: 8.413232172708673e-17
grad ChooseDest W: 4.6120781898498535
grad AddEdge W: 5.67977214862432e-17
grad ChooseDest W: 5.009637355804443
grad AddEdge W: 7.307733077300133e-17
grad ChooseDest W: 3.9548463821411133
grad AddEdge W: 1.0932711424935194e-15
grad ChooseDest W: 4.910438060760498
grad AddEdge W: 3.077540265610337e-15
grad ChooseDest W: 4.720513343811035
grad AddEdge W: 1.7882959937849264e-17
grad ChooseDest W: 4.043320178985596
grad AddEdge W: 9.870187075501193e-18
grad ChooseDest W: 4.399380207061768
grad AddEdge W: 7.567001921520794e-17
grad ChooseDest W: 5.2318620681762695
=== Epoch 37: Train Loss: 4.3979, Train Log Prob: 0.0368 ===
Total mismatches: 63723
Predicted valid destination but wrong order: 26788
Epoch 37: Validation Loss: 4.0681, Validation Log Prob: 0.0243
Epoch 37: Edge Precision: 0.3825, Recall: 0.3804, F1: 0.3814, Jaccard: 0.2543
Epoch 37: TP: 2.6655690765926985, FP: 4.3195418754473875, FN: 4.355905511811024
Epoch 37: Current Learning Rate: 6e-05
[Epoch 37] ‚è±Ô∏è Total: 1935.46s | Current time: 2025-07-15 07:39:46 | üèãÔ∏è Train: 1693.85s | ‚úÖ Val: 241.61s
grad AddEdge W: 7.421818727355953e-15
grad ChooseDest W: 13.461552619934082
grad AddEdge W: 9.386275829245832e-17
grad ChooseDest W: 3.6085829734802246
grad AddEdge W: 5.461431952296855e-14
grad ChooseDest W: 4.759969234466553
grad AddEdge W: 2.877644884041736e-17
grad ChooseDest W: 6.474145412445068
grad AddEdge W: 2.5380458173836413e-16
grad ChooseDest W: 3.2886929512023926
grad AddEdge W: 1.0952703520072764e-15
grad ChooseDest W: 3.492781639099121
grad AddEdge W: 6.757407777595575e-15
grad ChooseDest W: 5.894270896911621
grad AddEdge W: 1.6672291378825059e-15
grad ChooseDest W: 4.211289882659912
grad AddEdge W: 1.9675753478060764e-16
grad ChooseDest W: 3.268747329711914
grad AddEdge W: 1.751536418235315e-16
grad ChooseDest W: 6.500699520111084
grad AddEdge W: 3.103893009081525e-17
grad ChooseDest W: 6.920884609222412
grad AddEdge W: 3.617914953122797e-17
grad ChooseDest W: 5.428411483764648
grad AddEdge W: 1.0119910255452992e-16
grad ChooseDest W: 4.615962505340576
grad AddEdge W: 9.594306956978854e-14
grad ChooseDest W: 6.474548816680908
grad AddEdge W: 2.6075219412592767e-17
grad ChooseDest W: 3.4385030269622803
grad AddEdge W: 1.0782871693612602e-16
grad ChooseDest W: 5.89076566696167
grad AddEdge W: 1.5543037641457466e-14
grad ChooseDest W: 6.1079888343811035
grad AddEdge W: 1.7129172744942352e-16
grad ChooseDest W: 4.932983875274658
grad AddEdge W: 6.785638962211087e-15
grad ChooseDest W: 5.677528381347656
grad AddEdge W: 5.93184716849373e-17
grad ChooseDest W: 4.1057209968566895
grad AddEdge W: 9.254633700822492e-15
grad ChooseDest W: 3.5681960582733154
grad AddEdge W: 5.0770592375606226e-17
grad ChooseDest W: 4.159480094909668
grad AddEdge W: 4.48893316029093e-16
grad ChooseDest W: 5.452519416809082
grad AddEdge W: 1.4288473055779684e-16
grad ChooseDest W: 8.357743263244629
grad AddEdge W: 2.9319192083513248e-15
grad ChooseDest W: 5.087441444396973
grad AddEdge W: 7.141979317434307e-17
grad ChooseDest W: 7.130601406097412
grad AddEdge W: 6.39981698998397e-17
grad ChooseDest W: 3.5243043899536133
grad AddEdge W: 2.091171457323888e-15
grad ChooseDest W: 4.580111026763916
grad AddEdge W: 2.0957331532613262e-16
grad ChooseDest W: 4.9269843101501465
grad AddEdge W: 2.3441850691081944e-15
grad ChooseDest W: 4.413753509521484
grad AddEdge W: 6.721015854049741e-17
grad ChooseDest W: 4.498995780944824
grad AddEdge W: 1.3877329549755102e-17
grad ChooseDest W: 4.164066314697266
grad AddEdge W: 7.225384163591156e-15
grad ChooseDest W: 5.342069149017334
grad AddEdge W: 6.262505670044657e-17
grad ChooseDest W: 6.359600067138672
grad AddEdge W: 9.677760115777432e-16
grad ChooseDest W: 5.73217248916626
grad AddEdge W: 4.250442828359805e-16
grad ChooseDest W: 5.2127180099487305
grad AddEdge W: 3.619987205993365e-17
grad ChooseDest W: 6.526857852935791
grad AddEdge W: 3.4329801983408464e-17
grad ChooseDest W: 4.499391555786133
grad AddEdge W: 1.0065610454509932e-12
grad ChooseDest W: 1.4700121879577637
grad AddEdge W: 4.097615850060264e-17
grad ChooseDest W: 4.02315092086792
grad AddEdge W: 1.7003938261946313e-17
grad ChooseDest W: 6.420685768127441
grad AddEdge W: 3.0561429851649197e-14
grad ChooseDest W: 5.736628532409668
grad AddEdge W: 3.095305550834244e-17
grad ChooseDest W: 3.119724750518799
grad AddEdge W: 2.1604708649804356e-14
grad ChooseDest W: 4.256251335144043
grad AddEdge W: 6.033147676773914e-18
grad ChooseDest W: 5.40674352645874
grad AddEdge W: 1.6824467200546398e-15
grad ChooseDest W: 3.498656749725342
grad AddEdge W: 6.075077845836031e-15
grad ChooseDest W: 5.556177616119385
grad AddEdge W: 3.781881407295467e-15
grad ChooseDest W: 6.734995365142822
grad AddEdge W: 1.4715938820523408e-16
grad ChooseDest W: 4.474130630493164
grad AddEdge W: 2.8553047209301487e-17
grad ChooseDest W: 3.8983497619628906
grad AddEdge W: 3.350046739254035e-17
grad ChooseDest W: 6.02063512802124
grad AddEdge W: 1.612894065428731e-16
grad ChooseDest W: 5.35350227355957
grad AddEdge W: 3.591713193274457e-15
grad ChooseDest W: 8.165980339050293
grad AddEdge W: 5.366120162830128e-15
grad ChooseDest W: 3.6167545318603516
grad AddEdge W: 6.045014078969355e-17
grad ChooseDest W: 7.18327522277832
grad AddEdge W: 1.9857774240980813e-16
grad ChooseDest W: 5.404590606689453
grad AddEdge W: 4.211147964085053e-15
grad ChooseDest W: 4.01632022857666
grad AddEdge W: 4.499261668291512e-17
grad ChooseDest W: 3.9905507564544678
grad AddEdge W: 1.1450845290418912e-14
grad ChooseDest W: 2.9397878646850586
grad AddEdge W: 3.5235465492480523e-17
grad ChooseDest W: 8.051261901855469
grad AddEdge W: 9.47186377047533e-15
grad ChooseDest W: 12.031468391418457
grad AddEdge W: 1.4405400700426285e-12
grad ChooseDest W: 5.552560329437256
grad AddEdge W: 1.789101085366402e-15
grad ChooseDest W: 2.8565311431884766
grad AddEdge W: 1.2833901756640297e-16
grad ChooseDest W: 3.0235400199890137
grad AddEdge W: 1.723600609890378e-16
grad ChooseDest W: 7.319308280944824
grad AddEdge W: 2.326873197973974e-15
grad ChooseDest W: 3.169203996658325
=== Epoch 38: Train Loss: 4.3661, Train Log Prob: 0.0378 ===
Total mismatches: 63210
Predicted valid destination but wrong order: 26899
Epoch 38: Validation Loss: 4.0267, Validation Log Prob: 0.0252
Epoch 38: Edge Precision: 0.3816, Recall: 0.3793, F1: 0.3803, Jaccard: 0.2537
Epoch 38: TP: 2.657695060844667, FP: 4.324123120973515, FN: 4.363779527559055
Epoch 38: Current Learning Rate: 6e-05
[Epoch 38] ‚è±Ô∏è Total: 1933.34s | Current time: 2025-07-15 08:12:00 | üèãÔ∏è Train: 1689.68s | ‚úÖ Val: 243.66s
grad AddEdge W: 1.6291791049907745e-14
grad ChooseDest W: 18.602794647216797
grad AddEdge W: 4.68874622084497e-15
grad ChooseDest W: 4.724003791809082
grad AddEdge W: 2.6707817035699025e-16
grad ChooseDest W: 3.5732975006103516
grad AddEdge W: 2.5055984203940524e-15
grad ChooseDest W: 6.414409637451172
grad AddEdge W: 1.3263601676661522e-14
grad ChooseDest W: 6.3441009521484375
grad AddEdge W: 3.242821963426746e-17
grad ChooseDest W: 4.177154541015625
grad AddEdge W: 2.5480622996222786e-14
grad ChooseDest W: 6.243624210357666
grad AddEdge W: 3.519513745976836e-16
grad ChooseDest W: 6.008781909942627
grad AddEdge W: 2.4064453788631745e-15
grad ChooseDest W: 3.471595048904419
grad AddEdge W: 2.944163704878596e-16
grad ChooseDest W: 7.276909351348877
grad AddEdge W: 6.385726464557497e-17
grad ChooseDest W: 5.96734094619751
grad AddEdge W: 3.0585267846944215e-17
grad ChooseDest W: 4.121179580688477
grad AddEdge W: 9.041336616901993e-16
grad ChooseDest W: 2.382183790206909
grad AddEdge W: 4.018152579079235e-17
grad ChooseDest W: 7.037644863128662
grad AddEdge W: 1.738434803774761e-16
grad ChooseDest W: 4.736080646514893
grad AddEdge W: 1.920049626154838e-15
grad ChooseDest W: 6.773013114929199
grad AddEdge W: 1.710980745418575e-16
grad ChooseDest W: 5.268599987030029
grad AddEdge W: 8.007155763358354e-15
grad ChooseDest W: 4.56544303894043
grad AddEdge W: 1.1181619256265922e-14
grad ChooseDest W: 4.332875728607178
grad AddEdge W: 2.463402627093632e-16
grad ChooseDest W: 7.212759017944336
grad AddEdge W: 1.0378794626124938e-16
grad ChooseDest W: 5.928610324859619
grad AddEdge W: 6.125511987460565e-16
grad ChooseDest W: 5.8914055824279785
grad AddEdge W: 1.572889191667811e-14
grad ChooseDest W: 0.7810982465744019
grad AddEdge W: 9.056271131251066e-18
grad ChooseDest W: 9.205267906188965
grad AddEdge W: 6.682580378815361e-14
grad ChooseDest W: 3.5303850173950195
grad AddEdge W: 2.0161124289139187e-13
grad ChooseDest W: 4.90654993057251
grad AddEdge W: 2.725519191847797e-13
grad ChooseDest W: 5.605381011962891
grad AddEdge W: 2.7092249291557494e-15
grad ChooseDest W: 4.267909526824951
grad AddEdge W: 3.727136873821034e-17
grad ChooseDest W: 4.7529168128967285
grad AddEdge W: 1.5661180738149312e-15
grad ChooseDest W: 3.7393343448638916
grad AddEdge W: 1.235767551458392e-17
grad ChooseDest W: 3.3680167198181152
grad AddEdge W: 2.3748704787488167e-16
grad ChooseDest W: 4.519343376159668
grad AddEdge W: 6.130829130907836e-15
grad ChooseDest W: 4.351891994476318
grad AddEdge W: 1.2881825954353659e-17
grad ChooseDest W: 4.414055824279785
grad AddEdge W: 5.250216925653288e-17
grad ChooseDest W: 6.197012424468994
grad AddEdge W: 4.238692827020163e-17
grad ChooseDest W: 4.207055568695068
grad AddEdge W: 4.979808274687253e-17
grad ChooseDest W: 7.4567365646362305
grad AddEdge W: 3.721247678731901e-17
grad ChooseDest W: 3.2651376724243164
grad AddEdge W: 1.83900762472647e-17
grad ChooseDest W: 3.541597604751587
grad AddEdge W: 4.0510337495820465e-15
grad ChooseDest W: 3.290825843811035
grad AddEdge W: 4.612319285047161e-15
grad ChooseDest W: 4.4417724609375
grad AddEdge W: 9.181023202513863e-18
grad ChooseDest W: 5.210590362548828
grad AddEdge W: 1.5590531440554505e-17
grad ChooseDest W: 5.220191955566406
grad AddEdge W: 2.904179183731212e-17
grad ChooseDest W: 9.470403671264648
grad AddEdge W: 1.6944843287845443e-15
grad ChooseDest W: 5.550943374633789
grad AddEdge W: 4.7266296635318e-16
grad ChooseDest W: 7.648130416870117
grad AddEdge W: 7.293135258547594e-16
grad ChooseDest W: 4.626645088195801
grad AddEdge W: 4.362939987237058e-17
grad ChooseDest W: 6.467214107513428
grad AddEdge W: 2.7366668908226574e-15
grad ChooseDest W: 5.972558975219727
grad AddEdge W: 8.423178854138501e-16
grad ChooseDest W: 9.30628490447998
grad AddEdge W: 7.959861758157749e-17
grad ChooseDest W: 6.23215913772583
grad AddEdge W: 4.371348152432206e-15
grad ChooseDest W: 4.433748245239258
grad AddEdge W: 2.3565951721571825e-18
grad ChooseDest W: 2.95324444770813
grad AddEdge W: 1.5918729576091454e-16
grad ChooseDest W: 5.705633640289307
grad AddEdge W: 1.7892920489443603e-14
grad ChooseDest W: 4.230873107910156
grad AddEdge W: 1.2992840871747666e-16
grad ChooseDest W: 5.8780364990234375
grad AddEdge W: 4.3682710008488397e-17
grad ChooseDest W: 3.218862771987915
grad AddEdge W: 2.826536874768102e-15
grad ChooseDest W: 7.167623996734619
grad AddEdge W: 1.3735023051532705e-16
grad ChooseDest W: 4.450260162353516
grad AddEdge W: 2.0737524365218403e-15
grad ChooseDest W: 5.182053089141846
grad AddEdge W: 1.0159674852436556e-14
grad ChooseDest W: 4.296492099761963
grad AddEdge W: 3.687611868047535e-17
grad ChooseDest W: 5.9045820236206055
grad AddEdge W: 1.6963750519066037e-17
grad ChooseDest W: 4.440136909484863
grad AddEdge W: 4.2324759148837376e-13
grad ChooseDest W: 8.902174949645996
grad AddEdge W: 1.236805663127146e-17
grad ChooseDest W: 3.3021929264068604
grad AddEdge W: 1.772026840061111e-17
grad ChooseDest W: 3.8952555656433105
=== Epoch 39: Train Loss: 4.3259, Train Log Prob: 0.0392 ===
Total mismatches: 62595
Predicted valid destination but wrong order: 26960
Epoch 39: Validation Loss: 3.9838, Validation Log Prob: 0.0263
Epoch 39: Edge Precision: 0.3806, Recall: 0.3783, F1: 0.3794, Jaccard: 0.2528
Epoch 39: TP: 2.6503937007874017, FP: 4.3301360057265565, FN: 4.371080887616321
Epoch 39: Current Learning Rate: 6e-05
[Epoch 39] ‚è±Ô∏è Total: 1946.55s | Current time: 2025-07-15 08:44:26 | üèãÔ∏è Train: 1701.52s | ‚úÖ Val: 245.03s
grad AddEdge W: 1.1005298336866625e-14
grad ChooseDest W: 11.631474494934082
grad AddEdge W: 3.938218701886667e-15
grad ChooseDest W: 4.281045913696289
grad AddEdge W: 8.878377430487396e-15
grad ChooseDest W: 2.4141855239868164
grad AddEdge W: 8.448715838707034e-16
grad ChooseDest W: 8.234907150268555
grad AddEdge W: 5.669977668427203e-17
grad ChooseDest W: 7.351250171661377
grad AddEdge W: 1.9811541594532897e-14
grad ChooseDest W: 5.997542858123779
grad AddEdge W: 1.735595919912479e-15
grad ChooseDest W: 5.185125350952148
grad AddEdge W: 5.033653100353025e-17
grad ChooseDest W: 2.6621856689453125
grad AddEdge W: 3.867824281799645e-16
grad ChooseDest W: 4.84942102432251
grad AddEdge W: 9.121734866673003e-17
grad ChooseDest W: 5.680344581604004
grad AddEdge W: 5.790184216787899e-17
grad ChooseDest W: 4.92501163482666
grad AddEdge W: 1.783206583086459e-15
grad ChooseDest W: 8.032557487487793
grad AddEdge W: 2.8606847036341936e-17
grad ChooseDest W: 5.235093116760254
grad AddEdge W: 6.091062628100141e-15
grad ChooseDest W: 6.49758768081665
grad AddEdge W: 1.0678387664939722e-15
grad ChooseDest W: 8.454069137573242
grad AddEdge W: 1.951483766249318e-11
grad ChooseDest W: 10.279351234436035
grad AddEdge W: 3.1292212794378985e-17
grad ChooseDest W: 2.9791035652160645
grad AddEdge W: 6.114489971234419e-17
grad ChooseDest W: 1.3565033674240112
grad AddEdge W: 4.1131155603782825e-17
grad ChooseDest W: 5.246310234069824
grad AddEdge W: 3.256905871408319e-17
grad ChooseDest W: 9.754165649414062
grad AddEdge W: 1.1830685198335164e-16
grad ChooseDest W: 5.379671096801758
grad AddEdge W: 1.7729734655541167e-17
grad ChooseDest W: 6.893707275390625
grad AddEdge W: 2.205566892315991e-12
grad ChooseDest W: 1.8645020723342896
grad AddEdge W: 3.820018006954408e-17
grad ChooseDest W: 7.194735050201416
grad AddEdge W: 9.232330899804813e-17
grad ChooseDest W: 3.3282902240753174
grad AddEdge W: 7.073308106469135e-17
grad ChooseDest W: 6.570006370544434
grad AddEdge W: 5.226775090314678e-16
grad ChooseDest W: 4.7567949295043945
grad AddEdge W: 1.4309085166752666e-11
grad ChooseDest W: 2.0539917945861816
grad AddEdge W: 3.290164818605606e-17
grad ChooseDest W: 7.365359783172607
grad AddEdge W: 9.765603652805909e-17
grad ChooseDest W: 6.744053840637207
grad AddEdge W: 3.855505775768607e-16
grad ChooseDest W: 5.456625938415527
grad AddEdge W: 1.8583482655008173e-17
grad ChooseDest W: 3.368917465209961
grad AddEdge W: 1.970782624825965e-17
grad ChooseDest W: 4.100766181945801
grad AddEdge W: 3.123725822320341e-17
grad ChooseDest W: 4.656319618225098
grad AddEdge W: 7.335272897742229e-17
grad ChooseDest W: 4.563775062561035
grad AddEdge W: 3.0763696660772314e-15
grad ChooseDest W: 3.173785448074341
grad AddEdge W: 2.3980702148657444e-17
grad ChooseDest W: 6.053321361541748
grad AddEdge W: 3.762178362151148e-16
grad ChooseDest W: 7.641944408416748
grad AddEdge W: 9.538861535504303e-17
grad ChooseDest W: 4.909923553466797
grad AddEdge W: 5.798429156087133e-16
grad ChooseDest W: 7.898875713348389
grad AddEdge W: 3.3071848736546073e-15
grad ChooseDest W: 5.692626953125
grad AddEdge W: 2.0242513990974959e-13
grad ChooseDest W: 3.1625068187713623
grad AddEdge W: 1.9767087121704174e-17
grad ChooseDest W: 7.958588123321533
grad AddEdge W: 4.9464801751907567e-17
grad ChooseDest W: 4.736902713775635
grad AddEdge W: 3.279341045676204e-13
grad ChooseDest W: 3.0067410469055176
grad AddEdge W: 2.660070177858484e-16
grad ChooseDest W: 4.858715534210205
grad AddEdge W: 6.320570016806956e-15
grad ChooseDest W: 3.814063787460327
grad AddEdge W: 4.7932353714202027e-17
grad ChooseDest W: 6.619732856750488
grad AddEdge W: 2.4601237625548108e-15
grad ChooseDest W: 2.2892215251922607
grad AddEdge W: 3.9359384362530993e-17
grad ChooseDest W: 10.549165725708008
grad AddEdge W: 7.769432578579646e-15
grad ChooseDest W: 7.683144569396973
grad AddEdge W: 1.5591438030505863e-17
grad ChooseDest W: 7.736103057861328
grad AddEdge W: 1.1672030633358513e-16
grad ChooseDest W: 3.4456183910369873
grad AddEdge W: 6.326621431940378e-17
grad ChooseDest W: 7.264199733734131
grad AddEdge W: 2.9881433098612645e-17
grad ChooseDest W: 3.8809192180633545
grad AddEdge W: 1.3302636554761026e-16
grad ChooseDest W: 4.8137431144714355
grad AddEdge W: 2.399321672958088e-16
grad ChooseDest W: 4.392251968383789
grad AddEdge W: 6.363857794395065e-17
grad ChooseDest W: 4.61073637008667
grad AddEdge W: 1.758602922946682e-15
grad ChooseDest W: 6.369713306427002
grad AddEdge W: 4.477579279203027e-17
grad ChooseDest W: 7.547436237335205
grad AddEdge W: 2.3650765014775112e-15
grad ChooseDest W: 7.0242919921875
grad AddEdge W: 2.1238838962166288e-16
grad ChooseDest W: 7.545213222503662
grad AddEdge W: 1.0906630486395846e-16
grad ChooseDest W: 3.7099812030792236
grad AddEdge W: 2.7344906514229243e-15
grad ChooseDest W: 4.14616060256958
grad AddEdge W: 1.3485333620549898e-17
grad ChooseDest W: 9.868401527404785
grad AddEdge W: 1.115473252469594e-15
grad ChooseDest W: 3.090019702911377
=== Epoch 40: Train Loss: 4.2914, Train Log Prob: 0.0403 ===
Total mismatches: 62118
Predicted valid destination but wrong order: 27089
Epoch 40: Validation Loss: 3.9208, Validation Log Prob: 0.0278
Epoch 40: Edge Precision: 0.3765, Recall: 0.3741, F1: 0.3752, Jaccard: 0.2496
Epoch 40: TP: 2.6223335719398713, FP: 4.356907659269864, FN: 4.399141016463851
Epoch 40: Current Learning Rate: 6e-05
[Epoch 40] ‚è±Ô∏è Total: 1927.84s | Current time: 2025-07-15 09:16:34 | üèãÔ∏è Train: 1684.49s | ‚úÖ Val: 243.35s
grad AddEdge W: 3.3438106884081664e-13
grad ChooseDest W: 10.402386665344238
grad AddEdge W: 9.062449839554592e-17
grad ChooseDest W: 9.014936447143555
grad AddEdge W: 1.4011657063788814e-17
grad ChooseDest W: 2.8892829418182373
grad AddEdge W: 2.1399243444272407e-15
grad ChooseDest W: 4.688853740692139
grad AddEdge W: 1.007871222461279e-13
grad ChooseDest W: 3.44557785987854
grad AddEdge W: 5.123829014070172e-14
grad ChooseDest W: 6.305871963500977
grad AddEdge W: 5.729484379949777e-17
grad ChooseDest W: 3.9582254886627197
grad AddEdge W: 2.774297765489973e-17
grad ChooseDest W: 5.096938610076904
grad AddEdge W: 1.2769973268435259e-16
grad ChooseDest W: 5.184721946716309
grad AddEdge W: 7.806102328932179e-15
grad ChooseDest W: 2.2663238048553467
grad AddEdge W: 2.0530379493352048e-14
grad ChooseDest W: 4.132291316986084
grad AddEdge W: 5.07601137839553e-15
grad ChooseDest W: 5.1490583419799805
grad AddEdge W: 5.906433268400345e-16
grad ChooseDest W: 4.690239906311035
grad AddEdge W: 9.518412804904869e-14
grad ChooseDest W: 3.9513657093048096
grad AddEdge W: 3.888979062006219e-17
grad ChooseDest W: 6.440763473510742
grad AddEdge W: 1.1677833967100063e-17
grad ChooseDest W: 8.652383804321289
grad AddEdge W: 4.42099148292136e-15
grad ChooseDest W: 2.4275617599487305
grad AddEdge W: 1.425828559563293e-16
grad ChooseDest W: 3.498018980026245
grad AddEdge W: 1.5643722462664115e-17
grad ChooseDest W: 6.1411566734313965
grad AddEdge W: 1.585496493582215e-15
grad ChooseDest W: 6.683587074279785
grad AddEdge W: 4.501249972256073e-15
grad ChooseDest W: 8.21111011505127
grad AddEdge W: 2.2293616004157566e-16
grad ChooseDest W: 3.5508244037628174
grad AddEdge W: 3.642891506282713e-17
grad ChooseDest W: 4.571832180023193
grad AddEdge W: 1.97207054503971e-17
grad ChooseDest W: 5.122891902923584
grad AddEdge W: 6.026623537846586e-17
grad ChooseDest W: 5.574629306793213
grad AddEdge W: 5.496458998715219e-17
grad ChooseDest W: 4.264832973480225
grad AddEdge W: 2.5355833867268546e-15
grad ChooseDest W: 3.512333631515503
grad AddEdge W: 6.883558300254289e-16
grad ChooseDest W: 4.925396919250488
grad AddEdge W: 1.5233108286057118e-14
grad ChooseDest W: 5.85148286819458
grad AddEdge W: 2.9779272322495406e-16
grad ChooseDest W: 9.31799602508545
grad AddEdge W: 4.145150544966787e-15
grad ChooseDest W: 4.683994293212891
grad AddEdge W: 4.532956109537696e-15
grad ChooseDest W: 5.518631935119629
grad AddEdge W: 4.956950627384453e-16
grad ChooseDest W: 1.8422032594680786
grad AddEdge W: 1.8342254527303065e-14
grad ChooseDest W: 2.7174644470214844
grad AddEdge W: 2.2115596148424314e-15
grad ChooseDest W: 2.060940980911255
grad AddEdge W: 3.3812059711844174e-17
grad ChooseDest W: 4.925576210021973
grad AddEdge W: 2.5365818268134306e-15
grad ChooseDest W: 6.644364356994629
grad AddEdge W: 2.7383634978160078e-14
grad ChooseDest W: 7.36434268951416
grad AddEdge W: 6.876467152178113e-15
grad ChooseDest W: 6.344249725341797
grad AddEdge W: 4.530991840133013e-15
grad ChooseDest W: 3.03318452835083
grad AddEdge W: 8.759931148516475e-12
grad ChooseDest W: 1.669172763824463
grad AddEdge W: 4.5008907625238015e-13
grad ChooseDest W: 4.268823623657227
grad AddEdge W: 4.536369652315131e-15
grad ChooseDest W: 7.167003154754639
grad AddEdge W: 2.209737402127426e-17
grad ChooseDest W: 3.916654586791992
grad AddEdge W: 1.7521429202953286e-15
grad ChooseDest W: 6.261194705963135
grad AddEdge W: 1.1827030052644415e-17
grad ChooseDest W: 3.677304744720459
grad AddEdge W: 1.1918578101502599e-16
grad ChooseDest W: 7.432779788970947
grad AddEdge W: 3.433521370867221e-13
grad ChooseDest W: 3.9454591274261475
grad AddEdge W: 6.319867402977209e-15
grad ChooseDest W: 3.773746967315674
grad AddEdge W: 2.740218023514462e-16
grad ChooseDest W: 5.000856876373291
grad AddEdge W: 2.7124961240759312e-17
grad ChooseDest W: 5.332129955291748
grad AddEdge W: 1.0592862748255456e-15
grad ChooseDest W: 5.720767974853516
grad AddEdge W: 2.41500491811042e-17
grad ChooseDest W: 3.166930913925171
grad AddEdge W: 1.6224683170595628e-15
grad ChooseDest W: 5.199163436889648
grad AddEdge W: 2.3446531077511116e-16
grad ChooseDest W: 7.017398357391357
grad AddEdge W: 8.556031419113246e-15
grad ChooseDest W: 5.904491901397705
grad AddEdge W: 1.592288583970869e-13
grad ChooseDest W: 9.438142776489258
grad AddEdge W: 8.791780779955627e-13
grad ChooseDest W: 4.365782260894775
grad AddEdge W: 2.0550583664363787e-16
grad ChooseDest W: 8.99211311340332
grad AddEdge W: 1.8050335633460184e-15
grad ChooseDest W: 8.006115913391113
grad AddEdge W: 5.031592097138788e-17
grad ChooseDest W: 8.008210182189941
grad AddEdge W: 9.933565654035006e-17
grad ChooseDest W: 2.906527519226074
grad AddEdge W: 2.700996004073174e-15
grad ChooseDest W: 5.263747215270996
grad AddEdge W: 9.601081399436052e-17
grad ChooseDest W: 6.2155046463012695
grad AddEdge W: 9.859323216208167e-17
grad ChooseDest W: 6.541753768920898
grad AddEdge W: 1.0295567683356793e-16
grad ChooseDest W: 5.6437087059021
=== Epoch 41: Train Loss: 4.2629, Train Log Prob: 0.0413 ===
Total mismatches: 61788
Predicted valid destination but wrong order: 27047
Epoch 41: Validation Loss: 3.9198, Validation Log Prob: 0.0278
Epoch 41: Edge Precision: 0.3792, Recall: 0.3768, F1: 0.3779, Jaccard: 0.2517
Epoch 41: TP: 2.640372226198998, FP: 4.337866857551897, FN: 4.381102362204724
Epoch 41: Current Learning Rate: 6e-05
[Epoch 41] ‚è±Ô∏è Total: 1933.59s | Current time: 2025-07-15 09:48:48 | üèãÔ∏è Train: 1691.13s | ‚úÖ Val: 242.46s
grad AddEdge W: 1.6823921541921777e-13
grad ChooseDest W: 6.381781578063965
grad AddEdge W: 4.398183506159982e-17
grad ChooseDest W: 4.743355751037598
grad AddEdge W: 1.116836064954255e-14
grad ChooseDest W: 4.812641620635986
grad AddEdge W: 2.7118636617795732e-17
grad ChooseDest W: 5.445228099822998
grad AddEdge W: 2.8932127672771186e-15
grad ChooseDest W: 7.17559814453125
grad AddEdge W: 4.611693645336496e-16
grad ChooseDest W: 5.802820205688477
grad AddEdge W: 2.3875291934455367e-13
grad ChooseDest W: 1.2422256469726562
grad AddEdge W: 1.3110951940006194e-15
grad ChooseDest W: 4.125172138214111
grad AddEdge W: 1.4897904989523028e-17
grad ChooseDest W: 5.760458469390869
grad AddEdge W: 9.358153358132726e-13
grad ChooseDest W: 6.342535495758057
grad AddEdge W: 8.775608278249747e-14
grad ChooseDest W: 4.479855060577393
grad AddEdge W: 6.887981929821325e-17
grad ChooseDest W: 2.1773183345794678
grad AddEdge W: 3.1041830516915104e-16
grad ChooseDest W: 3.7851085662841797
grad AddEdge W: 1.6958616043567798e-15
grad ChooseDest W: 2.2958292961120605
grad AddEdge W: 1.3440473961569922e-16
grad ChooseDest W: 4.4369001388549805
grad AddEdge W: 1.0510670059185687e-14
grad ChooseDest W: 4.515462398529053
grad AddEdge W: 5.78007278744983e-15
grad ChooseDest W: 6.043002128601074
grad AddEdge W: 8.607265941651399e-12
grad ChooseDest W: 1.993388056755066
grad AddEdge W: 1.388188400620782e-17
grad ChooseDest W: 4.90446662902832
grad AddEdge W: 3.0829068546059032e-15
grad ChooseDest W: 3.8786962032318115
grad AddEdge W: 2.5434123005000893e-17
grad ChooseDest W: 8.43189811706543
grad AddEdge W: 6.401730755049173e-17
grad ChooseDest W: 5.715428352355957
grad AddEdge W: 6.313691685758778e-15
grad ChooseDest W: 5.362247467041016
grad AddEdge W: 5.202886643619739e-17
grad ChooseDest W: 3.3173091411590576
grad AddEdge W: 1.4401636392835063e-15
grad ChooseDest W: 1.3040261268615723
grad AddEdge W: 5.246793721406299e-17
grad ChooseDest W: 5.392617225646973
grad AddEdge W: 9.018852127317127e-17
grad ChooseDest W: 4.400615215301514
grad AddEdge W: 3.3248683804944354e-15
grad ChooseDest W: 4.563950538635254
grad AddEdge W: 2.5763325006929237e-16
grad ChooseDest W: 6.5200910568237305
grad AddEdge W: 2.845313054109888e-15
grad ChooseDest W: 3.301220417022705
grad AddEdge W: 3.4711648406497643e-17
grad ChooseDest W: 4.074807167053223
grad AddEdge W: 4.102584598268417e-15
grad ChooseDest W: 8.467429161071777
grad AddEdge W: 4.2230859140947574e-17
grad ChooseDest W: 6.300164699554443
grad AddEdge W: 5.095531835000157e-17
grad ChooseDest W: 6.044325351715088
grad AddEdge W: 9.955026440775644e-14
grad ChooseDest W: 5.321442127227783
grad AddEdge W: 5.757697194538246e-17
grad ChooseDest W: 5.5942816734313965
grad AddEdge W: 2.1354242701367154e-15
grad ChooseDest W: 4.606123447418213
grad AddEdge W: 3.730371639707039e-15
grad ChooseDest W: 4.840085029602051
grad AddEdge W: 9.780606062139661e-17
grad ChooseDest W: 7.030537128448486
grad AddEdge W: 1.561923164319478e-14
grad ChooseDest W: 8.568517684936523
grad AddEdge W: 4.114564284503108e-18
grad ChooseDest W: 10.755451202392578
grad AddEdge W: 3.1369691559808826e-15
grad ChooseDest W: 7.573007583618164
grad AddEdge W: 9.543074200927913e-17
grad ChooseDest W: 2.3430142402648926
grad AddEdge W: 2.8277369086961244e-15
grad ChooseDest W: 4.396836757659912
grad AddEdge W: 8.665132492032712e-17
grad ChooseDest W: 5.435305595397949
grad AddEdge W: 5.771381276498935e-16
grad ChooseDest W: 4.479574680328369
grad AddEdge W: 1.8750614497774512e-17
grad ChooseDest W: 5.582502365112305
grad AddEdge W: 4.721607816945766e-16
grad ChooseDest W: 4.380110740661621
grad AddEdge W: 8.803535123114159e-10
grad ChooseDest W: 4.072874069213867
grad AddEdge W: 2.450084655272059e-17
grad ChooseDest W: 6.817158222198486
grad AddEdge W: 1.998885093520719e-17
grad ChooseDest W: 3.974688768386841
grad AddEdge W: 1.0542648517559853e-15
grad ChooseDest W: 4.349992752075195
grad AddEdge W: 5.7327782793234125e-15
grad ChooseDest W: 6.237536430358887
grad AddEdge W: 3.362130630393573e-15
grad ChooseDest W: 5.9046549797058105
grad AddEdge W: 2.03454484972788e-17
grad ChooseDest W: 6.087319374084473
grad AddEdge W: 1.3179562667524976e-16
grad ChooseDest W: 10.946394920349121
grad AddEdge W: 8.146882662444558e-17
grad ChooseDest W: 8.307046890258789
grad AddEdge W: 2.5768603080981816e-16
grad ChooseDest W: 4.497164726257324
grad AddEdge W: 3.0268739310791368e-15
grad ChooseDest W: 7.190677165985107
grad AddEdge W: 2.937626812811456e-13
grad ChooseDest W: 3.466614007949829
grad AddEdge W: 8.813709217821608e-16
grad ChooseDest W: 4.876669406890869
grad AddEdge W: 2.298193170599712e-14
grad ChooseDest W: 7.538795471191406
grad AddEdge W: 4.506954447988255e-17
grad ChooseDest W: 7.586496829986572
grad AddEdge W: 3.5399203049234088e-15
grad ChooseDest W: 3.6396472454071045
grad AddEdge W: 1.3332385940055373e-16
grad ChooseDest W: 6.081851005554199
grad AddEdge W: 1.0324366141818949e-16
grad ChooseDest W: 2.3406624794006348
=== Epoch 42: Train Loss: 4.2230, Train Log Prob: 0.0426 ===
Total mismatches: 61067
Predicted valid destination but wrong order: 27123
Epoch 42: Validation Loss: 3.8335, Validation Log Prob: 0.0302
Epoch 42: Edge Precision: 0.3782, Recall: 0.3757, F1: 0.3768, Jaccard: 0.2513
Epoch 42: TP: 2.6329277022190407, FP: 4.34201861130995, FN: 4.388546886184681
Epoch 42: Current Learning Rate: 6e-05
[Epoch 42] ‚è±Ô∏è Total: 1939.86s | Current time: 2025-07-15 10:21:08 | üèãÔ∏è Train: 1696.76s | ‚úÖ Val: 243.10s
grad AddEdge W: 1.401608795931035e-14
grad ChooseDest W: 10.050124168395996
grad AddEdge W: 3.745978645276673e-15
grad ChooseDest W: 4.454403400421143
grad AddEdge W: 8.890741702767365e-17
grad ChooseDest W: 4.298852443695068
grad AddEdge W: 6.738956858905534e-15
grad ChooseDest W: 4.234995365142822
grad AddEdge W: 6.517808753651877e-14
grad ChooseDest W: 2.866914987564087
grad AddEdge W: 2.243956702310118e-13
grad ChooseDest W: 4.850446701049805
grad AddEdge W: 2.1633610578634976e-16
grad ChooseDest W: 5.793557643890381
grad AddEdge W: 3.289366754750615e-17
grad ChooseDest W: 3.3663156032562256
grad AddEdge W: 1.8592947057053657e-15
grad ChooseDest W: 4.907200813293457
grad AddEdge W: 1.131991639020694e-16
grad ChooseDest W: 7.35474967956543
grad AddEdge W: 2.0808243908314317e-13
grad ChooseDest W: 1.8786323070526123
grad AddEdge W: 1.7790986511691947e-13
grad ChooseDest W: 3.2872791290283203
grad AddEdge W: 6.878000705329117e-15
grad ChooseDest W: 6.355854511260986
grad AddEdge W: 4.747752349130607e-17
grad ChooseDest W: 3.3240089416503906
grad AddEdge W: 1.749571698844379e-17
grad ChooseDest W: 5.566076278686523
grad AddEdge W: 7.433841063023028e-17
grad ChooseDest W: 2.1189498901367188
grad AddEdge W: 3.4661278533497982e-15
grad ChooseDest W: 5.256385326385498
grad AddEdge W: 1.7235595817319954e-16
grad ChooseDest W: 3.2736589908599854
grad AddEdge W: 1.531068135007679e-17
grad ChooseDest W: 6.476856231689453
grad AddEdge W: 1.5178896589246066e-16
grad ChooseDest W: 4.705211162567139
grad AddEdge W: 2.829804066134119e-17
grad ChooseDest W: 7.234169006347656
grad AddEdge W: 1.4151352979997994e-17
grad ChooseDest W: 3.0427825450897217
grad AddEdge W: 2.973617242740291e-14
grad ChooseDest W: 9.911676406860352
grad AddEdge W: 6.563774113559331e-17
grad ChooseDest W: 3.7930569648742676
grad AddEdge W: 4.586113250329416e-16
grad ChooseDest W: 4.540779113769531
grad AddEdge W: 1.7733185322184493e-16
grad ChooseDest W: 5.988687038421631
grad AddEdge W: 3.029877086393627e-16
grad ChooseDest W: 4.580358982086182
grad AddEdge W: 1.0240388119054606e-16
grad ChooseDest W: 4.266911506652832
grad AddEdge W: 1.4238607961477028e-16
grad ChooseDest W: 7.24415397644043
grad AddEdge W: 3.191408183729483e-13
grad ChooseDest W: 6.058562755584717
grad AddEdge W: 3.741402099792878e-17
grad ChooseDest W: 6.1127519607543945
grad AddEdge W: 1.856845112891686e-16
grad ChooseDest W: 4.1421685218811035
grad AddEdge W: 1.0984806333471498e-17
grad ChooseDest W: 6.020061016082764
grad AddEdge W: 7.151046858074224e-15
grad ChooseDest W: 3.9279425144195557
grad AddEdge W: 1.5450640111197415e-15
grad ChooseDest W: 7.363045692443848
grad AddEdge W: 1.893617539519294e-15
grad ChooseDest W: 2.9784839153289795
grad AddEdge W: 2.841118904297109e-17
grad ChooseDest W: 4.452436447143555
grad AddEdge W: 1.1828727758133619e-16
grad ChooseDest W: 7.021947860717773
grad AddEdge W: 9.40698379957273e-16
grad ChooseDest W: 3.709198236465454
grad AddEdge W: 1.327464613926077e-14
grad ChooseDest W: 9.237505912780762
grad AddEdge W: 1.2985029143478838e-17
grad ChooseDest W: 4.310234069824219
grad AddEdge W: 1.41414440180041e-16
grad ChooseDest W: 7.252211093902588
grad AddEdge W: 4.0229085367291697e-17
grad ChooseDest W: 3.30947208404541
grad AddEdge W: 1.0087488084163364e-16
grad ChooseDest W: 7.164826393127441
grad AddEdge W: 4.425086728402657e-17
grad ChooseDest W: 6.318980693817139
grad AddEdge W: 1.8763316683260876e-17
grad ChooseDest W: 6.105730056762695
grad AddEdge W: 9.323476303610585e-15
grad ChooseDest W: 2.092226266860962
grad AddEdge W: 4.026389312746793e-17
grad ChooseDest W: 6.741392135620117
grad AddEdge W: 3.951373295611094e-17
grad ChooseDest W: 4.528719425201416
grad AddEdge W: 2.579005683734899e-15
grad ChooseDest W: 3.738314390182495
grad AddEdge W: 3.848578899144639e-15
grad ChooseDest W: 4.354783058166504
grad AddEdge W: 7.036713801605912e-18
grad ChooseDest W: 6.7351765632629395
grad AddEdge W: 7.053151025195308e-15
grad ChooseDest W: 2.7326066493988037
grad AddEdge W: 1.5612679366891735e-16
grad ChooseDest W: 5.529932498931885
grad AddEdge W: 9.219229847827075e-18
grad ChooseDest W: 5.3602824211120605
grad AddEdge W: 7.824894378283265e-12
grad ChooseDest W: 3.5492167472839355
grad AddEdge W: 7.160010266601187e-16
grad ChooseDest W: 5.609626770019531
grad AddEdge W: 4.525998580908949e-15
grad ChooseDest W: 5.983088970184326
grad AddEdge W: 1.7838947973561033e-15
grad ChooseDest W: 5.58286190032959
grad AddEdge W: 6.049895768072398e-17
grad ChooseDest W: 6.092953681945801
grad AddEdge W: 2.5843654964668875e-15
grad ChooseDest W: 9.312684059143066
grad AddEdge W: 1.2883678177181288e-16
grad ChooseDest W: 9.20472240447998
grad AddEdge W: 1.9288229816642613e-15
grad ChooseDest W: 2.7319207191467285
grad AddEdge W: 2.6015091653866287e-17
grad ChooseDest W: 8.277929306030273
grad AddEdge W: 9.255724891016792e-17
grad ChooseDest W: 4.963479995727539
grad AddEdge W: 5.151586622564874e-16
grad ChooseDest W: 1.444388747215271
=== Epoch 43: Train Loss: 4.1887, Train Log Prob: 0.0440 ===
Total mismatches: 60640
Predicted valid destination but wrong order: 27209
Epoch 43: Validation Loss: 3.8416, Validation Log Prob: 0.0299
Epoch 43: Edge Precision: 0.3764, Recall: 0.3737, F1: 0.3750, Jaccard: 0.2495
Epoch 43: TP: 2.619040801717967, FP: 4.354760200429491, FN: 4.402433786685755
Epoch 43: Current Learning Rate: 6e-05
[Epoch 43] ‚è±Ô∏è Total: 1923.99s | Current time: 2025-07-15 10:53:12 | üèãÔ∏è Train: 1678.91s | ‚úÖ Val: 245.08s
grad AddEdge W: 5.267785566884535e-15
grad ChooseDest W: 11.381832122802734
grad AddEdge W: 3.391888512487172e-17
grad ChooseDest W: 4.223893165588379
grad AddEdge W: 3.965409730042951e-15
grad ChooseDest W: 7.869020462036133
grad AddEdge W: 2.8030268400423483e-15
grad ChooseDest W: 2.936648368835449
grad AddEdge W: 6.407662632657913e-17
grad ChooseDest W: 3.4618077278137207
grad AddEdge W: 9.681149008572612e-18
grad ChooseDest W: 5.002283096313477
grad AddEdge W: 1.4939784164554742e-13
grad ChooseDest W: 2.135495901107788
grad AddEdge W: 1.0150814384882463e-16
grad ChooseDest W: 5.392537593841553
grad AddEdge W: 2.936380266186717e-16
grad ChooseDest W: 4.657016754150391
grad AddEdge W: 9.249497293030342e-15
grad ChooseDest W: 6.48283052444458
grad AddEdge W: 5.164388996167031e-16
grad ChooseDest W: 1.9243279695510864
grad AddEdge W: 6.6087187670016076e-15
grad ChooseDest W: 7.226309299468994
grad AddEdge W: 3.323379098049815e-17
grad ChooseDest W: 9.61064338684082
grad AddEdge W: 6.9775253825656025e-15
grad ChooseDest W: 3.1513736248016357
grad AddEdge W: 1.0225315035409317e-15
grad ChooseDest W: 5.632218837738037
grad AddEdge W: 6.464529645409709e-17
grad ChooseDest W: 4.577841758728027
grad AddEdge W: 3.12921520462348e-15
grad ChooseDest W: 2.6137192249298096
grad AddEdge W: 7.894875802257623e-17
grad ChooseDest W: 3.8272058963775635
grad AddEdge W: 1.1750758481217979e-14
grad ChooseDest W: 4.205382823944092
grad AddEdge W: 1.0538995026230328e-16
grad ChooseDest W: 4.896999359130859
grad AddEdge W: 4.197589229765668e-17
grad ChooseDest W: 3.119922637939453
grad AddEdge W: 2.9470854391510314e-16
grad ChooseDest W: 2.8850412368774414
grad AddEdge W: 2.2761548767956364e-16
grad ChooseDest W: 3.641923427581787
grad AddEdge W: 5.404256815428628e-17
grad ChooseDest W: 4.536679744720459
grad AddEdge W: 9.678745718020901e-17
grad ChooseDest W: 7.709028244018555
grad AddEdge W: 2.223441564327619e-13
grad ChooseDest W: 3.673063039779663
grad AddEdge W: 4.104903245082407e-16
grad ChooseDest W: 7.971698760986328
grad AddEdge W: 1.3611734759081881e-14
grad ChooseDest W: 4.507437229156494
grad AddEdge W: 5.803737405688457e-17
grad ChooseDest W: 5.188817024230957
grad AddEdge W: 1.150847042412828e-15
grad ChooseDest W: 6.111332893371582
grad AddEdge W: 6.079366558936437e-17
grad ChooseDest W: 3.3843369483947754
grad AddEdge W: 3.409140853087068e-17
grad ChooseDest W: 9.508880615234375
grad AddEdge W: 2.842984348779649e-15
grad ChooseDest W: 2.802703857421875
grad AddEdge W: 5.199861147811265e-17
grad ChooseDest W: 3.7873568534851074
grad AddEdge W: 3.902080941164569e-17
grad ChooseDest W: 3.45794939994812
grad AddEdge W: 6.787561541712897e-17
grad ChooseDest W: 5.953296661376953
grad AddEdge W: 5.666666025305744e-10
grad ChooseDest W: 3.8741815090179443
grad AddEdge W: 2.1972846719203742e-12
grad ChooseDest W: 0.21737687289714813
grad AddEdge W: 4.4540294471636424e-17
grad ChooseDest W: 10.378981590270996
grad AddEdge W: 2.736504048738548e-16
grad ChooseDest W: 5.180939197540283
grad AddEdge W: 4.925096365216179e-15
grad ChooseDest W: 6.48857307434082
grad AddEdge W: 3.5863523217512846e-16
grad ChooseDest W: 9.883528709411621
grad AddEdge W: 1.621082094701822e-16
grad ChooseDest W: 4.553310871124268
grad AddEdge W: 4.874041030803952e-14
grad ChooseDest W: 4.617050647735596
grad AddEdge W: 1.82022139348588e-16
grad ChooseDest W: 3.9857077598571777
grad AddEdge W: 7.873614348839254e-16
grad ChooseDest W: 7.559901714324951
grad AddEdge W: 8.673281544555339e-18
grad ChooseDest W: 1.3010728359222412
grad AddEdge W: 7.05544232872697e-17
grad ChooseDest W: 4.00755500793457
grad AddEdge W: 2.6315346437171113e-15
grad ChooseDest W: 6.557530403137207
grad AddEdge W: 6.357177510237866e-15
grad ChooseDest W: 2.6604483127593994
grad AddEdge W: 2.3342707668362645e-17
grad ChooseDest W: 6.274038314819336
grad AddEdge W: 7.693827264740674e-15
grad ChooseDest W: 4.994542598724365
grad AddEdge W: 3.714685013040363e-15
grad ChooseDest W: 1.9205029010772705
grad AddEdge W: 7.016183675110713e-17
grad ChooseDest W: 3.338127851486206
grad AddEdge W: 4.3966614938328847e-17
grad ChooseDest W: 5.162271976470947
grad AddEdge W: 1.1483854587889886e-15
grad ChooseDest W: 3.7641968727111816
grad AddEdge W: 5.755999819921287e-17
grad ChooseDest W: 4.401205539703369
grad AddEdge W: 4.471111057685107e-16
grad ChooseDest W: 4.761058330535889
grad AddEdge W: 4.973716056388576e-16
grad ChooseDest W: 3.67681884765625
grad AddEdge W: 9.396970943693897e-17
grad ChooseDest W: 6.021349906921387
grad AddEdge W: 1.0204991538631135e-15
grad ChooseDest W: 4.131124496459961
grad AddEdge W: 4.931911870242473e-17
grad ChooseDest W: 6.239493370056152
grad AddEdge W: 3.2013540758304827e-17
grad ChooseDest W: 3.8292453289031982
grad AddEdge W: 3.0354977852733696e-15
grad ChooseDest W: 5.507964611053467
grad AddEdge W: 1.928538510942882e-16
grad ChooseDest W: 4.612802505493164
grad AddEdge W: 1.609931038300117e-17
grad ChooseDest W: 5.659884452819824
=== Epoch 44: Train Loss: 4.1679, Train Log Prob: 0.0447 ===
Total mismatches: 60326
Predicted valid destination but wrong order: 27279
Epoch 44: Validation Loss: 3.8376, Validation Log Prob: 0.0300
Epoch 44: Edge Precision: 0.3793, Recall: 0.3767, F1: 0.3779, Jaccard: 0.2516
Epoch 44: TP: 2.641088045812455, FP: 4.336148890479599, FN: 4.380386542591267
Epoch 44: Current Learning Rate: 6e-05
[Epoch 44] ‚è±Ô∏è Total: 1949.07s | Current time: 2025-07-15 11:25:41 | üèãÔ∏è Train: 1706.04s | ‚úÖ Val: 243.03s
grad AddEdge W: 2.4484118379931256e-15
grad ChooseDest W: 7.008816242218018
grad AddEdge W: 6.206526056654009e-17
grad ChooseDest W: 3.5223453044891357
grad AddEdge W: 5.4051476293913436e-14
grad ChooseDest W: 3.4430010318756104
grad AddEdge W: 4.4125250328597154e-13
grad ChooseDest W: 3.2979986667633057
grad AddEdge W: 2.6607793032540133e-17
grad ChooseDest W: 9.125020027160645
grad AddEdge W: 3.0755568447907167e-13
grad ChooseDest W: 3.885793924331665
grad AddEdge W: 2.1267317798039754e-16
grad ChooseDest W: 3.8674609661102295
grad AddEdge W: 4.6716398213749076e-17
grad ChooseDest W: 8.013559341430664
grad AddEdge W: 6.202413049950599e-16
grad ChooseDest W: 4.961272239685059
grad AddEdge W: 2.8941329097556328e-18
grad ChooseDest W: 7.467215061187744
grad AddEdge W: 3.618842811542065e-15
grad ChooseDest W: 2.617894172668457
grad AddEdge W: 2.6521961066412487e-15
grad ChooseDest W: 6.7785139083862305
grad AddEdge W: 1.6060065626019205e-17
grad ChooseDest W: 7.408304214477539
grad AddEdge W: 1.117712828757958e-14
grad ChooseDest W: 5.124761581420898
grad AddEdge W: 2.070912308579917e-16
grad ChooseDest W: 4.2887444496154785
grad AddEdge W: 3.9898993980768736e-17
grad ChooseDest W: 6.880555629730225
grad AddEdge W: 1.9337705937534023e-17
grad ChooseDest W: 5.700226783752441
grad AddEdge W: 9.527531808090287e-17
grad ChooseDest W: 5.0431952476501465
grad AddEdge W: 8.06205363626602e-17
grad ChooseDest W: 7.370931148529053
grad AddEdge W: 4.4570251644700644e-17
grad ChooseDest W: 5.60472297668457
grad AddEdge W: 5.518817359800282e-17
grad ChooseDest W: 3.3847930431365967
grad AddEdge W: 3.3386827996498834e-16
grad ChooseDest W: 2.944490671157837
grad AddEdge W: 3.570685917996224e-17
grad ChooseDest W: 5.32164192199707
grad AddEdge W: 7.939785092074352e-17
grad ChooseDest W: 7.5398688316345215
grad AddEdge W: 5.199097494669756e-17
grad ChooseDest W: 5.0096211433410645
grad AddEdge W: 1.0249208511362381e-16
grad ChooseDest W: 6.679659366607666
grad AddEdge W: 4.3423230894956025e-18
grad ChooseDest W: 10.218915939331055
grad AddEdge W: 9.791731363445813e-15
grad ChooseDest W: 7.0424699783325195
grad AddEdge W: 1.168432928705485e-15
grad ChooseDest W: 5.134404182434082
grad AddEdge W: 1.3576068054557575e-16
grad ChooseDest W: 4.459731101989746
grad AddEdge W: 5.924233542967117e-13
grad ChooseDest W: 4.661920547485352
grad AddEdge W: 1.932985301567069e-16
grad ChooseDest W: 9.94426155090332
grad AddEdge W: 1.6551662240433022e-15
grad ChooseDest W: 8.635087966918945
grad AddEdge W: 2.9111270905950734e-15
grad ChooseDest W: 10.041197776794434
grad AddEdge W: 4.383340868415906e-15
grad ChooseDest W: 5.711071968078613
grad AddEdge W: 1.9443753800785771e-16
grad ChooseDest W: 4.984748840332031
grad AddEdge W: 1.4487161838914922e-16
grad ChooseDest W: 5.259425640106201
grad AddEdge W: 6.025572687596399e-16
grad ChooseDest W: 3.9492270946502686
grad AddEdge W: 5.119286609308108e-16
grad ChooseDest W: 4.801661491394043
grad AddEdge W: 1.2530928659319274e-16
grad ChooseDest W: 5.886123180389404
grad AddEdge W: 6.442642446401555e-17
grad ChooseDest W: 4.604331970214844
grad AddEdge W: 2.1429459756478928e-16
grad ChooseDest W: 5.90675687789917
grad AddEdge W: 1.0131552723313003e-15
grad ChooseDest W: 2.6322271823883057
grad AddEdge W: 7.398819559376513e-16
grad ChooseDest W: 4.295516490936279
grad AddEdge W: 1.3316470932130293e-14
grad ChooseDest W: 6.720367908477783
grad AddEdge W: 1.4647155112994928e-17
grad ChooseDest W: 5.761279582977295
grad AddEdge W: 1.2053425746705483e-16
grad ChooseDest W: 7.513611793518066
grad AddEdge W: 8.18232437384225e-17
grad ChooseDest W: 3.8367526531219482
grad AddEdge W: 2.808650410893178e-17
grad ChooseDest W: 4.216933250427246
grad AddEdge W: 5.463824989779438e-15
grad ChooseDest W: 9.73983097076416
grad AddEdge W: 3.620365776781228e-15
grad ChooseDest W: 8.117754936218262
grad AddEdge W: 6.849964708868387e-17
grad ChooseDest W: 5.725946426391602
grad AddEdge W: 1.1986170007204512e-16
grad ChooseDest W: 5.04932165145874
grad AddEdge W: 4.614120077093024e-15
grad ChooseDest W: 4.405357360839844
grad AddEdge W: 2.929129267111526e-17
grad ChooseDest W: 3.6223273277282715
grad AddEdge W: 6.062529132131798e-18
grad ChooseDest W: 10.174038887023926
grad AddEdge W: 1.3612884871005575e-16
grad ChooseDest W: 4.698381423950195
grad AddEdge W: 1.0146705282471545e-17
grad ChooseDest W: 5.3681769371032715
grad AddEdge W: 3.8411438689267674e-17
grad ChooseDest W: 3.551910161972046
grad AddEdge W: 7.240641119560447e-18
grad ChooseDest W: 8.713179588317871
grad AddEdge W: 5.767640884882979e-15
grad ChooseDest W: 5.925991535186768
grad AddEdge W: 1.2280889297850133e-14
grad ChooseDest W: 4.39732551574707
grad AddEdge W: 6.260799031004838e-17
grad ChooseDest W: 7.773660659790039
grad AddEdge W: 7.596959899266315e-14
grad ChooseDest W: 4.510651588439941
grad AddEdge W: 4.347093787504053e-15
grad ChooseDest W: 5.029946804046631
grad AddEdge W: 8.742173516129367e-14
grad ChooseDest W: 3.7853994369506836
=== Epoch 45: Train Loss: 4.1271, Train Log Prob: 0.0461 ===
Total mismatches: 59783
Predicted valid destination but wrong order: 27227
Epoch 45: Validation Loss: 3.7008, Validation Log Prob: 0.0337
Epoch 45: Edge Precision: 0.3783, Recall: 0.3757, F1: 0.3769, Jaccard: 0.2515
Epoch 45: TP: 2.632641374373658, FP: 4.341302791696492, FN: 4.388833214030065
Epoch 45: Current Learning Rate: 6e-05
[Epoch 45] ‚è±Ô∏è Total: 1925.89s | Current time: 2025-07-15 11:57:47 | üèãÔ∏è Train: 1682.17s | ‚úÖ Val: 243.73s
grad AddEdge W: 1.4035988151373142e-14
grad ChooseDest W: 8.879929542541504
grad AddEdge W: 3.620252274366296e-15
grad ChooseDest W: 4.48995304107666
grad AddEdge W: 2.311394590687743e-17
grad ChooseDest W: 3.527681589126587
grad AddEdge W: 5.609842961383578e-17
grad ChooseDest W: 3.9570796489715576
grad AddEdge W: 2.3246814274310597e-17
grad ChooseDest W: 2.6485114097595215
grad AddEdge W: 6.233500085557118e-17
grad ChooseDest W: 2.4328255653381348
grad AddEdge W: 2.579797659540582e-16
grad ChooseDest W: 5.186707019805908
grad AddEdge W: 2.2686265538395586e-15
grad ChooseDest W: 6.851762294769287
grad AddEdge W: 1.362887129439602e-15
grad ChooseDest W: 3.774916410446167
grad AddEdge W: 7.296885099874868e-17
grad ChooseDest W: 4.563778877258301
grad AddEdge W: 9.771632145110195e-17
grad ChooseDest W: 3.3650498390197754
grad AddEdge W: 2.209114369690051e-17
grad ChooseDest W: 7.902321815490723
grad AddEdge W: 7.620730544854115e-16
grad ChooseDest W: 4.952124118804932
grad AddEdge W: 2.119295128312103e-17
grad ChooseDest W: 3.9980592727661133
grad AddEdge W: 1.7891089468909436e-17
grad ChooseDest W: 6.5246968269348145
grad AddEdge W: 1.4693468889317323e-15
grad ChooseDest W: 4.559660911560059
grad AddEdge W: 9.879709287545328e-15
grad ChooseDest W: 3.6534435749053955
grad AddEdge W: 6.013245711235888e-17
grad ChooseDest W: 4.5964765548706055
grad AddEdge W: 1.8368569882210565e-16
grad ChooseDest W: 7.732795715332031
grad AddEdge W: 1.7612893938180173e-15
grad ChooseDest W: 3.984637975692749
grad AddEdge W: 1.8342316493057112e-17
grad ChooseDest W: 5.681029319763184
grad AddEdge W: 9.799058198439563e-15
grad ChooseDest W: 3.7114462852478027
grad AddEdge W: 1.0495467723606604e-15
grad ChooseDest W: 2.166163921356201
grad AddEdge W: 4.458516405678375e-17
grad ChooseDest W: 4.727196216583252
grad AddEdge W: 4.4536022513906506e-15
grad ChooseDest W: 4.167233943939209
grad AddEdge W: 4.95721400169149e-17
grad ChooseDest W: 4.53974723815918
grad AddEdge W: 1.0216292016938691e-16
grad ChooseDest W: 6.068142414093018
grad AddEdge W: 2.210011198910181e-17
grad ChooseDest W: 4.72625732421875
grad AddEdge W: 4.254655096736721e-17
grad ChooseDest W: 5.967696666717529
grad AddEdge W: 1.6276405119937344e-15
grad ChooseDest W: 6.97653341293335
grad AddEdge W: 3.366952577204055e-15
grad ChooseDest W: 3.099855899810791
grad AddEdge W: 3.0194534195353767e-17
grad ChooseDest W: 7.212976455688477
grad AddEdge W: 1.4697165468154083e-13
grad ChooseDest W: 4.609737873077393
grad AddEdge W: 1.8260929199971285e-15
grad ChooseDest W: 3.886619806289673
grad AddEdge W: 5.4280132838024735e-15
grad ChooseDest W: 2.3420932292938232
grad AddEdge W: 1.6821035393621038e-16
grad ChooseDest W: 4.133449554443359
grad AddEdge W: 1.1270142881341706e-15
grad ChooseDest W: 5.643475532531738
grad AddEdge W: 2.495531433815935e-15
grad ChooseDest W: 17.989973068237305
grad AddEdge W: 5.0890196074736494e-17
grad ChooseDest W: 10.615002632141113
grad AddEdge W: 3.5516455437842337e-17
grad ChooseDest W: 3.5797436237335205
grad AddEdge W: 2.133742808092462e-13
grad ChooseDest W: 4.300796985626221
grad AddEdge W: 3.709249602617832e-15
grad ChooseDest W: 3.75984263420105
grad AddEdge W: 2.0261542935536117e-16
grad ChooseDest W: 5.7982707023620605
grad AddEdge W: 5.40798688383054e-15
grad ChooseDest W: 7.889378070831299
grad AddEdge W: 5.4867994316760084e-18
grad ChooseDest W: 8.575743675231934
grad AddEdge W: 5.713208641868286e-16
grad ChooseDest W: 4.167737007141113
grad AddEdge W: 2.0864045676549777e-15
grad ChooseDest W: 2.318932294845581
grad AddEdge W: 1.274645486925915e-16
grad ChooseDest W: 5.801719665527344
grad AddEdge W: 4.939885891347484e-17
grad ChooseDest W: 4.027923107147217
grad AddEdge W: 4.011430724133172e-15
grad ChooseDest W: 3.672346591949463
grad AddEdge W: 2.3468793154772878e-17
grad ChooseDest W: 8.587295532226562
grad AddEdge W: 7.470156442583698e-18
grad ChooseDest W: 6.143092632293701
grad AddEdge W: 2.9857264121884764e-18
grad ChooseDest W: 5.682946681976318
grad AddEdge W: 9.96435133120076e-17
grad ChooseDest W: 7.0921406745910645
grad AddEdge W: 1.2726228516572106e-15
grad ChooseDest W: 6.801207542419434
grad AddEdge W: 5.994356452995644e-15
grad ChooseDest W: 4.357640743255615
grad AddEdge W: 1.9535419441639836e-15
grad ChooseDest W: 3.0224344730377197
grad AddEdge W: 8.22693654038295e-18
grad ChooseDest W: 6.754566192626953
grad AddEdge W: 6.036001119014977e-17
grad ChooseDest W: 5.152442932128906
grad AddEdge W: 1.3830500499468091e-14
grad ChooseDest W: 3.39310884475708
grad AddEdge W: 9.745589455402372e-16
grad ChooseDest W: 8.102498054504395
grad AddEdge W: 6.132617799794641e-17
grad ChooseDest W: 6.387790679931641
grad AddEdge W: 1.694093853213305e-17
grad ChooseDest W: 5.901116371154785
grad AddEdge W: 6.05352212787783e-16
grad ChooseDest W: 4.250583171844482
grad AddEdge W: 1.005294436003866e-17
grad ChooseDest W: 3.4206137657165527
grad AddEdge W: 1.599206251229118e-15
grad ChooseDest W: 7.609076499938965
=== Epoch 46: Train Loss: 4.0947, Train Log Prob: 0.0476 ===
Total mismatches: 59084
Predicted valid destination but wrong order: 27448
Epoch 46: Validation Loss: 3.7191, Validation Log Prob: 0.0333
Epoch 46: Edge Precision: 0.3761, Recall: 0.3738, F1: 0.3748, Jaccard: 0.2494
Epoch 46: TP: 2.6197566213314243, FP: 4.360629921259843, FN: 4.4017179670722975
Epoch 46: Current Learning Rate: 6e-05
[Epoch 46] ‚è±Ô∏è Total: 1942.24s | Current time: 2025-07-15 12:30:09 | üèãÔ∏è Train: 1695.87s | ‚úÖ Val: 246.37s
grad AddEdge W: 1.8915833898964628e-16
grad ChooseDest W: 9.147356986999512
grad AddEdge W: 1.5864826516910559e-15
grad ChooseDest W: 3.15653920173645
grad AddEdge W: 1.8714744637691762e-17
grad ChooseDest W: 5.940384387969971
grad AddEdge W: 4.0153246140010385e-17
grad ChooseDest W: 3.0772793292999268
grad AddEdge W: 7.609649977475489e-15
grad ChooseDest W: 3.750347375869751
grad AddEdge W: 5.521389031237485e-16
grad ChooseDest W: 4.394476413726807
grad AddEdge W: 8.218742820107245e-17
grad ChooseDest W: 5.009424686431885
grad AddEdge W: 1.1231843492538214e-16
grad ChooseDest W: 7.60164737701416
grad AddEdge W: 1.4848143458233063e-16
grad ChooseDest W: 5.061911106109619
grad AddEdge W: 1.9811054381181636e-13
grad ChooseDest W: 4.409295558929443
grad AddEdge W: 5.4459907243098885e-17
grad ChooseDest W: 3.6696767807006836
grad AddEdge W: 1.0156461712360485e-16
grad ChooseDest W: 6.221854209899902
grad AddEdge W: 1.1829901851677632e-14
grad ChooseDest W: 7.485469341278076
grad AddEdge W: 1.648827221371953e-17
grad ChooseDest W: 5.189958095550537
grad AddEdge W: 3.885062196369658e-17
grad ChooseDest W: 4.884885787963867
grad AddEdge W: 5.963723506458192e-15
grad ChooseDest W: 4.502513885498047
grad AddEdge W: 3.619696303115542e-16
grad ChooseDest W: 6.898788928985596
grad AddEdge W: 3.6385681251825674e-13
grad ChooseDest W: 2.400817632675171
grad AddEdge W: 2.3576031297838865e-15
grad ChooseDest W: 5.019471168518066
grad AddEdge W: 3.0777302789232076e-17
grad ChooseDest W: 2.6755282878875732
grad AddEdge W: 5.4506053995111994e-17
grad ChooseDest W: 3.160723924636841
grad AddEdge W: 9.648927511299589e-17
grad ChooseDest W: 14.809280395507812
grad AddEdge W: 6.377301133710277e-17
grad ChooseDest W: 3.9028472900390625
grad AddEdge W: 3.3395212034489875e-15
grad ChooseDest W: 8.253653526306152
grad AddEdge W: 8.9834858547913e-17
grad ChooseDest W: 1.8116086721420288
grad AddEdge W: 2.0412509353027455e-16
grad ChooseDest W: 6.193931579589844
grad AddEdge W: 9.828252327167205e-18
grad ChooseDest W: 5.175684928894043
grad AddEdge W: 2.7748195510203715e-17
grad ChooseDest W: 3.358485221862793
grad AddEdge W: 1.8348394616198152e-17
grad ChooseDest W: 4.721179962158203
grad AddEdge W: 8.319783765728655e-15
grad ChooseDest W: 5.6222028732299805
grad AddEdge W: 9.363908700046275e-18
grad ChooseDest W: 5.197413444519043
grad AddEdge W: 1.4364017806762927e-17
grad ChooseDest W: 6.606823921203613
grad AddEdge W: 1.3549446073723168e-16
grad ChooseDest W: 3.0336103439331055
grad AddEdge W: 1.2529554454241473e-14
grad ChooseDest W: 2.4427382946014404
grad AddEdge W: 2.1921528657935288e-17
grad ChooseDest W: 6.422741413116455
grad AddEdge W: 1.9672952313634415e-17
grad ChooseDest W: 6.3136162757873535
grad AddEdge W: 1.4724246691723645e-17
grad ChooseDest W: 6.630186080932617
grad AddEdge W: 4.656854795106135e-17
grad ChooseDest W: 6.633681774139404
grad AddEdge W: 3.199449482543912e-15
grad ChooseDest W: 4.07999849319458
grad AddEdge W: 1.0117280218151768e-15
grad ChooseDest W: 3.655486822128296
grad AddEdge W: 5.603205002403962e-17
grad ChooseDest W: 3.036313533782959
grad AddEdge W: 4.799054421593391e-17
grad ChooseDest W: 3.2148549556732178
grad AddEdge W: 4.3432884242258774e-13
grad ChooseDest W: 6.76972770690918
grad AddEdge W: 7.427595915572701e-16
grad ChooseDest W: 3.101525068283081
grad AddEdge W: 1.4392317971624081e-15
grad ChooseDest W: 8.081764221191406
grad AddEdge W: 6.93283960356783e-17
grad ChooseDest W: 3.959754228591919
grad AddEdge W: 3.5043149308784395e-17
grad ChooseDest W: 4.876073360443115
grad AddEdge W: 1.0437790967209568e-17
grad ChooseDest W: 3.886204957962036
grad AddEdge W: 1.6070494544481728e-13
grad ChooseDest W: 6.295370101928711
grad AddEdge W: 2.825828305237944e-17
grad ChooseDest W: 3.7025954723358154
grad AddEdge W: 1.1592620301936688e-17
grad ChooseDest W: 4.773381233215332
grad AddEdge W: 3.984129158177271e-15
grad ChooseDest W: 2.8155248165130615
grad AddEdge W: 6.927695704828053e-15
grad ChooseDest W: 6.949370384216309
grad AddEdge W: 7.127536743939132e-17
grad ChooseDest W: 6.261203765869141
grad AddEdge W: 7.741240103369823e-14
grad ChooseDest W: 2.7376346588134766
grad AddEdge W: 4.244951354944078e-15
grad ChooseDest W: 4.375525951385498
grad AddEdge W: 3.1177125501393257e-16
grad ChooseDest W: 2.524116277694702
grad AddEdge W: 1.041270519312157e-15
grad ChooseDest W: 3.9667282104492188
grad AddEdge W: 1.3655634359155703e-15
grad ChooseDest W: 6.935440540313721
grad AddEdge W: 5.0156930240210287e-17
grad ChooseDest W: 6.313544273376465
grad AddEdge W: 8.438151220272405e-16
grad ChooseDest W: 6.8462605476379395
grad AddEdge W: 9.280518140952967e-18
grad ChooseDest W: 8.157767295837402
grad AddEdge W: 8.081141550202176e-15
grad ChooseDest W: 2.802802801132202
grad AddEdge W: 1.8998243851985367e-15
grad ChooseDest W: 4.36417818069458
grad AddEdge W: 1.7663297163102133e-17
grad ChooseDest W: 6.327277183532715
grad AddEdge W: 2.623678201373091e-16
grad ChooseDest W: 6.0098161697387695
=== Epoch 47: Train Loss: 4.0636, Train Log Prob: 0.0489 ===
Total mismatches: 58642
Predicted valid destination but wrong order: 27520
Epoch 47: Validation Loss: 3.6624, Validation Log Prob: 0.0350
Epoch 47: Edge Precision: 0.3777, Recall: 0.3751, F1: 0.3763, Jaccard: 0.2501
Epoch 47: TP: 2.629062276306371, FP: 4.34688618468146, FN: 4.392412312097352
Epoch 47: Current Learning Rate: 6e-05
[Epoch 47] ‚è±Ô∏è Total: 1946.34s | Current time: 2025-07-15 13:02:35 | üèãÔ∏è Train: 1702.17s | ‚úÖ Val: 244.17s
grad AddEdge W: 1.3902437790068537e-16
grad ChooseDest W: 11.446393966674805
grad AddEdge W: 3.595872972078423e-15
grad ChooseDest W: 6.669389247894287
grad AddEdge W: 1.0652575182905095e-14
grad ChooseDest W: 4.514311790466309
grad AddEdge W: 1.547208248555936e-17
grad ChooseDest W: 6.852125644683838
grad AddEdge W: 8.442281432332555e-17
grad ChooseDest W: 2.344895124435425
grad AddEdge W: 8.159278460232033e-17
grad ChooseDest W: 9.330232620239258
grad AddEdge W: 2.856754775161399e-15
grad ChooseDest W: 6.316746711730957
grad AddEdge W: 2.760976187160929e-17
grad ChooseDest W: 1.7384283542633057
grad AddEdge W: 9.303872758367789e-17
grad ChooseDest W: 4.773782253265381
grad AddEdge W: 7.241996868584422e-18
grad ChooseDest W: 11.33450698852539
grad AddEdge W: 5.822465833547842e-16
grad ChooseDest W: 9.527763366699219
grad AddEdge W: 4.913463977048241e-14
grad ChooseDest W: 2.6119706630706787
grad AddEdge W: 2.2211785633430986e-14
grad ChooseDest W: 1.845625877380371
grad AddEdge W: 2.308077430995283e-16
grad ChooseDest W: 5.103315353393555
grad AddEdge W: 1.7111292673519202e-15
grad ChooseDest W: 3.9540510177612305
grad AddEdge W: 7.916692194605342e-17
grad ChooseDest W: 4.5789289474487305
grad AddEdge W: 2.8984129142985496e-15
grad ChooseDest W: 5.393077373504639
grad AddEdge W: 2.5774648778642843e-16
grad ChooseDest W: 5.359594345092773
grad AddEdge W: 5.671944373051609e-17
grad ChooseDest W: 7.989931583404541
grad AddEdge W: 8.199135330867288e-17
grad ChooseDest W: 8.981268882751465
grad AddEdge W: 2.9819295158648763e-15
grad ChooseDest W: 2.4793500900268555
grad AddEdge W: 4.54657143624587e-17
grad ChooseDest W: 7.042822360992432
grad AddEdge W: 2.1640755830940658e-15
grad ChooseDest W: 4.617048740386963
grad AddEdge W: 4.328391630900923e-17
grad ChooseDest W: 3.4171133041381836
grad AddEdge W: 3.997626204675295e-14
grad ChooseDest W: 4.533507347106934
grad AddEdge W: 1.9018837737562182e-17
grad ChooseDest W: 6.672857284545898
grad AddEdge W: 1.7212106534901408e-15
grad ChooseDest W: 3.784367799758911
grad AddEdge W: 6.478844052232053e-15
grad ChooseDest W: 3.5554049015045166
grad AddEdge W: 4.6274141136163924e-17
grad ChooseDest W: 6.7724103927612305
grad AddEdge W: 3.6929260918781154e-14
grad ChooseDest W: 4.690903663635254
grad AddEdge W: 1.0370580127072246e-15
grad ChooseDest W: 6.2008585929870605
grad AddEdge W: 2.639581807440607e-17
grad ChooseDest W: 5.588935375213623
grad AddEdge W: 1.851713498247226e-13
grad ChooseDest W: 3.247621774673462
grad AddEdge W: 7.398521031931615e-12
grad ChooseDest W: 5.558548927307129
grad AddEdge W: 2.2824153105436827e-17
grad ChooseDest W: 2.5432493686676025
grad AddEdge W: 5.632110001729015e-17
grad ChooseDest W: 5.578835964202881
grad AddEdge W: 3.5024891778304124e-16
grad ChooseDest W: 8.318397521972656
grad AddEdge W: 5.687082969401411e-16
grad ChooseDest W: 7.127708911895752
grad AddEdge W: 3.057367752455002e-15
grad ChooseDest W: 4.115821361541748
grad AddEdge W: 2.9245506569849228e-15
grad ChooseDest W: 7.3461127281188965
grad AddEdge W: 1.9985837681671783e-16
grad ChooseDest W: 6.571704387664795
grad AddEdge W: 3.651197776061285e-15
grad ChooseDest W: 3.9285645484924316
grad AddEdge W: 3.892150803346992e-17
grad ChooseDest W: 4.436844348907471
grad AddEdge W: 1.5541870853572623e-15
grad ChooseDest W: 4.45005989074707
grad AddEdge W: 2.3506172255514067e-14
grad ChooseDest W: 2.0827114582061768
grad AddEdge W: 6.316333952098178e-17
grad ChooseDest W: 6.782532691955566
grad AddEdge W: 8.990266254272397e-18
grad ChooseDest W: 7.760688781738281
grad AddEdge W: 4.99826942394711e-16
grad ChooseDest W: 6.693428993225098
grad AddEdge W: 1.13208046167487e-17
grad ChooseDest W: 6.015035629272461
grad AddEdge W: 3.501402593377763e-17
grad ChooseDest W: 3.88342022895813
grad AddEdge W: 6.159669649849779e-16
grad ChooseDest W: 2.889662027359009
grad AddEdge W: 8.843574011355019e-16
grad ChooseDest W: 3.809452772140503
grad AddEdge W: 3.3487848752295852e-18
grad ChooseDest W: 5.294412612915039
grad AddEdge W: 2.436959449620435e-17
grad ChooseDest W: 5.102646350860596
grad AddEdge W: 1.5637553763246e-18
grad ChooseDest W: 5.925919055938721
grad AddEdge W: 5.314795246947548e-17
grad ChooseDest W: 6.572291374206543
grad AddEdge W: 3.543582451870863e-16
grad ChooseDest W: 6.001702785491943
grad AddEdge W: 1.99577820313997e-17
grad ChooseDest W: 8.74079704284668
grad AddEdge W: 3.3312432695694794e-17
grad ChooseDest W: 4.31337833404541
grad AddEdge W: 2.0932005578362603e-17
grad ChooseDest W: 5.943844795227051
grad AddEdge W: 1.7733869565987197e-16
grad ChooseDest W: 4.808974742889404
grad AddEdge W: 9.206919249642694e-17
grad ChooseDest W: 4.093137741088867
grad AddEdge W: 7.686465701396087e-15
grad ChooseDest W: 5.82514762878418
grad AddEdge W: 4.827649062752614e-17
grad ChooseDest W: 5.108830451965332
grad AddEdge W: 2.2398954080269295e-15
grad ChooseDest W: 3.1394309997558594
grad AddEdge W: 8.747443249554393e-18
grad ChooseDest W: 5.180980205535889
=== Epoch 48: Train Loss: 4.0228, Train Log Prob: 0.0503 ===
Total mismatches: 58149
Predicted valid destination but wrong order: 27525
Epoch 48: Validation Loss: 3.6810, Validation Log Prob: 0.0346
Epoch 48: Edge Precision: 0.3773, Recall: 0.3744, F1: 0.3757, Jaccard: 0.2500
Epoch 48: TP: 2.624051539012169, FP: 4.345597709377237, FN: 4.397423049391553
Epoch 48: Current Learning Rate: 6e-05
[Epoch 48] ‚è±Ô∏è Total: 1933.36s | Current time: 2025-07-15 13:34:49 | üèãÔ∏è Train: 1688.66s | ‚úÖ Val: 244.70s
grad AddEdge W: 2.7358727804939476e-13
grad ChooseDest W: 9.123130798339844
grad AddEdge W: 1.9866850135483172e-13
grad ChooseDest W: 4.536361217498779
grad AddEdge W: 1.901117010415606e-16
grad ChooseDest W: 6.696234226226807
grad AddEdge W: 8.40441230979649e-16
grad ChooseDest W: 5.668521404266357
grad AddEdge W: 4.102695559584507e-14
grad ChooseDest W: 5.920968532562256
grad AddEdge W: 1.6356531472132285e-13
grad ChooseDest W: 3.8913121223449707
grad AddEdge W: 4.499444971515254e-17
grad ChooseDest W: 1.3767443895339966
grad AddEdge W: 4.7435787266319093e-17
grad ChooseDest W: 3.2136070728302
grad AddEdge W: 2.5691064943836328e-14
grad ChooseDest W: 3.913003444671631
grad AddEdge W: 9.777687768938574e-16
grad ChooseDest W: 5.010987281799316
grad AddEdge W: 6.767586784280966e-17
grad ChooseDest W: 3.9678537845611572
grad AddEdge W: 1.0287700494282254e-14
grad ChooseDest W: 3.142770528793335
grad AddEdge W: 1.5339264147068432e-12
grad ChooseDest W: 5.375494956970215
grad AddEdge W: 5.0640003665001695e-14
grad ChooseDest W: 5.221273422241211
grad AddEdge W: 2.056560928769425e-14
grad ChooseDest W: 5.052367210388184
grad AddEdge W: 1.0742124353121767e-14
grad ChooseDest W: 5.096525192260742
grad AddEdge W: 6.808182955860497e-16
grad ChooseDest W: 2.1796038150787354
grad AddEdge W: 6.33115358760378e-16
grad ChooseDest W: 1.7515428066253662
grad AddEdge W: 1.0164040672004941e-15
grad ChooseDest W: 6.421438217163086
grad AddEdge W: 1.0849180973056691e-17
grad ChooseDest W: 4.512974262237549
grad AddEdge W: 1.0491254131740708e-16
grad ChooseDest W: 3.443166971206665
grad AddEdge W: 4.129816254227667e-18
grad ChooseDest W: 4.13128662109375
grad AddEdge W: 1.0449206604146166e-12
grad ChooseDest W: 4.690287113189697
grad AddEdge W: 8.681707206274804e-17
grad ChooseDest W: 4.79666805267334
grad AddEdge W: 1.8003980431932713e-16
grad ChooseDest W: 6.405660152435303
grad AddEdge W: 2.756410315615759e-17
grad ChooseDest W: 12.254278182983398
grad AddEdge W: 3.640146590138017e-17
grad ChooseDest W: 4.700786113739014
grad AddEdge W: 1.4368251317137974e-17
grad ChooseDest W: 6.033160209655762
grad AddEdge W: 1.1119509718375553e-16
grad ChooseDest W: 5.3738694190979
grad AddEdge W: 3.822339737497722e-17
grad ChooseDest W: 5.0181097984313965
grad AddEdge W: 6.82794486979465e-15
grad ChooseDest W: 3.999497652053833
grad AddEdge W: 1.223047333434674e-17
grad ChooseDest W: 7.360630989074707
grad AddEdge W: 6.771036458307558e-17
grad ChooseDest W: 7.018550395965576
grad AddEdge W: 1.3699299966377847e-15
grad ChooseDest W: 3.8566179275512695
grad AddEdge W: 7.959758856889547e-18
grad ChooseDest W: 2.9430294036865234
grad AddEdge W: 2.682964452718808e-17
grad ChooseDest W: 2.995561122894287
grad AddEdge W: 3.0690865723942735e-17
grad ChooseDest W: 4.415756702423096
grad AddEdge W: 5.089953540707336e-15
grad ChooseDest W: 4.209627151489258
grad AddEdge W: 4.9803561991250083e-17
grad ChooseDest W: 4.521714210510254
grad AddEdge W: 7.701118504498304e-18
grad ChooseDest W: 6.701298713684082
grad AddEdge W: 7.151820946926341e-18
grad ChooseDest W: 5.7751054763793945
grad AddEdge W: 2.1282561413240126e-17
grad ChooseDest W: 4.446751594543457
grad AddEdge W: 1.492978790522772e-15
grad ChooseDest W: 11.30053424835205
grad AddEdge W: 9.617599203652001e-18
grad ChooseDest W: 4.198011875152588
grad AddEdge W: 3.2166079480704506e-17
grad ChooseDest W: 5.382992267608643
grad AddEdge W: 1.7538230763206565e-17
grad ChooseDest W: 3.527035713195801
grad AddEdge W: 2.6901301529292324e-17
grad ChooseDest W: 9.075180053710938
grad AddEdge W: 2.7370633551815316e-16
grad ChooseDest W: 1.8984253406524658
grad AddEdge W: 2.796036237423989e-17
grad ChooseDest W: 6.114506721496582
grad AddEdge W: 3.0427107605101626e-17
grad ChooseDest W: 2.9713051319122314
grad AddEdge W: 2.721242731873067e-17
grad ChooseDest W: 11.043526649475098
grad AddEdge W: 9.863285080470051e-17
grad ChooseDest W: 5.5554704666137695
grad AddEdge W: 1.7434788849756604e-16
grad ChooseDest W: 7.163561820983887
grad AddEdge W: 4.375763396373064e-14
grad ChooseDest W: 1.9166597127914429
grad AddEdge W: 9.516491263018419e-17
grad ChooseDest W: 6.33454704284668
grad AddEdge W: 6.2393253395849e-18
grad ChooseDest W: 4.875657081604004
grad AddEdge W: 5.3714134437710877e-17
grad ChooseDest W: 2.9377665519714355
grad AddEdge W: 3.031258173614125e-15
grad ChooseDest W: 5.221296787261963
grad AddEdge W: 7.336641385347637e-17
grad ChooseDest W: 5.131906509399414
grad AddEdge W: 1.934727860097808e-15
grad ChooseDest W: 2.756502151489258
grad AddEdge W: 6.952965662259964e-15
grad ChooseDest W: 6.088194847106934
grad AddEdge W: 6.591695098827691e-14
grad ChooseDest W: 2.7565419673919678
grad AddEdge W: 1.2959128060474438e-14
grad ChooseDest W: 6.049442768096924
grad AddEdge W: 4.836682642665301e-15
grad ChooseDest W: 6.679147720336914
grad AddEdge W: 8.842904855326688e-18
grad ChooseDest W: 8.843330383300781
grad AddEdge W: 8.783137416475036e-17
grad ChooseDest W: 6.266465663909912
=== Epoch 49: Train Loss: 3.9923, Train Log Prob: 0.0520 ===
Total mismatches: 57623
Predicted valid destination but wrong order: 27607
Epoch 49: Validation Loss: 3.6242, Validation Log Prob: 0.0364
Epoch 49: Edge Precision: 0.3734, Recall: 0.3710, F1: 0.3721, Jaccard: 0.2471
Epoch 49: TP: 2.5995705082319254, FP: 4.376664280601289, FN: 4.421904080171797
Epoch 49: Current Learning Rate: 6e-05
[Epoch 49] ‚è±Ô∏è Total: 1938.58s | Current time: 2025-07-15 14:07:07 | üèãÔ∏è Train: 1696.08s | ‚úÖ Val: 242.50s
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:3638: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
grad AddEdge W: 1.8219466937203187e-14
grad ChooseDest W: 6.468258380889893
grad AddEdge W: 1.0725981387454757e-15
grad ChooseDest W: 3.273158311843872
grad AddEdge W: 2.229787432995099e-17
grad ChooseDest W: 4.385351181030273
grad AddEdge W: 3.740007804152359e-17
grad ChooseDest W: 6.899068832397461
grad AddEdge W: 5.002162003560886e-17
grad ChooseDest W: 4.319467067718506
grad AddEdge W: 4.970445979816582e-16
grad ChooseDest W: 3.4275829792022705
grad AddEdge W: 1.5941046247273645e-16
grad ChooseDest W: 6.24904203414917
grad AddEdge W: 1.127724948776917e-15
grad ChooseDest W: 7.6891703605651855
grad AddEdge W: 5.729802017304998e-17
grad ChooseDest W: 2.702345848083496
grad AddEdge W: 5.1295296199205763e-17
grad ChooseDest W: 8.08586597442627
grad AddEdge W: 5.937871690331076e-17
grad ChooseDest W: 7.032354831695557
grad AddEdge W: 1.6389642506201158e-17
grad ChooseDest W: 11.781318664550781
grad AddEdge W: 3.145436666421898e-17
grad ChooseDest W: 4.296627998352051
grad AddEdge W: 1.1669509386851452e-15
grad ChooseDest W: 3.914290428161621
grad AddEdge W: 3.975583879523786e-17
grad ChooseDest W: 7.075864791870117
grad AddEdge W: 3.9798862113257967e-17
grad ChooseDest W: 3.7897560596466064
grad AddEdge W: 1.6902799748717292e-15
grad ChooseDest W: 3.406402826309204
grad AddEdge W: 3.304123987750806e-17
grad ChooseDest W: 5.984421253204346
grad AddEdge W: 2.2359322268935103e-17
grad ChooseDest W: 4.737843990325928
grad AddEdge W: 1.4191000739374396e-16
grad ChooseDest W: 3.001835823059082
grad AddEdge W: 1.6999091512952345e-15
grad ChooseDest W: 3.355929136276245
grad AddEdge W: 3.4540919386857882e-15
grad ChooseDest W: 3.9080657958984375
grad AddEdge W: 4.4797411984519956e-17
grad ChooseDest W: 4.172242164611816
grad AddEdge W: 1.1491514942106617e-15
grad ChooseDest W: 3.2763261795043945
grad AddEdge W: 4.189980160746915e-17
grad ChooseDest W: 7.568325996398926
grad AddEdge W: 7.943322513420323e-15
grad ChooseDest W: 2.839808464050293
grad AddEdge W: 1.8606370742557515e-17
grad ChooseDest W: 5.525294303894043
grad AddEdge W: 1.9002015530880813e-16
grad ChooseDest W: 6.914064884185791
grad AddEdge W: 7.060534611396524e-15
grad ChooseDest W: 5.844847202301025
grad AddEdge W: 2.7566445864001237e-15
grad ChooseDest W: 3.0036537647247314
grad AddEdge W: 3.323232190773026e-17
grad ChooseDest W: 3.4782049655914307
grad AddEdge W: 2.717288312236696e-16
grad ChooseDest W: 3.6219282150268555
grad AddEdge W: 1.0501128186712753e-17
grad ChooseDest W: 6.547135353088379
grad AddEdge W: 7.024337823065914e-16
grad ChooseDest W: 5.629469394683838
grad AddEdge W: 3.639843299403341e-15
grad ChooseDest W: 2.1339759826660156
grad AddEdge W: 2.7396187477042794e-16
grad ChooseDest W: 7.057982444763184
grad AddEdge W: 2.9535596296042512e-15
grad ChooseDest W: 6.869146823883057
grad AddEdge W: 1.491714127980874e-14
grad ChooseDest W: 3.2387008666992188
grad AddEdge W: 1.9202683591785767e-18
grad ChooseDest W: 4.329364776611328
grad AddEdge W: 1.1958236448790841e-15
grad ChooseDest W: 6.9677863121032715
grad AddEdge W: 6.05866851477689e-17
grad ChooseDest W: 4.750736713409424
grad AddEdge W: 1.1865254895931103e-17
grad ChooseDest W: 6.565643787384033
grad AddEdge W: 1.2102050996531596e-14
grad ChooseDest W: 3.695068120956421
grad AddEdge W: 3.515726663787244e-13
grad ChooseDest W: 2.100823402404785
grad AddEdge W: 2.1915709078366508e-15
grad ChooseDest W: 4.60410737991333
grad AddEdge W: 2.1209202073435248e-17
grad ChooseDest W: 5.779979228973389
grad AddEdge W: 3.405522434215516e-16
grad ChooseDest W: 5.663938522338867
grad AddEdge W: 4.8402949999573245e-17
grad ChooseDest W: 7.99667501449585
grad AddEdge W: 3.652079497654707e-17
grad ChooseDest W: 5.9820027351379395
grad AddEdge W: 7.866066590447504e-18
grad ChooseDest W: 6.953791618347168
grad AddEdge W: 1.8433980148677706e-15
grad ChooseDest W: 3.966494083404541
grad AddEdge W: 3.2800586435187884e-15
grad ChooseDest W: 6.137832164764404
grad AddEdge W: 5.7584707738471056e-18
grad ChooseDest W: 6.062981128692627
grad AddEdge W: 9.413137361585634e-17
grad ChooseDest W: 6.222347259521484
grad AddEdge W: 4.567178490538036e-17
grad ChooseDest W: 5.095276355743408
grad AddEdge W: 6.363203990838903e-17
grad ChooseDest W: 6.070637226104736
grad AddEdge W: 1.3005381095270092e-17
grad ChooseDest W: 6.312171459197998
grad AddEdge W: 1.564121610540808e-17
grad ChooseDest W: 3.5180118083953857
grad AddEdge W: 4.058104740921056e-17
grad ChooseDest W: 4.50332498550415
grad AddEdge W: 2.367699947803615e-17
grad ChooseDest W: 3.9687678813934326
grad AddEdge W: 1.3760729177992893e-16
grad ChooseDest W: 5.453707218170166
grad AddEdge W: 1.67184340915498e-13
grad ChooseDest W: 5.325300216674805
grad AddEdge W: 2.6037787835513517e-17
grad ChooseDest W: 4.275902271270752
grad AddEdge W: 1.1934341847872144e-17
grad ChooseDest W: 5.593113899230957
grad AddEdge W: 1.5863188037553214e-16
grad ChooseDest W: 5.423968315124512
grad AddEdge W: 7.542947509307752e-17
grad ChooseDest W: 7.443318843841553
=== Epoch 50: Train Loss: 3.9627, Train Log Prob: 0.0527 ===
Total mismatches: 57134
Predicted valid destination but wrong order: 27595
Epoch 50: Validation Loss: 3.5938, Validation Log Prob: 0.0373
Epoch 50: Edge Precision: 0.3766, Recall: 0.3739, F1: 0.3751, Jaccard: 0.2495
Epoch 50: TP: 2.619040801717967, FP: 4.352326413743737, FN: 4.402433786685755
Epoch 50: Current Learning Rate: 6e-05
üíæ Checkpoint saved: /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/checkpoint_epoch_50.pth
[Epoch 50] ‚è±Ô∏è Total: 1861.20s | Current time: 2025-07-15 14:38:08 | üèãÔ∏è Train: 1618.43s | ‚úÖ Val: 242.77s
Training finished at: 2025-07-15 14:38:08
Training time: 97543.77613210678
‚úÖ Model saved to: /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/model.pth
üìà Metrics saved to: /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.FIXED
Device for model: cuda:4

Epoch-wise Validation Metrics:

Epoch 1:
  Validation Loss: 6.5919, Validation Log Prob: 0.0023
  Edge Precision: 0.3717, Recall: 0.3709, F1: 0.3712, Jaccard: 0.2461
  TP: 2.5954187544738727, FP: 4.41159627773801, FN: 4.4260558339298495

Epoch 2:
  Validation Loss: 6.4952, Validation Log Prob: 0.0026
  Edge Precision: 0.3865, Recall: 0.3861, F1: 0.3862, Jaccard: 0.2588
  TP: 2.7047959914101645, FP: 4.310665712240516, FN: 4.316678596993557

Epoch 3:
  Validation Loss: 6.1395, Validation Log Prob: 0.0036
  Edge Precision: 0.3885, Recall: 0.3880, F1: 0.3883, Jaccard: 0.2609
  TP: 2.7175375805297066, FP: 4.295919828203293, FN: 4.303937007874016

Epoch 4:
  Validation Loss: 5.8290, Validation Log Prob: 0.0048
  Edge Precision: 0.3890, Recall: 0.3884, F1: 0.3887, Jaccard: 0.2610
  TP: 2.7211166785969936, FP: 4.290622763063708, FN: 4.300357909806729

Epoch 5:
  Validation Loss: 5.7733, Validation Log Prob: 0.0051
  Edge Precision: 0.3937, Recall: 0.3932, F1: 0.3934, Jaccard: 0.2654
  TP: 2.755762347888332, FP: 4.258554044380816, FN: 4.26571224051539

Epoch 6:
  Validation Loss: 5.6883, Validation Log Prob: 0.0056
  Edge Precision: 0.3972, Recall: 0.3967, F1: 0.3969, Jaccard: 0.2683
  TP: 2.7808160343593413, FP: 4.234073013600573, FN: 4.240658554044381

Epoch 7:
  Validation Loss: 5.6416, Validation Log Prob: 0.0059
  Edge Precision: 0.3957, Recall: 0.3952, F1: 0.3954, Jaccard: 0.2664
  TP: 2.7696492483894057, FP: 4.2446671438797425, FN: 4.2518253400143164

Epoch 8:
  Validation Loss: 5.5350, Validation Log Prob: 0.0065
  Edge Precision: 0.3954, Recall: 0.3947, F1: 0.3950, Jaccard: 0.2669
  TP: 2.7675017895490335, FP: 4.243664996420902, FN: 4.253972798854688

Epoch 9:
  Validation Loss: 5.4975, Validation Log Prob: 0.0067
  Edge Precision: 0.3956, Recall: 0.3948, F1: 0.3952, Jaccard: 0.2664
  TP: 2.767072297780959, FP: 4.241660701503221, FN: 4.254402290622763

Epoch 10:
  Validation Loss: 5.4824, Validation Log Prob: 0.0068
  Edge Precision: 0.3948, Recall: 0.3943, F1: 0.3945, Jaccard: 0.2660
  TP: 2.7627773801002147, FP: 4.250536864710093, FN: 4.2586972083035075

Epoch 11:
  Validation Loss: 5.4076, Validation Log Prob: 0.0073
  Edge Precision: 0.3944, Recall: 0.3938, F1: 0.3941, Jaccard: 0.2660
  TP: 2.760200429491768, FP: 4.251109520400859, FN: 4.261274158911954

Epoch 12:
  Validation Loss: 5.4308, Validation Log Prob: 0.0072
  Edge Precision: 0.3973, Recall: 0.3965, F1: 0.3969, Jaccard: 0.2685
  TP: 2.7802433786685756, FP: 4.228203292770222, FN: 4.241231209735147

Epoch 13:
  Validation Loss: 5.3034, Validation Log Prob: 0.0082
  Edge Precision: 0.3946, Recall: 0.3940, F1: 0.3943, Jaccard: 0.2664
  TP: 2.7614889047959914, FP: 4.24924838940587, FN: 4.259985683607731

Epoch 14:
  Validation Loss: 5.2743, Validation Log Prob: 0.0083
  Edge Precision: 0.3946, Recall: 0.3936, F1: 0.3940, Jaccard: 0.2661
  TP: 2.7579098067287044, FP: 4.247530422333572, FN: 4.263564781675018

Epoch 15:
  Validation Loss: 5.2279, Validation Log Prob: 0.0086
  Edge Precision: 0.3940, Recall: 0.3931, F1: 0.3935, Jaccard: 0.2660
  TP: 2.7543307086614175, FP: 4.251682176091625, FN: 4.267143879742305

Epoch 16:
  Validation Loss: 5.1532, Validation Log Prob: 0.0090
  Edge Precision: 0.3963, Recall: 0.3954, F1: 0.3958, Jaccard: 0.2675
  TP: 2.7712240515390123, FP: 4.2342161775232645, FN: 4.25025053686471

Epoch 17:
  Validation Loss: 5.0753, Validation Log Prob: 0.0098
  Edge Precision: 0.3950, Recall: 0.3941, F1: 0.3945, Jaccard: 0.2662
  TP: 2.7626342161775232, FP: 4.242233357193987, FN: 4.258840372226199

Epoch 18:
  Validation Loss: 5.1047, Validation Log Prob: 0.0098
  Edge Precision: 0.3962, Recall: 0.3952, F1: 0.3956, Jaccard: 0.2676
  TP: 2.7705082319255547, FP: 4.234931997136721, FN: 4.250966356478168

Epoch 19:
  Validation Loss: 4.9734, Validation Log Prob: 0.0107
  Edge Precision: 0.3947, Recall: 0.3936, F1: 0.3941, Jaccard: 0.2658
  TP: 2.7586256263421616, FP: 4.241947029348604, FN: 4.26284896206156

Epoch 20:
  Validation Loss: 4.9759, Validation Log Prob: 0.0107
  Edge Precision: 0.3921, Recall: 0.3909, F1: 0.3914, Jaccard: 0.2636
  TP: 2.7395848246241945, FP: 4.260844667143879, FN: 4.281889763779527

Epoch 21:
  Validation Loss: 4.8548, Validation Log Prob: 0.0119
  Edge Precision: 0.3920, Recall: 0.3909, F1: 0.3914, Jaccard: 0.2634
  TP: 2.740586972083035, FP: 4.260987831066571, FN: 4.280887616320687

Epoch 22:
  Validation Loss: 4.8338, Validation Log Prob: 0.0122
  Edge Precision: 0.3917, Recall: 0.3904, F1: 0.3910, Jaccard: 0.2630
  TP: 2.7360057265569075, FP: 4.263421617752327, FN: 4.285468861846814

Epoch 23:
  Validation Loss: 4.8292, Validation Log Prob: 0.0122
  Edge Precision: 0.3898, Recall: 0.3885, F1: 0.3891, Jaccard: 0.2617
  TP: 2.7222619899785254, FP: 4.276735862562634, FN: 4.299212598425197

Epoch 24:
  Validation Loss: 4.7617, Validation Log Prob: 0.0131
  Edge Precision: 0.3898, Recall: 0.3884, F1: 0.3890, Jaccard: 0.2616
  TP: 2.7225483178239083, FP: 4.275161059413028, FN: 4.2989262705798135

Epoch 25:
  Validation Loss: 4.6886, Validation Log Prob: 0.0138
  Edge Precision: 0.3906, Recall: 0.3893, F1: 0.3899, Jaccard: 0.2624
  TP: 2.7294201861130993, FP: 4.268432355046528, FN: 4.292054402290622

Epoch 26:
  Validation Loss: 4.6525, Validation Log Prob: 0.0144
  Edge Precision: 0.3865, Recall: 0.3849, F1: 0.3857, Jaccard: 0.2583
  TP: 2.697494631352899, FP: 4.296349319971367, FN: 4.323979957050823

Epoch 27:
  Validation Loss: 4.5932, Validation Log Prob: 0.0152
  Edge Precision: 0.3868, Recall: 0.3849, F1: 0.3858, Jaccard: 0.2588
  TP: 2.6990694345025052, FP: 4.288188976377953, FN: 4.322405153901217

Epoch 28:
  Validation Loss: 4.4945, Validation Log Prob: 0.0164
  Edge Precision: 0.3836, Recall: 0.3820, F1: 0.3828, Jaccard: 0.2556
  TP: 2.677165354330709, FP: 4.314101646385111, FN: 4.344309234073013

Epoch 29:
  Validation Loss: 4.4597, Validation Log Prob: 0.0170
  Edge Precision: 0.3836, Recall: 0.3818, F1: 0.3826, Jaccard: 0.2561
  TP: 2.6758768790264855, FP: 4.315103793843951, FN: 4.345597709377237

Epoch 30:
  Validation Loss: 4.4136, Validation Log Prob: 0.0176
  Edge Precision: 0.3846, Recall: 0.3825, F1: 0.3835, Jaccard: 0.2564
  TP: 2.681746599856836, FP: 4.305368647100931, FN: 4.339727988546886

Epoch 31:
  Validation Loss: 4.3506, Validation Log Prob: 0.0188
  Edge Precision: 0.3856, Recall: 0.3839, F1: 0.3847, Jaccard: 0.2574
  TP: 2.6911954187544738, FP: 4.3006442376521115, FN: 4.330279169649248

Epoch 32:
  Validation Loss: 4.3411, Validation Log Prob: 0.0191
  Edge Precision: 0.3826, Recall: 0.3808, F1: 0.3816, Jaccard: 0.2549
  TP: 2.6692913385826773, FP: 4.319112383679313, FN: 4.352183249821045

Epoch 33:
  Validation Loss: 4.2896, Validation Log Prob: 0.0199
  Edge Precision: 0.3818, Recall: 0.3793, F1: 0.3805, Jaccard: 0.2538
  TP: 2.6586972083035074, FP: 4.320257695060844, FN: 4.362777380100215

Epoch 34:
  Validation Loss: 4.1799, Validation Log Prob: 0.0220
  Edge Precision: 0.3847, Recall: 0.3825, F1: 0.3835, Jaccard: 0.2564
  TP: 2.6807444523979957, FP: 4.299355762347888, FN: 4.340730136005726

Epoch 35:
  Validation Loss: 4.1700, Validation Log Prob: 0.0220
  Edge Precision: 0.3818, Recall: 0.3798, F1: 0.3807, Jaccard: 0.2546
  TP: 2.660987831066571, FP: 4.323836793128132, FN: 4.360486757337151

Epoch 36:
  Validation Loss: 4.0889, Validation Log Prob: 0.0238
  Edge Precision: 0.3810, Recall: 0.3789, F1: 0.3799, Jaccard: 0.2537
  TP: 2.65411596277738, FP: 4.327702219040802, FN: 4.367358625626342

Epoch 37:
  Validation Loss: 4.0681, Validation Log Prob: 0.0243
  Edge Precision: 0.3825, Recall: 0.3804, F1: 0.3814, Jaccard: 0.2543
  TP: 2.6655690765926985, FP: 4.3195418754473875, FN: 4.355905511811024

Epoch 38:
  Validation Loss: 4.0267, Validation Log Prob: 0.0252
  Edge Precision: 0.3816, Recall: 0.3793, F1: 0.3803, Jaccard: 0.2537
  TP: 2.657695060844667, FP: 4.324123120973515, FN: 4.363779527559055

Epoch 39:
  Validation Loss: 3.9838, Validation Log Prob: 0.0263
  Edge Precision: 0.3806, Recall: 0.3783, F1: 0.3794, Jaccard: 0.2528
  TP: 2.6503937007874017, FP: 4.3301360057265565, FN: 4.371080887616321

Epoch 40:
  Validation Loss: 3.9208, Validation Log Prob: 0.0278
  Edge Precision: 0.3765, Recall: 0.3741, F1: 0.3752, Jaccard: 0.2496
  TP: 2.6223335719398713, FP: 4.356907659269864, FN: 4.399141016463851

Epoch 41:
  Validation Loss: 3.9198, Validation Log Prob: 0.0278
  Edge Precision: 0.3792, Recall: 0.3768, F1: 0.3779, Jaccard: 0.2517
  TP: 2.640372226198998, FP: 4.337866857551897, FN: 4.381102362204724

Epoch 42:
  Validation Loss: 3.8335, Validation Log Prob: 0.0302
  Edge Precision: 0.3782, Recall: 0.3757, F1: 0.3768, Jaccard: 0.2513
  TP: 2.6329277022190407, FP: 4.34201861130995, FN: 4.388546886184681

Epoch 43:
  Validation Loss: 3.8416, Validation Log Prob: 0.0299
  Edge Precision: 0.3764, Recall: 0.3737, F1: 0.3750, Jaccard: 0.2495
  TP: 2.619040801717967, FP: 4.354760200429491, FN: 4.402433786685755

Epoch 44:
  Validation Loss: 3.8376, Validation Log Prob: 0.0300
  Edge Precision: 0.3793, Recall: 0.3767, F1: 0.3779, Jaccard: 0.2516
  TP: 2.641088045812455, FP: 4.336148890479599, FN: 4.380386542591267

Epoch 45:
  Validation Loss: 3.7008, Validation Log Prob: 0.0337
  Edge Precision: 0.3783, Recall: 0.3757, F1: 0.3769, Jaccard: 0.2515
  TP: 2.632641374373658, FP: 4.341302791696492, FN: 4.388833214030065

Epoch 46:
  Validation Loss: 3.7191, Validation Log Prob: 0.0333
  Edge Precision: 0.3761, Recall: 0.3738, F1: 0.3748, Jaccard: 0.2494
  TP: 2.6197566213314243, FP: 4.360629921259843, FN: 4.4017179670722975

Epoch 47:
  Validation Loss: 3.6624, Validation Log Prob: 0.0350
  Edge Precision: 0.3777, Recall: 0.3751, F1: 0.3763, Jaccard: 0.2501
  TP: 2.629062276306371, FP: 4.34688618468146, FN: 4.392412312097352

Epoch 48:
  Validation Loss: 3.6810, Validation Log Prob: 0.0346
  Edge Precision: 0.3773, Recall: 0.3744, F1: 0.3757, Jaccard: 0.2500
  TP: 2.624051539012169, FP: 4.345597709377237, FN: 4.397423049391553

Epoch 49:
  Validation Loss: 3.6242, Validation Log Prob: 0.0364
  Edge Precision: 0.3734, Recall: 0.3710, F1: 0.3721, Jaccard: 0.2471/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4434: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4449: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))

  TP: 2.5995705082319254, FP: 4.376664280601289, FN: 4.421904080171797

Epoch 50:
  Validation Loss: 3.5938, Validation Log Prob: 0.0373
  Edge Precision: 0.3766, Recall: 0.3739, F1: 0.3751, Jaccard: 0.2495
  TP: 2.619040801717967, FP: 4.352326413743737, FN: 4.402433786685755
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.RANDOM

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 81.17%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 18.83%
  ‚ùå False Discovery rate (FP/TP+FP): 14.83%
  üéØ Precision (TP/TP+FP): 85.17%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 21.87%
  ‚ö†Ô∏è Std. False Negative rate: 21.87%
  ‚ùå Std. False Discovery rate: 17.78%
  üéØ Std. Precision: 17.78%
üìâ  Average detailed edge-metrics
  F1: 0.83
  Jaccard: 0.76
  TP: 4.65
  FP: 0.75
  FN: 1.10

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 53.43%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 46.57%
  ‚ùå False Discovery rate (FP/TP+FP): 43.70%
  üéØ Precision (TP/TP+FP): 56.30%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 21.75%
  ‚ö†Ô∏è Std. False Negative rate: 21.75%
  ‚ùå Std. False Discovery rate: 22.07%
  üéØ Std. Precision: 22.07%
üìâ  Average detailed edge-metrics
  F1: 0.55
  Jaccard: 0.41
  TP: 3.27
  FP: 2.46
  FN: 2.77

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 45.89%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 54.11%
  ‚ùå False Discovery rate (FP/TP+FP): 52.54%
  üéØ Precision (TP/TP+FP): 47.46%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 19.53%
  ‚ö†Ô∏è Std. False Negative rate: 19.53%
  ‚ùå Std. False Discovery rate: 19.74%
  üéØ Std. Precision: 19.74%
üìâ  Average detailed edge-metrics
  F1: 0.47
  Jaccard: 0.33
  TP: 3.01
  FP: 3.30
  FN: 3.53

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 37.65%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 62.35%
  ‚ùå False Discovery rate (FP/TP+FP): 61.55%
  üéØ Precision (TP/TP+FP): 38.45%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.02%
  ‚ö†Ô∏è Std. False Negative rate: 18.02%
  ‚ùå Std. False Discovery rate: 18.32%
  üéØ Std. Precision: 18.32%
üìâ  Average detailed edge-metrics
  F1: 0.38
  Jaccard: 0.25
  TP: 2.64
  FP: 4.22
  FN: 4.37

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 31.82%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 68.18%
  ‚ùå False Discovery rate (FP/TP+FP): 67.83%
  üéØ Precision (TP/TP+FP): 32.17%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.15%
  ‚ö†Ô∏è Std. False Negative rate: 17.15%
  ‚ùå Std. False Discovery rate: 17.29%
  üéØ Std. Precision: 17.29%
üìâ  Average detailed edge-metrics
  F1: 0.32
  Jaccard: 0.20
  TP: 2.27
  FP: 4.77
  FN: 4.85

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 35.30%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 64.70%
  ‚ùå False Discovery rate (FP/TP+FP): 64.03%
  üéØ Precision (TP/TP+FP): 35.97%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.47%
  ‚ö†Ô∏è Std. False Negative rate: 18.47%
  ‚ùå Std. False Discovery rate: 18.80%
  üéØ Std. Precision: 18.80%
üìâ  Average detailed edge-metrics
  F1: 0.36
  Jaccard: 0.23
  TP: 2.47
  FP: 4.42
  FN: 4.55
[6, 7, 8, 9, 10, 999]
[0.8116666666666668, 0.5342937174869948, 0.4588966318234611, 0.37652232432934185, 0.31815945184583777, 0.35295480110440736]
[np.float64(0.17778732613247025), np.float64(0.22068537657947157), np.float64(0.19736551696553445), np.float64(0.183187991494171), np.float64(0.17290663574943765), np.float64(0.1879811874228284)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.FIXED

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 73.83%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 26.17%
  ‚ùå False Discovery rate (FP/TP+FP): 20.58%
  üéØ Precision (TP/TP+FP): 79.42%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 20.47%
  ‚ö†Ô∏è Std. False Negative rate: 20.47%
  ‚ùå Std. False Discovery rate: 17.85%
  üéØ Std. Precision: 17.85%
üìâ  Average detailed edge-metrics
  F1: 0.76
  Jaccard: 0.66
  TP: 4.25
  FP: 1.05
  FN: 1.50

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 62.27%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 37.73%
  ‚ùå False Discovery rate (FP/TP+FP): 36.51%
  üéØ Precision (TP/TP+FP): 63.49%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 21.85%
  ‚ö†Ô∏è Std. False Negative rate: 21.85%
  ‚ùå Std. False Discovery rate: 21.67%
  üéØ Std. Precision: 21.67%
üìâ  Average detailed edge-metrics
  F1: 0.63
  Jaccard: 0.50
  TP: 3.78
  FP: 2.14
  FN: 2.26

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 47.41%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 52.59%
  ‚ùå False Discovery rate (FP/TP+FP): 52.00%
  üéØ Precision (TP/TP+FP): 48.00%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.10%
  ‚ö†Ô∏è Std. False Negative rate: 18.10%
  ‚ùå Std. False Discovery rate: 18.26%
  üéØ Std. Precision: 18.26%
üìâ  Average detailed edge-metrics
  F1: 0.48
  Jaccard: 0.33
  TP: 3.11
  FP: 3.34
  FN: 3.42

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 40.08%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 59.92%
  ‚ùå False Discovery rate (FP/TP+FP): 59.60%
  üéØ Precision (TP/TP+FP): 40.40%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.49%
  ‚ö†Ô∏è Std. False Negative rate: 18.49%
  ‚ùå Std. False Discovery rate: 18.53%
  üéØ Std. Precision: 18.53%
üìâ  Average detailed edge-metrics
  F1: 0.40
  Jaccard: 0.27
  TP: 2.82
  FP: 4.14
  FN: 4.20

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 33.59%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 66.41%
  ‚ùå False Discovery rate (FP/TP+FP): 66.27%
  üéØ Precision (TP/TP+FP): 33.73%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.81%
  ‚ö†Ô∏è Std. False Negative rate: 17.81%
  ‚ùå Std. False Discovery rate: 17.84%
  üéØ Std. Precision: 17.84%
üìâ  Average detailed edge-metrics
  F1: 0.34
  Jaccard: 0.22
  TP: 2.39
  FP: 4.69
  FN: 4.72

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 37.39%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 62.61%
  ‚ùå False Discovery rate (FP/TP+FP): 62.34%
  üéØ Precision (TP/TP+FP): 37.66%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.99%
  ‚ö†Ô∏è Std. False Negative rate: 18.99%
  ‚ùå Std. False Discovery rate: 19.10%
  üéØ Std. Precision: 19.10%
üìâ  Average detailed edge-metrics
  F1: 0.38
  Jaccard: 0.25
  TP: 2.62
  FP: 4.35
  FN: 4.40
[6, 7, 8, 9, 10, 999]
[0.7383333333333333, 0.622689075630252, 0.4740998838559814, 0.40076348278102664, 0.3359104943966737, 0.37387479974094145]
[np.float64(0.17851820635442203), np.float64(0.21668779238092215), np.float64(0.18255012592422978), np.float64(0.18534240231670274), np.float64(0.17842637297028416), np.float64(0.19104620530360159)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_ASC

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 77.17%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 22.83%
  ‚ùå False Discovery rate (FP/TP+FP): 16.33%
  üéØ Precision (TP/TP+FP): 83.67%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 19.70%
  ‚ö†Ô∏è Std. False Negative rate: 19.70%
  ‚ùå Std. False Discovery rate: 15.23%
  üéØ Std. Precision: 15.23%
üìâ  Average detailed edge-metrics
  F1: 0.80
  Jaccard: 0.70
  TP: 4.45
  FP: 0.80/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4477: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4491: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))

  FN: 1.30

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 58.06%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 41.94%
  ‚ùå False Discovery rate (FP/TP+FP): 39.86%
  üéØ Precision (TP/TP+FP): 60.14%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 23.35%
  ‚ö†Ô∏è Std. False Negative rate: 23.35%
  ‚ùå Std. False Discovery rate: 22.97%
  üéØ Std. Precision: 22.97%
üìâ  Average detailed edge-metrics
  F1: 0.59
  Jaccard: 0.46
  TP: 3.54
  FP: 2.27
  FN: 2.50

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 46.16%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 53.84%
  ‚ùå False Discovery rate (FP/TP+FP): 51.68%
  üéØ Precision (TP/TP+FP): 48.32%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 20.32%
  ‚ö†Ô∏è Std. False Negative rate: 20.32%
  ‚ùå Std. False Discovery rate: 20.88%
  üéØ Std. Precision: 20.88%
üìâ  Average detailed edge-metrics
  F1: 0.47
  Jaccard: 0.33
  TP: 3.03
  FP: 3.20
  FN: 3.50

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 37.68%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 62.32%
  ‚ùå False Discovery rate (FP/TP+FP): 60.92%
  üéØ Precision (TP/TP+FP): 39.08%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.90%
  ‚ö†Ô∏è Std. False Negative rate: 18.90%
  ‚ùå Std. False Discovery rate: 19.33%
  üéØ Std. Precision: 19.33%
üìâ  Average detailed edge-metrics
  F1: 0.38
  Jaccard: 0.26
  TP: 2.64
  FP: 4.10
  FN: 4.37

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 31.44%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 68.56%
  ‚ùå False Discovery rate (FP/TP+FP): 67.80%
  üéØ Precision (TP/TP+FP): 32.20%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.73%
  ‚ö†Ô∏è Std. False Negative rate: 17.73%
  ‚ùå Std. False Discovery rate: 18.01%
  üéØ Std. Precision: 18.01%
üìâ  Average detailed edge-metrics
  F1: 0.32
  Jaccard: 0.20
  TP: 2.24
  FP: 4.70
  FN: 4.88

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 35.18%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 64.82%
  ‚ùå False Discovery rate (FP/TP+FP): 63.71%
  üéØ Precision (TP/TP+FP): 36.29%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 19.26%
  ‚ö†Ô∏è Std. False Negative rate: 19.26%
  ‚ùå Std. False Discovery rate: 19.72%
  üéØ Std. Precision: 19.72%
üìâ  Average detailed edge-metrics
  F1: 0.36
  Jaccard: 0.24
  TP: 2.46
  FP: 4.34
  FN: 4.56
[6, 7, 8, 9, 10, 999]
[0.7716666666666667, 0.5805922368947579, 0.46160278745644595, 0.37681472199016053, 0.314387509072345, 0.3517973889627433]
[np.float64(0.15226074127408332), np.float64(0.22974020458856054), np.float64(0.20880194808263325), np.float64(0.19325173775027132), np.float64(0.18007050313213507), np.float64(0.19718718745666186)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_DESC

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 80.83%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 19.17%
  ‚ùå False Discovery rate (FP/TP+FP): 16.50%
  üéØ Precision (TP/TP+FP): 83.50%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 20.16%
  ‚ö†Ô∏è Std. False Negative rate: 20.16%
  ‚ùå Std. False Discovery rate: 18.96%
  üéØ Std. Precision: 18.96%
üìâ  Average detailed edge-metrics
  F1: 0.82
  Jaccard: 0.74
  TP: 4.65
  FP: 0.90
  FN: 1.10

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 59.30%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 40.70%
  ‚ùå False Discovery rate (FP/TP+FP): 39.85%
  üéØ Precision (TP/TP+FP): 60.15%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 22.38%
  ‚ö†Ô∏è Std. False Negative rate: 22.38%
  ‚ùå Std. False Discovery rate: 22.41%
  üéØ Std. Precision: 22.41%
üìâ  Average detailed edge-metrics
  F1: 0.60
  Jaccard: 0.47
  TP: 3.61
  FP: 2.34
  FN: 2.43

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 47.17%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 52.83%
  ‚ùå False Discovery rate (FP/TP+FP): 52.43%
  üéØ Precision (TP/TP+FP): 47.57%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.84%
  ‚ö†Ô∏è Std. False Negative rate: 18.84%
  ‚ùå Std. False Discovery rate: 18.88%
  üéØ Std. Precision: 18.88%
üìâ  Average detailed edge-metrics
  F1: 0.47
  Jaccard: 0.33
  TP: 3.09
  FP: 3.39
  FN: 3.44

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 39.97%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 60.03%
  ‚ùå False Discovery rate (FP/TP+FP): 59.88%
  üéØ Precision (TP/TP+FP): 40.12%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.85%
  ‚ö†Ô∏è Std. False Negative rate: 17.85%
  ‚ùå Std. False Discovery rate: 17.89%
  üéØ Std. Precision: 17.89%
üìâ  Average detailed edge-metrics
  F1: 0.40
  Jaccard: 0.27
  TP: 2.81
  FP: 4.18
  FN: 4.21

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 33.03%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 66.97%
  ‚ùå False Discovery rate (FP/TP+FP): 66.92%
  üéØ Precision (TP/TP+FP): 33.08%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.16%
  ‚ö†Ô∏è Std. False Negative rate: 17.16%
  ‚ùå Std. False Discovery rate: 17.18%
  üéØ Std. Precision: 17.18%
üìâ  Average detailed edge-metrics
  F1: 0.33
  Jaccard: 0.21
  TP: 2.35
  FP: 4.75
  FN: 4.76

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 36.99%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 63.01%
  ‚ùå False Discovery rate (FP/TP+FP): 62.88%
  üéØ Precision (TP/TP+FP): 37.12%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.51%
  ‚ö†Ô∏è Std. False Negative rate: 18.51%
  ‚ùå Std. False Discovery rate: 18.59%
  üéØ Std. Precision: 18.59%
üìâ  Average detailed edge-metrics
  F1: 0.37
  Jaccard: 0.24
  TP: 2.59
  FP: 4.41
  FN: 4.43
[6, 7, 8, 9, 10, 999]
[0.8083333333333333, 0.5929571828731492, 0.4717305458768873, 0.3996519075466444, 0.3302902535336015, 0.3699067730170092]
[np.float64(0.18958287545732255), np.float64(0.2240645583492811), np.float64(0.18879597160991735), np.float64(0.17894243150828829), np.float64(0.17184788107693555), np.float64(0.1859323641627711)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.NEIGH_MIN_REM

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 79.33%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 20.67%
  ‚ùå False Discovery rate (FP/TP+FP): 16.50%
  üéØ Precision (TP/TP+FP): 83.50%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 23.28%
  ‚ö†Ô∏è Std. False Negative rate: 23.28%
  ‚ùå Std. False Discovery rate: 20.30%
  üéØ Std. Precision: 20.30%
üìâ  Average detailed edge-metrics
  F1: 0.81
  Jaccard: 0.73
  TP: 4.60
  FP: 0.80
  FN: 1.15

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 57.44%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 42.56%
  ‚ùå False Discovery rate (FP/TP+FP): 41.03%
  üéØ Precision (TP/TP+FP): 58.97%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 21.95%
  ‚ö†Ô∏è Std. False Negative rate: 21.95%
  ‚ùå Std. False Discovery rate: 21.83%
  üéØ Std. Precision: 21.83%
üìâ  Average detailed edge-metrics
  F1: 0.58
  Jaccard: 0.45
  TP: 3.50
  FP: 2.38
  FN: 2.55

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 46.13%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 53.87%
  ‚ùå False Discovery rate (FP/TP+FP): 52.29%
  üéØ Precision (TP/TP+FP): 47.71%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 20.16%
  ‚ö†Ô∏è Std. False Negative rate: 20.16%
  ‚ùå Std. False Discovery rate: 20.43%/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4505: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:4525: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5344: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5361: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5377: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5393: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5409: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5425: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))
/home/nschmitz/GNNs/MasterThesisGNN/DGMG/DGMG_current.py:5663: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loaded_model.load_state_dict(torch.load(load_model_path))

  üéØ Std. Precision: 20.43%
üìâ  Average detailed edge-metrics
  F1: 0.47
  Jaccard: 0.33
  TP: 3.03
  FP: 3.28
  FN: 3.50

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 38.15%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 61.85%
  ‚ùå False Discovery rate (FP/TP+FP): 60.73%
  üéØ Precision (TP/TP+FP): 39.27%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.36%
  ‚ö†Ô∏è Std. False Negative rate: 18.36%
  ‚ùå Std. False Discovery rate: 18.78%
  üéØ Std. Precision: 18.78%
üìâ  Average detailed edge-metrics
  F1: 0.39
  Jaccard: 0.26
  TP: 2.68
  FP: 4.14
  FN: 4.34

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 30.93%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 69.07%
  ‚ùå False Discovery rate (FP/TP+FP): 68.38%
  üéØ Precision (TP/TP+FP): 31.62%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 17.37%
  ‚ö†Ô∏è Std. False Negative rate: 17.37%
  ‚ùå Std. False Discovery rate: 17.64%
  üéØ Std. Precision: 17.64%
üìâ  Average detailed edge-metrics
  F1: 0.31
  Jaccard: 0.20
  TP: 2.20
  FP: 4.74
  FN: 4.91

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 35.06%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 64.94%
  ‚ùå False Discovery rate (FP/TP+FP): 64.01%
  üéØ Precision (TP/TP+FP): 35.99%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.95%
  ‚ö†Ô∏è Std. False Negative rate: 18.95%
  ‚ùå Std. False Discovery rate: 19.34%
  üéØ Std. Precision: 19.34%
üìâ  Average detailed edge-metrics
  F1: 0.35
  Jaccard: 0.23
  TP: 2.46
  FP: 4.38
  FN: 4.57
[6, 7, 8, 9, 10, 999]
[0.7933333333333333, 0.574389755902361, 0.46127758420441345, 0.3814513134688573, 0.30926701602883466, 0.3505995841428912]
[np.float64(0.20295730257043393), np.float64(0.2183473673534272), np.float64(0.20425083351792134), np.float64(0.1878405341674245), np.float64(0.17642651938917628), np.float64(0.19337135832170296)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.NEIGH_MAX_REM

Face Count 6: 20 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 77.50%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 22.50%
  ‚ùå False Discovery rate (FP/TP+FP): 17.83%
  üéØ Precision (TP/TP+FP): 82.17%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 19.46%
  ‚ö†Ô∏è Std. False Negative rate: 19.46%
  ‚ùå Std. False Discovery rate: 17.83%
  üéØ Std. Precision: 17.83%
üìâ  Average detailed edge-metrics
  F1: 0.80
  Jaccard: 0.70
  TP: 4.45
  FP: 0.95
  FN: 1.30

Face Count 7: 119 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 57.50%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 42.50%
  ‚ùå False Discovery rate (FP/TP+FP): 41.66%
  üéØ Precision (TP/TP+FP): 58.34%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 22.80%
  ‚ö†Ô∏è Std. False Negative rate: 22.80%
  ‚ùå Std. False Discovery rate: 22.84%
  üéØ Std. Precision: 22.84%
üìâ  Average detailed edge-metrics
  F1: 0.58
  Jaccard: 0.45
  TP: 3.50
  FP: 2.45
  FN: 2.54

Face Count 8: 410 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 46.31%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 53.69%
  ‚ùå False Discovery rate (FP/TP+FP): 53.18%
  üéØ Precision (TP/TP+FP): 46.82%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.03%
  ‚ö†Ô∏è Std. False Negative rate: 18.03%
  ‚ùå Std. False Discovery rate: 18.15%
  üéØ Std. Precision: 18.15%
üìâ  Average detailed edge-metrics
  F1: 0.47
  Jaccard: 0.32
  TP: 3.03
  FP: 3.44
  FN: 3.50

Face Count 9: 2565 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 39.40%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 60.60%
  ‚ùå False Discovery rate (FP/TP+FP): 60.45%
  üéØ Precision (TP/TP+FP): 39.55%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.13%
  ‚ö†Ô∏è Std. False Negative rate: 18.13%
  ‚ùå Std. False Discovery rate: 18.16%
  üéØ Std. Precision: 18.16%
üìâ  Average detailed edge-metrics
  F1: 0.39
  Jaccard: 0.26
  TP: 2.77
  FP: 4.22
  FN: 4.25

Face Count 10: 3871 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 32.65%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 67.35%
  ‚ùå False Discovery rate (FP/TP+FP): 67.27%
  üéØ Precision (TP/TP+FP): 32.73%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 16.95%
  ‚ö†Ô∏è Std. False Negative rate: 16.95%
  ‚ùå Std. False Discovery rate: 17.00%
  üéØ Std. Precision: 17.00%
üìâ  Average detailed edge-metrics
  F1: 0.33
  Jaccard: 0.21
  TP: 2.33
  FP: 4.77
  FN: 4.79

Face Count 999: 6985 graphs evaluated
üìâ  Average edge-level rates
  ‚úÖ Recall (TP/TP+FN): 36.48%
  ‚ö†Ô∏è False Negative rate (FN/TP+FN): 63.52%
  ‚ùå False Discovery rate (FP/TP+FP): 63.36%
  üéØ Precision (TP/TP+FP): 36.64%
üìä Standard Deviation Across Graphs:
  ‚úÖ Std. Recall: 18.39%
  ‚ö†Ô∏è Std. False Negative rate: 18.39%
  ‚ùå Std. False Discovery rate: 18.50%
  üéØ Std. Precision: 18.50%
üìâ  Average detailed edge-metrics
  F1: 0.37
  Jaccard: 0.24
  TP: 2.56
  FP: 4.44
  FN: 4.47
[6, 7, 8, 9, 10, 999]
[0.775, 0.575030012004802, 0.463089430894309, 0.3939640768588137, 0.32648909473373433, 0.3648034904727818]
[np.float64(0.17834890897713204), np.float64(0.22836811785685676), np.float64(0.1815068890964447), np.float64(0.181629878561857), np.float64(0.17000118075467097), np.float64(0.18495196003271785)]
‚úÖ Stats saved to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/metrics.json
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.FIXED
Device for model: cuda:4
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.RANDOM
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/random
0
0
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.FIXED
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/fixed
0
0
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_ASC
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/deg_asc
0
0
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.DEG_DESC
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/deg_desc
0
0
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.NEIGH_MIN_REM
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/neigh_min_rem
56666
5947
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.NEIGH_MAX_REM
‚úÖ  Reports written to /home/nschmitz/GNNs/MasterThesisGNN/SavedModels/18__constraints_fixed__trained_dgmg_model-path=6_7_8_9_10-n=3000-mf=50-node_hidden_size=128-num_prop_rounds=2-epochs=50-lr=0.00006/reports/neigh_max_rem
56195
7045
DGMG-Model with constraints config:  True
DGMG-Model node ordering strategy:  NodeOrder.FIXED
Device for model: cuda:4
‚úÖ Code finished successfully at: 2025-07-15 16:02:59
